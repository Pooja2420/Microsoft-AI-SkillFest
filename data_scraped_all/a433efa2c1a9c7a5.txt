Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Quickstart: Use images in your AI chats
Article
2025-02-21
11 contributors
In this article
Get started using GPT-4 Turbo with images with the Azure OpenAI Service.
Note
Model choice
The latest vision-capable models aregpt-4oandgpt-4o mini. These models are in public preview. The latest available GA model isgpt-4versionturbo-2024-04-09.
gpt-4o
gpt-4o mini
gpt-4
turbo-2024-04-09
Important
Extra usage fees might apply when using chat completion models with vision functionality.
Use this article to get started usingAzure AI Foundryto deploy and test a chat completion model with image understanding.
Prerequisites
An Azure subscription.Create one for free.
Once you have your Azure subscription,create an Azure OpenAI resource.
For more information about resource creation, see theresource deployment guide.
AnAzure AI Foundry hubwith your Azure OpenAI resource added as a connection.
Prepare your media
You need an image to complete this quickstart. You can use this sample image or any other image you have available.

Go to Azure AI Foundry
Browse toAzure AI Foundryand sign in with the credentials associated with your Azure OpenAI resource. During or after the sign-in workflow, select the appropriate directory, Azure subscription, and Azure OpenAI resource.
Select the hub you'd like to work in.
On the left nav menu, selectModels + endpointsand select+ Deploy model.
Choose an image-capable deployment by selecting model name:gpt-4oorgpt-4o-mini. In the window that appears, select a name and deployment type. Make sure your Azure OpenAI resource is connected. For more information about model deployment, see theresource deployment guide.
SelectDeploy.
Next, select your new model and selectOpen in playground. In the chat playground, the deployment you created should be selected in theDeploymentdropdown.
Playground
In this chat session, you instruct the assistant to aid you in understanding images that you input.
For general help with assistant setup, chat sessions, settings, and panels, refer to theChat quickstart.
Start a chat session to analyze images
In this chat session, you're instructing the assistant to aid in understanding images that you input.
To start, make sure your image-capable deployment is selected in theDeploymentdropdown.
To start, make sure your image-capable deployment is selected in theDeploymentdropdown.
In the context text box on theSetuppanel, provide this prompt to guide the assistant:"You're an AI assistant that helps people find information."Or, you can tailor the prompt to your image or scenario.NoteWe recommend you update the System Message to be specific to the task in order to avoid unhelpful responses from the model.
In the context text box on theSetuppanel, provide this prompt to guide the assistant:"You're an AI assistant that helps people find information."Or, you can tailor the prompt to your image or scenario.
"You're an AI assistant that helps people find information."
Note
We recommend you update the System Message to be specific to the task in order to avoid unhelpful responses from the model.
SelectApply changesto save your changes.
SelectApply changesto save your changes.
In the chat session pane, select the attachment button and thenUpload image. Choose your image.
In the chat session pane, select the attachment button and thenUpload image. Choose your image.
Add the following prompt in the chat field:Describe this image, and then select the send icon to submit it.
Add the following prompt in the chat field:Describe this image, and then select the send icon to submit it.
Describe this image
The send icon is replaced by a stop button. If you select it, the assistant stops processing your request. For this quickstart, let the assistant finish its reply.
The send icon is replaced by a stop button. If you select it, the assistant stops processing your request. For this quickstart, let the assistant finish its reply.
The assistant replies with a description of the image.
The assistant replies with a description of the image.
Ask a follow-up question related to the analysis of your image. You could enter,"What should I highlight about this image to my insurance company?".
Ask a follow-up question related to the analysis of your image. You could enter,"What should I highlight about this image to my insurance company?".
"What should I highlight about this image to my insurance company?"
You should receive a relevant response similar to what's shown here:When reporting the incident to your insurance company, you should highlight the following key points from the image:  

1. **Location of Damage**: Clearly state that the front end of the car, particularly the driver's side, is damaged. Mention the crumpled hood, broken front bumper, and the damaged left headlight.  

2. **Point of Impact**: Indicate that the car has collided with a guardrail, which may suggest that no other vehicles were involved in the accident.  

3. **Condition of the Car**: Note that the damage seems to be concentrated on the front end, and there is no visible damage to the windshield or rear of the car from this perspective.  

4. **License Plate Visibility**: Mention that the license plate is intact and can be used for identification purposes.  

5. **Environment**: Report that the accident occurred near a roadside with a guardrail, possibly in a rural or semi-rural area, which might help in establishing the accident location and context.  

6. **Other Observations**: If there were any other circumstances or details not visible in the image that may have contributed to the accident, such as weather conditions, road conditions, or any other relevant information, be sure to include those as well.  

Remember to be factual and descriptive, avoiding speculation about the cause of the accident, as the insurance company will conduct its own investigation.
You should receive a relevant response similar to what's shown here:
When reporting the incident to your insurance company, you should highlight the following key points from the image:  

1. **Location of Damage**: Clearly state that the front end of the car, particularly the driver's side, is damaged. Mention the crumpled hood, broken front bumper, and the damaged left headlight.  

2. **Point of Impact**: Indicate that the car has collided with a guardrail, which may suggest that no other vehicles were involved in the accident.  

3. **Condition of the Car**: Note that the damage seems to be concentrated on the front end, and there is no visible damage to the windshield or rear of the car from this perspective.  

4. **License Plate Visibility**: Mention that the license plate is intact and can be used for identification purposes.  

5. **Environment**: Report that the accident occurred near a roadside with a guardrail, possibly in a rural or semi-rural area, which might help in establishing the accident location and context.  

6. **Other Observations**: If there were any other circumstances or details not visible in the image that may have contributed to the accident, such as weather conditions, road conditions, or any other relevant information, be sure to include those as well.  

Remember to be factual and descriptive, avoiding speculation about the cause of the accident, as the insurance company will conduct its own investigation.
When reporting the incident to your insurance company, you should highlight the following key points from the image:  

1. **Location of Damage**: Clearly state that the front end of the car, particularly the driver's side, is damaged. Mention the crumpled hood, broken front bumper, and the damaged left headlight.  

2. **Point of Impact**: Indicate that the car has collided with a guardrail, which may suggest that no other vehicles were involved in the accident.  

3. **Condition of the Car**: Note that the damage seems to be concentrated on the front end, and there is no visible damage to the windshield or rear of the car from this perspective.  

4. **License Plate Visibility**: Mention that the license plate is intact and can be used for identification purposes.  

5. **Environment**: Report that the accident occurred near a roadside with a guardrail, possibly in a rural or semi-rural area, which might help in establishing the accident location and context.  

6. **Other Observations**: If there were any other circumstances or details not visible in the image that may have contributed to the accident, such as weather conditions, road conditions, or any other relevant information, be sure to include those as well.  

Remember to be factual and descriptive, avoiding speculation about the cause of the accident, as the insurance company will conduct its own investigation.
View and export code
At any point in the chat session, you can enable theShow raw JSONswitch at the top of the chat window to see the conversation formatted as JSON. Heres' what it looks like at the beginning of the quickstart chat session:
[
	{
		"role": "system",
		"content": [
			"You are an AI assistant that helps people find information."
		]
	},
]
[
	{
		"role": "system",
		"content": [
			"You are an AI assistant that helps people find information."
		]
	},
]
Clean up resources
If you want to clean up and remove an Azure OpenAI resource, you can delete the resource or resource group. Deleting the resource group also deletes any other resources associated with it.
Azure portal
Azure CLI
Use this article to get started using the Azure OpenAI REST APIs to deploy and use the GPT-4 Turbo with Vision model.
Prerequisites
An Azure subscription.Create one for free.
Python 3.8 or later version.
The following Python libraries:requests,json.
requests
json
An Azure OpenAI Service resource with a GPT-4 Turbo with Vision model deployed. SeeGPT-4 and GPT-4 Turbo Preview model availabilityfor available regions. For more information about resource creation, see theresource deployment guide.
Note
It is currently not supported to turn off content filtering for the GPT-4 Turbo with Vision model.
Retrieve key and endpoint
To successfully call the Azure OpenAI APIs, you need the following information about your Azure OpenAI resource:
api_base
https://docs-test-001.openai.azure.com/
api_key
Go to your resource in the Azure portal. On the navigation pane, selectKeys and EndpointunderResource Management. Copy theEndpointvalue and an access key value. You can use either theKEY 1orKEY 2value. Having two keys allows you to securely rotate and regenerate keys without causing a service disruption.

Create a new Python application
Create a new Python file namedquickstart.py. Open the new file in your preferred editor or IDE.
Replace the contents ofquickstart.pywith the following code.# Packages required:
import requests 
import json 

api_base = '<your_azure_openai_endpoint>' 
deployment_name = '<your_deployment_name>'
API_KEY = '<your_azure_openai_key>'

base_url = f"{api_base}openai/deployments/{deployment_name}" 
headers = {   
    "Content-Type": "application/json",   
    "api-key": API_KEY 
} 

# Prepare endpoint, headers, and request body 
endpoint = f"{base_url}/chat/completions?api-version=2023-12-01-preview" 
data = { 
    "messages": [ 
        { "role": "system", "content": "You are a helpful assistant." }, 
        { "role": "user", "content": [  
            { 
                "type": "text", 
                "text": "Describe this picture:" 
            },
            { 
                "type": "image_url",
                "image_url": {
                    "url": "<image URL>"
                }
            }
        ] } 
    ], 
    "max_tokens": 2000 
}   

# Make the API call   
response = requests.post(endpoint, headers=headers, data=json.dumps(data))   

print(f"Status Code: {response.status_code}")   
print(response.text)
Replace the contents ofquickstart.pywith the following code.
# Packages required:
import requests 
import json 

api_base = '<your_azure_openai_endpoint>' 
deployment_name = '<your_deployment_name>'
API_KEY = '<your_azure_openai_key>'

base_url = f"{api_base}openai/deployments/{deployment_name}" 
headers = {   
    "Content-Type": "application/json",   
    "api-key": API_KEY 
} 

# Prepare endpoint, headers, and request body 
endpoint = f"{base_url}/chat/completions?api-version=2023-12-01-preview" 
data = { 
    "messages": [ 
        { "role": "system", "content": "You are a helpful assistant." }, 
        { "role": "user", "content": [  
            { 
                "type": "text", 
                "text": "Describe this picture:" 
            },
            { 
                "type": "image_url",
                "image_url": {
                    "url": "<image URL>"
                }
            }
        ] } 
    ], 
    "max_tokens": 2000 
}   

# Make the API call   
response = requests.post(endpoint, headers=headers, data=json.dumps(data))   

print(f"Status Code: {response.status_code}")   
print(response.text)
# Packages required:
import requests 
import json 

api_base = '<your_azure_openai_endpoint>' 
deployment_name = '<your_deployment_name>'
API_KEY = '<your_azure_openai_key>'

base_url = f"{api_base}openai/deployments/{deployment_name}" 
headers = {   
    "Content-Type": "application/json",   
    "api-key": API_KEY 
} 

# Prepare endpoint, headers, and request body 
endpoint = f"{base_url}/chat/completions?api-version=2023-12-01-preview" 
data = { 
    "messages": [ 
        { "role": "system", "content": "You are a helpful assistant." }, 
        { "role": "user", "content": [  
            { 
                "type": "text", 
                "text": "Describe this picture:" 
            },
            { 
                "type": "image_url",
                "image_url": {
                    "url": "<image URL>"
                }
            }
        ] } 
    ], 
    "max_tokens": 2000 
}   

# Make the API call   
response = requests.post(endpoint, headers=headers, data=json.dumps(data))   

print(f"Status Code: {response.status_code}")   
print(response.text)
Make the following changes:Enter your endpoint URL and key in the appropriate fields.Enter your GPT-4 Turbo with Vision deployment name in the appropriate field.Change the value of the"image"field to the URL of your image.TipYou can also use a base 64 encoded image data instead of a URL. For more information, see theGPT-4 Turbo with Vision how-to guide.
Make the following changes:
Enter your endpoint URL and key in the appropriate fields.
Enter your GPT-4 Turbo with Vision deployment name in the appropriate field.
Change the value of the"image"field to the URL of your image.TipYou can also use a base 64 encoded image data instead of a URL. For more information, see theGPT-4 Turbo with Vision how-to guide.
"image"
Tip
You can also use a base 64 encoded image data instead of a URL. For more information, see theGPT-4 Turbo with Vision how-to guide.
Run the application with thepythoncommand:python quickstart.py
Run the application with thepythoncommand:
python
python quickstart.py
python quickstart.py
Clean up resources
If you want to clean up and remove an Azure OpenAI resource, you can delete the resource or resource group. Deleting the resource group also deletes any other resources associated with it.
Azure portal
Azure CLI
Use this article to get started using the Azure OpenAI Python SDK to deploy and use the GPT-4 Turbo with Vision model.
Library source code|Package (PyPi)|
Prerequisites
An Azure subscription.Create one for free.
Python 3.8 or later version.
The following Python libraries:os
os
An Azure OpenAI Service resource with a GPT-4 Turbo with Vision model deployed. SeeGPT-4 and GPT-4 Turbo Preview model availabilityfor available regions. For more information about resource creation, see theresource deployment guide.
Set up
Install the OpenAI Python client library with:
pip install openai
pip install openai
Note
This library is maintained by OpenAI. Refer to therelease historyto track the latest updates to the library.
Retrieve key and endpoint
To successfully make a call against Azure OpenAI, you need anendpointand akey.
ENDPOINT
https://docs-test-001.openai.azure.com/
API-KEY
KEY1
KEY2
Go to your resource in the Azure portal. TheKeys & Endpointsection can be found in theResource Managementsection. Copy your endpoint and access key as you'll need both for authenticating your API calls. You can use eitherKEY1orKEY2. Always having two keys allows you to securely rotate and regenerate keys without causing a service disruption.
KEY1
KEY2

Environment variables
Create and assign persistent environment variables for your key and endpoint.
Important
We recommend Microsoft Entra ID authentication withmanaged identities for Azure resourcesto avoid storing credentials with your applications that run in the cloud.
Use API keys with caution. Don't include the API key directly in your code, and never post it publicly. If using API keys, store them securely in Azure Key Vault, rotate the keys regularly, and restrict access to Azure Key Vault using role based access control and network access restrictions. For more information about using API keys securely in your apps, seeAPI keys with Azure Key Vault.
For more information about AI services security, seeAuthenticate requests to Azure AI services.
Command Line
PowerShell
Bash
setx AZURE_OPENAI_API_KEY "REPLACE_WITH_YOUR_KEY_VALUE_HERE" 
setx AZURE_OPENAI_ENDPOINT "REPLACE_WITH_YOUR_ENDPOINT_HERE"
setx AZURE_OPENAI_API_KEY "REPLACE_WITH_YOUR_KEY_VALUE_HERE" 
setx AZURE_OPENAI_ENDPOINT "REPLACE_WITH_YOUR_ENDPOINT_HERE"
[System.Environment]::SetEnvironmentVariable('AZURE_OPENAI_API_KEY', 'REPLACE_WITH_YOUR_KEY_VALUE_HERE', 'User')
[System.Environment]::SetEnvironmentVariable('AZURE_OPENAI_ENDPOINT', 'REPLACE_WITH_YOUR_ENDPOINT_HERE', 'User')
[System.Environment]::SetEnvironmentVariable('AZURE_OPENAI_API_KEY', 'REPLACE_WITH_YOUR_KEY_VALUE_HERE', 'User')
[System.Environment]::SetEnvironmentVariable('AZURE_OPENAI_ENDPOINT', 'REPLACE_WITH_YOUR_ENDPOINT_HERE', 'User')
export AZURE_OPENAI_API_KEY="REPLACE_WITH_YOUR_KEY_VALUE_HERE"
export AZURE_OPENAI_ENDPOINT="REPLACE_WITH_YOUR_ENDPOINT_HERE"
export AZURE_OPENAI_API_KEY="REPLACE_WITH_YOUR_KEY_VALUE_HERE"
export AZURE_OPENAI_ENDPOINT="REPLACE_WITH_YOUR_ENDPOINT_HERE"
Create a new Python application
Create a new Python file namedquickstart.py. Open the new file in your preferred editor or IDE.
Replace the contents ofquickstart.pywith the following code.from openai import AzureOpenAI

api_base = os.getenv("AZURE_OPENAI_ENDPOINT")
api_key= os.getenv("AZURE_OPENAI_API_KEY")
deployment_name = '<your_deployment_name>'
api_version = '2023-12-01-preview' # this might change in the future

client = AzureOpenAI(
    api_key=api_key,  
    api_version=api_version,
    base_url=f"{api_base}/openai/deployments/{deployment_name}"
)

response = client.chat.completions.create(
    model=deployment_name,
    messages=[
        { "role": "system", "content": "You are a helpful assistant." },
        { "role": "user", "content": [  
            { 
                "type": "text", 
                "text": "Describe this picture:" 
            },
            { 
                "type": "image_url",
                "image_url": {
                    "url": "<image URL>"
                }
            }
        ] } 
    ],
    max_tokens=2000 
)

print(response)
Replace the contents ofquickstart.pywith the following code.
from openai import AzureOpenAI

api_base = os.getenv("AZURE_OPENAI_ENDPOINT")
api_key= os.getenv("AZURE_OPENAI_API_KEY")
deployment_name = '<your_deployment_name>'
api_version = '2023-12-01-preview' # this might change in the future

client = AzureOpenAI(
    api_key=api_key,  
    api_version=api_version,
    base_url=f"{api_base}/openai/deployments/{deployment_name}"
)

response = client.chat.completions.create(
    model=deployment_name,
    messages=[
        { "role": "system", "content": "You are a helpful assistant." },
        { "role": "user", "content": [  
            { 
                "type": "text", 
                "text": "Describe this picture:" 
            },
            { 
                "type": "image_url",
                "image_url": {
                    "url": "<image URL>"
                }
            }
        ] } 
    ],
    max_tokens=2000 
)

print(response)
from openai import AzureOpenAI

api_base = os.getenv("AZURE_OPENAI_ENDPOINT")
api_key= os.getenv("AZURE_OPENAI_API_KEY")
deployment_name = '<your_deployment_name>'
api_version = '2023-12-01-preview' # this might change in the future

client = AzureOpenAI(
    api_key=api_key,  
    api_version=api_version,
    base_url=f"{api_base}/openai/deployments/{deployment_name}"
)

response = client.chat.completions.create(
    model=deployment_name,
    messages=[
        { "role": "system", "content": "You are a helpful assistant." },
        { "role": "user", "content": [  
            { 
                "type": "text", 
                "text": "Describe this picture:" 
            },
            { 
                "type": "image_url",
                "image_url": {
                    "url": "<image URL>"
                }
            }
        ] } 
    ],
    max_tokens=2000 
)

print(response)
Make the following changes:Enter the name of your GPT-4 Turbo with Vision deployment in the appropriate field.Change the value of the"url"field to the URL of your image.TipYou can also use a base 64 encoded image data instead of a URL. For more information, see theGPT-4 Turbo with Vision how-to guide.
Make the following changes:
Enter the name of your GPT-4 Turbo with Vision deployment in the appropriate field.
Change the value of the"url"field to the URL of your image.TipYou can also use a base 64 encoded image data instead of a URL. For more information, see theGPT-4 Turbo with Vision how-to guide.
"url"
Tip
You can also use a base 64 encoded image data instead of a URL. For more information, see theGPT-4 Turbo with Vision how-to guide.
Run the application with thepythoncommand:python quickstart.py
Run the application with thepythoncommand:
python
python quickstart.py
python quickstart.py
Important
Use API keys with caution. Don't include the API key directly in your code, and never post it publicly. If you use an API key, store it securely in Azure Key Vault. For more information about using API keys securely in your apps, seeAPI keys with Azure Key Vault.
For more information about AI services security, seeAuthenticate requests to Azure AI services.
Clean up resources
If you want to clean up and remove an Azure OpenAI resource, you can delete the resource or resource group. Deleting the resource group also deletes any other resources associated with it.
Azure portal
Azure CLI
Use this article to get started using the OpenAI JavaScript SDK to deploy and use the GPT-4 Turbo with Vision model.
This SDK is provided by OpenAI with Azure specific types provided by Azure.
Reference documentation|Library source code|Package (npm)|Samples
Prerequisites
An Azure subscription -Create one for free
LTS versions of Node.js
Azure CLIused for passwordless authentication in a local development environment, create the necessary context by signing in with the Azure CLI.
An Azure OpenAI resource created in a supported region (seeRegion availability). For more information, seeCreate a resource and deploy a model with Azure OpenAI.
Note
This library is maintained by OpenAI. Refer to therelease historyto track the latest updates to the library.
Microsoft Entra ID prerequisites
For the recommended keyless authentication with Microsoft Entra ID, you need to:
Install theAzure CLIused for keyless authentication with Microsoft Entra ID.
Assign theCognitive Services Userrole to your user account. You can assign roles in the Azure portal underAccess control (IAM)>Add role assignment.
Cognitive Services User
Set up
Create a new foldervision-quickstartand go to the quickstart folder with the following command:mkdir vision-quickstart && cd vision-quickstart
Create a new foldervision-quickstartand go to the quickstart folder with the following command:
vision-quickstart
mkdir vision-quickstart && cd vision-quickstart
mkdir vision-quickstart && cd vision-quickstart
Create thepackage.jsonwith the following command:npm init -y
Create thepackage.jsonwith the following command:
package.json
npm init -y
npm init -y
Install the OpenAI client library for JavaScript with:npm install openai
Install the OpenAI client library for JavaScript with:
npm install openai
npm install openai
For therecommendedpasswordless authentication:npm install @azure/identity
For therecommendedpasswordless authentication:
npm install @azure/identity
npm install @azure/identity
Retrieve resource information
You need to retrieve the following information to authenticate your application with your Azure OpenAI resource:
Microsoft Entra ID
API key
AZURE_OPENAI_ENDPOINT
AZURE_OPENAI_DEPLOYMENT_NAME
OPENAI_API_VERSION
Learn more aboutkeyless authenticationandsetting environment variables.
AZURE_OPENAI_ENDPOINT
AZURE_OPENAI_API_KEY
KEY1
KEY2
AZURE_OPENAI_DEPLOYMENT_NAME
OPENAI_API_VERSION
Learn more aboutfinding API keysandsetting environment variables.
Important
Use API keys with caution. Don't include the API key directly in your code, and never post it publicly. If you use an API key, store it securely in Azure Key Vault. For more information about using API keys securely in your apps, seeAPI keys with Azure Key Vault.
For more information about AI services security, seeAuthenticate requests to Azure AI services.
Caution
To use the recommended keyless authentication with the SDK, make sure that theAZURE_OPENAI_API_KEYenvironment variable isn't set.
AZURE_OPENAI_API_KEY
Create a new JavaScript application for image prompts
Select an image from theazure-samples/cognitive-services-sample-data-files. Use the image URL in the code below or set theIMAGE_URLenvironment variable to the image URL.
IMAGE_URL
Tip
You can also use a base 64 encoded image data instead of a URL. For more information, see theGPT-4 Turbo with Vision how-to guide.
Microsoft Entra ID
API key
Create theindex.jsfile with the following code:const AzureOpenAI = require('openai').AzureOpenAI;
const { 
    DefaultAzureCredential, 
    getBearerTokenProvider 
} = require('@azure/identity');

// You will need to set these environment variables or edit the following values
const endpoint = process.env.AZURE_OPENAI_ENDPOINT || "Your endpoint";
const imageUrl = process.env.IMAGE_URL || "<image url>";

// Required Azure OpenAI deployment name and API version
const apiVersion = process.env.OPENAI_API_VERSION || "2024-07-01-preview";
const deploymentName = process.env.AZURE_OPENAI_DEPLOYMENT_NAME || "gpt-4-with-turbo";

// keyless authentication    
const credential = new DefaultAzureCredential();
const scope = "https://cognitiveservices.azure.com/.default";
const azureADTokenProvider = getBearerTokenProvider(credential, scope);

function getClient(): AzureOpenAI {
  return new AzureOpenAI({
    endpoint,
    azureADTokenProvider,
    apiVersion,
    deployment: deploymentName,
  });
}
function createMessages() {
  return {
    messages: [
      { role: "system", content: "You are a helpful assistant." },
      {
        role: "user",
        content: [
          {
            type: "text",
            text: "Describe this picture:",
          },
          {
            type: "image_url",
            image_url: {
              url: imageUrl,
            },
          },
        ],
      },
    ],
    model: "",
    max_tokens: 2000,
  };
}
async function printChoices(completion) {
  for (const choice of completion.choices) {
    console.log(choice.message);
  }
}
export async function main() {
  console.log("== Get GPT-4 Turbo with vision Sample ==");

  const client = getClient();
  const messages = createMessages();
  const completion = await client.chat.completions.create(messages);
  await printChoices(completion);
}

main().catch((err) => {
  console.error("Error occurred:", err);
});
Create theindex.jsfile with the following code:
index.js
const AzureOpenAI = require('openai').AzureOpenAI;
const { 
    DefaultAzureCredential, 
    getBearerTokenProvider 
} = require('@azure/identity');

// You will need to set these environment variables or edit the following values
const endpoint = process.env.AZURE_OPENAI_ENDPOINT || "Your endpoint";
const imageUrl = process.env.IMAGE_URL || "<image url>";

// Required Azure OpenAI deployment name and API version
const apiVersion = process.env.OPENAI_API_VERSION || "2024-07-01-preview";
const deploymentName = process.env.AZURE_OPENAI_DEPLOYMENT_NAME || "gpt-4-with-turbo";

// keyless authentication    
const credential = new DefaultAzureCredential();
const scope = "https://cognitiveservices.azure.com/.default";
const azureADTokenProvider = getBearerTokenProvider(credential, scope);

function getClient(): AzureOpenAI {
  return new AzureOpenAI({
    endpoint,
    azureADTokenProvider,
    apiVersion,
    deployment: deploymentName,
  });
}
function createMessages() {
  return {
    messages: [
      { role: "system", content: "You are a helpful assistant." },
      {
        role: "user",
        content: [
          {
            type: "text",
            text: "Describe this picture:",
          },
          {
            type: "image_url",
            image_url: {
              url: imageUrl,
            },
          },
        ],
      },
    ],
    model: "",
    max_tokens: 2000,
  };
}
async function printChoices(completion) {
  for (const choice of completion.choices) {
    console.log(choice.message);
  }
}
export async function main() {
  console.log("== Get GPT-4 Turbo with vision Sample ==");

  const client = getClient();
  const messages = createMessages();
  const completion = await client.chat.completions.create(messages);
  await printChoices(completion);
}

main().catch((err) => {
  console.error("Error occurred:", err);
});
const AzureOpenAI = require('openai').AzureOpenAI;
const { 
    DefaultAzureCredential, 
    getBearerTokenProvider 
} = require('@azure/identity');

// You will need to set these environment variables or edit the following values
const endpoint = process.env.AZURE_OPENAI_ENDPOINT || "Your endpoint";
const imageUrl = process.env.IMAGE_URL || "<image url>";

// Required Azure OpenAI deployment name and API version
const apiVersion = process.env.OPENAI_API_VERSION || "2024-07-01-preview";
const deploymentName = process.env.AZURE_OPENAI_DEPLOYMENT_NAME || "gpt-4-with-turbo";

// keyless authentication    
const credential = new DefaultAzureCredential();
const scope = "https://cognitiveservices.azure.com/.default";
const azureADTokenProvider = getBearerTokenProvider(credential, scope);

function getClient(): AzureOpenAI {
  return new AzureOpenAI({
    endpoint,
    azureADTokenProvider,
    apiVersion,
    deployment: deploymentName,
  });
}
function createMessages() {
  return {
    messages: [
      { role: "system", content: "You are a helpful assistant." },
      {
        role: "user",
        content: [
          {
            type: "text",
            text: "Describe this picture:",
          },
          {
            type: "image_url",
            image_url: {
              url: imageUrl,
            },
          },
        ],
      },
    ],
    model: "",
    max_tokens: 2000,
  };
}
async function printChoices(completion) {
  for (const choice of completion.choices) {
    console.log(choice.message);
  }
}
export async function main() {
  console.log("== Get GPT-4 Turbo with vision Sample ==");

  const client = getClient();
  const messages = createMessages();
  const completion = await client.chat.completions.create(messages);
  await printChoices(completion);
}

main().catch((err) => {
  console.error("Error occurred:", err);
});
Sign in to Azure with the following command:az login
Sign in to Azure with the following command:
az login
az login
Run the JavaScript file.node index.js
Run the JavaScript file.
node index.js
node index.js
Create theindex.jsfile with the following code:const { AzureOpenAI } = require("openai");

// You will need to set these environment variables or edit the following values
const endpoint = process.env.AZURE_OPENAI_ENDPOINT || "Your endpoint";
const apiKey = process.env.AZURE_OPENAI_API_KEY || "Your API key";
const imageUrl = process.env.IMAGE_URL || "<image url>";

// Required Azure OpenAI deployment name and API version
const apiVersion = process.env.OPENAI_API_VERSION || "2024-07-01-preview";
const deploymentName = process.env.AZURE_OPENAI_DEPLOYMENT_NAME || "gpt-4-with-turbo";

function getClient() {
  return new AzureOpenAI({
    endpoint,
    apiKey,
    apiVersion,
    deployment: deploymentName,
  });
}
function createMessages() {
  return {
    messages: [
      { role: "system", content: "You are a helpful assistant." },
      {
        role: "user",
        content: [
          {
            type: "text",
            text: "Describe this picture:",
          },
          {
            type: "image_url",
            image_url: {
              url: imageUrl,
            },
          },
        ],
      },
    ],
    model: "",
    max_tokens: 2000,
  };
}
async function printChoices(completion) {
  for (const choice of completion.choices) {
    console.log(choice.message);
  }
}
export async function main() {
  console.log("== Get GPT-4 Turbo with vision Sample ==");

  const client = getClient();
  const messages = createMessages();
  const completion = await client.chat.completions.create(messages);
  await printChoices(completion);
}

main().catch((err) => {
  console.error("Error occurred:", err);
});
Create theindex.jsfile with the following code:
index.js
const { AzureOpenAI } = require("openai");

// You will need to set these environment variables or edit the following values
const endpoint = process.env.AZURE_OPENAI_ENDPOINT || "Your endpoint";
const apiKey = process.env.AZURE_OPENAI_API_KEY || "Your API key";
const imageUrl = process.env.IMAGE_URL || "<image url>";

// Required Azure OpenAI deployment name and API version
const apiVersion = process.env.OPENAI_API_VERSION || "2024-07-01-preview";
const deploymentName = process.env.AZURE_OPENAI_DEPLOYMENT_NAME || "gpt-4-with-turbo";

function getClient() {
  return new AzureOpenAI({
    endpoint,
    apiKey,
    apiVersion,
    deployment: deploymentName,
  });
}
function createMessages() {
  return {
    messages: [
      { role: "system", content: "You are a helpful assistant." },
      {
        role: "user",
        content: [
          {
            type: "text",
            text: "Describe this picture:",
          },
          {
            type: "image_url",
            image_url: {
              url: imageUrl,
            },
          },
        ],
      },
    ],
    model: "",
    max_tokens: 2000,
  };
}
async function printChoices(completion) {
  for (const choice of completion.choices) {
    console.log(choice.message);
  }
}
export async function main() {
  console.log("== Get GPT-4 Turbo with vision Sample ==");

  const client = getClient();
  const messages = createMessages();
  const completion = await client.chat.completions.create(messages);
  await printChoices(completion);
}

main().catch((err) => {
  console.error("Error occurred:", err);
});
const { AzureOpenAI } = require("openai");

// You will need to set these environment variables or edit the following values
const endpoint = process.env.AZURE_OPENAI_ENDPOINT || "Your endpoint";
const apiKey = process.env.AZURE_OPENAI_API_KEY || "Your API key";
const imageUrl = process.env.IMAGE_URL || "<image url>";

// Required Azure OpenAI deployment name and API version
const apiVersion = process.env.OPENAI_API_VERSION || "2024-07-01-preview";
const deploymentName = process.env.AZURE_OPENAI_DEPLOYMENT_NAME || "gpt-4-with-turbo";

function getClient() {
  return new AzureOpenAI({
    endpoint,
    apiKey,
    apiVersion,
    deployment: deploymentName,
  });
}
function createMessages() {
  return {
    messages: [
      { role: "system", content: "You are a helpful assistant." },
      {
        role: "user",
        content: [
          {
            type: "text",
            text: "Describe this picture:",
          },
          {
            type: "image_url",
            image_url: {
              url: imageUrl,
            },
          },
        ],
      },
    ],
    model: "",
    max_tokens: 2000,
  };
}
async function printChoices(completion) {
  for (const choice of completion.choices) {
    console.log(choice.message);
  }
}
export async function main() {
  console.log("== Get GPT-4 Turbo with vision Sample ==");

  const client = getClient();
  const messages = createMessages();
  const completion = await client.chat.completions.create(messages);
  await printChoices(completion);
}

main().catch((err) => {
  console.error("Error occurred:", err);
});
Run the JavaScript file.node index.js
Run the JavaScript file.
node index.js
node index.js
Clean up resources
If you want to clean up and remove an Azure OpenAI resource, you can delete the resource or resource group. Deleting the resource group also deletes any other resources associated with it.
Azure portal
Azure CLI
Use this article to get started using the OpenAI JavaScript SDK to deploy and use the GPT-4 Turbo with Vision model.
This SDK is provided by OpenAI with Azure specific types provided by Azure.
Reference documentation|Library source code|Package (npm)|Samples
Prerequisites
An Azure subscription -Create one for free
LTS versions of Node.js
TypeScript
Azure CLIused for passwordless authentication in a local development environment, create the necessary context by signing in with the Azure CLI.
An Azure OpenAI resource created in a supported region (seeRegion availability). For more information, seeCreate a resource and deploy a model with Azure OpenAI.
Note
This library is maintained by OpenAI. Refer to therelease historyto track the latest updates to the library.
Microsoft Entra ID prerequisites
For the recommended keyless authentication with Microsoft Entra ID, you need to:
Install theAzure CLIused for keyless authentication with Microsoft Entra ID.
Assign theCognitive Services Userrole to your user account. You can assign roles in the Azure portal underAccess control (IAM)>Add role assignment.
Cognitive Services User
Set up
Create a new foldervision-quickstartand go to the quickstart folder with the following command:mkdir vision-quickstart && cd vision-quickstart
Create a new foldervision-quickstartand go to the quickstart folder with the following command:
vision-quickstart
mkdir vision-quickstart && cd vision-quickstart
mkdir vision-quickstart && cd vision-quickstart
Create thepackage.jsonwith the following command:npm init -y
Create thepackage.jsonwith the following command:
package.json
npm init -y
npm init -y
Update thepackage.jsonto ECMAScript with the following command:npm pkg set type=module
Update thepackage.jsonto ECMAScript with the following command:
package.json
npm pkg set type=module
npm pkg set type=module
Install the OpenAI client library for JavaScript with:npm install openai
Install the OpenAI client library for JavaScript with:
npm install openai
npm install openai
For therecommendedpasswordless authentication:npm install @azure/identity
For therecommendedpasswordless authentication:
npm install @azure/identity
npm install @azure/identity
Retrieve resource information
You need to retrieve the following information to authenticate your application with your Azure OpenAI resource:
Microsoft Entra ID
API key
AZURE_OPENAI_ENDPOINT
AZURE_OPENAI_DEPLOYMENT_NAME
OPENAI_API_VERSION
Learn more aboutkeyless authenticationandsetting environment variables.
AZURE_OPENAI_ENDPOINT
AZURE_OPENAI_API_KEY
KEY1
KEY2
AZURE_OPENAI_DEPLOYMENT_NAME
OPENAI_API_VERSION
Learn more aboutfinding API keysandsetting environment variables.
Important
Use API keys with caution. Don't include the API key directly in your code, and never post it publicly. If you use an API key, store it securely in Azure Key Vault. For more information about using API keys securely in your apps, seeAPI keys with Azure Key Vault.
For more information about AI services security, seeAuthenticate requests to Azure AI services.
Caution
To use the recommended keyless authentication with the SDK, make sure that theAZURE_OPENAI_API_KEYenvironment variable isn't set.
AZURE_OPENAI_API_KEY
Create a new JavaScript application for image prompts
Select an image from theazure-samples/cognitive-services-sample-data-files. Use the image URL in the code below or set theIMAGE_URLenvironment variable to the image URL.
IMAGE_URL
Tip
You can also use a base 64 encoded image data instead of a URL. For more information, see theGPT-4 Turbo with Vision how-to guide.
Microsoft Entra ID
API key
Create theindex.tsfile with the following code:import { AzureOpenAI } from "openai";
import { 
    DefaultAzureCredential, 
    getBearerTokenProvider 
} from "@azure/identity";
import type {
  ChatCompletion,
  ChatCompletionCreateParamsNonStreaming,
} from "openai/resources/index";

// You will need to set these environment variables or edit the following values
const endpoint = process.env.AZURE_OPENAI_ENDPOINT || "Your endpoint";
const imageUrl = process.env["IMAGE_URL"] || "<image url>";

// Required Azure OpenAI deployment name and API version
const apiVersion = process.env.OPENAI_API_VERSION || "2024-07-01-preview";
const deploymentName = process.env.AZURE_OPENAI_DEPLOYMENT_NAME || "gpt-4-with-turbo";

// keyless authentication    
const credential = new DefaultAzureCredential();
const scope = "https://cognitiveservices.azure.com/.default";
const azureADTokenProvider = getBearerTokenProvider(credential, scope);

function getClient(): AzureOpenAI {
  return new AzureOpenAI({
    endpoint,
    azureADTokenProvider,
    apiVersion,
    deployment: deploymentName,
  });
}
function createMessages(): ChatCompletionCreateParamsNonStreaming {
  return {
    messages: [
      { role: "system", content: "You are a helpful assistant." },
      {
        role: "user",
        content: [
          {
            type: "text",
            text: "Describe this picture:",
          },
          {
            type: "image_url",
            image_url: {
              url: imageUrl,
            },
          },
        ],
      },
    ],
    model: "",
    max_tokens: 2000,
  };
}
async function printChoices(completion: ChatCompletion): Promise<void> {
  for (const choice of completion.choices) {
    console.log(choice.message);
  }
}
export async function main() {
  console.log("== Get GPT-4 Turbo with vision Sample ==");

  const client = getClient();
  const messages = createMessages();
  const completion = await client.chat.completions.create(messages);
  await printChoices(completion);
}

main().catch((err) => {
  console.error("Error occurred:", err);
});
Create theindex.tsfile with the following code:
index.ts
import { AzureOpenAI } from "openai";
import { 
    DefaultAzureCredential, 
    getBearerTokenProvider 
} from "@azure/identity";
import type {
  ChatCompletion,
  ChatCompletionCreateParamsNonStreaming,
} from "openai/resources/index";

// You will need to set these environment variables or edit the following values
const endpoint = process.env.AZURE_OPENAI_ENDPOINT || "Your endpoint";
const imageUrl = process.env["IMAGE_URL"] || "<image url>";

// Required Azure OpenAI deployment name and API version
const apiVersion = process.env.OPENAI_API_VERSION || "2024-07-01-preview";
const deploymentName = process.env.AZURE_OPENAI_DEPLOYMENT_NAME || "gpt-4-with-turbo";

// keyless authentication    
const credential = new DefaultAzureCredential();
const scope = "https://cognitiveservices.azure.com/.default";
const azureADTokenProvider = getBearerTokenProvider(credential, scope);

function getClient(): AzureOpenAI {
  return new AzureOpenAI({
    endpoint,
    azureADTokenProvider,
    apiVersion,
    deployment: deploymentName,
  });
}
function createMessages(): ChatCompletionCreateParamsNonStreaming {
  return {
    messages: [
      { role: "system", content: "You are a helpful assistant." },
      {
        role: "user",
        content: [
          {
            type: "text",
            text: "Describe this picture:",
          },
          {
            type: "image_url",
            image_url: {
              url: imageUrl,
            },
          },
        ],
      },
    ],
    model: "",
    max_tokens: 2000,
  };
}
async function printChoices(completion: ChatCompletion): Promise<void> {
  for (const choice of completion.choices) {
    console.log(choice.message);
  }
}
export async function main() {
  console.log("== Get GPT-4 Turbo with vision Sample ==");

  const client = getClient();
  const messages = createMessages();
  const completion = await client.chat.completions.create(messages);
  await printChoices(completion);
}

main().catch((err) => {
  console.error("Error occurred:", err);
});
import { AzureOpenAI } from "openai";
import { 
    DefaultAzureCredential, 
    getBearerTokenProvider 
} from "@azure/identity";
import type {
  ChatCompletion,
  ChatCompletionCreateParamsNonStreaming,
} from "openai/resources/index";

// You will need to set these environment variables or edit the following values
const endpoint = process.env.AZURE_OPENAI_ENDPOINT || "Your endpoint";
const imageUrl = process.env["IMAGE_URL"] || "<image url>";

// Required Azure OpenAI deployment name and API version
const apiVersion = process.env.OPENAI_API_VERSION || "2024-07-01-preview";
const deploymentName = process.env.AZURE_OPENAI_DEPLOYMENT_NAME || "gpt-4-with-turbo";

// keyless authentication    
const credential = new DefaultAzureCredential();
const scope = "https://cognitiveservices.azure.com/.default";
const azureADTokenProvider = getBearerTokenProvider(credential, scope);

function getClient(): AzureOpenAI {
  return new AzureOpenAI({
    endpoint,
    azureADTokenProvider,
    apiVersion,
    deployment: deploymentName,
  });
}
function createMessages(): ChatCompletionCreateParamsNonStreaming {
  return {
    messages: [
      { role: "system", content: "You are a helpful assistant." },
      {
        role: "user",
        content: [
          {
            type: "text",
            text: "Describe this picture:",
          },
          {
            type: "image_url",
            image_url: {
              url: imageUrl,
            },
          },
        ],
      },
    ],
    model: "",
    max_tokens: 2000,
  };
}
async function printChoices(completion: ChatCompletion): Promise<void> {
  for (const choice of completion.choices) {
    console.log(choice.message);
  }
}
export async function main() {
  console.log("== Get GPT-4 Turbo with vision Sample ==");

  const client = getClient();
  const messages = createMessages();
  const completion = await client.chat.completions.create(messages);
  await printChoices(completion);
}

main().catch((err) => {
  console.error("Error occurred:", err);
});
Create thetsconfig.jsonfile to transpile the TypeScript code and copy the following code for ECMAScript.{
    "compilerOptions": {
      "module": "NodeNext",
      "target": "ES2022", // Supports top-level await
      "moduleResolution": "NodeNext",
      "skipLibCheck": true, // Avoid type errors from node_modules
      "strict": true // Enable strict type-checking options
    },
    "include": ["*.ts"]
}
Create thetsconfig.jsonfile to transpile the TypeScript code and copy the following code for ECMAScript.
tsconfig.json
{
    "compilerOptions": {
      "module": "NodeNext",
      "target": "ES2022", // Supports top-level await
      "moduleResolution": "NodeNext",
      "skipLibCheck": true, // Avoid type errors from node_modules
      "strict": true // Enable strict type-checking options
    },
    "include": ["*.ts"]
}
{
    "compilerOptions": {
      "module": "NodeNext",
      "target": "ES2022", // Supports top-level await
      "moduleResolution": "NodeNext",
      "skipLibCheck": true, // Avoid type errors from node_modules
      "strict": true // Enable strict type-checking options
    },
    "include": ["*.ts"]
}
Transpile from TypeScript to JavaScript.tsc
Transpile from TypeScript to JavaScript.
tsc
tsc
Sign in to Azure with the following command:az login
Sign in to Azure with the following command:
az login
az login
Run the code with the following command:node index.js
Run the code with the following command:
node index.js
node index.js
Create theindex.tsfile with the following code:import { AzureOpenAI } from "openai";
import type {
  ChatCompletion,
  ChatCompletionCreateParamsNonStreaming,
} from "openai/resources/index";

// You will need to set these environment variables or edit the following values
const endpoint = process.env.AZURE_OPENAI_ENDPOINT || "Your endpoint";
const apiKey = process.env.AZURE_OPENAI_API_KEY || "Your API key";
const imageUrl = process.env["IMAGE_URL"] || "<image url>";

// Required Azure OpenAI deployment name and API version
const apiVersion = process.env.OPENAI_API_VERSION || "2024-07-01-preview";
const deploymentName = process.env.AZURE_OPENAI_DEPLOYMENT_NAME || "gpt-4-with-turbo";

function getClient(): AzureOpenAI {
  return new AzureOpenAI({
    endpoint,
    apiKey,
    apiVersion,
    deployment: deploymentName,
  });
}
function createMessages(): ChatCompletionCreateParamsNonStreaming {
  return {
    messages: [
      { role: "system", content: "You are a helpful assistant." },
      {
        role: "user",
        content: [
          {
            type: "text",
            text: "Describe this picture:",
          },
          {
            type: "image_url",
            image_url: {
              url: imageUrl,
            },
          },
        ],
      },
    ],
    model: "",
    max_tokens: 2000,
  };
}
async function printChoices(completion: ChatCompletion): Promise<void> {
  for (const choice of completion.choices) {
    console.log(choice.message);
  }
}
export async function main() {
  console.log("== Get GPT-4 Turbo with vision Sample ==");

  const client = getClient();
  const messages = createMessages();
  const completion = await client.chat.completions.create(messages);
  await printChoices(completion);
}

main().catch((err) => {
  console.error("Error occurred:", err);
});
Create theindex.tsfile with the following code:
index.ts
import { AzureOpenAI } from "openai";
import type {
  ChatCompletion,
  ChatCompletionCreateParamsNonStreaming,
} from "openai/resources/index";

// You will need to set these environment variables or edit the following values
const endpoint = process.env.AZURE_OPENAI_ENDPOINT || "Your endpoint";
const apiKey = process.env.AZURE_OPENAI_API_KEY || "Your API key";
const imageUrl = process.env["IMAGE_URL"] || "<image url>";

// Required Azure OpenAI deployment name and API version
const apiVersion = process.env.OPENAI_API_VERSION || "2024-07-01-preview";
const deploymentName = process.env.AZURE_OPENAI_DEPLOYMENT_NAME || "gpt-4-with-turbo";

function getClient(): AzureOpenAI {
  return new AzureOpenAI({
    endpoint,
    apiKey,
    apiVersion,
    deployment: deploymentName,
  });
}
function createMessages(): ChatCompletionCreateParamsNonStreaming {
  return {
    messages: [
      { role: "system", content: "You are a helpful assistant." },
      {
        role: "user",
        content: [
          {
            type: "text",
            text: "Describe this picture:",
          },
          {
            type: "image_url",
            image_url: {
              url: imageUrl,
            },
          },
        ],
      },
    ],
    model: "",
    max_tokens: 2000,
  };
}
async function printChoices(completion: ChatCompletion): Promise<void> {
  for (const choice of completion.choices) {
    console.log(choice.message);
  }
}
export async function main() {
  console.log("== Get GPT-4 Turbo with vision Sample ==");

  const client = getClient();
  const messages = createMessages();
  const completion = await client.chat.completions.create(messages);
  await printChoices(completion);
}

main().catch((err) => {
  console.error("Error occurred:", err);
});
import { AzureOpenAI } from "openai";
import type {
  ChatCompletion,
  ChatCompletionCreateParamsNonStreaming,
} from "openai/resources/index";

// You will need to set these environment variables or edit the following values
const endpoint = process.env.AZURE_OPENAI_ENDPOINT || "Your endpoint";
const apiKey = process.env.AZURE_OPENAI_API_KEY || "Your API key";
const imageUrl = process.env["IMAGE_URL"] || "<image url>";

// Required Azure OpenAI deployment name and API version
const apiVersion = process.env.OPENAI_API_VERSION || "2024-07-01-preview";
const deploymentName = process.env.AZURE_OPENAI_DEPLOYMENT_NAME || "gpt-4-with-turbo";

function getClient(): AzureOpenAI {
  return new AzureOpenAI({
    endpoint,
    apiKey,
    apiVersion,
    deployment: deploymentName,
  });
}
function createMessages(): ChatCompletionCreateParamsNonStreaming {
  return {
    messages: [
      { role: "system", content: "You are a helpful assistant." },
      {
        role: "user",
        content: [
          {
            type: "text",
            text: "Describe this picture:",
          },
          {
            type: "image_url",
            image_url: {
              url: imageUrl,
            },
          },
        ],
      },
    ],
    model: "",
    max_tokens: 2000,
  };
}
async function printChoices(completion: ChatCompletion): Promise<void> {
  for (const choice of completion.choices) {
    console.log(choice.message);
  }
}
export async function main() {
  console.log("== Get GPT-4 Turbo with vision Sample ==");

  const client = getClient();
  const messages = createMessages();
  const completion = await client.chat.completions.create(messages);
  await printChoices(completion);
}

main().catch((err) => {
  console.error("Error occurred:", err);
});
Create thetsconfig.jsonfile to transpile the TypeScript code and copy the following code for ECMAScript.{
    "compilerOptions": {
      "module": "NodeNext",
      "target": "ES2022", // Supports top-level await
      "moduleResolution": "NodeNext",
      "skipLibCheck": true, // Avoid type errors from node_modules
      "strict": true // Enable strict type-checking options
    },
    "include": ["*.ts"]
}
Create thetsconfig.jsonfile to transpile the TypeScript code and copy the following code for ECMAScript.
tsconfig.json
{
    "compilerOptions": {
      "module": "NodeNext",
      "target": "ES2022", // Supports top-level await
      "moduleResolution": "NodeNext",
      "skipLibCheck": true, // Avoid type errors from node_modules
      "strict": true // Enable strict type-checking options
    },
    "include": ["*.ts"]
}
{
    "compilerOptions": {
      "module": "NodeNext",
      "target": "ES2022", // Supports top-level await
      "moduleResolution": "NodeNext",
      "skipLibCheck": true, // Avoid type errors from node_modules
      "strict": true // Enable strict type-checking options
    },
    "include": ["*.ts"]
}
Transpile from TypeScript to JavaScript.tsc
Transpile from TypeScript to JavaScript.
tsc
tsc
Run the code with the following command:node index.js
Run the code with the following command:
node index.js
node index.js
Clean up resources
If you want to clean up and remove an Azure OpenAI resource, you can delete the resource or resource group. Deleting the resource group also deletes any other resources associated with it.
Azure portal
Azure CLI
Use this article to get started using the Azure OpenAI .NET SDK to deploy and use the GPT-4 Turbo with Vision model.
Prerequisites
An Azure subscription. You cancreate one for free.
The .NET 8.0 SDK
An Azure OpenAI Service resource with a GPT-4 Turbo with Vision model deployed. SeeGPT-4 and GPT-4 Turbo Preview model availabilityfor available regions. For more information about resource creation, see theresource deployment guide.
Microsoft Entra ID prerequisites
For the recommended keyless authentication with Microsoft Entra ID, you need to:
Install theAzure CLIused for keyless authentication with Microsoft Entra ID.
Assign theCognitive Services Userrole to your user account. You can assign roles in the Azure portal underAccess control (IAM)>Add role assignment.
Cognitive Services User
Set up
Create a new foldervision-quickstartand go to the quickstart folder with the following command:mkdir vision-quickstart && cd vision-quickstart
Create a new foldervision-quickstartand go to the quickstart folder with the following command:
vision-quickstart
mkdir vision-quickstart && cd vision-quickstart
mkdir vision-quickstart && cd vision-quickstart
Create a new console application with the following command:dotnet new console
Create a new console application with the following command:
dotnet new console
dotnet new console
Install theOpenAI .NET client librarywith thedotnet add packagecommand:dotnet add package Azure.AI.OpenAI
Install theOpenAI .NET client librarywith thedotnet add packagecommand:
dotnet add package Azure.AI.OpenAI
dotnet add package Azure.AI.OpenAI
For therecommendedkeyless authentication with Microsoft Entra ID, install theAzure.Identitypackage with:dotnet add package Azure.Identity
For therecommendedkeyless authentication with Microsoft Entra ID, install theAzure.Identitypackage with:
dotnet add package Azure.Identity
dotnet add package Azure.Identity
For therecommendedkeyless authentication with Microsoft Entra ID, sign in to Azure with the following command:az login
For therecommendedkeyless authentication with Microsoft Entra ID, sign in to Azure with the following command:
az login
az login
Retrieve resource information
You need to retrieve the following information to authenticate your application with your Azure OpenAI resource:
Microsoft Entra ID
API key
AZURE_OPENAI_ENDPOINT
AZURE_OPENAI_DEPLOYMENT_NAME
OPENAI_API_VERSION
Learn more aboutkeyless authenticationandsetting environment variables.
AZURE_OPENAI_ENDPOINT
AZURE_OPENAI_API_KEY
KEY1
KEY2
AZURE_OPENAI_DEPLOYMENT_NAME
OPENAI_API_VERSION
Learn more aboutfinding API keysandsetting environment variables.
Important
Use API keys with caution. Don't include the API key directly in your code, and never post it publicly. If you use an API key, store it securely in Azure Key Vault. For more information about using API keys securely in your apps, seeAPI keys with Azure Key Vault.
For more information about AI services security, seeAuthenticate requests to Azure AI services.
Run the quickstart
The sample code in this quickstart uses Microsoft Entra ID for the recommended keyless authentication. If you prefer to use an API key, you can replace theDefaultAzureCredentialobject with anAzureKeyCredentialobject.
DefaultAzureCredential
AzureKeyCredential
Microsoft Entra ID
API key
AzureOpenAIClient openAIClient = new AzureOpenAIClient(new Uri(endpoint), new DefaultAzureCredential());
AzureOpenAIClient openAIClient = new AzureOpenAIClient(new Uri(endpoint), new DefaultAzureCredential());
AzureOpenAIClient openAIClient = new AzureOpenAIClient(new Uri(endpoint), new AzureKeyCredential(key));
AzureOpenAIClient openAIClient = new AzureOpenAIClient(new Uri(endpoint), new AzureKeyCredential(key));
To run the quickstart, follow these steps:
Replace the contents ofProgram.cswith the following code and update the placeholder values with your own.using Azure;
using Azure.AI.OpenAI;
using Azure.Identity;
using OpenAI.Chat; // Required for Passwordless auth

string deploymentName = "gpt-4";

string endpoint = Environment.GetEnvironmentVariable("AZURE_OPENAI_ENDPOINT") ?? "https://<your-resource-name>.openai.azure.com/";
string key = Environment.GetEnvironmentVariable("AZURE_OPENAI_API_KEY") ?? "<your-key>";

// Use the recommended keyless credential instead of the AzureKeyCredential credential.
AzureOpenAIClient openAIClient = new AzureOpenAIClient(new Uri(endpoint), new DefaultAzureCredential()); 
//AzureOpenAIClient openAIClient = new AzureOpenAIClient(new Uri(endpoint), new AzureKeyCredential(key));

var chatClient = openAIClient.GetChatClient(deploymentName);

var imageUri = "YOUR_IMAGE_URL";

var chatMessages = new List<ChatMessage>
{
    new SystemChatMessage("You are a helpful assistant."),
    new UserChatMessage($"Describe this picture: {imageUrl}")
};

ChatCompletion chatCompletion = await chatClient.CompleteChatAsync(chatMessages);

Console.WriteLine($"[ASSISTANT]:");
Console.WriteLine($"{chatCompletion.Content[0].Text}");
Replace the contents ofProgram.cswith the following code and update the placeholder values with your own.
Program.cs
using Azure;
using Azure.AI.OpenAI;
using Azure.Identity;
using OpenAI.Chat; // Required for Passwordless auth

string deploymentName = "gpt-4";

string endpoint = Environment.GetEnvironmentVariable("AZURE_OPENAI_ENDPOINT") ?? "https://<your-resource-name>.openai.azure.com/";
string key = Environment.GetEnvironmentVariable("AZURE_OPENAI_API_KEY") ?? "<your-key>";

// Use the recommended keyless credential instead of the AzureKeyCredential credential.
AzureOpenAIClient openAIClient = new AzureOpenAIClient(new Uri(endpoint), new DefaultAzureCredential()); 
//AzureOpenAIClient openAIClient = new AzureOpenAIClient(new Uri(endpoint), new AzureKeyCredential(key));

var chatClient = openAIClient.GetChatClient(deploymentName);

var imageUri = "YOUR_IMAGE_URL";

var chatMessages = new List<ChatMessage>
{
    new SystemChatMessage("You are a helpful assistant."),
    new UserChatMessage($"Describe this picture: {imageUrl}")
};

ChatCompletion chatCompletion = await chatClient.CompleteChatAsync(chatMessages);

Console.WriteLine($"[ASSISTANT]:");
Console.WriteLine($"{chatCompletion.Content[0].Text}");
using Azure;
using Azure.AI.OpenAI;
using Azure.Identity;
using OpenAI.Chat; // Required for Passwordless auth

string deploymentName = "gpt-4";

string endpoint = Environment.GetEnvironmentVariable("AZURE_OPENAI_ENDPOINT") ?? "https://<your-resource-name>.openai.azure.com/";
string key = Environment.GetEnvironmentVariable("AZURE_OPENAI_API_KEY") ?? "<your-key>";

// Use the recommended keyless credential instead of the AzureKeyCredential credential.
AzureOpenAIClient openAIClient = new AzureOpenAIClient(new Uri(endpoint), new DefaultAzureCredential()); 
//AzureOpenAIClient openAIClient = new AzureOpenAIClient(new Uri(endpoint), new AzureKeyCredential(key));

var chatClient = openAIClient.GetChatClient(deploymentName);

var imageUri = "YOUR_IMAGE_URL";

var chatMessages = new List<ChatMessage>
{
    new SystemChatMessage("You are a helpful assistant."),
    new UserChatMessage($"Describe this picture: {imageUrl}")
};

ChatCompletion chatCompletion = await chatClient.CompleteChatAsync(chatMessages);

Console.WriteLine($"[ASSISTANT]:");
Console.WriteLine($"{chatCompletion.Content[0].Text}");
Run the application using thedotnet runcommand or the run button at the top of Visual Studio:dotnet run
Run the application using thedotnet runcommand or the run button at the top of Visual Studio:
dotnet run
dotnet run
dotnet run
Output
The output of the application will be a description of the image you provided in theimageUrivariable. The assistant will analyze the image and provide a detailed description based on its content.
imageUri
Clean up resources
If you want to clean up and remove an Azure OpenAI resource, you can delete the resource or resource group. Deleting the resource group also deletes any other resources associated with it.
Azure portal
Azure CLI
Next steps
Get started with multimodal vision chat apps using Azure OpenAI AI App template
Learn more about these APIs in theVision-enabled models how-to guide
GPT-4 Turbo with Vision frequently asked questions
GPT-4 Turbo with Vision API reference
Feedback
Was this page helpful?
Additional resources