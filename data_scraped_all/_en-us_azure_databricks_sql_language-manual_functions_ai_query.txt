Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
ai_queryfunction
ai_query
Article
2025-04-04
3 contributors
In this article
Applies to:Databricks SQLDatabricks Runtime
Important
This feature is inPublic Preview.
Invokes an existing Azure DatabricksModel Serving endpointand parses and returns its response.
To useai_queryin production workflows, seePerform batch LLM inference using AI Functions.
ai_query
Requirements
This function is not available on Azure Databricks SQL Classic.
This function is not available on Azure Databricks SQL Classic.
You must enableAzure Private Linkto use this feature on pro SQL warehouses.
You must enableAzure Private Linkto use this feature on pro SQL warehouses.
Databricks Runtime 15.4 or above is recommended. Using Databricks Runtime 15.3 or below might result in slower performance speeds.
Databricks Runtime 15.4 or above is recommended. Using Databricks Runtime 15.3 or below might result in slower performance speeds.
Your workspace must be in a supportedModel Serving region.
Your workspace must be in a supportedModel Serving region.
An existing model serving endpoint with your model loaded. If you are using a Databricks hosted foundation model, an endpoint is created for you. Otherwise, seeCreate custom model serving endpointsorCreate foundation model serving endpoints.
An existing model serving endpoint with your model loaded. If you are using a Databricks hosted foundation model, an endpoint is created for you. Otherwise, seeCreate custom model serving endpointsorCreate foundation model serving endpoints.
Querying Foundation Model APIs is enabled by default. To query endpoints that servecustom modelsorexternal models:EnableAI_Query for Custom Models and External Modelsin theDatabricks Previews UI.
Querying Foundation Model APIs is enabled by default. To query endpoints that servecustom modelsorexternal models:
EnableAI_Query for Custom Models and External Modelsin theDatabricks Previews UI.
ThecurrentDLT warehouse channeldoes not use the latest Databricks Runtime version that supportsai_query(). Set thepipelines.channelin the table properties as'preview'to useai_query().> create or replace materialized view
    ai_query_mv
    TBLPROPERTIES('pipelines.channel' = 'PREVIEW') AS
  SELECT
    ai_query("databricks-dbrx-instruct", text) as response
  FROM
    messages
  LIMIT 10;
ThecurrentDLT warehouse channeldoes not use the latest Databricks Runtime version that supportsai_query(). Set thepipelines.channelin the table properties as'preview'to useai_query().
ai_query()
pipelines.channel
'preview'
ai_query()
> create or replace materialized view
    ai_query_mv
    TBLPROPERTIES('pipelines.channel' = 'PREVIEW') AS
  SELECT
    ai_query("databricks-dbrx-instruct", text) as response
  FROM
    messages
  LIMIT 10;
> create or replace materialized view
    ai_query_mv
    TBLPROPERTIES('pipelines.channel' = 'PREVIEW') AS
  SELECT
    ai_query("databricks-dbrx-instruct", text) as response
  FROM
    messages
  LIMIT 10;
Syntax
To query an endpoint that serves afoundation model:
ai_query(endpoint, request)
ai_query(endpoint, request)
To query a custom model serving endpoint with amodel schema:
ai_query(endpoint, request)
ai_query(endpoint, request)
To query a custom model serving endpoint without a model schema:
ai_query(endpoint, request, returnType, failOnError)
ai_query(endpoint, request, returnType, failOnError)
Arguments and returns
endpoint
STRING
CAN QUERY
request
If the endpoint is an external model serving endpoint or Databricks Foundation Model APIs endpoint, the request must be aSTRING.
STRING
If the endpoint is a custom model serving endpoint, the request can be a single column or a struct expression. The struct field names should match the input feature names expected by the endpoint.
returnType
returnType
from_json
STRING
schema_of_json
In Databricks Runtime 15.2 and above, if this expression is not provided,ai_query()automatically infers the return type from the model schema of the custom model serving endpoint.
ai_query()
In Databricks Runtime 15.1 and below, this expression is required for querying a custom model serving endpoint.
failOnError
ai_query
IffailOnError => true, the function returns the same result as the existing behavior, which is the parsed response from the endpoint. The data type of the parsed response is inferred from the model type, the model schema endpoint, or thereturnTypeparameter in theai_queryfunction.
failOnError => true
returnType
ai_query
IffailOnError => false, the function returns aSTRUCTobject that contains the parsed response and the error status string.
failOnError => false
STRUCT
If the inference of the row succeeds, theerrorStatusfield isnull.
errorStatus
null
If the inference of the row fails due to model endpoint errors, theresponsefield isnull.
response
null
If the inference of the row fails due to other errors, the whole query fails.
failOnError
modelParameters
null
temperature
0.0
responseFormat
text
text
json_object
json_object
json_schema
json_schema
IffailOnError => falseand you have specifiedresponseFormat, the function returns the parsed response and the error status string as aSTRUCTobject.
failOnError => false
responseFormat
STRUCT
Depending on the JSON string type specified inresponseFormat, the following response is returned:
responseFormat
ForresponseFormat => '{"type": "text"}', the response is a string such as,âHere is the responseâ.
responseFormat => '{"type": "text"}'
âHere is the responseâ
ForresponseFormat => '{"type": "json_object"}', the response is a key-value pair JSON string, such as{âkeyâ: âvalueâ}.
responseFormat => '{"type": "json_object"}'
{âkeyâ: âvalueâ}
ForresponseFormat => '{"type": "json_schema", "json_schema"...}', the response is a JSON string.
responseFormat => '{"type": "json_schema", "json_schema"...}'
Example: Query a foundation model
To query an external model serving endpoint:
> SELECT ai_query(
    'my-external-model-openai-chat',
    'Describe Databricks SQL in 30 words.'
  ) AS summary

  "Databricks SQL is a cloud-based platform for data analytics and machine learning, providing a unified workspace for collaborative data exploration, analysis, and visualization using SQL queries."
> SELECT ai_query(
    'my-external-model-openai-chat',
    'Describe Databricks SQL in 30 words.'
  ) AS summary

  "Databricks SQL is a cloud-based platform for data analytics and machine learning, providing a unified workspace for collaborative data exploration, analysis, and visualization using SQL queries."
To query a foundation model supported by Databricks Foundation Model APIs:
> SELECT *,
  ai_query(
    'databricks-meta-llama-3-3-70b-instruct',
    "Can you tell me the name of the US state that serves the provided ZIP code? zip code: " || pickup_zip
    )
  FROM samples.nyctaxi.trips
  LIMIT 10
> SELECT *,
  ai_query(
    'databricks-meta-llama-3-3-70b-instruct',
    "Can you tell me the name of the US state that serves the provided ZIP code? zip code: " || pickup_zip
    )
  FROM samples.nyctaxi.trips
  LIMIT 10
Optionally, you can also wrap a call toai_query()in a UDF for function calling as follows:
ai_query()
CREATE FUNCTION correct_grammar(text STRING)
  RETURNS STRING
  RETURN ai_query(
    'databricks-meta-llama-3-3-70b-instruct',
    CONCAT('Correct this to standard English:\n', text));
> GRANT EXECUTE ON correct_grammar TO ds;
- DS fixes grammar issues in a batch.
> SELECT
    * EXCEPT text,
    correct_grammar(text) AS text
  FROM articles;
CREATE FUNCTION correct_grammar(text STRING)
  RETURNS STRING
  RETURN ai_query(
    'databricks-meta-llama-3-3-70b-instruct',
    CONCAT('Correct this to standard English:\n', text));
> GRANT EXECUTE ON correct_grammar TO ds;
- DS fixes grammar issues in a batch.
> SELECT
    * EXCEPT text,
    correct_grammar(text) AS text
  FROM articles;
Example: Query a traditional ML model
To query a custom model or a traditional ML model serving endpoint:
> SELECT text, ai_query(
    endpoint => 'spam-classification-endpoint',
    request => named_struct(
      'timestamp', timestamp,
      'sender', from_number,
      'text', text),
    returnType => 'BOOLEAN') AS is_spam
  FROM messages
  LIMIT 10

> SELECT ai_query(
    'weekly-forecast',
    request => struct(*),
    returnType => 'FLOAT') AS predicted_revenue
  FROM retail_revenue

> SELECT ai_query(
    'custom-llama-chat',
    request => named_struct("messages",
        ARRAY(named_struct("role", "user", "content", "What is ML?"))),
    returnType => 'STRUCT<candidates:ARRAY<STRING>>')

  {"candidates":["ML stands for Machine Learning. It's a subfield of Artificial Intelligence that involves the use of algorithms and statistical models to enable machines to learn from data, make decisions, and improve their performance on a specific task over time."]}
> SELECT text, ai_query(
    endpoint => 'spam-classification-endpoint',
    request => named_struct(
      'timestamp', timestamp,
      'sender', from_number,
      'text', text),
    returnType => 'BOOLEAN') AS is_spam
  FROM messages
  LIMIT 10

> SELECT ai_query(
    'weekly-forecast',
    request => struct(*),
    returnType => 'FLOAT') AS predicted_revenue
  FROM retail_revenue

> SELECT ai_query(
    'custom-llama-chat',
    request => named_struct("messages",
        ARRAY(named_struct("role", "user", "content", "What is ML?"))),
    returnType => 'STRUCT<candidates:ARRAY<STRING>>')

  {"candidates":["ML stands for Machine Learning. It's a subfield of Artificial Intelligence that involves the use of algorithms and statistical models to enable machines to learn from data, make decisions, and improve their performance on a specific task over time."]}
Examples for advanced scenarios
The following sections provide examples for advanced use cases like error handling or how to incorporateai_queryinto a user-defined function.
ai_query
Concatenate the prompt and inference column
There are multiple ways to concatenate the prompt and the inference column, such as using||,CONCAT(), orformat_string():
||
CONCAT()
format_string()
SELECT
CONCAT('${prompt}', ${input_column_name}) AS concatenated_prompt
FROM ${input_table_name};
SELECT
CONCAT('${prompt}', ${input_column_name}) AS concatenated_prompt
FROM ${input_table_name};
Alternatively:
SELECT
'${prompt}' || ${input_column_name} AS concatenated_prompt
FROM ${input_table_name};
SELECT
'${prompt}' || ${input_column_name} AS concatenated_prompt
FROM ${input_table_name};
Or usingformat_string():
format_string()
SELECT
format_string('%s%s', '${prompt}', ${input_column_name}) AS concatenated_prompt
FROM ${input_table_name};
SELECT
format_string('%s%s', '${prompt}', ${input_column_name}) AS concatenated_prompt
FROM ${input_table_name};
Configure a model by passing model parameters
Customize model behavior by passing specific parameters such as maximum tokens and temperature. For example:
SELECT text, ai_query(
    "databricks-meta-llama-3-3-70b-instruct",
    "Please summarize the following article: " || text,
    modelParameters => named_struct('max_tokens', 100, 'temperature', 0.7)
) AS summary
FROM uc_catalog.schema.table;
SELECT text, ai_query(
    "databricks-meta-llama-3-3-70b-instruct",
    "Please summarize the following article: " || text,
    modelParameters => named_struct('max_tokens', 100, 'temperature', 0.7)
) AS summary
FROM uc_catalog.schema.table;
Handle errors usingfailOnError
failOnError
Use thefailOnErrorargument forai_queryto handle errors. The following example shows how to make sure that if one row has an error, it won't stop the whole query from running. SeeArguments and returnsfor expected behaviors based on how this argument is set.
failOnError
ai_query
SELECT text, ai_query(
    "databricks-meta-llama-3-3-70b-instruct",
    "Summarize the given text comprehensively, covering key points and main ideas concisely while retaining relevant details and examples. Ensure clarity and accuracy without unnecessary repetition or omissions: " || text,
failOnError => false
) AS summary
FROM uc_catalog.schema.table;
SELECT text, ai_query(
    "databricks-meta-llama-3-3-70b-instruct",
    "Summarize the given text comprehensively, covering key points and main ideas concisely while retaining relevant details and examples. Ensure clarity and accuracy without unnecessary repetition or omissions: " || text,
failOnError => false
) AS summary
FROM uc_catalog.schema.table;
Enforce output schema with structured output
Ensure that the output conforms to a specific schema for easier downstream processing usingresponseFormat.
responseFormat
The following example enforces a JSON schema response format:
SELECT ai_query(
    "databricks-meta-llama-3-3-70b-instruct",
    "Extract research paper details from the following abstract: " || abstract,
    responseFormat => 'STRUCT<research_paper_extraction:STRUCT<title:STRING, authors:ARRAY<STRING>, abstract:STRING, keywords:ARRAY<STRING>>>'
)
FROM research_papers;
SELECT ai_query(
    "databricks-meta-llama-3-3-70b-instruct",
    "Extract research paper details from the following abstract: " || abstract,
    responseFormat => 'STRUCT<research_paper_extraction:STRUCT<title:STRING, authors:ARRAY<STRING>, abstract:STRING, keywords:ARRAY<STRING>>>'
)
FROM research_papers;
Alternatively, using a DDL style JSON schema:
SELECT ai_query(
    "databricks-meta-llama-3-3-70b-instruct",
    "Extract research paper details from the following abstract: " || abstract,
    responseFormat => '{
      "type": "json_schema",
      "json_schema": {
        "name": "research_paper_extraction",
        "schema": {
          "type": "object",
          "properties": {
            "title": {"type": "string"},
            "authors": {"type": "array", "items": {"type": "string"}},
            "abstract": {"type": "string"},
            "keywords": {"type": "array", "items": {"type": "string"}}
          }
        }
      },
      "strict": true
    }'
)
FROM research_papers;
SELECT ai_query(
    "databricks-meta-llama-3-3-70b-instruct",
    "Extract research paper details from the following abstract: " || abstract,
    responseFormat => '{
      "type": "json_schema",
      "json_schema": {
        "name": "research_paper_extraction",
        "schema": {
          "type": "object",
          "properties": {
            "title": {"type": "string"},
            "authors": {"type": "array", "items": {"type": "string"}},
            "abstract": {"type": "string"},
            "keywords": {"type": "array", "items": {"type": "string"}}
          }
        }
      },
      "strict": true
    }'
)
FROM research_papers;
An expected output might look like:
{ "title": "Understanding AI Functions in Databricks", "authors": ["Alice Smith", "Bob Jones"], "abstract": "This paper explains how AI functions can be integrated into data workflows.", "keywords": ["Databricks", "AI", "LLM"] }
{ "title": "Understanding AI Functions in Databricks", "authors": ["Alice Smith", "Bob Jones"], "abstract": "This paper explains how AI functions can be integrated into data workflows.", "keywords": ["Databricks", "AI", "LLM"] }
Useai_queryin user-defined functions
ai_query
You can wrap a call toai_queryin a UDF, making it easy to use functions across different workflows and share them.
ai_query
CREATE FUNCTION correct_grammar(text STRING)
  RETURNS STRING
  RETURN ai_query(
    'databricks-meta-llama-3-3-70b-instruct',
    CONCAT('Correct this to standard English:\n', text));

GRANT EXECUTE ON correct_grammar TO ds;

SELECT
    * EXCEPT text,
    correct_grammar(text) AS text
  FROM articles;
CREATE FUNCTION correct_grammar(text STRING)
  RETURNS STRING
  RETURN ai_query(
    'databricks-meta-llama-3-3-70b-instruct',
    CONCAT('Correct this to standard English:\n', text));

GRANT EXECUTE ON correct_grammar TO ds;

SELECT
    * EXCEPT text,
    correct_grammar(text) AS text
  FROM articles;
Feedback
Was this page helpful?
Additional resources