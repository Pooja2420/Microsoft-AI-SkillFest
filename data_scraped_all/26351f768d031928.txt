Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
What is Image Analysis?
Article
2025-04-17
4 contributors
In this article
The Azure AI Vision Image Analysis service can extract a wide variety of visual features from your images. For example, it can determine whether an image contains adult content, find specific brands or objects, or find human faces.
The latest version of Image Analysis, 4.0, which is now in general availability, has new features like synchronous OCR and people detection. We recommend you use this version going forward.
You can use Image Analysis through a client library SDK or by calling theREST APIdirectly. Follow thequickstartto get started.
Quickstart
Or, you can try out the capabilities of Image Analysis quickly and easily in your browser using Vision Studio.
Try Vision Studio
This documentation contains the following types of articles:
Thequickstartsare step-by-step instructions that let you make calls to the service and get results in a short period of time.
Thehow-to guidescontain instructions for using the service in more specific or customized ways.
Theconceptual articlesprovide in-depth explanations of the service's functionality and features.
For a more structured approach, follow a Training module for Image Analysis.
Analyze images with the Azure AI Vision service
Image Analysis versions
Important
Select the Image Analysis API version that best fits your requirements.
We recommend you use the Image Analysis 4.0 API if it supports your use case. Use version 3.2 if your use case is not yet supported by 4.0.
You'll also need to use version 3.2 if you want to do image captioning and your Vision resource is outside the supported Azure regions. The image captioning feature in Image Analysis 4.0 is only supported in certain Azure regions. Image captioning in version 3.2 is available in all Azure AI Vision regions. SeeRegion availability.
Analyze Image
You can analyze images to provide insights about their visual features and characteristics. All of the features in this table are provided by the Analyze Image API. Follow aquickstartto get started.
Product Recognition (v4.0 preview only) (deprecated)
Important
This feature is now deprecated. On March 31, 2025, Azure AI Image Analysis 4.0 Custom Image Classification, Custom Object Detection, and Product Recognition preview API will be retired. After this date, API calls to these services will fail.
To maintain a smooth operation of your models, transition toAzure AI Custom Vision, which is now generally available. Custom Vision offers similar functionality to these retiring features.
The Product Recognition APIs let you analyze photos of shelves in a retail store. You can detect the presence or absence of products and get their bounding box coordinates. Use it in combination with model customization to train a model to identify your specific products. You can also compare Product Recognition results to your store's planogram document.
Product Recognition
Multimodal embeddings (v4.0 only)
The multimodal embeddings APIs enable thevectorizationof images and text queries. They convert images to coordinates in a multi-dimensional vector space. Then, incoming text queries can also be converted to vectors, and images can be matched to the text based on semantic closeness. This allows the user to search a set of images using text, without needing to use image tags or other metadata. Semantic closeness often produces better results in search.
The2024-02-01API includes a multi-lingual model that supports text search in 102 languages. The original English-only model is still available, but it cannot be combined with the new model in the same search index. If you vectorized text and images using the English-only model, these vectors wonât be compatible with multi-lingual text and image vectors.
2024-02-01
These APIs are only available in certain geographic regions. SeeRegion availability.
Multimodal embeddings
Background removal (v4.0 preview only)
Important
This feature is now deprecated. On March 31, 2025, the Azure AI Image Analysis 4.0 Segment API and background removal service will be retired. All requests to this service will fail after this date.
The segmentation feature of the open-sourceFlorence 2 modelmight meet your needs. It returns an alpha map marking the difference between foreground and background, but it doesn't edit the original image to remove the background. Install the Florence 2 model and try out its Region to segmentation feature.
For full-featured background removal, consider a third-party utility likeBiRefNet.
Service limits
Input requirements
Version 4.0
Version 3.2
Image Analysis works on images that meet the following requirements:
The image must be presented in JPEG, PNG, GIF, BMP, WEBP, ICO, TIFF, or MPO format
The file size of the image must be less than 20 megabytes (MB)
The dimensions of the image must be greater than 50 x 50 pixels and less than 16,000 x 16,000 pixels
Tip
Input requirements for multimodal embeddings are different and are listed inMultimodal embeddings
Image Analysis works on images that meet the following requirements:
The image must be presented in JPEG, PNG, GIF, or BMP format
The file size of the image must be less than 4 megabytes (MB)
The dimensions of the image must be greater than 50 x 50 pixels and less than 16,000 x 16,000 pixels
Language support
Different Image Analysis features are available in different languages. See theLanguage supportpage.
Region availability
To use the Image Analysis APIs, you must create your Azure AI Vision resource in a supported region. The Image Analysis features are available in the following regions:
Data privacy and security
As with all of the Azure AI services, developers using the Azure AI Vision service should be aware of Microsoft's policies on customer data. See theAzure AI services pageon the Microsoft Trust Center to learn more.
Next steps
Get started with Image Analysis by following the quickstart guide in your preferred development language and API version:
Quickstart (v4.0): Vision REST API or client libraries
Quickstart (v3.2): Vision REST API or client libraries
Feedback
Was this page helpful?
Additional resources