Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Tracing using Application Insights
Article
2024-12-13
2 contributors
In this article
Determining the reasoning behind your agent's executions is important for troubleshooting and debugging. However, it can be difficult for complex agents for a number of reasons:
There could be a high number of steps involved in generating a response, making it hard to keep track of all of them.
The sequence of steps might vary based on user input.
The inputs/outputs at each stage might be long and deserve more detailed inspection.
Each step of an agent's runtime might also involve nesting. For example, an agent might invoke a tool, which uses another process, which then invokes another tool. If you notice strange or incorrect output from a top-level agent run, it might be difficult to determine exactly where in the execution the issue was introduced.
Tracing solves this by allowing you to clearly see the inputs and outputs of each primitive involved in a particular agent run, in the order in which they were invoked.
Creating an Application Insights resource
Tracing lets you analyze your agent's performance and behavior by using OpenTelemetry and adding an Application Insights resource to your Azure AI Foundry project.
To add an Application Insights resource, navigate to theTracingtab in theAzure AI Foundry portal, and create a new resource if you don't already have one.

Once created, you can get an Application Insights connection string, configure your agents, and observe the full execution path of your agent through Azure Monitor. Typically you want to enable tracing before you create an agent.
Trace an agent
First, usepip installto install OpenTelemetry and the Azure SDK tracing plugin.
pip install
pip install opentelemetry
pip install azure-core-tracing-opentelemetry
pip install opentelemetry
pip install azure-core-tracing-opentelemetry
You will also need an exporter to send results to your observability backend. You can print traces to the console or use a local viewer such asAspire Dashboard. To connect to Aspire Dashboard or another OpenTelemetry compatible backend, install the OpenTelemetry Protocol (OTLP) exporter.
pip install opentelemetry-exporter-otlp
pip install opentelemetry-exporter-otlp
Once you have the packages installed, you can use one the following Python samples to implement tracing with your agents. Samples that use console tracing display the results locally in the console. Samples that use Azure Monitor send the traces to the Azure Monitor in theAzure AI Foundry portal, in theTracingtab in the left pane for the portal.
Note
There is a known bug in the agents tracing functionality. The bug will cause the agent's function tool to call related info (function names and parameter values, which could contain sensitive information) to be included in the traces even when content recording is not enabled.
Using Azure Monitor
Basic agent example
Agent example with function calling
Example with a stream event handler
Using console tracing
Basic agent example
Agent example with function calling
Example with a stream event handler
Feedback
Was this page helpful?
Additional resources