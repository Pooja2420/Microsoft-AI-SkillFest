Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Get started with the Azure OpenAI security building block
Article
2024-11-12
7 contributors
In this article
This article shows you how to create and use the Azure OpenAI security building block sample. The purpose is to demonstrate Azure OpenAI account provisioning with role-based access control (RBAC) for keyless (Microsoft Entra ID) authentication to Azure OpenAI. This chat app sample also includes all the infrastructure and configuration needed to provision Azure OpenAI resources and deploy the app to Azure Container Apps using the Azure Developer CLI.
By following the instructions in this article, you will:
Deploy a secure Azure Container chat app.
Use managed identity for Azure OpenAI access.
Chat with an Azure OpenAI Large Language Model (LLM) using the OpenAI library.
Once you complete this article, you can start modifying the new project with your custom code and data.
Note
This article uses one or moreAI app templatesas the basis for the examples and guidance in the article. AI app templates provide you with well-maintained, easy to deploy reference implementations that help to ensure a high-quality starting point for your AI apps.
Architectural overview
A simple architecture of the chat app is shown in the following diagram:
The chat app runs as an Azure Container App. The app uses managed identity via Microsoft Entra ID to authenticate with Azure OpenAI, instead of an API key. The chat app uses Azure OpenAI to generate responses to user messages.
The application architecture relies on the following services and components:
Azure OpenAIrepresents the AI provider that we send the user's queries to.
Azure Container Appsis the container environment where the application is hosted.
Managed Identityhelps us ensure best-in-class security and eliminates the requirement for you as a developer to securely manage a secret.
Bicep filesfor provisioning Azure resources, including Azure OpenAI, Azure Container Apps, Azure Container Registry, Azure Log Analytics, and RBAC roles.
Microsoft AI Chat Protocolprovides standardized API contracts across AI solutions and languages. The chat app conforms to the Microsoft AI Chat Protocol, which allows the evaluations app to run against any chat app that conforms to the protocol.
A PythonQuartthat uses theopenaipackage to generate responses to user messages.
openai
A basic HTML/JavaScript frontend that streams responses from the backend usingJSON Linesover aReadableStream.
A Blazor web app that uses theAzure.AI.OpenAINuGet package to generate responses to user messages.
A TypeScript web app that uses theopenainpm package to generate responses to user messages.
Cost
In an attempt to keep pricing as low as possible in this sample, most resources use a basic or consumption pricing tier. Alter your tier level as needed based on your intended usage. To stop incurring charges, delete the resources when you're done with the article.
Learn more aboutcost in the sample repo.
Learn more aboutcost in the sample repo.
Learn more aboutcost in the sample repo.
Prerequisites
Adevelopment containerenvironment is available with all dependencies required to complete this article. You can run the development container in GitHub Codespaces (in a browser) or locally using Visual Studio Code.
To use this article, you need to fulfill the following prerequisites:
GitHub Codespaces (recommended)
Visual Studio Code
An Azure subscription -Create one for free
An Azure subscription -Create one for free
Azure account permissions - Your Azure Account must haveMicrosoft.Authorization/roleAssignments/writepermissions, such asUser Access AdministratororOwner.
Azure account permissions - Your Azure Account must haveMicrosoft.Authorization/roleAssignments/writepermissions, such asUser Access AdministratororOwner.
Microsoft.Authorization/roleAssignments/write
GitHub account
GitHub account
An Azure subscription -Create one for free
An Azure subscription -Create one for free
Azure account permissions - Your Azure Account must haveMicrosoft.Authorization/roleAssignments/writepermissions, such asUser Access AdministratororOwner.
Azure account permissions - Your Azure Account must haveMicrosoft.Authorization/roleAssignments/writepermissions, such asUser Access AdministratororOwner.
Microsoft.Authorization/roleAssignments/write
Azure Developer CLI
Azure Developer CLI
Docker Desktop- start Docker Desktop if it's not already running
Docker Desktop- start Docker Desktop if it's not already running
Visual Studio Code
Visual Studio Code
Dev Container Extension
Dev Container Extension
Open development environment
Use the following instructions to deploy a preconfigured development environment containing all required dependencies to complete this article.
GitHub Codespaces (recommended)
Visual Studio Code
GitHub Codespacesruns a development container managed by GitHub withVisual Studio Code for the Webas the user interface. For the most straightforward development environment, use GitHub Codespaces so that you have the correct developer tools and dependencies preinstalled to complete this article.
Important
All GitHub accounts can use Codespaces for up to 60 hours free each month with 2 core instances. For more information, seeGitHub Codespaces monthly included storage and core hours.
Use the following steps to create a new GitHub Codespace on themainbranch of theAzure-Samples/openai-chat-app-quickstartGitHub repository.
main
Azure-Samples/openai-chat-app-quickstart
Right-click on the following button, and selectOpen link in new window. This action allows you to have the development environment and the documentation available for review.
Right-click on the following button, and selectOpen link in new window. This action allows you to have the development environment and the documentation available for review.
On theCreate codespacepage, review and then selectCreate new codespace
On theCreate codespacepage, review and then selectCreate new codespace

Wait for the codespace to start. This startup process can take a few minutes.
Wait for the codespace to start. This startup process can take a few minutes.
Sign in to Azure with the Azure Developer CLI in the terminal at the bottom of the screen.azd auth login
Sign in to Azure with the Azure Developer CLI in the terminal at the bottom of the screen.
azd auth login
azd auth login
Copy the code from the terminal and then paste it into a browser. Follow the instructions to authenticate with your Azure account.
Copy the code from the terminal and then paste it into a browser. Follow the instructions to authenticate with your Azure account.
The remaining tasks in this article take place in the context of this development container.
Use the following steps to create a new GitHub Codespace on themainbranch of theAzure-Samples/openai-chat-app-quickstart-dotnetGitHub repository.
main
Azure-Samples/openai-chat-app-quickstart-dotnet
Right-click on the following button, and selectOpen link in new window. This action allows you to have the development environment and the documentation available for review.
Right-click on the following button, and selectOpen link in new window. This action allows you to have the development environment and the documentation available for review.
On theCreate codespacepage, review and then selectCreate codespace
On theCreate codespacepage, review and then selectCreate codespace

Wait for the codespace to start. This startup process can take a few minutes.
Wait for the codespace to start. This startup process can take a few minutes.
Sign in to Azure with the Azure Developer CLI in the terminal at the bottom of the screen.azd auth login
Sign in to Azure with the Azure Developer CLI in the terminal at the bottom of the screen.
azd auth login
azd auth login
Copy the code from the terminal and then paste it into a browser. Follow the instructions to authenticate with your Azure account.
Copy the code from the terminal and then paste it into a browser. Follow the instructions to authenticate with your Azure account.
The remaining tasks in this article take place in the context of this development container.
Use the following steps to create a new GitHub Codespace on themainbranch of theAzure-Samples/openai-chat-app-quickstart-javascriptGitHub repository.
main
Azure-Samples/openai-chat-app-quickstart-javascript
Right-click on the following button, and selectOpen link in new window. This action allows you to have the development environment and the documentation available for review.

On theCreate codespacepage, review and then selectCreate new codespace
On theCreate codespacepage, review and then selectCreate new codespace

Wait for the codespace to start. This startup process can take a few minutes.
Wait for the codespace to start. This startup process can take a few minutes.
Sign in to Azure with the Azure Developer CLI in the terminal at the bottom of the screen.azd auth login
Sign in to Azure with the Azure Developer CLI in the terminal at the bottom of the screen.
azd auth login
azd auth login
Copy the code from the terminal and then paste it into a browser. Follow the instructions to authenticate with your Azure account.
Copy the code from the terminal and then paste it into a browser. Follow the instructions to authenticate with your Azure account.
The remaining tasks in this article take place in the context of this development container.
TheDev Containers extensionfor Visual Studio Code requiresDockerto be installed on your local machine. The extension hosts the development container locally using the Docker host with the correct developer tools and dependencies preinstalled to complete this article.
Create a new local directory on your computer for the project.mkdir my-secure-chat-app
Create a new local directory on your computer for the project.
mkdir my-secure-chat-app
mkdir my-secure-chat-app
Navigate to the directory you created.cd my-secure-chat-app
Navigate to the directory you created.
cd my-secure-chat-app
cd my-secure-chat-app
Open Visual Studio Code in that directory:code .
Open Visual Studio Code in that directory:
code .
code .
Open a new terminal in Visual Studio Code.
Open a new terminal in Visual Studio Code.
Run the following AZD command to bring the GitHub repository to your local computer.azd init -t openai-chat-app-quickstart
Run the following AZD command to bring the GitHub repository to your local computer.
azd init -t openai-chat-app-quickstart
azd init -t openai-chat-app-quickstart
Open the Command Palette, search for and selectDev Containers: Open Folder in Containerto open the project in a dev container. Wait until the dev container opens before continuing.
Open the Command Palette, search for and selectDev Containers: Open Folder in Containerto open the project in a dev container. Wait until the dev container opens before continuing.
Sign in to Azure with the Azure Developer CLI.azd auth login
Sign in to Azure with the Azure Developer CLI.
azd auth login
azd auth login
The remaining exercises in this project take place in the context of this development container.
The remaining exercises in this project take place in the context of this development container.
Create a new local directory on your computer for the project.mkdir my-secure-chat-app
Create a new local directory on your computer for the project.
mkdir my-secure-chat-app
mkdir my-secure-chat-app
Navigate to the directory you created.cd my-secure-chat-app
Navigate to the directory you created.
cd my-secure-chat-app
cd my-secure-chat-app
Open Visual Studio Code in that directory:code .
Open Visual Studio Code in that directory:
code .
code .
Open a new terminal in Visual Studio Code.
Open a new terminal in Visual Studio Code.
Run the following AZD command to bring the GitHub repository to your local computer.azd init -t openai-chat-app-quickstart-dotnet
Run the following AZD command to bring the GitHub repository to your local computer.
azd init -t openai-chat-app-quickstart-dotnet
azd init -t openai-chat-app-quickstart-dotnet
Open the Command Palette, search for and selectDev Containers: Open Folder in Containerto open the project in a dev container. Wait until the dev container opens before continuing.
Open the Command Palette, search for and selectDev Containers: Open Folder in Containerto open the project in a dev container. Wait until the dev container opens before continuing.
Sign in to Azure with the Azure Developer CLI.azd auth login
Sign in to Azure with the Azure Developer CLI.
azd auth login
azd auth login
The remaining exercises in this project take place in the context of this development container.
The remaining exercises in this project take place in the context of this development container.
Create a new local directory on your computer for the project.mkdir my-secure-chat-app
Create a new local directory on your computer for the project.
mkdir my-secure-chat-app
mkdir my-secure-chat-app
Open the directory in Visual Studio Code.code my-secure-chat-app
Open the directory in Visual Studio Code.
code my-secure-chat-app
code my-secure-chat-app
Open a new terminal in Visual Studio Code.
Open a new terminal in Visual Studio Code.
Run the following AZD command to bring the GitHub repository to your local computer.azd init -t openai-chat-app-quickstart-javascript
Run the following AZD command to bring the GitHub repository to your local computer.
azd init -t openai-chat-app-quickstart-javascript
azd init -t openai-chat-app-quickstart-javascript
Open the Command Palette, search for and selectDev Containers: Open Folder in Containerto open the project in a dev container. Wait until the dev container opens before continuing.
Open the Command Palette, search for and selectDev Containers: Open Folder in Containerto open the project in a dev container. Wait until the dev container opens before continuing.
Sign in to Azure with the Azure Developer CLI.azd auth login
Sign in to Azure with the Azure Developer CLI.
azd auth login
azd auth login
The remaining exercises in this project take place in the context of this development container.
The remaining exercises in this project take place in the context of this development container.
Deploy and run
The sample repository contains all the code and configuration files for chat app Azure deployment. The following steps walk you through the sample chat app Azure deployment process.
Deploy chat app to Azure
Important
Azure resources created in this section incur immediate costs. These resources may accrue costs even if you interrupt the command before it is fully executed.
Run the following Azure Developer CLI command for Azure resource provisioning and source code deployment:azd up
Run the following Azure Developer CLI command for Azure resource provisioning and source code deployment:
azd up
azd up
Use the following table to answer the prompts:PromptAnswerEnvironment nameKeep it short and lowercase. Add your name or alias. For example,secure-chat. It's used as part of the resource group name.SubscriptionSelect the subscription to create the resources in.Location (for hosting)Select a location near you from the list.Location for the OpenAI modelSelect a location near you from the list. If the same location is available as your first location, select that.
Use the following table to answer the prompts:
secure-chat
Wait until app is deployed. Deployment usually takes between 5 and 10 minutes to complete.
Wait until app is deployed. Deployment usually takes between 5 and 10 minutes to complete.
Use chat app to ask questions to the Large Language Model
The terminal displays a URL after successful application deployment.
The terminal displays a URL after successful application deployment.
Select that URL labeledDeploying service webto open the chat application in a browser.
Select that URL labeledDeploying service webto open the chat application in a browser.
Deploying service web

In the browser, enter a question such as "Why is managed identity better than keys?".
In the browser, enter a question such as "Why is managed identity better than keys?".
The answer comes from Azure OpenAI and the result is displayed.
The answer comes from Azure OpenAI and the result is displayed.
Exploring the sample code
While OpenAI and Azure OpenAI Service rely on acommon Python client library, small code changes are needed when using Azure OpenAI endpoints. Let's see how this sample configures keyless authentication with Microsoft Entra ID and communicates with Azure OpenAI.
Configure authentication with managed identity
In this sample, thesrc\quartapp\chat.pyfile begins with configuring keyless authentication.
src\quartapp\chat.py
The following snippet uses theazure.identity.aiomodule to create an asynchronous Microsoft Entra authentication flow.
The following code snippet uses theAZURE_CLIENT_IDazdenvironment variable to create aManagedIdentityCredentialinstance capable of authenticating via user-assigned managed identity.
AZURE_CLIENT_ID
azd
user_assigned_managed_identity_credential = ManagedIdentityCredential(client_id=os.getenv("AZURE_CLIENT_ID"))
user_assigned_managed_identity_credential = ManagedIdentityCredential(client_id=os.getenv("AZURE_CLIENT_ID"))
Note
Theazdresource environment variables are provisioned duringazdapp deployment.
azd
azd
The following code snippet usesAZURE_TENANT_IDazdresource environment variable to create anAzureDeveloperCliCredentialinstance capable of authenticating with the current Microsoft Entra tenant.
AZURE_TENANT_ID
azd
azure_dev_cli_credential = AzureDeveloperCliCredential(tenant_id=os.getenv("AZURE_TENANT_ID"), process_timeout=60)
azure_dev_cli_credential = AzureDeveloperCliCredential(tenant_id=os.getenv("AZURE_TENANT_ID"), process_timeout=60)
The Azure Identity client library providescredentialsâpublic classes that implement the Azure Core library'sTokenCredentialprotocol. A credential represents a distinct authentication flow for acquiring an access token from Microsoft Entra ID. These credentials can be chained together to form an ordered sequence of authentication mechanisms to be attempted.
The following snippet creates aChainedTokenCredentialusing aManagedIdentityCredentialand anAzureDeveloperCliCredential:
ChainedTokenCredential
ManagedIdentityCredential
AzureDeveloperCliCredential
TheManagedIdentityCredentialis used for Azure Functions and Azure App Service. A user-assigned managed identity is supported by passing theclient_idtoManagedIdentityCredential.
ManagedIdentityCredential
client_id
ManagedIdentityCredential
TheAzureDeveloperCliCredentialis used for local development. It was set previously based on the Microsoft Entra tenant to use.
AzureDeveloperCliCredential
azure_credential = ChainedTokenCredential(
    user_assigned_managed_identity_credential,
    azure_dev_cli_credential
)
azure_credential = ChainedTokenCredential(
    user_assigned_managed_identity_credential,
    azure_dev_cli_credential
)
Tip
The order of the credentials is important, as the first valid Microsoft Entra access token is used. For more information, check out theChainedTokenCredential Overviewarticle.
The following code snippet gets the Azure OpenAI token provider based on the selected Azure credential.
This value is obtained by calling theazure.identity.aio.get_bearer_token_providerwith two arguments:
azure_credential: TheChainedTokenCredentialinstance created earlier to authenticate the request.
azure_credential: TheChainedTokenCredentialinstance created earlier to authenticate the request.
azure_credential
ChainedTokenCredential
https://cognitiveservices.azure.com/.default: Required one or more bearer token scopes. In this case, theAzure Cognitive Servicesendpoint.
https://cognitiveservices.azure.com/.default: Required one or more bearer token scopes. In this case, theAzure Cognitive Servicesendpoint.
https://cognitiveservices.azure.com/.default
token_provider = get_bearer_token_provider(
    azure_credential, "https://cognitiveservices.azure.com/.default"
)
token_provider = get_bearer_token_provider(
    azure_credential, "https://cognitiveservices.azure.com/.default"
)
The following lines check for the requiredAZURE_OPENAI_ENDPOINTandAZURE_OPENAI_CHATGPT_DEPLOYMENTazdresource environment variables, which are provisioned duringazdapp deployment. An error is thrown if a value isn't present.
AZURE_OPENAI_ENDPOINT
AZURE_OPENAI_CHATGPT_DEPLOYMENT
azd
azd
if not os.getenv("AZURE_OPENAI_ENDPOINT"):
    raise ValueError("AZURE_OPENAI_ENDPOINT is required for Azure OpenAI")
if not os.getenv("AZURE_OPENAI_CHATGPT_DEPLOYMENT"):
    raise ValueError("AZURE_OPENAI_CHATGPT_DEPLOYMENT is required for Azure OpenAI")
if not os.getenv("AZURE_OPENAI_ENDPOINT"):
    raise ValueError("AZURE_OPENAI_ENDPOINT is required for Azure OpenAI")
if not os.getenv("AZURE_OPENAI_CHATGPT_DEPLOYMENT"):
    raise ValueError("AZURE_OPENAI_CHATGPT_DEPLOYMENT is required for Azure OpenAI")
This snippet initializes the Azure OpenAI client, setting theapi_version,azure_endpoint, andazure_ad_token_provider(client_args) parameters:
api_version
azure_endpoint
azure_ad_token_provider
client_args
bp.openai_client = AsyncAzureOpenAI(
    api_version=os.getenv("AZURE_OPENAI_API_VERSION") or "2024-02-15-preview",
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
    azure_ad_token_provider=token_provider,
)
bp.openai_client = AsyncAzureOpenAI(
    api_version=os.getenv("AZURE_OPENAI_API_VERSION") or "2024-02-15-preview",
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
    azure_ad_token_provider=token_provider,
)
The following line sets the Azure OpenAI model deployment name for use in API calls:
bp.openai_model = os.getenv("AZURE_OPENAI_CHATGPT_DEPLOYMENT")
bp.openai_model = os.getenv("AZURE_OPENAI_CHATGPT_DEPLOYMENT")
Note
OpenAI uses themodelkeyword argument to specify what model to use. Azure OpenAI has the concept ofunique model deployments. When you use Azure OpenAI,modelshould refer to theunderlying deployment namechosen during Azure OpenAI model deployment.
model
model
Once this function completes, the client is properly configured and ready to interact with Azure OpenAI services.
Response stream using the OpenAI Client and model
Theresponse_streamhandles the chat completion call in the route. The following code snippet shows howopenai_clientandmodelare used.
response_stream
openai_client
model
async def response_stream():
    # This sends all messages, so API request may exceed token limits
    all_messages = [
        {"role": "system", "content": "You are a helpful assistant."},
    ] + request_messages

    chat_coroutine = bp.openai_client.chat.completions.create(
        # Azure OpenAI takes the deployment name as the model name
        model=bp.openai_model,
        messages=all_messages,
        stream=True,
    )
async def response_stream():
    # This sends all messages, so API request may exceed token limits
    all_messages = [
        {"role": "system", "content": "You are a helpful assistant."},
    ] + request_messages

    chat_coroutine = bp.openai_client.chat.completions.create(
        # Azure OpenAI takes the deployment name as the model name
        model=bp.openai_model,
        messages=all_messages,
        stream=True,
    )
Explore the sample code
.NET applications rely on theAzure.AI.OpenAIclient library to communicate with Azure OpenAI services, which takes a dependency on theOpenAIlibrary. The sample app configures keyless authentication using Microsoft Entra ID to communicate with Azure OpenAI.
Configure authentication and service registration
In this sample, keyless authentication is configured in theprogram.csfile. The following code snippet uses theAZURE_CLIENT_IDenvironment variable set byazdto create aManagedIdentityCredentialinstance capable of authenticating via user-assigned managed identity.
program.cs
AZURE_CLIENT_ID
azd
var userAssignedIdentityCredential = 
    new ManagedIdentityCredential(builder.Configuration.GetValue<string>("AZURE_CLIENT_ID"));
var userAssignedIdentityCredential = 
    new ManagedIdentityCredential(builder.Configuration.GetValue<string>("AZURE_CLIENT_ID"));
Note
Theazdresource environment variables are provisioned duringazdapp deployment.
azd
azd
The following code snippet uses theAZURE_TENANT_IDenvironment variable set byazdto create anAzureDeveloperCliCredentialinstance capable of authenticating locally using the account signed-in toazd.
AZURE_TENANT_ID
azd
azd
var azureDevCliCredential = new AzureDeveloperCliCredential(
    new AzureDeveloperCliCredentialOptions()
    { 
        TenantId = builder.Configuration.GetValue<string>("AZURE_TENANT_ID") 
    });
var azureDevCliCredential = new AzureDeveloperCliCredential(
    new AzureDeveloperCliCredentialOptions()
    { 
        TenantId = builder.Configuration.GetValue<string>("AZURE_TENANT_ID") 
    });
The Azure Identity client library provides credential classes that implement the Azure Core library'sTokenCredentialprotocol. A credential represents a distinct authentication flow for acquiring an access token from Microsoft Entra ID. These credentials can be chained together usingChainedTokenCredentialto form an ordered sequence of authentication mechanisms to be attempted.
ChainedTokenCredential
The following snippet registers theAzureOpenAIClientfor dependency injection and creates aChainedTokenCredentialusing aManagedIdentityCredentialand anAzureDeveloperCliCredential:
AzureOpenAIClient
ChainedTokenCredential
ManagedIdentityCredential
AzureDeveloperCliCredential
TheManagedIdentityCredentialis used for Azure Functions and Azure App Service. A user-assigned managed identity is supported using theAZURE_CLIENT_IDthat was provided to theManagedIdentityCredential.
ManagedIdentityCredential
AZURE_CLIENT_ID
ManagedIdentityCredential
TheAzureDeveloperCliCredentialis used for local development. It was set previously based on the Microsoft Entra tenant to use.
AzureDeveloperCliCredential
builder.Services.AddAzureClients(
    clientBuilder => {
        clientBuilder.AddClient<AzureOpenAIClient, AzureOpenAIClientOptions>((options, _, _)
            => new AzureOpenAIClient(
                new Uri(endpoint),
                new ChainedTokenCredential(
                    userAssignedIdentityCredential, azureDevCliCredential), options));
    });
builder.Services.AddAzureClients(
    clientBuilder => {
        clientBuilder.AddClient<AzureOpenAIClient, AzureOpenAIClientOptions>((options, _, _)
            => new AzureOpenAIClient(
                new Uri(endpoint),
                new ChainedTokenCredential(
                    userAssignedIdentityCredential, azureDevCliCredential), options));
    });
Tip
The order of the credentials is important, as the first valid Microsoft Entra access token is used. For more information, check out theChainedTokenCredential Overviewarticle.
Get chat completions using the Azure OpenAI client
The Blazor web app injects the registeredAzureOpenAIClientat the top of theHome.Razorcomponent:
AzureOpenAIClient
Home.Razor
@inject AzureOpenAIClient azureOpenAIClient
@inject AzureOpenAIClient azureOpenAIClient
When the user submits the form, theAzureOpenAIClientsends their prompt to the OpenAI model to generate a completion:
AzureOpenAIClient
ChatClient chatClient = azureOpenAIClient.GetChatClient("gpt-4o-mini");

messages.Add(new UserChatMessage(model.UserMessage));

ChatCompletion completion = await chatClient.CompleteChatAsync(messages);
    messages.Add(new SystemChatMessage(completion.Content[0].Text));
ChatClient chatClient = azureOpenAIClient.GetChatClient("gpt-4o-mini");

messages.Add(new UserChatMessage(model.UserMessage));

ChatCompletion completion = await chatClient.CompleteChatAsync(messages);
    messages.Add(new SystemChatMessage(completion.Content[0].Text));
Explore the sample code
While OpenAI and Azure OpenAI Service rely on aopenai(common JavaScript client library), small code changes are needed when using Azure OpenAI endpoints. Let's see how this sample configures keyless authentication with Microsoft Entra ID and communicates with Azure OpenAI.
Keyless authentication for each environment
The Azure Identity client library provides credential classes that implement the Azure Core library'sTokenCredentialprotocol. A credential represents a distinct authentication flow for acquiring an access token from Microsoft Entra ID. These credentials can be chained together usingChainedTokenCredentialto form an ordered sequence of authentication mechanisms to be attempted. This allows you to deploy the same code in both production and local development environments.
ChainedTokenCredential

Configure authentication with managed identity
In this sample, the./src/azure-authentication.tsprovides several functions to provide keyless authentication to Azure OpenAI.
./src/azure-authentication.ts
The first function,getChainedCredential(), returns the first valid Azure credential found in the chain.
getChainedCredential()
function getChainedCredential() {

    return new ChainedTokenCredential(
        new ManagedIdentityCredential(process.env.AZURE_CLIENT_ID!), 
        new AzureDeveloperCliCredential({
            tenantId: process.env.AZURE_TENANT_ID! ? process.env.AZURE_TENANT_ID! : undefined
          })
    );
}
function getChainedCredential() {

    return new ChainedTokenCredential(
        new ManagedIdentityCredential(process.env.AZURE_CLIENT_ID!), 
        new AzureDeveloperCliCredential({
            tenantId: process.env.AZURE_TENANT_ID! ? process.env.AZURE_TENANT_ID! : undefined
          })
    );
}
ManagedIdentityCredentialis attempted first. It's set up with the AZURE_CLIENT_ID environment variable in the production runtime and is capable of authenticating via user-assigned managed identity.
AzureDeveloperCliCredentialis attempted second. It's set up when a develop signs in with Azure CLIaz login.
az login
Tip
The order of the credentials is important, as the first valid Microsoft Entra access token is used. For more information, check out theChainedTokenCredential Overviewarticle.
Get bearer token for OpenAI
The second function in./src/azure-authentication.tsisgetTokenProvider(), which returns a callback that provides a bearer token scoped to theAzure Cognitive Servicesendpoint.
./src/azure-authentication.ts
getTokenProvider()
function getTokenProvider(): () => Promise<string> {
    const credential  = getChainedCredential();
    const scope = "https://cognitiveservices.azure.com/.default";
    return getBearerTokenProvider(credential, scope);
}
function getTokenProvider(): () => Promise<string> {
    const credential  = getChainedCredential();
    const scope = "https://cognitiveservices.azure.com/.default";
    return getBearerTokenProvider(credential, scope);
}
The preceding code snippet usesgetBearerTokenProviderto take the credential and the scope, then returns a callback that provides a bearer token.
getBearerTokenProvider
Create authenticated Azure OpenAI client
The third function in./src/azure-authentication.tsisgetOpenAiClient(), which returns the Azure OpenAI client.
./src/azure-authentication.ts
getOpenAiClient()
export function getOpenAiClient(): AzureOpenAI | undefined{
    try {

        if (!process.env.AZURE_OPENAI_ENDPOINT) {
            throw new Error("AZURE_OPENAI_ENDPOINT is required for Azure OpenAI");
        }
        if (!process.env.AZURE_OPENAI_CHAT_DEPLOYMENT) {
            throw new Error("AZURE_OPENAI_CHAT_DEPLOYMENT is required for Azure OpenAI");
        }

        const options = { 
            azureADTokenProvider: getTokenProvider(), 
            deployment: process.env.AZURE_OPENAI_CHAT_DEPLOYMENT!, 
            apiVersion: process.env.AZURE_OPENAI_API_VERSION! || "2024-02-15-preview",
            endpoint: process.env.AZURE_OPENAI_ENDPOINT!
        }

        // Create the Asynchronous Azure OpenAI client
        return new AzureOpenAI (options);

    } catch (error) {
        console.error('Error getting Azure OpenAI client: ', error);
    }
}
export function getOpenAiClient(): AzureOpenAI | undefined{
    try {

        if (!process.env.AZURE_OPENAI_ENDPOINT) {
            throw new Error("AZURE_OPENAI_ENDPOINT is required for Azure OpenAI");
        }
        if (!process.env.AZURE_OPENAI_CHAT_DEPLOYMENT) {
            throw new Error("AZURE_OPENAI_CHAT_DEPLOYMENT is required for Azure OpenAI");
        }

        const options = { 
            azureADTokenProvider: getTokenProvider(), 
            deployment: process.env.AZURE_OPENAI_CHAT_DEPLOYMENT!, 
            apiVersion: process.env.AZURE_OPENAI_API_VERSION! || "2024-02-15-preview",
            endpoint: process.env.AZURE_OPENAI_ENDPOINT!
        }

        // Create the Asynchronous Azure OpenAI client
        return new AzureOpenAI (options);

    } catch (error) {
        console.error('Error getting Azure OpenAI client: ', error);
    }
}
This code takes the options, including the correctly scoped token, and creates theAzureOpenAIclient
AzureOpenAI
Stream chat answer with Azure OpenAI
Use the following Fastify route handler in./src/openai-chat-api.tsto send a message to Azure OpenAI and stream the response.
./src/openai-chat-api.ts
import { FastifyReply, FastifyRequest } from 'fastify';
import { AzureOpenAI } from "openai";
import { getOpenAiClient } from './azure-authentication.js';
import { ChatCompletionChunk, ChatCompletionMessageParam } from 'openai/resources/chat/completions';

interface ChatRequestBody {
    messages: ChatCompletionMessageParam [];
  }

export async function chatRoute (request: FastifyRequest<{ Body: ChatRequestBody }>, reply: FastifyReply) {

    const requestMessages: ChatCompletionMessageParam[] = request?.body?.messages;
    const openaiClient: AzureOpenAI | undefined = getOpenAiClient();

    if (!openaiClient) {
      throw new Error("Azure OpenAI client is not configured");
    }

    const allMessages = [
      { role: "system", content: "You are a helpful assistant."},
      ...requestMessages
    ] as ChatCompletionMessageParam [];

    const chatCompletionChunks = await openaiClient.chat.completions.create({
      // Azure Open AI takes the deployment name as the model name
      model: process.env.AZURE_OPENAI_CHAT_DEPLOYMENT_MODEL || "gpt-4o-mini",
      messages: allMessages,
      stream: true

    })
    reply.raw.setHeader('Content-Type', 'text/html; charset=utf-8');
    reply.raw.setHeader('Cache-Control', 'no-cache');
    reply.raw.setHeader('Connection', 'keep-alive');
    reply.raw.flushHeaders();

    for await (const chunk of chatCompletionChunks as AsyncIterable<ChatCompletionChunk>) {
      for (const choice of chunk.choices) {
        reply.raw.write(JSON.stringify(choice) + "\n")
      }
    }

    reply.raw.end()

}
import { FastifyReply, FastifyRequest } from 'fastify';
import { AzureOpenAI } from "openai";
import { getOpenAiClient } from './azure-authentication.js';
import { ChatCompletionChunk, ChatCompletionMessageParam } from 'openai/resources/chat/completions';

interface ChatRequestBody {
    messages: ChatCompletionMessageParam [];
  }

export async function chatRoute (request: FastifyRequest<{ Body: ChatRequestBody }>, reply: FastifyReply) {

    const requestMessages: ChatCompletionMessageParam[] = request?.body?.messages;
    const openaiClient: AzureOpenAI | undefined = getOpenAiClient();

    if (!openaiClient) {
      throw new Error("Azure OpenAI client is not configured");
    }

    const allMessages = [
      { role: "system", content: "You are a helpful assistant."},
      ...requestMessages
    ] as ChatCompletionMessageParam [];

    const chatCompletionChunks = await openaiClient.chat.completions.create({
      // Azure Open AI takes the deployment name as the model name
      model: process.env.AZURE_OPENAI_CHAT_DEPLOYMENT_MODEL || "gpt-4o-mini",
      messages: allMessages,
      stream: true

    })
    reply.raw.setHeader('Content-Type', 'text/html; charset=utf-8');
    reply.raw.setHeader('Cache-Control', 'no-cache');
    reply.raw.setHeader('Connection', 'keep-alive');
    reply.raw.flushHeaders();

    for await (const chunk of chatCompletionChunks as AsyncIterable<ChatCompletionChunk>) {
      for (const choice of chunk.choices) {
        reply.raw.write(JSON.stringify(choice) + "\n")
      }
    }

    reply.raw.end()

}
The function gets the chat conversation, including any previous messages, and sends them to Azure OpenAI. As the stream chunks are returned from Azure OpenAI, the are sent to the client.
Other security considerations
This article demonstrates how the sample usesChainedTokenCredentialfor authenticating to the Azure OpenAI service.
ChainedTokenCredential
The sample also has aGitHub Actionthat scans the infrastructure-as-code files and generates a report containing any detected issues. To ensure continued best practices in your own repository, we recommend that anyone creating solutions based on our templates ensure that theGitHub secret scanning settingis enabled.
Consider other security measures, such as:
Restrict access to the appropriate set of app users using Microsoft Entra.
Restrict access to the appropriate set of app users using Microsoft Entra.
Protecting the Azure Container Apps instance with afirewalland/orVirtual Network.
Protecting the Azure Container Apps instance with afirewalland/orVirtual Network.
Clean up resources
Clean up Azure resources
The Azure resources created in this article are billed to your Azure subscription. If you don't expect to need these resources in the future, delete them to avoid incurring more charges.
To delete the Azure resources and remove the source code, run the following Azure Developer CLI command:
azd down --purge
azd down --purge
Clean up GitHub Codespaces
GitHub Codespaces
Visual Studio Code
Deleting the GitHub Codespaces environment ensures that you can maximize the amount of free per-core hours entitlement you get for your account.
Important
For more information about your GitHub account's entitlements, seeGitHub Codespaces monthly included storage and core hours.
Sign into theGitHub Codespaces dashboard.
Sign into theGitHub Codespaces dashboard.
Locate your currently running Codespaces sourced from theAzure-Samples/openai-chat-app-quickstartGitHub repository.
Locate your currently running Codespaces sourced from theAzure-Samples/openai-chat-app-quickstartGitHub repository.
Azure-Samples/openai-chat-app-quickstart
Open the context menu for the codespace and then selectDelete.
Open the context menu for the codespace and then selectDelete.
Sign into theGitHub Codespaces dashboard.
Sign into theGitHub Codespaces dashboard.
Locate your currently running Codespaces sourced from theAzure-Samples/openai-chat-app-quickstart-dotnetGitHub repository.
Locate your currently running Codespaces sourced from theAzure-Samples/openai-chat-app-quickstart-dotnetGitHub repository.
Azure-Samples/openai-chat-app-quickstart-dotnet
Open the context menu for the codespace and then selectDelete.
Open the context menu for the codespace and then selectDelete.
Sign into theGitHub Codespaces dashboard.
Sign into theGitHub Codespaces dashboard.
Locate your currently running Codespaces sourced from theAzure-Samples/openai-chat-app-quickstart-javascriptGitHub repository.
Locate your currently running Codespaces sourced from theAzure-Samples/openai-chat-app-quickstart-javascriptGitHub repository.
Azure-Samples/openai-chat-app-quickstart-javascript
Open the context menu for the codespace and then selectDelete.
Open the context menu for the codespace and then selectDelete.
You aren't necessarily required to clean up your local environment, but you can stop the running development container and return to running Visual Studio Code in the context of a local workspace.
Open theCommand Palette, search for theDev Containerscommands, and then selectDev Containers: Reopen Folder Locally.

Tip
Visual Studio Code will stop the running development container, but the container still exists in Docker in a stopped state. You always have the option to deleting the container instance, container image, and volumes from Docker to free up more space on your local machine.
Get help
If your issue isn't addressed, log your issue to the repository'sIssues.
Next steps
Get started with the chat using your own data sample for Python
If your issue isn't addressed, log your issue to the repository'sIssues.
Get started with the chat using your own data sample for .NET
If your issue isn't addressed, log your issue to the repository'sIssues.
Get started with the chat using your own data sample for JavaScript
Feedback
Was this page helpful?
Additional resources