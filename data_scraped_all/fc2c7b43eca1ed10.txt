Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Copy data to Azure Data Explorer by using Azure Data Factory
Article
2023-01-26
12 contributors
In this article
Important
This connector can be used inReal-Time Intelligencein Microsoft Fabric. Use the instructions in this article with the following exceptions:
If required, create databases using the instructions inCreate a KQL database.
If required, create tables using the instructions inCreate an empty table.
Get query or ingestion URIs using the instructions inCopy URI.
Run queries in aKQL queryset.
Azure Data Explorer is a fast, fully managed, data-analytics service. It offers real-time analysis on large volumes of data that stream from many sources, such as applications, websites, and IoT devices. With Azure Data Explorer, you can iteratively explore data and identify patterns and anomalies to improve products, enhance customer experiences, monitor devices, and boost operations. It helps you explore new questions and get answers in minutes.
Azure Data Factory is a fully managed, cloud-based, data-integration service. You can use it to populate your Azure Data Explorer database with data from your existing system. It can help you save time when you're building analytics solutions.
When you load data into Azure Data Explorer, Data Factory provides the following benefits:
Easy setup: Get an intuitive, five-step wizard with no scripting required.
Rich data store support: Get built-in support for a rich set of on-premises and cloud-based data stores. For a detailed list, see the table ofSupported data stores.
Secure and compliant: Data is transferred over HTTPS or Azure ExpressRoute. The global service presence ensures that your data never leaves the geographical boundary.
High performance: The data-loading speed is up to 1 gigabyte per second (GBps) into Azure Data Explorer. For more information, seeCopy activity performance.
In this article, you use the Data Factory Copy Data tool to load data from Amazon Simple Storage Service (S3) into Azure Data Explorer. You can follow a similar process to copy data from other data stores, such as:
Azure Blob storage
Azure SQL Database
Azure SQL Data Warehouse
Google BigQuery
Oracle
File system
Prerequisites
An Azure subscription. Create afree Azure account.
An Azure Data Explorer cluster and database.Create a cluster and database.
A source of data.
Create a data factory
Sign in to theAzure portal.
Sign in to theAzure portal.
In the left pane, selectCreate a resource>Analytics>Data Factory.
In the left pane, selectCreate a resource>Analytics>Data Factory.

In theNew data factorypane, provide values for the fields in the following table:SettingValue to enterNameIn the box, enter a globally unique name for your data factory. If you receive an error,Data factory name "LoadADXDemo" is not available, enter a different name for the data factory. For rules about naming Data Factory artifacts, seeData Factory naming rules.SubscriptionIn the drop-down list, select the Azure subscription in which to create the data factory.Resource GroupSelectCreate new, and then enter the name of a new resource group. If you already have a resource group, selectUse existing.VersionIn the drop-down list, selectV2.LocationIn the drop-down list, select the location for the data factory. Only supported locations are displayed in the list. The data stores that are used by the data factory can exist in other locations or regions.
In theNew data factorypane, provide values for the fields in the following table:

SelectCreate.
SelectCreate.
To monitor the creation process, selectNotificationson the toolbar. After you've created the data factory, select it.TheData Factorypane opens.
To monitor the creation process, selectNotificationson the toolbar. After you've created the data factory, select it.
TheData Factorypane opens.

To open the application in a separate pane, select theAuthor & Monitortile.
To open the application in a separate pane, select theAuthor & Monitortile.
Load data into Azure Data Explorer
You can load data from many types ofdata storesinto Azure Data Explorer. This article discusses how to load data from Amazon S3.
You can load your data in either of the following ways:
In the Azure Data Factory user interface, in the left pane, select theAuthoricon. This is shown in the "Create a data factory" section ofCreate a data factory by using the Azure Data Factory UI.
In the Azure Data Factory Copy Data tool, as shown inUse the Copy Data tool to copy data.
Copy data from Amazon S3 (source)
In theLet's get startedpane, open the Copy Data tool by selectingCopy Data.
In theLet's get startedpane, open the Copy Data tool by selectingCopy Data.

In thePropertiespane, in theTask namebox, enter a name, and then selectNext.
In thePropertiespane, in theTask namebox, enter a name, and then selectNext.

In theSource data storepane, selectCreate new connection.
In theSource data storepane, selectCreate new connection.

SelectAmazon S3, and then selectContinue.
SelectAmazon S3, and then selectContinue.

In theNew Linked Service (Amazon S3)pane, do the following:a. In theNamebox, enter the name of your new linked service.b. In theConnect via integration runtimedrop-down list, select the value.c. In theAccess Key IDbox, enter the value.NoteIn Amazon S3, to locate your access key, select your Amazon username on the navigation bar, and then selectMy Security Credentials.d. In theSecret Access Keybox, enter a value.e. To test the linked service connection you created, selectTest Connection.f. SelectFinish.TheSource data storepane displays your new AmazonS31 connection.
In theNew Linked Service (Amazon S3)pane, do the following:

a. In theNamebox, enter the name of your new linked service.
b. In theConnect via integration runtimedrop-down list, select the value.
c. In theAccess Key IDbox, enter the value.
Note
In Amazon S3, to locate your access key, select your Amazon username on the navigation bar, and then selectMy Security Credentials.
d. In theSecret Access Keybox, enter a value.
e. To test the linked service connection you created, selectTest Connection.
f. SelectFinish.
TheSource data storepane displays your new AmazonS31 connection.
SelectNext.
SelectNext.

In theChoose the input file or folderpane, do the following steps:a. Browse to the file or folder that you want to copy, and then select it.b. Select the copy behavior that you want. Make sure that theBinary copycheck box is cleared.c. SelectNext.
In theChoose the input file or folderpane, do the following steps:
a. Browse to the file or folder that you want to copy, and then select it.
b. Select the copy behavior that you want. Make sure that theBinary copycheck box is cleared.
c. SelectNext.

In theFile format settingspane, select the relevant settings for your file. and then selectNext.
In theFile format settingspane, select the relevant settings for your file. and then selectNext.

Copy data into Azure Data Explorer (destination)
The new Azure Data Explorer linked service is created to copy the data into the Azure Data Explorer destination table (sink) that's specified in this section.
Note
Use theAzure Data Factory command activity to run Azure Data Explorer management commandsand use any of theingest from query commands, such as.set-or-replace.
.set-or-replace
To create the Azure Data Explorer linked service, do the following steps:
To use an existing data store connection or specify a new data store, in theDestination data storepane, selectCreate new connection.
To use an existing data store connection or specify a new data store, in theDestination data storepane, selectCreate new connection.

In theNew Linked Servicepane, selectAzure Data Explorer, and then selectContinue.
In theNew Linked Servicepane, selectAzure Data Explorer, and then selectContinue.

In theNew Linked Service (Azure Data Explorer)pane, do the following steps:In theNamebox, enter a name for the Azure Data Explorer linked service.UnderAuthentication method, chooseSystem Assigned Managed IdentityorService Principal.To Authenticate using a Managed Identity, grant the Managed Identity access to the database by using theManaged identity nameorManaged identity object ID.To Authenticate using a Service Principal:In theTenantbox, enter the tenant name.In theService principal IDbox, enter the service principal ID.SelectService principal keyand then, in theService principal keybox, enter the value for the key.NoteThe service principal is used by Azure Data Factory to access the Azure Data Explorer service. To create a service principal, go tocreate a Microsoft Entra service principal.To assign permissions to a Managed Identity or a Service Principal or , seemanage permissions.Do not use the Azure Key Vault method or User Assigned Managed Identity.UnderAccount selection method, choose one of the following options:SelectFrom Azure subscriptionand then, in the drop-down lists, select yourAzure subscriptionand yourCluster.NoteTheClusterdrop-down control lists only clusters that are associated with your subscription.Your cluster must have the appropriateSKUforbest performance.SelectEnter manually, and then enter yourEndpoint.In theDatabasedrop-down list, select your database name. Alternatively, select theEditcheck box, and then enter the database name.To test the linked service connection you created, selectTest Connection. If you can connect to your linked service, the pane displays a green checkmark and aConnection successfulmessage.SelectCreateto complete the linked service creation.
In theNew Linked Service (Azure Data Explorer)pane, do the following steps:

In theNamebox, enter a name for the Azure Data Explorer linked service.
In theNamebox, enter a name for the Azure Data Explorer linked service.
UnderAuthentication method, chooseSystem Assigned Managed IdentityorService Principal.To Authenticate using a Managed Identity, grant the Managed Identity access to the database by using theManaged identity nameorManaged identity object ID.To Authenticate using a Service Principal:In theTenantbox, enter the tenant name.In theService principal IDbox, enter the service principal ID.SelectService principal keyand then, in theService principal keybox, enter the value for the key.NoteThe service principal is used by Azure Data Factory to access the Azure Data Explorer service. To create a service principal, go tocreate a Microsoft Entra service principal.To assign permissions to a Managed Identity or a Service Principal or , seemanage permissions.Do not use the Azure Key Vault method or User Assigned Managed Identity.
UnderAuthentication method, chooseSystem Assigned Managed IdentityorService Principal.
To Authenticate using a Managed Identity, grant the Managed Identity access to the database by using theManaged identity nameorManaged identity object ID.
To Authenticate using a Managed Identity, grant the Managed Identity access to the database by using theManaged identity nameorManaged identity object ID.
To Authenticate using a Service Principal:In theTenantbox, enter the tenant name.In theService principal IDbox, enter the service principal ID.SelectService principal keyand then, in theService principal keybox, enter the value for the key.
To Authenticate using a Service Principal:
In theTenantbox, enter the tenant name.
In theService principal IDbox, enter the service principal ID.
SelectService principal keyand then, in theService principal keybox, enter the value for the key.
Note
The service principal is used by Azure Data Factory to access the Azure Data Explorer service. To create a service principal, go tocreate a Microsoft Entra service principal.
To assign permissions to a Managed Identity or a Service Principal or , seemanage permissions.
Do not use the Azure Key Vault method or User Assigned Managed Identity.
UnderAccount selection method, choose one of the following options:SelectFrom Azure subscriptionand then, in the drop-down lists, select yourAzure subscriptionand yourCluster.NoteTheClusterdrop-down control lists only clusters that are associated with your subscription.Your cluster must have the appropriateSKUforbest performance.SelectEnter manually, and then enter yourEndpoint.
UnderAccount selection method, choose one of the following options:
SelectFrom Azure subscriptionand then, in the drop-down lists, select yourAzure subscriptionand yourCluster.NoteTheClusterdrop-down control lists only clusters that are associated with your subscription.Your cluster must have the appropriateSKUforbest performance.
SelectFrom Azure subscriptionand then, in the drop-down lists, select yourAzure subscriptionand yourCluster.
Note
TheClusterdrop-down control lists only clusters that are associated with your subscription.
Your cluster must have the appropriateSKUforbest performance.
SelectEnter manually, and then enter yourEndpoint.
SelectEnter manually, and then enter yourEndpoint.
In theDatabasedrop-down list, select your database name. Alternatively, select theEditcheck box, and then enter the database name.
In theDatabasedrop-down list, select your database name. Alternatively, select theEditcheck box, and then enter the database name.
To test the linked service connection you created, selectTest Connection. If you can connect to your linked service, the pane displays a green checkmark and aConnection successfulmessage.
To test the linked service connection you created, selectTest Connection. If you can connect to your linked service, the pane displays a green checkmark and aConnection successfulmessage.
SelectCreateto complete the linked service creation.
SelectCreateto complete the linked service creation.
After you've created the linked service connection, theDestination data storepane opens, and the connection you created is available for use. To configure the connection, do the following steps:
SelectNext.
SelectNext.

In theTable mappingpane, set the destination table name, and then selectNext.
In theTable mappingpane, set the destination table name, and then selectNext.

In theColumn mappingpane, the following mappings take place:a. The first mapping is performed by Azure Data Factory according to theAzure Data Factory schema mapping. Do the following:Set theColumn mappingsfor the Azure Data Factory destination table. The default mapping is displayed from source to the Azure Data Factory destination table.Cancel the selection of the columns that you don't need to define your column mapping.b. The second mapping occurs when this tabular data is ingested into Azure Data Explorer. Mapping is performed according toCSV mapping rules. Even if the source data isn't in CSV format, Azure Data Factory converts the data into a tabular format. Therefore, CSV mapping is the only relevant mapping at this stage. Do the following:(Optional) UnderAzure Data Explorer (Kusto) sink properties, add the relevantIngestion mapping nameso that column mapping can be used.IfIngestion mapping nameisn't specified, theby-namemapping order that's defined in theColumn mappingssection will be used. Ifby-namemapping fails, Azure Data Explorer tries to ingest the data in aby-column positionorder (that is, it maps by  position as the default).SelectNext.
In theColumn mappingpane, the following mappings take place:
a. The first mapping is performed by Azure Data Factory according to theAzure Data Factory schema mapping. Do the following:
Set theColumn mappingsfor the Azure Data Factory destination table. The default mapping is displayed from source to the Azure Data Factory destination table.
Set theColumn mappingsfor the Azure Data Factory destination table. The default mapping is displayed from source to the Azure Data Factory destination table.
Cancel the selection of the columns that you don't need to define your column mapping.
Cancel the selection of the columns that you don't need to define your column mapping.
b. The second mapping occurs when this tabular data is ingested into Azure Data Explorer. Mapping is performed according toCSV mapping rules. Even if the source data isn't in CSV format, Azure Data Factory converts the data into a tabular format. Therefore, CSV mapping is the only relevant mapping at this stage. Do the following:
(Optional) UnderAzure Data Explorer (Kusto) sink properties, add the relevantIngestion mapping nameso that column mapping can be used.
(Optional) UnderAzure Data Explorer (Kusto) sink properties, add the relevantIngestion mapping nameso that column mapping can be used.
IfIngestion mapping nameisn't specified, theby-namemapping order that's defined in theColumn mappingssection will be used. Ifby-namemapping fails, Azure Data Explorer tries to ingest the data in aby-column positionorder (that is, it maps by  position as the default).
IfIngestion mapping nameisn't specified, theby-namemapping order that's defined in theColumn mappingssection will be used. Ifby-namemapping fails, Azure Data Explorer tries to ingest the data in aby-column positionorder (that is, it maps by  position as the default).
SelectNext.
SelectNext.

In theSettingspane, do the following steps:a. UnderFault tolerance settings, enter the relevant settings.b. UnderPerformance settings,Enable stagingdoesn't apply, andAdvanced settingsincludes cost considerations. If you have no specific requirements, leave these settings as is.c. SelectNext.
In theSettingspane, do the following steps:
a. UnderFault tolerance settings, enter the relevant settings.
b. UnderPerformance settings,Enable stagingdoesn't apply, andAdvanced settingsincludes cost considerations. If you have no specific requirements, leave these settings as is.
c. SelectNext.

In theSummarypane, review the settings, and then selectNext.
In theSummarypane, review the settings, and then selectNext.

In theDeployment completepane, do the following:a. To switch to theMonitortab and view the status of the pipeline (that is, progress, errors, and data flow), selectMonitor.b. To edit linked services, datasets, and pipelines, selectEdit Pipeline.c. SelectFinishto complete the copy data task.
In theDeployment completepane, do the following:
a. To switch to theMonitortab and view the status of the pipeline (that is, progress, errors, and data flow), selectMonitor.
b. To edit linked services, datasets, and pipelines, selectEdit Pipeline.
c. SelectFinishto complete the copy data task.

Related content
Learn about theAzure Data Explorer connectorfor Azure Data Factory.
Edit linked services, datasets, and pipelines in theData Factory UI.
Query data in the Azure Data Explorer web UI.
Feedback
Was this page helpful?
Additional resources