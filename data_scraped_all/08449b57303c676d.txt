Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Understand Azure Policy for Kubernetes clusters
Article
2025-03-04
26 contributors
In this article
Azure Policy extendsGatekeeperv3, anadmission
controller webhookforOpen Policy Agent(OPA), to apply at-scale enforcements and safeguards on your cluster components in a centralized, consistent manner. Cluster components include pods, containers, and namespaces.
Azure Policy makes it possible to manage and report on the compliance state of your Kubernetes cluster components from one place. By using Azure Policy's Add-on or Extension, governing your cluster components is enhanced with Azure Policy features, like the ability to useselectorsandoverridesfor safe policy rollout and rollback.
Azure Policy for Kubernetes supports the following cluster environments:
Azure Kubernetes Service (AKS), throughAzure Policy'sAdd-onfor AKS
Azure Arc enabled Kubernetes, throughAzure Policy'sExtensionfor Arc
Important
The Azure Policy Add-on Helm model and the add-on for AKS Engine have beendeprecated. Follow the instructions toremove the add-ons.
Important
Installations of Gatekeeper outside of the Azure Policy Add-on aren't supported. Uninstall any components installed by a previous Gatekeeper installation before enabling the Azure Policy Add-on.
Overview
By installing Azure Policy's add-on or extension on your Kubernetes clusters, Azure Policy enacts the following functions:
Checks with Azure Policy service for policy assignments to the cluster.
Deploys policy definitions into the cluster asconstraint templateandconstraintcustom resources or as a mutation template resource (depending on policy definition content).
Reports auditing and compliance details back to Azure Policy service.
To enable and use Azure Policy with your Kubernetes cluster, take the following actions:
Configure your Kubernetes cluster and install theAzure Kubernetes Service (AKS)add-on or Azure Policy's Extension forArc-enabled Kubernetes clusters(depending on your cluster type).NoteFor common issues with installation, seeTroubleshoot - Azure Policy Add-on.
Configure your Kubernetes cluster and install theAzure Kubernetes Service (AKS)add-on or Azure Policy's Extension forArc-enabled Kubernetes clusters(depending on your cluster type).
Note
For common issues with installation, seeTroubleshoot - Azure Policy Add-on.
Create or use a sample Azure Policy definition for Kubernetes
Create or use a sample Azure Policy definition for Kubernetes
Assign a definition to your Kubernetes cluster
Assign a definition to your Kubernetes cluster
Wait for validation
Wait for validation
Loggingandtroubleshooting
Loggingandtroubleshooting
Reviewlimitationsandrecommendations in our FAQ section
Reviewlimitationsandrecommendations in our FAQ section
Install Azure Policy Add-on for AKS
The Azure Policy Add-on for AKS is part of Kubernetes version 1.27 with long term support (LTS).
Prerequisites
Register the resource providers and preview features.Azure portal:Register theMicrosoft.PolicyInsightsresource providers. For steps, seeResource providers and types.Azure CLI:# Log in first with az login if you're not using Cloud Shell

# Provider register: Register the Azure Policy provider
az provider register --namespace Microsoft.PolicyInsights
Register the resource providers and preview features.
Azure portal:Register theMicrosoft.PolicyInsightsresource providers. For steps, seeResource providers and types.
Azure portal:
Register theMicrosoft.PolicyInsightsresource providers. For steps, seeResource providers and types.
Microsoft.PolicyInsights
Azure CLI:# Log in first with az login if you're not using Cloud Shell

# Provider register: Register the Azure Policy provider
az provider register --namespace Microsoft.PolicyInsights
Azure CLI:
# Log in first with az login if you're not using Cloud Shell

# Provider register: Register the Azure Policy provider
az provider register --namespace Microsoft.PolicyInsights
# Log in first with az login if you're not using Cloud Shell

# Provider register: Register the Azure Policy provider
az provider register --namespace Microsoft.PolicyInsights
You need the Azure CLI version 2.12.0 or later installed and configured. To find the version, run theaz --versioncommand. If you need to install or upgrade, seeHow to install the Azure CLI.
You need the Azure CLI version 2.12.0 or later installed and configured. To find the version, run theaz --versioncommand. If you need to install or upgrade, seeHow to install the Azure CLI.
az --version
The AKS cluster must be asupported Kubernetes version in Azure Kubernetes Service (AKS). Use the following script to validate your AKS
cluster version:# Log in first with az login if you're not using Cloud Shell

# Look for the value in kubernetesVersion
az aks list
The AKS cluster must be asupported Kubernetes version in Azure Kubernetes Service (AKS). Use the following script to validate your AKS
cluster version:
# Log in first with az login if you're not using Cloud Shell

# Look for the value in kubernetesVersion
az aks list
# Log in first with az login if you're not using Cloud Shell

# Look for the value in kubernetesVersion
az aks list
Open ports for the Azure Policy extension. The Azure Policy extension uses these domains and ports to fetch policy
definitions and assignments and report compliance of the cluster back to Azure Policy.DomainPortdata.policy.core.windows.net443store.policy.core.windows.net443login.windows.net443dc.services.visualstudio.com443
Open ports for the Azure Policy extension. The Azure Policy extension uses these domains and ports to fetch policy
definitions and assignments and report compliance of the cluster back to Azure Policy.
data.policy.core.windows.net
443
store.policy.core.windows.net
443
login.windows.net
443
dc.services.visualstudio.com
443
After the prerequisites are completed, install the Azure Policy Add-on in the AKS cluster
you want to manage.
Azure portalLaunch the AKS service in the Azure portal by selectingAll services, then searching for
and selectingKubernetes services.Select one of your AKS clusters.SelectPolicieson the left side of the Kubernetes service page.In the main page, select theEnable add-onbutton.
Azure portal
Launch the AKS service in the Azure portal by selectingAll services, then searching for
and selectingKubernetes services.
Launch the AKS service in the Azure portal by selectingAll services, then searching for
and selectingKubernetes services.
Select one of your AKS clusters.
Select one of your AKS clusters.
SelectPolicieson the left side of the Kubernetes service page.
SelectPolicieson the left side of the Kubernetes service page.
In the main page, select theEnable add-onbutton.
In the main page, select theEnable add-onbutton.
Azure CLI# Log in first with az login if you're not using Cloud Shell

az aks enable-addons --addons azure-policy --name MyAKSCluster --resource-group MyResourceGroup
Azure CLI
# Log in first with az login if you're not using Cloud Shell

az aks enable-addons --addons azure-policy --name MyAKSCluster --resource-group MyResourceGroup
# Log in first with az login if you're not using Cloud Shell

az aks enable-addons --addons azure-policy --name MyAKSCluster --resource-group MyResourceGroup
To validate that the add-on installation was successful and that theazure-policyandgatekeeperpods are running, run the following command:
# azure-policy pod is installed in kube-system namespace
kubectl get pods -n kube-system

# gatekeeper pod is installed in gatekeeper-system namespace
kubectl get pods -n gatekeeper-system
# azure-policy pod is installed in kube-system namespace
kubectl get pods -n kube-system

# gatekeeper pod is installed in gatekeeper-system namespace
kubectl get pods -n gatekeeper-system
Lastly, verify that the latest add-on is installed by running this Azure CLI command, replacing<rg>with your resource group name and<cluster-name>with the name of your AKS cluster:az aks show --query addonProfiles.azurepolicy -g <rg> -n <cluster-name>. The result should look
similar to the following output for clusters using service principals:
<rg>
<cluster-name>
az aks show --query addonProfiles.azurepolicy -g <rg> -n <cluster-name>
{
  "config": null,
  "enabled": true,
  "identity": null
}
{
  "config": null,
  "enabled": true,
  "identity": null
}
And the following output for clusters using managed identity:
{
   "config": null,
   "enabled": true,
   "identity": {
     "clientId": "########-####-####-####-############",
     "objectId": "########-####-####-####-############",
     "resourceId": "<resource-id>"
   }
 }
{
   "config": null,
   "enabled": true,
   "identity": {
     "clientId": "########-####-####-####-############",
     "objectId": "########-####-####-####-############",
     "resourceId": "<resource-id>"
   }
 }
Install Azure Policy Extension for Azure Arc enabled Kubernetes
Azure Policy for Kubernetesmakes it possible to manage and report on the compliance state of your Kubernetes clusters from one place. With Azure Policy's Extension for Arc-enabled Kubernetes clusters, you can govern your Arc-enabled Kubernetes cluster components, like pods and containers.
This article describes how tocreate,show extension status, anddeletethe Azure Policy for Kubernetes extension.
For an overview of the extensions platform, seeAzure Arc cluster extensions.
Prerequisites
If you already deployed Azure Policy for Kubernetes on an Azure Arc cluster using Helm directly without extensions, follow the instructions todelete the Helm chart. After the deletion is done, you can then proceed.
Ensure your Kubernetes cluster is a supported distribution.NoteAzure Policy for Arc extension is supported onthe following Kubernetes distributions.
Ensure your Kubernetes cluster is a supported distribution.
Note
Azure Policy for Arc extension is supported onthe following Kubernetes distributions.
Ensure you met all the common prerequisites for Kubernetes extensions listedhereincludingconnecting your cluster to Azure Arc.NoteAzure Policy extension is supported for Arc enabled Kubernetes clustersin these regions.
Ensure you met all the common prerequisites for Kubernetes extensions listedhereincludingconnecting your cluster to Azure Arc.
Note
Azure Policy extension is supported for Arc enabled Kubernetes clustersin these regions.
Open ports for the Azure Policy extension. The Azure Policy extension uses these domains and ports to fetch policy
definitions and assignments and report compliance of the cluster back to Azure Policy.DomainPortdata.policy.core.windows.net443store.policy.core.windows.net443login.windows.net443dc.services.visualstudio.com443
Open ports for the Azure Policy extension. The Azure Policy extension uses these domains and ports to fetch policy
definitions and assignments and report compliance of the cluster back to Azure Policy.
data.policy.core.windows.net
443
store.policy.core.windows.net
443
login.windows.net
443
dc.services.visualstudio.com
443
Before you install the Azure Policy extension or enabling any of the service features, your subscription must enable theMicrosoft.PolicyInsightsresource providers.NoteTo enable the resource provider, follow the steps inResource providers and typesor run either the Azure CLI or Azure PowerShell command.Azure CLI# Log in first with az login if you're not using Cloud Shell
# Provider register: Register the Azure Policy provider
az provider register --namespace 'Microsoft.PolicyInsights'Azure PowerShell# Log in first with Connect-AzAccount if you're not using Cloud Shell

# Provider register: Register the Azure Policy provider
Register-AzResourceProvider -ProviderNamespace 'Microsoft.PolicyInsights'
Before you install the Azure Policy extension or enabling any of the service features, your subscription must enable theMicrosoft.PolicyInsightsresource providers.
Microsoft.PolicyInsights
Note
To enable the resource provider, follow the steps inResource providers and typesor run either the Azure CLI or Azure PowerShell command.
Azure CLI# Log in first with az login if you're not using Cloud Shell
# Provider register: Register the Azure Policy provider
az provider register --namespace 'Microsoft.PolicyInsights'
Azure CLI
# Log in first with az login if you're not using Cloud Shell
# Provider register: Register the Azure Policy provider
az provider register --namespace 'Microsoft.PolicyInsights'
# Log in first with az login if you're not using Cloud Shell
# Provider register: Register the Azure Policy provider
az provider register --namespace 'Microsoft.PolicyInsights'
Azure PowerShell# Log in first with Connect-AzAccount if you're not using Cloud Shell

# Provider register: Register the Azure Policy provider
Register-AzResourceProvider -ProviderNamespace 'Microsoft.PolicyInsights'
Azure PowerShell
# Log in first with Connect-AzAccount if you're not using Cloud Shell

# Provider register: Register the Azure Policy provider
Register-AzResourceProvider -ProviderNamespace 'Microsoft.PolicyInsights'
# Log in first with Connect-AzAccount if you're not using Cloud Shell

# Provider register: Register the Azure Policy provider
Register-AzResourceProvider -ProviderNamespace 'Microsoft.PolicyInsights'
Create Azure Policy extension
Note
Note the following for Azure Policy extension creation:
Auto-upgrade is enabled by default which will update Azure Policy extension minor version if any new changes are deployed.
Any proxy variables passed as parameters toconnectedk8swill be propagated to the Azure Policy extension to support outbound proxy.
connectedk8s
To create an extension instance, for your Arc enabled cluster, run the following command substituting<>with your values:
<>
az k8s-extension create --cluster-type connectedClusters --cluster-name <CLUSTER_NAME> --resource-group <RESOURCE_GROUP> --extension-type Microsoft.PolicyInsights --name <EXTENSION_INSTANCE_NAME>
az k8s-extension create --cluster-type connectedClusters --cluster-name <CLUSTER_NAME> --resource-group <RESOURCE_GROUP> --extension-type Microsoft.PolicyInsights --name <EXTENSION_INSTANCE_NAME>
az k8s-extension create --cluster-type connectedClusters --cluster-name my-test-cluster --resource-group my-test-rg --extension-type Microsoft.PolicyInsights --name azurepolicy
az k8s-extension create --cluster-type connectedClusters --cluster-name my-test-cluster --resource-group my-test-rg --extension-type Microsoft.PolicyInsights --name azurepolicy
{
  "aksAssignedIdentity": null,
  "autoUpgradeMinorVersion": true,
  "configurationProtectedSettings": {},
  "configurationSettings": {},
  "customLocationSettings": null,
  "errorInfo": null,
  "extensionType": "microsoft.policyinsights",
  "id": "/subscriptions/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx/resourceGroups/my-test-rg/providers/Microsoft.Kubernetes/connectedClusters/my-test-cluster/providers/Microsoft.KubernetesConfiguration/extensions/azurepolicy",
 "identity": {
    "principalId": "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx",
    "tenantId": null,
    "type": "SystemAssigned"
  },
  "location": null,
  "name": "azurepolicy",
  "packageUri": null,
  "provisioningState": "Succeeded",
  "releaseTrain": "Stable",
  "resourceGroup": "my-test-rg",
  "scope": {
    "cluster": {
      "releaseNamespace": "kube-system"
    },
    "namespace": null
  },
  "statuses": [],
  "systemData": {
    "createdAt": "2021-10-27T01:20:06.834236+00:00",
    "createdBy": null,
    "createdByType": null,
    "lastModifiedAt": "2021-10-27T01:20:06.834236+00:00",
    "lastModifiedBy": null,
    "lastModifiedByType": null
  },
  "type": "Microsoft.KubernetesConfiguration/extensions",
  "version": "1.1.0"
}
{
  "aksAssignedIdentity": null,
  "autoUpgradeMinorVersion": true,
  "configurationProtectedSettings": {},
  "configurationSettings": {},
  "customLocationSettings": null,
  "errorInfo": null,
  "extensionType": "microsoft.policyinsights",
  "id": "/subscriptions/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx/resourceGroups/my-test-rg/providers/Microsoft.Kubernetes/connectedClusters/my-test-cluster/providers/Microsoft.KubernetesConfiguration/extensions/azurepolicy",
 "identity": {
    "principalId": "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx",
    "tenantId": null,
    "type": "SystemAssigned"
  },
  "location": null,
  "name": "azurepolicy",
  "packageUri": null,
  "provisioningState": "Succeeded",
  "releaseTrain": "Stable",
  "resourceGroup": "my-test-rg",
  "scope": {
    "cluster": {
      "releaseNamespace": "kube-system"
    },
    "namespace": null
  },
  "statuses": [],
  "systemData": {
    "createdAt": "2021-10-27T01:20:06.834236+00:00",
    "createdBy": null,
    "createdByType": null,
    "lastModifiedAt": "2021-10-27T01:20:06.834236+00:00",
    "lastModifiedBy": null,
    "lastModifiedByType": null
  },
  "type": "Microsoft.KubernetesConfiguration/extensions",
  "version": "1.1.0"
}
Show Azure Policy extension
To check the extension instance creation was successful, and inspect extension metadata, run the following command substituting<>with your values:
<>
az k8s-extension show --cluster-type connectedClusters --cluster-name <CLUSTER_NAME> --resource-group <RESOURCE_GROUP> --name <EXTENSION_INSTANCE_NAME>
az k8s-extension show --cluster-type connectedClusters --cluster-name <CLUSTER_NAME> --resource-group <RESOURCE_GROUP> --name <EXTENSION_INSTANCE_NAME>
az k8s-extension show --cluster-type connectedClusters --cluster-name my-test-cluster --resource-group my-test-rg --name azurepolicy
az k8s-extension show --cluster-type connectedClusters --cluster-name my-test-cluster --resource-group my-test-rg --name azurepolicy
To validate that the extension installation was successful and that the azure-policy and gatekeeper pods are running, run the following command:
# azure-policy pod is installed in kube-system namespace
kubectl get pods -n kube-system

# gatekeeper pod is installed in gatekeeper-system namespace
kubectl get pods -n gatekeeper-system
# azure-policy pod is installed in kube-system namespace
kubectl get pods -n kube-system

# gatekeeper pod is installed in gatekeeper-system namespace
kubectl get pods -n gatekeeper-system
Delete Azure Policy extension
To delete the extension instance, run the following command substituting<>with your values:
<>
az k8s-extension delete --cluster-type connectedClusters --cluster-name <CLUSTER_NAME> --resource-group <RESOURCE_GROUP> --name <EXTENSION_INSTANCE_NAME>
az k8s-extension delete --cluster-type connectedClusters --cluster-name <CLUSTER_NAME> --resource-group <RESOURCE_GROUP> --name <EXTENSION_INSTANCE_NAME>
Create a policy definition
The Azure Policy language structure for managing Kubernetes follows that of existing policy
definitions. There are sample definition files available to assign inAzure Policy's built-in policy librarythat can be used to govern your cluster components.
Azure Policy for Kubernetes also support custom definition creation at the component-level for both Azure Kubernetes Service clusters and Azure Arc-enabled Kubernetes clusters. Constraint template and mutation template samples are available in theGatekeeper community library.Azure Policy's Visual Studio Code Extensioncan be used to help translate an existing constraint template or mutation template to a custom Azure Policy policy definition.
With aResource Provider modeofMicrosoft.Kubernetes.Data, the effectsaudit,deny,disabled, andmutateare used to manage your Kubernetes clusters.
Microsoft.Kubernetes.Data
Auditanddenymust providedetailsproperties
specific to working withOPA Constraint Frameworkand Gatekeeper v3.
details
As part of thedetails.templateInfoordetails.constraintInfoproperties in the policy definition, Azure Policy passes the URI orBase64Encodedvalue of theseCustomResourceDefinitions(CRD) to the add-on. Rego is the language that OPA and Gatekeeper support to validate a request to
the Kubernetes cluster. By supporting an existing standard for Kubernetes management, Azure Policy
makes it possible to reuse existing rules and pair them with Azure Policy for a unified cloud
compliance reporting experience. For more information, seeWhat is Rego?.
Base64Encoded
Assign a policy definition
To assign a policy definition to your Kubernetes cluster, you must be assigned the appropriate Azure
role-based access control (Azure RBAC) policy assignment operations. The Azure built-in rolesResource Policy ContributorandOwnerhave these operations. To learn more, seeAzure RBAC permissions in Azure Policy.
Find the built-in policy definitions for managing your cluster using the Azure portal with the
following steps. If using a custom policy definition, search for it by name or the category that
you created it with.
Start the Azure Policy service in the Azure portal. SelectAll servicesin the left pane and
then search for and selectPolicy.
Start the Azure Policy service in the Azure portal. SelectAll servicesin the left pane and
then search for and selectPolicy.
In the left pane of the Azure Policy page, selectDefinitions.
In the left pane of the Azure Policy page, selectDefinitions.
From the Category dropdown list box, useSelect allto clear the filter and then selectKubernetes.
From the Category dropdown list box, useSelect allto clear the filter and then selectKubernetes.
Select the policy definition, then select theAssignbutton.
Select the policy definition, then select theAssignbutton.
Set theScopeto the management group, subscription, or resource group of the Kubernetes
cluster where the policy assignment applies.NoteWhen assigning the Azure Policy for Kubernetes definition, theScopemust include the
cluster resource.
Set theScopeto the management group, subscription, or resource group of the Kubernetes
cluster where the policy assignment applies.
Note
When assigning the Azure Policy for Kubernetes definition, theScopemust include the
cluster resource.
Give the policy assignment aNameandDescriptionthat you can use to identify it easily.
Give the policy assignment aNameandDescriptionthat you can use to identify it easily.
Set thePolicy enforcementto one of the following values:Enabled- Enforce the policy on the cluster. Kubernetes admission requests with violations
are denied.Disabled- Don't enforce the policy on the cluster. Kubernetes admission requests with
violations aren't denied. Compliance assessment results are still available. When you roll out
new policy definitions to running clusters,Disabledoption is helpful for testing the policy
definition as admission requests with violations aren't denied.
Set thePolicy enforcementto one of the following values:
Enabled- Enforce the policy on the cluster. Kubernetes admission requests with violations
are denied.
Enabled- Enforce the policy on the cluster. Kubernetes admission requests with violations
are denied.
Disabled- Don't enforce the policy on the cluster. Kubernetes admission requests with
violations aren't denied. Compliance assessment results are still available. When you roll out
new policy definitions to running clusters,Disabledoption is helpful for testing the policy
definition as admission requests with violations aren't denied.
Disabled- Don't enforce the policy on the cluster. Kubernetes admission requests with
violations aren't denied. Compliance assessment results are still available. When you roll out
new policy definitions to running clusters,Disabledoption is helpful for testing the policy
definition as admission requests with violations aren't denied.
SelectNext.
SelectNext.
Setparameter valuesTo exclude Kubernetes namespaces from policy evaluation, specify the list of namespaces in
parameterNamespace exclusions. The recommendation is to exclude:kube-system,gatekeeper-system, andazure-arc.
Setparameter values
To exclude Kubernetes namespaces from policy evaluation, specify the list of namespaces in
parameterNamespace exclusions. The recommendation is to exclude:kube-system,gatekeeper-system, andazure-arc.
SelectReview + create.
SelectReview + create.
Alternately, use theAssign a policy - Portalquickstart to find and
assign a Kubernetes policy. Search for a Kubernetes policy definition instead of the sampleaudit
vms.
Important
Built-in policy definitions are available for Kubernetes clusters in categoryKubernetes. For
a list of built-in policy definitions, seeKubernetes samples.
Policy evaluation
The add-on checks in with Azure Policy service for changes in policy assignments every 15 minutes.
During this refresh cycle, the add-on checks for changes. These changes trigger creates, updates, or
deletes of the constraint templates and constraints.
In a Kubernetes cluster, if a namespace has the cluster-appropriate label, the admission requests
with violations aren't denied. Compliance assessment results are still available.
Azure Arc-enabled Kubernetes cluster:admission.policy.azure.com/ignore
admission.policy.azure.com/ignore
Note
While a cluster admin might have permission to create and update constraint templates and
constraints resources install by the Azure Policy Add-on, these aren't supported scenarios as
manual updates are overwritten. Gatekeeper continues to evaluate policies that existed prior to
installing the add-on and assigning Azure Policy policy definitions.
Every 15 minutes, the add-on calls for a full scan of the cluster. After gathering details of the
full scan and any real-time evaluations by Gatekeeper of attempted changes to the cluster, the
add-on reports the results back to Azure Policy for inclusion incompliance detailslike any Azure Policy assignment. Only
results for active policy assignments are returned during the audit cycle. Audit results can also be
seen asviolationslisted in the status
field of the failed constraint. For details onNon-compliantresources, seeComponent details for Resource Provider modes.
Note
Each compliance report in Azure Policy for your Kubernetes clusters include all violations within
the last 45 minutes. The timestamp indicates when a violation occurred.
Some other considerations:
If the cluster subscription is registered with Microsoft Defender for Cloud, then Microsoft Defender for Cloud Kubernetes policies are applied on the cluster automatically.
If the cluster subscription is registered with Microsoft Defender for Cloud, then Microsoft Defender for Cloud Kubernetes policies are applied on the cluster automatically.
When a deny policy is applied on cluster with existing Kubernetes resources, any preexisting
resource that isn't compliant with the new policy continues to run. When the non-compliant
resource gets rescheduled on a different node the Gatekeeper blocks the resource creation.
When a deny policy is applied on cluster with existing Kubernetes resources, any preexisting
resource that isn't compliant with the new policy continues to run. When the non-compliant
resource gets rescheduled on a different node the Gatekeeper blocks the resource creation.
When a cluster has a deny policy that validates resources, the user doesn't get a rejection
message when creating a deployment. For example, consider a Kubernetes deployment that containsreplicasetsand pods. When a user executeskubectl describe deployment $MY_DEPLOYMENT, it doesn't return a rejection message as part of events. However,kubectl describe replicasets.apps $MY_DEPLOYMENTreturns the events associated with rejection.
When a cluster has a deny policy that validates resources, the user doesn't get a rejection
message when creating a deployment. For example, consider a Kubernetes deployment that containsreplicasetsand pods. When a user executeskubectl describe deployment $MY_DEPLOYMENT, it doesn't return a rejection message as part of events. However,kubectl describe replicasets.apps $MY_DEPLOYMENTreturns the events associated with rejection.
replicasets
kubectl describe deployment $MY_DEPLOYMENT
kubectl describe replicasets.apps $MY_DEPLOYMENT
Note
Init containers might be included during policy evaluation. To see if init containers are included, review the CRD for the following or a similar declaration:
input_containers[c] {
   c := input.review.object.spec.initContainers[_]
}
input_containers[c] {
   c := input.review.object.spec.initContainers[_]
}
Constraint template conflicts
If constraint templates have the same resource metadata name, but the policy definition references
the source at different locations, the policy definitions are considered to be in conflict. Example:
Two policy definitions reference the sametemplate.yamlfile stored at different source locations
like the Azure Policy template store (store.policy.core.windows.net) and GitHub.
template.yaml
store.policy.core.windows.net
When policy definitions and their constraint templates are assigned but aren't already installed on
the cluster and are in conflict, they're reported as a conflict and aren't installed into the
cluster until the conflict is resolved. Likewise, any existing policy definitions and their
constraint templates that are already on the cluster that conflicts with newly assigned policy
definitions continue to function normally. If an existing assignment is updated and there's a
failure to sync the constraint template, the cluster is also marked as a conflict. For all conflict
messages, seeAKS Resource Provider mode compliance reasons
Logging
As a Kubernetes controller/container, both theazure-policyandgatekeeperpods keep logs in the
Kubernetes cluster. In general,azure-policylogs can be used to troubleshoot issues with policy ingestion onto the cluster and compliance reporting. Thegatekeeper-controller-managerpod logs can be used to troubleshoot runtime denies. Thegatekeeper-auditpod logs can be used to troubleshoot audits of existing resources. The logs can be exposed in theInsightspage of the Kubernetes cluster. For
more information, seeMonitor your Kubernetes cluster performance with Azure Monitor for containers.
To view the add-on logs, usekubectl:
kubectl
# Get the azure-policy pod name installed in kube-system namespace
kubectl logs <azure-policy pod name> -n kube-system

# Get the gatekeeper pod name installed in gatekeeper-system namespace
kubectl logs <gatekeeper pod name> -n gatekeeper-system
# Get the azure-policy pod name installed in kube-system namespace
kubectl logs <azure-policy pod name> -n kube-system

# Get the gatekeeper pod name installed in gatekeeper-system namespace
kubectl logs <gatekeeper pod name> -n gatekeeper-system
If you're attempting to troubleshoot a particular ComplianceReasonCode that is appearing in your compliance results, you can search the azure-policy pod logs for that code to see the full accompanying error.
For more information, seeDebugging Gatekeeperin the
Gatekeeper documentation.
View Gatekeeper artifacts
After the add-on downloads the policy assignments and installs the constraint templates and
constraints on the cluster, it annotates both with Azure Policy information like the policy
assignment ID and the policy definition ID. To configure your client to view the add-on related
artifacts, use the following steps:
Set upkubeconfigfor the cluster.For an Azure Kubernetes Service cluster, use the following Azure CLI:# Set context to the subscription
az account set --subscription <YOUR-SUBSCRIPTION>

# Save credentials for kubeconfig into .kube in your home folder
az aks get-credentials --resource-group <RESOURCE-GROUP> --name <CLUSTER-NAME>
Set upkubeconfigfor the cluster.
kubeconfig
For an Azure Kubernetes Service cluster, use the following Azure CLI:
# Set context to the subscription
az account set --subscription <YOUR-SUBSCRIPTION>

# Save credentials for kubeconfig into .kube in your home folder
az aks get-credentials --resource-group <RESOURCE-GROUP> --name <CLUSTER-NAME>
# Set context to the subscription
az account set --subscription <YOUR-SUBSCRIPTION>

# Save credentials for kubeconfig into .kube in your home folder
az aks get-credentials --resource-group <RESOURCE-GROUP> --name <CLUSTER-NAME>
Test the cluster connection.Run thekubectl cluster-infocommand. A successful run has each service responding with a URL
of where it's running.
Test the cluster connection.
Run thekubectl cluster-infocommand. A successful run has each service responding with a URL
of where it's running.
kubectl cluster-info
View the add-on constraint templates
To view constraint templates downloaded by the add-on, runkubectl get constrainttemplates.
Constraint templates that start withk8sazureare the ones installed by the add-on.
kubectl get constrainttemplates
k8sazure
View the add-on mutation templates
To view mutation templates downloaded by the add-on, runkubectl get assign,kubectl get assignmetadata, andkubectl get modifyset.
kubectl get assign
kubectl get assignmetadata
kubectl get modifyset
Get Azure Policy mappings
To identify the mapping between a constraint template downloaded to the cluster and the policy
definition, usekubectl get constrainttemplates <TEMPLATE> -o yaml. The results look similar to
the following output:
kubectl get constrainttemplates <TEMPLATE> -o yaml
apiVersion: templates.gatekeeper.sh/v1beta1
kind: ConstraintTemplate
metadata:
    annotations:
    azure-policy-definition-id: /subscriptions/<SUBID>/providers/Microsoft.Authorization/policyDefinitions/<GUID>
    constraint-template-installed-by: azure-policy-addon
    constraint-template: <URL-OF-YAML>
    creationTimestamp: "2021-09-01T13:20:55Z"
    generation: 1
    managedFields:
    - apiVersion: templates.gatekeeper.sh/v1beta1
    fieldsType: FieldsV1
...
apiVersion: templates.gatekeeper.sh/v1beta1
kind: ConstraintTemplate
metadata:
    annotations:
    azure-policy-definition-id: /subscriptions/<SUBID>/providers/Microsoft.Authorization/policyDefinitions/<GUID>
    constraint-template-installed-by: azure-policy-addon
    constraint-template: <URL-OF-YAML>
    creationTimestamp: "2021-09-01T13:20:55Z"
    generation: 1
    managedFields:
    - apiVersion: templates.gatekeeper.sh/v1beta1
    fieldsType: FieldsV1
...
<SUBID>is the subscription ID and<GUID>is the ID of the mapped policy definition.<URL-OF-YAML>is the source location of the constraint template that the add-on downloaded to
install on the cluster.
<SUBID>
<GUID>
<URL-OF-YAML>
View constraints related to a constraint template
Once you have the names of theadd-on downloaded constraint templates, you can use the
name to see the related constraints. Usekubectl get <constraintTemplateName>to get the list.
Constraints installed by the add-on start withazurepolicy-.
kubectl get <constraintTemplateName>
azurepolicy-
View constraint details
The constraint has details about violations and mappings to the policy definition and assignment. To
see the details, usekubectl get <CONSTRAINT-TEMPLATE> <CONSTRAINT> -o yaml. The results look
similar to the following output:
kubectl get <CONSTRAINT-TEMPLATE> <CONSTRAINT> -o yaml
apiVersion: constraints.gatekeeper.sh/v1beta1
kind: K8sAzureContainerAllowedImages
metadata:
  annotations:
    azure-policy-assignment-id: /subscriptions/<SUB-ID>/resourceGroups/<RG-NAME>/providers/Microsoft.Authorization/policyAssignments/<ASSIGNMENT-GUID>
    azure-policy-definition-id: /providers/Microsoft.Authorization/policyDefinitions/<DEFINITION-GUID>
    azure-policy-definition-reference-id: ""
    azure-policy-setdefinition-id: ""
    constraint-installed-by: azure-policy-addon
    constraint-url: <URL-OF-YAML>
  creationTimestamp: "2021-09-01T13:20:55Z"
spec:
  enforcementAction: deny
  match:
    excludedNamespaces:
    - kube-system
    - gatekeeper-system
    - azure-arc
  parameters:
    imageRegex: ^.+azurecr.io/.+$
status:
  auditTimestamp: "2021-09-01T13:48:16Z"
  totalViolations: 32
  violations:
  - enforcementAction: deny
    kind: Pod
    message: Container image nginx for container hello-world has not been allowed.
    name: hello-world-78f7bfd5b8-lmc5b
    namespace: default
  - enforcementAction: deny
    kind: Pod
    message: Container image nginx for container hello-world has not been allowed.
    name: hellow-world-89f8bfd6b9-zkggg
apiVersion: constraints.gatekeeper.sh/v1beta1
kind: K8sAzureContainerAllowedImages
metadata:
  annotations:
    azure-policy-assignment-id: /subscriptions/<SUB-ID>/resourceGroups/<RG-NAME>/providers/Microsoft.Authorization/policyAssignments/<ASSIGNMENT-GUID>
    azure-policy-definition-id: /providers/Microsoft.Authorization/policyDefinitions/<DEFINITION-GUID>
    azure-policy-definition-reference-id: ""
    azure-policy-setdefinition-id: ""
    constraint-installed-by: azure-policy-addon
    constraint-url: <URL-OF-YAML>
  creationTimestamp: "2021-09-01T13:20:55Z"
spec:
  enforcementAction: deny
  match:
    excludedNamespaces:
    - kube-system
    - gatekeeper-system
    - azure-arc
  parameters:
    imageRegex: ^.+azurecr.io/.+$
status:
  auditTimestamp: "2021-09-01T13:48:16Z"
  totalViolations: 32
  violations:
  - enforcementAction: deny
    kind: Pod
    message: Container image nginx for container hello-world has not been allowed.
    name: hello-world-78f7bfd5b8-lmc5b
    namespace: default
  - enforcementAction: deny
    kind: Pod
    message: Container image nginx for container hello-world has not been allowed.
    name: hellow-world-89f8bfd6b9-zkggg
Troubleshooting the add-on
For more information about troubleshooting the Add-on for Kubernetes, see theKubernetes sectionof the Azure Policy troubleshooting article.
For Azure Policy extension for Arc extension related issues, go to:
Azure Arc enabled Kubernetes troubleshooting
For Azure Policy related issues, go to:
Inspect Azure Policy logs
General troubleshooting for Azure Policy on Kubernetes
Azure Policy Add-on for AKS Changelog
Azure Policy's Add-on for AKS has a version number that indicates the image version of add-on. As feature support is newly introduced on the Add-on, the version number is increased.
This section helps you identify which Add-on version is installed on your cluster and also share a historical table of the Azure Policy Add-on version installed per AKS cluster.
Identify which Add-on version is installed on your cluster
The Azure Policy Add-on uses the standardSemantic Versioningschema for each version. To identify the Azure Policy Add-on version being used, you can run the following command:kubectl get pod azure-policy-<unique-pod-identifier> -n kube-system -o json | jq '.spec.containers[0].image'
kubectl get pod azure-policy-<unique-pod-identifier> -n kube-system -o json | jq '.spec.containers[0].image'
To identify the Gatekeeper version that your Azure Policy Add-on is using, you can run the following command:kubectl get pod gatekeeper-controller-<unique-pod-identifier> -n gatekeeper-system -o json | jq '.spec.containers[0].image'
kubectl get pod gatekeeper-controller-<unique-pod-identifier> -n gatekeeper-system -o json | jq '.spec.containers[0].image'
Finally, to identify the AKS cluster version that you're using, follow the linked AKS guidance.
Add-on versions available per each AKS cluster version
Update thepolicy-kubernetes-addon-prodandpolicy-kubernetes-webhookimages to patchCVE-2025-30204andCVE-2025-22870.
policy-kubernetes-addon-prod
policy-kubernetes-webhook
Released April 2025
Kubernetes 1.27+
Gatekeeper 3.18.2
Security improvements.
CEL is enabled by default, you can continue using Rego. New CRD configpodstatuses.status.gatekeeper.sh is introduced (Reference:https://github.com/open-policy-agent/gatekeeper/issues/2918)
Released February 2025
Kubernetes 1.27+
Gatekeeper 3.18.2
Gatekeeper Release:https://github.com/open-policy-agent/gatekeeper/releases/tag/v3.18.2Changes:https://github.com/open-policy-agent/gatekeeper/compare/v3.17.1...v3.18.2
Security improvements.
Patch CVE-2024-45337 and CVE-2024-45338.
Released January 2025
Kubernetes 1.27+
Gatekeeper 3.17.1
Patch CVE-2024-45337 and CVE-2024-45338.
Policy can now be used to evaluate CONNECT operations, for instance, to denyexecs. Note that there is no brownfield compliance available for noncompliant CONNECT operations, so a policy with Audit effect that targets CONNECTs is a no op.
exec
Security improvements.
Released November 2024
Kubernetes 1.27+
Gatekeeper 3.17.1
Introducing CEL and VAP. Common Expression Language (CEL) is a Kubernetes-native expression language that can be used to declare validation rules of a policy. Validating Admission Policy (VAP) feature provides in-tree policy evaluation, reduces admission request latency, and improves reliability and availability. The supported validation actions include Deny, Warn, and Audit. Custom policy authoring for CEL/VAP is allowed, and existing users won't need to convert their Rego to CEL as they will both be supported and be used to enforce policies. To use CEL and VAP, users need to enroll in the feature flagAKS-AzurePolicyK8sNativeValidationin theMicrosoft.ContainerServicenamespace. For more information, view theGatekeeper Documentation.
AKS-AzurePolicyK8sNativeValidation
Microsoft.ContainerService
Security improvements.
Released September 2024
Kubernetes 1.27+ (VAP generation is only supported on 1.30+)
Gatekeeper 3.17.1
Introducing expansion, a shift left feature that lets you know up front whether your workload resources (Deployments, ReplicaSets, Jobs, etc.) will produce admissible pods. Expansion shouldn't change the behavior of your policies; rather, it just shifts Gatekeeper's evaluation of pod-scoped policies to occur at workload admission time rather than pod admission time. However, to perform this evaluation it must generate and evaluate a what-if pod that is based on the pod spec defined in the workload, which might have incomplete metadata. For instance, the what-if pod won't contain the proper owner references. Because of this small risk of policy behavior changing, we're introducing expansion as disabled by default. To enable expansion for a given policy definition, set.policyRule.then.details.sourcetoAll. Built-ins will be updated soon to enable parameterization of this field. If you test your policy definition and find that the what-if pod being generated for evaluation purposes is incomplete, you can also use a mutation with sourceGeneratedto mutate the what-if pods. For more information on this option, view theGatekeeper documentation.
.policyRule.then.details.source
All
Generated
Expansion is currently only available on AKS clusters, not Arc clusters.
Security improvements.
Released July 2024
Kubernetes 1.27+
Gatekeeper 3.16.3
Security improvements.
Released May 2024
Gatekeeper 3.14.2
Security improvements.
Released May 2024
Kubernetes 1.27+
Gatekeeper 3.16.3
Enables mutation and external data by default. The additional mutating webhook and increased validating webhook timeout cap might add latency to calls in the worst case. Also introduces support for viewing policy definition and set definition version in compliance results.
Released May 2024
Kubernetes 1.25+
Gatekeeper 3.14.0
Introduces error state for policies in error, enabling them to be distinguished from policies in noncompliant states. Adds support for v1 constraint templates and use of the excludedNamespaces parameter in mutation policies. Adds an error status check on constraint templates post-installation.
Released February 2024
Kubernetes 1.25+
Gatekeeper 3.14.0
Released October 2023
Kubernetes 1.25+
Gatekeeper 3.13.3
Released July 2023
Kubernetes 1.27+
Gatekeeper 3.11.1
Released June 2023
Kubernetes 1.24+
Gatekeeper 3.11.1
Azure Policy for Kubernetes now supports mutation to remediate AKS clusters at-scale!
Remove the add-on
Remove the add-on from AKS
To remove the Azure Policy Add-on from your AKS cluster, use either the Azure portal or Azure CLI:
Azure portalLaunch the AKS service in the Azure portal by selectingAll services, then searching for
and selectingKubernetes services.Select your AKS cluster where you want to disable the Azure Policy Add-on.SelectPolicieson the left side of the Kubernetes service page.In the main page, select theDisable add-onbutton.
Azure portal
Launch the AKS service in the Azure portal by selectingAll services, then searching for
and selectingKubernetes services.
Launch the AKS service in the Azure portal by selectingAll services, then searching for
and selectingKubernetes services.
Select your AKS cluster where you want to disable the Azure Policy Add-on.
Select your AKS cluster where you want to disable the Azure Policy Add-on.
SelectPolicieson the left side of the Kubernetes service page.
SelectPolicieson the left side of the Kubernetes service page.
In the main page, select theDisable add-onbutton.
In the main page, select theDisable add-onbutton.
Azure CLI# Log in first with az login if you're not using Cloud Shell

az aks disable-addons --addons azure-policy --name MyAKSCluster --resource-group MyResourceGroup
Azure CLI
# Log in first with az login if you're not using Cloud Shell

az aks disable-addons --addons azure-policy --name MyAKSCluster --resource-group MyResourceGroup
# Log in first with az login if you're not using Cloud Shell

az aks disable-addons --addons azure-policy --name MyAKSCluster --resource-group MyResourceGroup
Remove the add-on from Azure Arc enabled Kubernetes
Note
Azure Policy Add-on Helm model is now deprecated. You should opt for theAzure Policy Extension for Azure Arc enabled Kubernetesinstead.
To remove the Azure Policy Add-on and Gatekeeper from your Azure Arc enabled Kubernetes cluster, run
the following Helm command:
helm uninstall azure-policy-addon
helm uninstall azure-policy-addon
Remove the add-on from AKS Engine
Note
The AKS Engine product is now deprecated for Azure public cloud customers. Consider usingAzure Kubernetes Service (AKS)for managed Kubernetes orCluster API Provider Azurefor self-managed Kubernetes. There are no new features planned; this project will only be updated for CVEs & similar, with Kubernetes 1.24 as the final version to receive updates.
To remove the Azure Policy Add-on and Gatekeeper from your AKS Engine cluster, use the method that
aligns with how the add-on was installed:
If installed by setting theaddonsproperty in the cluster definition for AKS Engine:Redeploy the cluster definition to AKS Engine after changing theaddonsproperty forazure-policyto false:"addons": [
  {
    "name": "azure-policy",
    "enabled": false
  }
]For more information, seeAKS Engine - Disable Azure Policy Add-on.
If installed by setting theaddonsproperty in the cluster definition for AKS Engine:
Redeploy the cluster definition to AKS Engine after changing theaddonsproperty forazure-policyto false:
"addons": [
  {
    "name": "azure-policy",
    "enabled": false
  }
]
"addons": [
  {
    "name": "azure-policy",
    "enabled": false
  }
]
For more information, seeAKS Engine - Disable Azure Policy Add-on.
If installed with Helm Charts, run the following Helm command:helm uninstall azure-policy-addon
If installed with Helm Charts, run the following Helm command:
helm uninstall azure-policy-addon
helm uninstall azure-policy-addon
Limitations
For general Azure Policy definitions and assignment limits, reviewAzure Policy's documented limits
Azure Policy Add-on for Kubernetes can only be deployed to Linux node pools.
Maximum number of pods supported by the Azure Policy Add-on per cluster:10,000
Maximum number of Non-compliant records per policy per cluster:500
Maximum number of Non-compliant records per subscription:1 million
Reasons for non-compliancearen't available for the Microsoft.Kubernetes.DataResource Provider mode. UseComponent details.
Component-levelexemptionsaren't supported forResource Provider modes. Parameters support is available  in Azure Policy definitions to exclude and include particular namespaces.
Using themetadata.gatekeeper.sh/requires-sync-dataannotation in a constraint template to configure thereplication of datafrom your cluster into the OPA cache is currently only allowed for built-in policies. The reason is because it can dramatically increase the Gatekeeper pods resource usage if not used carefully.
metadata.gatekeeper.sh/requires-sync-data
Configuring the Gatekeeper Config
Changing the Gatekeeper config is unsupported, as it contains critical security settings. Edits to the config are reconciled.
Using data.inventory in constraint templates
Currently, several built-in policies make use ofdata replication, which enables users to sync existing on-cluster resources to the OPA cache and reference them during evaluation of anAdmissionReviewrequest. Data replication policies can be differentiated by the presence ofdata.inventoryin the Rego, and the presence of themetadata.gatekeeper.sh/requires-sync-dataannotation, which informs the Azure Policy addon which resources need to be cached for policy evaluation to work properly. This process differs from standalone Gatekeeper, where this annotation is descriptive, not prescriptive.
AdmissionReview
data.inventory
metadata.gatekeeper.sh/requires-sync-data
Data replication is currently blocked for use in custom policy definitions, because replicating resources with high instance counts can dramatically increase the Gatekeeper pods' resource usage if not used carefully. You'll see aConstraintTemplateInstallFailederror when attempting to create a custom policy definition containing a constraint template with this annotation.
ConstraintTemplateInstallFailed
Removing the annotation may appear to mitigate the error you see, but then the policy addon will not sync any required resources for that constraint template into the cache. Thus, your policies will be evaluated against an emptydata.inventory(assuming that no built-in is assigned that replicates the requisite resources). This will lead to misleading compliance results. As notedpreviously, manually editing the config to cache the required resources is also not permitted.
data.inventory
The following limitations apply only to the Azure Policy Add-on for AKS:
AKS Pod security policyand the Azure Policy Add-on for AKS can't both be enabled. For more information, seeAKS pod security limitation.
Namespaces automatically excluded by Azure Policy Add-on for evaluation: kube-system and gatekeeper-system.
Frequently asked questions
What does the Azure Policy Add-on / Azure Policy Extension deploy on my cluster upon installation?
The Azure Policy Add-on requires three Gatekeeper components to run: One audit pod and two webhook pod replicas. One Azure Policy pod and one Azure Policy webhook pod is also installed.
How much resource consumption should I expect the Azure Policy Add-on / Extension to use on each cluster?
The Azure Policy for Kubernetes components that run on your cluster consume more resources as the count of Kubernetes resources and policy assignments increases in the cluster, which requires audit and enforcement operations.
The following are estimates to help you plan:
For fewer than 500 pods in a single cluster with a max of 20 constraints: two vCPUs and 350 MB of memory per component.
For more than 500 pods in a single cluster with a max of 40 constraints: three vCPUs and 600 MB of memory per component.
Can Azure Policy for Kubernetes definitions be applied on Windows pods?
Windows podsdon't support security contexts. Thus, some of the Azure Policy definitions, like disallowing root privileges, can't be escalated in Windows pods and only apply to Linux pods.
What type of diagnostic data gets collected by Azure Policy Add-on?
The Azure Policy Add-on for Kubernetes collects limited cluster diagnostic data. This diagnostic
data is vital technical data related to software and performance. The data is used in the following ways:
Keep Azure Policy Add-on up to date.
Keep Azure Policy Add-on secure, reliable, performant.
Improve Azure Policy Add-on - through the aggregate analysis of the use of the add-on.
The information collected by the add-on isn't personal data. The following details are currently
collected:
Azure Policy Add-on agent version
Cluster type
Cluster region
Cluster resource group
Cluster resource ID
Cluster subscription ID
Cluster OS (Example: Linux)
Cluster city (Example: Seattle)
Cluster state or province (Example: Washington)
Cluster country or region (Example: United States)
Exceptions/errors encountered by Azure Policy Add-on during agent installation on policy
evaluation
Number of Gatekeeper policy definitions not installed by Azure Policy Add-on
What are general best practices to keep in mind when installing the Azure Policy Add-on?
Use system node pool withCriticalAddonsOnlytaint to schedule Gatekeeper pods. For more information, seeUsing system node pools.
CriticalAddonsOnly
Secure outbound traffic from your AKS clusters. For more information, seeControl egress trafficfor cluster nodes.
If the cluster hasaad-pod-identityenabled, Node Managed Identity (NMI) pods modify the nodesiptablesto intercept calls to the Azure Instance Metadata endpoint. This configuration means any request made to the Metadata endpoint is intercepted by NMI even if the pod doesn't useaad-pod-identity.
aad-pod-identity
iptables
aad-pod-identity
AzurePodIdentityExceptionCRD can be configured to informaad-pod-identitythat any requests to the Metadata endpoint originating from a pod that matches labels defined in CRD should be proxied without any processing in NMI. The system pods withkubernetes.azure.com/managedby: akslabel in kube-system namespace should be excluded inaad-pod-identityby configuring theAzurePodIdentityExceptionCRD. For more information, seeDisable aad-pod-identity for a specific pod or application. To configure an exception, install themic-exception YAML.
AzurePodIdentityException
aad-pod-identity
kubernetes.azure.com/managedby: aks
aad-pod-identity
AzurePodIdentityException
Next steps
Review examples atAzure Policy samples.
Review thePolicy definition structure.
ReviewUnderstanding policy effects.
Understand how toprogrammatically create policies.
Learn how toget compliance data.
Learn how toremediate non-compliant resources.
Review what a management group is withOrganize your resources with Azure management groups.
Feedback
Was this page helpful?
Additional resources