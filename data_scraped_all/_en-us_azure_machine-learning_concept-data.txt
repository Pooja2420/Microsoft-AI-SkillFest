Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Data concepts in Azure Machine Learning
Article
2025-02-10
21 contributors
In this article
With Azure Machine Learning, you can import data from a local machine or an existing cloud-based storage resource. This article describes key Azure Machine Learning data concepts.
Note
Azure Machine Learning resources do not support data imports from Synapse SQL data resources.
Datastore
An Azure Machine Learning datastore serves as areferenceto anexistingAzure storage account. An Azure Machine Learning datastore offers these benefits:
A common, easy-to-use API that interacts with different storage types (Blob/Files/ADLS).
Easier discovery of useful datastores in team operations.
For credential-based access (service principal/SAS/key), an Azure Machine Learning datastore secures connection information. This way, you don't need to place that information in your scripts.
When you create a datastore with an existing Azure storage account, you have two different authentication method options:
Credential-based- authenticate data access with a service principal, shared access signature (SAS) token, or account key. Users withReaderworkspace access can access the credentials.
Identity-based- use your Microsoft Entra identity or managed identity to authenticate data access.
This table summarizes the Azure cloud-based storage services that an Azure Machine Learning datastore can create. Additionally, the table summarizes the authentication types that can access those services:
For more information about datastores, visitCreate datastores.
Default datastores
Each Azure Machine Learning workspace has a default storage account (Azure storage account) that contains these datastores:
Tip
To find the ID for your workspace, go to the workspace in theAzure portal. ExpandSettings, and then selectProperties. TheWorkspace IDappears.
workspaceblobstore
azureml-blobstore-{workspace-id}
workspaceworkingdirectory
code-{GUID}
workspacefilestore
azureml-filestore-{workspace-id}
workspaceartifactstore
azureml
Data types
A URI (storage location) can reference a file, a folder, or a data table. A machine learning job input and output definition requires one of these three data types:
uri_file
FileDataset
os.path.join
uri_folder
FileDataset
FileDataset
mltable
TabularDataset
TabularDataset
mltable
URI
A Uniform Resource Identifier (URI) represents a storage location on your local computer, Azure storage, or a publicly available http(s) location. These examples show URIs for different storage options:
azureml://datastores/<data_store_name>/paths/<folder1>/<folder2>/<folder3>/<file>.parquet
./home/username/data/my_data
https://raw.githubusercontent.com/pandas-dev/pandas/main/doc/data/titanic.csv
wasbs://<containername>@<accountname>.blob.core.windows.net/<folder>/
abfss://<file_system>@<account_name>.dfs.core.windows.net/<folder>/<file>.csv
adl://<accountname>.azuredatalakestore.net/<folder1>/<folder2>
An Azure Machine Learning job maps URIs to the compute target filesystem. This mapping means that for a command that consumes or produces a URI, that URI works like a file or a folder. A URI usesidentity-based authenticationto connect to storage services, with either your Microsoft Entra ID (default) or Managed Identity. Azure Machine LearningDatastoreURIs can apply either identity-based authentication, orcredential-based(for example, Service Principal, SAS token, account key) authentication, without exposure of secrets.
A URI can serve as eitherinputor anoutputto an Azure Machine Learning job, and it can map to the compute target filesystem with one of four differentmodeoptions:
Read-onlymount (ro_mount): The URI represents a storage location that ismountedto the compute target filesystem. The mounted data location exclusively supports read-only output.
ro_mount
Read-writemount (rw_mount): The URI represents a storage location that ismountedto the compute target filesystem. The mounted data location supports both read output from itanddata writes to it.
rw_mount
Download (download): The URI represents a storage location containing data that isdownloadedto the compute target filesystem.
download
Upload (upload): All data written to a compute target location isuploadedto the storage location represented by the URI.
upload
Additionally, you can pass in the URI as a job input string with thedirectmode. This table summarizes the combination of modes available for inputs and outputs:
upload
download
ro_mount
rw_mount
direct
For more information, visitAccess data in a job.
Data runtime capability
Azure Machine Learning uses its owndata runtimefor one of three purposes:
for mounts/uploads/downloads
to map storage URIs to the compute target filesystem
to materialize tabular data into pandas/spark with Azure Machine Learning tables (mltable)
mltable
The Azure Machine Learning data runtime is designed forhigh speed and high efficiencyof machine learning tasks. It offers these key benefits:
Rustlanguage architecture. The Rust language is known for high speed and high memory efficiency.
Light weight; the Azure Machine Learning data runtime hasnodependencies on other technologies - JVM, for example - so the runtime installs quickly on compute targets.
Multi-process (parallel) data loading.
Data pre-fetches operate as background task on the CPU(s), to enhance utilization of the GPU(s) in deep-learning operations.
Seamless authentication to cloud storage.
Data asset
An Azure Machine Learning data asset resembles web browser bookmarks (favorites). Instead of remembering long storage paths (URIs) that point to your most frequently used data, you can create a data asset, and then access that asset with a friendly name.
Data asset creation also creates areferenceto the data source location, along with a copy of its metadata. Because the data remains in its existing location, you incur no extra storage cost, and you don't risk data source integrity. You can create Data assets from Azure Machine Learning datastores, Azure Storage, public URLs, or local files.
For more information about data assets, visitCreate data assets.
Next steps
Access data in a job
Install and set up the CLI (v2)
Create datastores
Create data assets
Data administration
Feedback
Was this page helpful?
Additional resources