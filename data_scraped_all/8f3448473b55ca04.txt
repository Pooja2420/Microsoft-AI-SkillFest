Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Application resilience FAQs for Azure NetApp Files
Article
2023-08-18
2 contributors
In this article
This article answers frequently asked questions (FAQs) about Azure NetApp Files application resilience.
What do you recommend for handling potential application disruptions due to storage service maintenance events?
Azure NetApp Files might undergo occasional planned maintenance (for example, platform updates, service or software upgrades). From a file protocol (NFS/SMB) perspective, the maintenance operations are nondisruptive, as long as the application can handle the IO pauses that might briefly occur during these events. The I/O pauses are typically short, ranging from a few seconds up to 30 seconds. The NFS protocol is especially robust, and client-server file operations continue normally. Some applications might require tuning to handle IO pauses for as long as 30-45 seconds. As such, ensure that you're aware of the applicationâs resiliency settings to cope with the storage service maintenance events. For human interactive applications leveraging the SMB protocol, the standard protocol settings are usually sufficient.
Important
To ensure a resilient architecture, it is crucial to recognize that the cloud operates under ashared responsibilitymodel. This model encompasses the Azure cloud platform, its infrastructure services, the OS-layer, and application vendors. Each of these components plays a vital role in gracefully handling potential application disruptions that may arise during storage service maintenance events.
Do I need to take special precautions for SMB-based applications?
Yes, certain SMB-based applications require SMB Transparent Failover. SMB Transparent Failover enables maintenance operations on the Azure NetApp Files service without interrupting connectivity to server applications storing and accessing data on SMB volumes. To support SMB Transparent Failover for specific applications, Azure NetApp Files now supports theSMB Continuous Availability shares option. Using SMB Continuous Availability is only supported for workloads on:
Citrix App Layering
FSLogix user profile containers
FSLogix ODFC containers
Microsoft SQL Server (not Linux SQL Server)
MSIX app attach
Caution
Custom applications are not supported with SMB Continuous Availability and cannot be used with SMB Continuous Availability enabled volumes.
I'm running IBM MQ on Azure NetApp Files. What precautions can I take to avoid disruptions due to storage service maintenance events despite using the NFS protocol?
If you're running theIBM MQ application in a shared files configuration, where the IBM MQ data and logs are stored on an Azure NetApp Files volume, the following considerations are recommended to improve resilience during storage service maintenance events:
You must use NFS v4.1 protocol only.
For High Availability, you should use anIBM MQ multi-instance configuration using shared NFS v4.1 volumes.
You should verify the functionality of theIBM multi-instance configuration using shared NFS v4.1 volumes.
You should implement a scale-out IBM MQ architecture instead of using one large multi-instance IBM MQ configuration. By spreading message processing load across multiple IBM MQ multi-instance pairs, the chance of service interruption might be decreased because each MQ multi-instance pair would be processing fewer messages.
Note
The number of messages that each MQ multi-instance pair should process is highly dependent on your specific environment. You need to decide how many MQ multi-instance pairs would be needed, or what the scale-up or scale-down rules would be.
The scale-out architecture would be comprised of multiple IBM MQ multi-instance pairs deployed behind an Azure Load Balancer. Applications configured to communicate with IBM MQ would then be configured to communicate with the IBM MQ instances via Azure Load Balancer. For support related to IBM MQ on shared NFS volumes, you should obtain vendor support at IBM.
I'm running Apache ActiveMQ with LevelDB or KahaDB on Azure NetApp Files. What precautions can I take to avoid disruptions due to storage service maintenance events despite using theNFSprotocol?
If you're running the Apache ActiveMQ, it's recommended to deployActiveMQ High Availability with Pluggable Storage Lockers.
ActiveMQ high availability (HA) models ensure that a broker instance is always online and able to process message traffic. The two most common ActiveMQ HA models involve sharing a filesystem over a network. The purpose is to provide either LevelDB or KahaDB to the active and passive broker instances. These HA models require that an OS-level lock be obtained and maintained on a file in the LevelDB or KahaDB directories, called "lock." There are some problems with this ActiveMQ HA model. They can lead to  a "no-master" situation, where the replica isnât aware that it can lock the file.  They can also lead to a "master-master" configuration that results in index or journal corruption and ultimately message loss. Most of these problems stem from factors outside of ActiveMQ's control. For instance, a poorly optimized NFS client can cause locking data to become stale under load, leading to âno-masterâ downtime during failover.
Because most problems with this HA solution stem from inaccurate OS-level file locking, the ActiveMQ communityintroduced the concept of a pluggable storage lockerin version 5.7 of the broker. This approach allows a user to take advantage of a different means of the shared lock, using a row-level JDBC database lock as opposed to an OS-level filesystem lock. For support or consultancy on ActiveMQ HA architectures and deployments, you shouldcontact OpenLogic by Perforce.
I'm running Apache ActiveMQ with LevelDB or KahaDB on Azure NetApp Files. What precautions can I take to avoid disruptions due to storage service maintenance events despites using theSMBprotocol?
The general industry recommendation is tonot run your KahaDB shared storage on CIFS [Common Internet File System]/SMB. If you're having trouble maintaining accurate lock state, check out the JDBC Pluggable Storage Locker, which can provide a more reliable locking mechanism. For support or consultancy on ActiveMQ HA architectures and deployments, you shouldcontact OpenLogic by Perforce.
Iâm running Boomi on Azure NetApp Files. What precautions can I take to avoid disruptions due to storage service maintenance events?
If you're running Boomi, it's recommended you follow theBoomi Best Practices for Run Time High Availability and Disaster Recovery.
Boomi recommends Boomi Molecule is used to implement high availability for Boomi Atom. TheBoomi Molecule system requirementsstate that either NFS with NFS locking enabled (NLM support) or SMB file shares can be used. In the context of Azure NetApp Files, NFSv4.1 volumes have NLM support.
Boomi recommends that SMB file share is used with Windows VMs; for NFS, Boomi recommends Linux VMs.
Note
Azure NetApp Files Continuous Availability Sharesare not supported with Boomi.
Next steps
How to create an Azure support request
Networking FAQs
Security FAQs
Performance FAQs
NFS FAQs
SMB FAQs
Capacity management FAQs
Data migration and protection FAQs
Azure NetApp Files backup FAQs
Integration FAQs
Mount NFS volumes for Linux or Windows VMs
Mount SMB volumes for Windows VMs
Feedback
Was this page helpful?
Additional resources