Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
How to use Azure OpenAI image generation models
Article
2025-04-24
2 contributors
In this article
OpenAI's image generation models render images based on user-provided text prompts and optionally provided images. This guide demonstrates how to use the image generation models and configure their options through REST API calls.
Prerequisites
An Azure subscription. You cancreate one for free.
An Azure OpenAI resource created in a supported region. SeeRegion availability.
Deploy adall-e-3orgpt-image-1model with your Azure OpenAI resource. For more information on deployments, seeCreate a resource and deploy a model with Azure OpenAI.GPT-image-1 is the newer model and features a number of improvements over DALL-E 3. It's available in limited access: apply for access withthis form.
dall-e-3
gpt-image-1
GPT-image-1 is the newer model and features a number of improvements over DALL-E 3. It's available in limited access: apply for access withthis form.
Call the Image Generation API
The following command shows the most basic way to use an image model with code. If this is your first time using these models programmatically, we recommend starting with thequickstart.
GPT-image-1
DALL-E 3
Send a POST request to:
https://<your_resource_name>.openai.azure.com/openai/deployments/<your_deployment_name>/images/generations?api-version=<api_version>
https://<your_resource_name>.openai.azure.com/openai/deployments/<your_deployment_name>/images/generations?api-version=<api_version>
URL:
Replace the following values:
<your_resource_name>is the name of your Azure OpenAI resource.
<your_resource_name>
<your_deployment_name>is the name of your DALL-E 3 or GPT-image-1 model deployment.
<your_deployment_name>
<api_version>is the version of the API you want to use. For example,2025-04-01-preview.
<api_version>
2025-04-01-preview
Required headers:
Content-Type:application/json
Content-Type
application/json
api-key:<your_API_key>
api-key
<your_API_key>
Body:
The following is a sample request body. You specify a number of options, defined in later sections.
{
    "prompt": "A multi-colored umbrella on the beach, disposable camera",
    "model": "gpt-image-1",
    "size": "1024x1024", 
    "n": 1,
    "quality": "high"
}
{
    "prompt": "A multi-colored umbrella on the beach, disposable camera",
    "model": "gpt-image-1",
    "size": "1024x1024", 
    "n": 1,
    "quality": "high"
}
Send a POST request to:
https://<your_resource_name>.openai.azure.com/openai/deployments/<your_deployment_name>/images/generations?api-version=<api_version>
https://<your_resource_name>.openai.azure.com/openai/deployments/<your_deployment_name>/images/generations?api-version=<api_version>
URL:
Replace the following values:
<your_resource_name>is the name of your Azure OpenAI resource.
<your_resource_name>
<your_deployment_name>is the name of your DALL-E 3 or GPT-image-1 model deployment.
<your_deployment_name>
<api_version>is the version of the API you want to use. For example,2024-02-01.
<api_version>
2024-02-01
Required headers:
Content-Type:application/json
Content-Type
application/json
api-key:<your_API_key>
api-key
<your_API_key>
Body:
The following is a sample request body. You specify a number of options, defined in later sections.
{
    "prompt": "A multi-colored umbrella on the beach, disposable camera",
    "size": "1024x1024", 
    "n": 1,
    "quality": "hd", 
    "style": "vivid"
}
{
    "prompt": "A multi-colored umbrella on the beach, disposable camera",
    "size": "1024x1024", 
    "n": 1,
    "quality": "hd", 
    "style": "vivid"
}
Output
The response from a successful image generation API call looks like the following example. Theurlfield contains a URL where you can download the generated image. The URL stays active for 24 hours.
url
{ 
    "created": 1698116662, 
    "data": [ 
        { 
            "url": "<URL_to_generated_image>",
            "revised_prompt": "<prompt_that_was_used>" 
        }
    ]
}
{ 
    "created": 1698116662, 
    "data": [ 
        { 
            "url": "<URL_to_generated_image>",
            "revised_prompt": "<prompt_that_was_used>" 
        }
    ]
}
API call rejection
Prompts and images are filtered based on our content policy, returning an error when a prompt or image is flagged.
If your prompt is flagged, theerror.codevalue in the message is set tocontentFilter. Here's an example:
error.code
contentFilter
{
    "created": 1698435368,
    "error":
    {
        "code": "contentFilter",
        "message": "Your task failed as a result of our safety system."
    }
}
{
    "created": 1698435368,
    "error":
    {
        "code": "contentFilter",
        "message": "Your task failed as a result of our safety system."
    }
}
It's also possible that the generated image itself is filtered. In this case, the error message is set toGenerated image was filtered as a result of our safety system. Here's an example:
{
    "created": 1698435368,
    "error":
    {
        "code": "contentFilter",
        "message": "Generated image was filtered as a result of our safety system."
    }
}
{
    "created": 1698435368,
    "error":
    {
        "code": "contentFilter",
        "message": "Generated image was filtered as a result of our safety system."
    }
}
Write text-to-image prompts
Your prompts should describe the content you want to see in the image, and the visual style of image.
When you write prompts, consider that the Image APIs come with a content moderation filter. If the service recognizes your prompt as harmful content, it doesn't generate an image. For more information, seeContent filtering.
Tip
For a thorough look at how you can tweak your text prompts to generate different kinds of images, see theImage prompt engineering guide.
Specify API options
The following API body parameters are available for image generation models.
GPT-image-1
DALL-E 3
Specify the size of the generated images. Must be one of1024x1024,1024x1536, or1536x1024for GPT-image-1 models. Square images are faster to generate.
1024x1024
1024x1536
1536x1024
There are three options for image quality:low,medium, andhigh.Lower quality images can be generated faster.
low
medium
high
The default value ishigh.
high
You can generate between one and 10 images in a single API call. The default value is1.
1
The format in which the generated images are returned. Must be eitherurl(a URL pointing to the image) orb64_json(the base 64-byte code in JSON format). The default isurl.
url
b64_json
url
Use theuserparameter to specify a unique identifier for the user making the request. This is useful for tracking and monitoring usage patterns. The value can be any string, such as a user ID or email address.
Use theoutput_formatparameter to specify the format of the generated image. Supported formats arePNGandJPEG. The default isPNG.
PNG
JPEG
PNG
Note
WEBP images are not supported in the Azure OpenAI Service.
Use theoutput_compressionparameter to specify the compression level for the generated image. Input an integer between0and100, where0is no compression and100is maximum compression. The default is100.
0
100
0
100
100
Specify the size of the generated images. Must be one of1024x1024,1792x1024, or1024x1792for DALL-E 3 models. Square images are faster to generate.
1024x1024
1792x1024
1024x1792
DALL-E 3 offers two style options:naturalandvivid. The natural style is more similar to the default style of older models, while the vivid style generates more hyper-real and cinematic images.
natural
vivid
The natural style is useful in cases where DALL-E 3 over-exaggerates or confuses a subject that's meant to be more simple, subdued, or realistic.
The default value isvivid.
vivid
There are two options for image quality:hdandstandard. The hd option creates images with finer details and greater consistency across the image. Standard images can be generated faster.
hd
standard
The default value isstandard.
standard
With DALL-E 3, you can't generate more than one image in a single API call: thenparameter must be set to1. If you need to generate multiple images at once, make parallel requests.
n
The format in which the generated images are returned. Must be one ofurl(a URL pointing to the image) orb64_json(the base 64-byte code in JSON format). The default isurl.
url
b64_json
url
Call the Image Edit API
The Image Edit API allows you to modify existing images based on text prompts you provide. The API call is similar to the image generation API call, but you also need to provide an image URL or base 64-encoded image data.
GPT-image-1
DALL-E 3
Send a POST request to:
https://<your_resource_name>.openai.azure.com/openai/deployments/<your_deployment_name>/images/edits?api-version=<api_version>
https://<your_resource_name>.openai.azure.com/openai/deployments/<your_deployment_name>/images/edits?api-version=<api_version>
URL:
Replace the following values:
<your_resource_name>is the name of your Azure OpenAI resource.
<your_resource_name>
<your_deployment_name>is the name of your DALL-E 3 or GPT-image-1 model deployment.
<your_deployment_name>
<api_version>is the version of the API you want to use. For example,2025-04-01-preview.
<api_version>
2025-04-01-preview
Required headers:
Content-Type:application/json
Content-Type
application/json
api-key:<your_API_key>
api-key
<your_API_key>
Body:
The following is a sample request body. You specify a number of options, defined in later sections.
{
    "image": "<base64_encoded_image>",
    "prompt": "Add a beach ball in the center.",
    "model": "gpt-image-1",
    "size": "1024x1024", 
    "n": 1,
    "quality": "high"
}
{
    "image": "<base64_encoded_image>",
    "prompt": "Add a beach ball in the center.",
    "model": "gpt-image-1",
    "size": "1024x1024", 
    "n": 1,
    "quality": "high"
}
Output
The response from a successful image editing API call looks like the following example. Theurlfield contains a URL where you can download the generated image. The URL stays active for 24 hours.
url
{ 
    "created": 1698116662, 
    "data": [ 
        { 
            "url": "<URL_to_generated_image>",
            "revised_prompt": "<prompt_that_was_used>" 
        }
    ]
}
{ 
    "created": 1698116662, 
    "data": [ 
        { 
            "url": "<URL_to_generated_image>",
            "revised_prompt": "<prompt_that_was_used>" 
        }
    ]
}
Specify API options
The following API body parameters are available for image editing models, in addition to the ones available for image generation models.
Image
Theimagevalue indicates the image file you want to edit. It can be either a URL string to an image file, or base 64-encoded image data.
Themaskparameter is the same type as the mainimageinput parameter. It defines the area of the image that you want the model to change, using fully transparent pixels (alpha of zero) in those areas. The mask can be a URL or base 64-encoded image data. It must be a PNG file and have the same dimensions as the image.
DALL-E models don't support the Image Edit API.
Related content
What is Azure OpenAI Service?
Quickstart: Generate images with Azure OpenAI Service
Image API reference
Image API (preview) reference
Feedback
Was this page helpful?
Additional resources