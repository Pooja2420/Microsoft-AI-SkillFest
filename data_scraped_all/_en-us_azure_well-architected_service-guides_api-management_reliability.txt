Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Architecture best practices for Azure API Management
Article
2025-04-17
4 contributors
In this article
Azure API Management is a management platform and gateway for APIs across all environments, including hybrid and multicloud. As a platform as a service (PaaS) solution, API Management helps support your workload's API lifecycle.
This article assumes that as an architect, you've reviewed theintegration services decision treeand chosen API Management as the integration service for your workload. The guidance in this article provides architectural recommendations that are mapped to the principles of theWell-Architected Framework pillars.
Important
How to use this guide
Each section has adesign checklistthat presents architectural areas of concern along with design strategies localized to the technology scope.
Also included are recommendations for the technology capabilities that can help materialize those strategies. The recommendations don't represent an exhaustive list of all configurations that are available for API Management or the back-end API servers of your workload. Instead, they list the key recommendations mapped to the design perspectives. Use the recommendations to build your proof-of-concept or to optimize your existing environments.
Foundational architecture that demonstrates the key recommendations:API Management landing zone architecture.
Technology scope
This review focuses on the interrelated decisions for the following Azure resource:
Azure API Management
The scope of this guide is the API Management service, primarily the gateway component (data plane), which proxies API requests from client applications to back-end APIs hosted on various platforms or cross-premises locations. The workload's architecture should account for the API Management control plane and related components such as client applications that access the gateway and the back-end APIs that process routed requests. It also integrates supporting Azure services, including networking, monitoring, identity management, and other capabilities.
This guide doesn't coverAzure API Center. It addresses API-level topics as they relate to API Management instead of providing a well-architected perspective on API design considerations.
Note
Not all recommendations apply to allservice tiersof API Management. Many recommendations in this guide focus on the Standard v2 and classic Premium tiers of API Management, which are the recommended production tiers for most enterprise workloads.
Important
The Premium v2 tier with enterprise capabilities is in preview. To determine whether your design should rely on early access features or generally available capabilities, evaluate your design and implementation timelines in relation to the available information about Premium v2's release and migration paths.
Reliability
The purpose of the Reliability pillar is to provide continued functionality bybuilding enough resilience and the ability to recover fast from failures.
Reliability design principlesprovide a high-level design strategy applied for individual components, system flows, and the system as a whole.
Design checklist
Start your design strategy based on thedesign review checklist for Reliability. Determine its relevance to your business requirements while keeping in mind the tiers and features of API Management and its dependencies. Extend the strategy to include more approaches as needed.
Evaluate gateway capabilities for reliability and redundancy:Determine the API Managementtier and featuresthat are needed to meet the workload's reliability requirements for each environment.Evaluate gateway redundancy features, including availability zones, multiple gateway units, multiple regions, and workspaces. These features are all supported in the Premium tier. The Developer tier, which doesn't include a service-level agreement (SLA), isn't suitable for production workloads. Consider the tradeoffs of adopting features such as external caching that can introduce potential points of failure and performance bottlenecks.
Evaluate gateway capabilities for reliability and redundancy:Determine the API Managementtier and featuresthat are needed to meet the workload's reliability requirements for each environment.
Evaluate gateway redundancy features, including availability zones, multiple gateway units, multiple regions, and workspaces. These features are all supported in the Premium tier. The Developer tier, which doesn't include a service-level agreement (SLA), isn't suitable for production workloads. Consider the tradeoffs of adopting features such as external caching that can introduce potential points of failure and performance bottlenecks.
Review observability capabilities:Consider the service'sobservability capabilities, including Azure Monitor logs and metrics, Application Insights, built-in analytics, and built-in diagnostics. Use these capabilities to monitor the reliability signals of your workload.For example, consider usingAzure Monitor alertsto notify you of potential problems with the API Management gateway or its dependencies.
Review observability capabilities:Consider the service'sobservability capabilities, including Azure Monitor logs and metrics, Application Insights, built-in analytics, and built-in diagnostics. Use these capabilities to monitor the reliability signals of your workload.
For example, consider usingAzure Monitor alertsto notify you of potential problems with the API Management gateway or its dependencies.
Review scaling strategies:Define criteria forscaling outthe gateway by adding units to maintain service reliability. Consider whether to scale based on requests, exceptions, or both. Evaluate the impact of scaling the gateway component on other components of the workload. For example, its effect on network address space and the scaling capabilities of the back ends.
Review scaling strategies:Define criteria forscaling outthe gateway by adding units to maintain service reliability. Consider whether to scale based on requests, exceptions, or both. Evaluate the impact of scaling the gateway component on other components of the workload. For example, its effect on network address space and the scaling capabilities of the back ends.
Isolate critical workloads:Determine if compute isolation is needed to fulfill workload requirements, like data sovereignty or performance optimization, in your APIs. Use dedicated gateways for critical APIs and shared gateways for less critical APIs.Choose an isolation approach, like using adedicated workspace gatewayor a separate API Management instance. For multiple instances, keep the environments synchronized as part of your safe deployment practices.
Isolate critical workloads:Determine if compute isolation is needed to fulfill workload requirements, like data sovereignty or performance optimization, in your APIs. Use dedicated gateways for critical APIs and shared gateways for less critical APIs.
Choose an isolation approach, like using adedicated workspace gatewayor a separate API Management instance. For multiple instances, keep the environments synchronized as part of your safe deployment practices.
Service-level objective (SLO) alignment:Factor in the gateway's SLA scope when you set your workload's SLOs. The service provides its own SLA, but you also need to account for the anticipated reliability of other workload components, such as the API back ends.
Service-level objective (SLO) alignment:Factor in the gateway's SLA scope when you set your workload's SLOs. The service provides its own SLA, but you also need to account for the anticipated reliability of other workload components, such as the API back ends.
Address back-end faults:Plan for both expected and unexpected back-end faults. Test client experiences in these scenarios. Evaluate gatewaypoliciesto improve resiliency and enhance the client experience. Focus on quotas, rate limits, retry policies, back-end circuit breakers, load balancing, and exception handling as documented in your API specifications.
Address back-end faults:Plan for both expected and unexpected back-end faults. Test client experiences in these scenarios. Evaluate gatewaypoliciesto improve resiliency and enhance the client experience. Focus on quotas, rate limits, retry policies, back-end circuit breakers, load balancing, and exception handling as documented in your API specifications.
Define testing strategies:Use a testing solution such asAzure Load Testingfrom within your network to reflect actual production workloads. Don't rely on published throughput or other estimates which might not apply to your workload.
Define testing strategies:Use a testing solution such asAzure Load Testingfrom within your network to reflect actual production workloads. Don't rely on published throughput or other estimates which might not apply to your workload.
Plan for disaster recovery (DR):Review options for backing up and restoring the gateway infrastructure and APIs. Built-inbackup and restore capabilitiesmight be useful in some scenarios. But customer-managed options such asAPIOpstooling and infrastructure as code (IaC) solutions can also be considered. Develop strategies for maintaining other system data, including user subscriptions.
Plan for disaster recovery (DR):Review options for backing up and restoring the gateway infrastructure and APIs. Built-inbackup and restore capabilitiesmight be useful in some scenarios. But customer-managed options such asAPIOpstooling and infrastructure as code (IaC) solutions can also be considered. Develop strategies for maintaining other system data, including user subscriptions.
Recommendations
These reliability recommendations can apply either to the service itself or to the traffic that flows through APIs and their policies. The(Service)or(API)designators indicate whether a recommendation targets the service or the APIs.
Security
The purpose of the Security pillar is to provideconfidentiality, integrity, and availabilityguarantees to the workload.
TheSecurity design principlesprovide a high-level design strategy for achieving those goals by applying approaches to the technical design in protecting the API Management gateway.
Note
The checklist and recommendations in this section focus on securing the API Management gateway resource. Securing the APIs themselves is only briefly addressed. For more information, seeMitigate OWASP API security top 10 in API Management.
Design checklist
Start your design strategy based on thedesign review checklist for Securityand identify vulnerabilities and controls to improve the security posture. Extend the strategy to include more approaches as needed.
Establish a security baseline:Review thesecurity baseline for API Managementand incorporate applicable measures in your baseline.
Establish a security baseline:Review thesecurity baseline for API Managementand incorporate applicable measures in your baseline.
Protect the deployment pipeline:Identify the individuals and role-based access control roles that are required to manage the service platform, continuous integration and continuous deployment (CI/CD) pipelines, and the individual APIs. Ensure that only authorized individuals have access to manage the service and its APIs.
Protect the deployment pipeline:Identify the individuals and role-based access control roles that are required to manage the service platform, continuous integration and continuous deployment (CI/CD) pipelines, and the individual APIs. Ensure that only authorized individuals have access to manage the service and its APIs.
Evaluate data sensitivity:If sensitive data flows through API requests and responses in the API Management gateway, ensure its protection throughout its entire lifecycle. Account for varying data protection requirements across different regions. Evaluate service features such asmultiple regionsto isolate specific data. Also, confirm whether your caching strategy aligns with these isolation requirements.
Evaluate data sensitivity:If sensitive data flows through API requests and responses in the API Management gateway, ensure its protection throughout its entire lifecycle. Account for varying data protection requirements across different regions. Evaluate service features such asmultiple regionsto isolate specific data. Also, confirm whether your caching strategy aligns with these isolation requirements.
Develop segmentation strategies on shared gateways:If your API Management instance hosts APIs for multiple workload teams, useworkspacesto segregate roles, networks, and possibly gateways. This approach ensures that each team has appropriate access and control over the APIs that they manage while restricting access to the APIs of other teams.
Develop segmentation strategies on shared gateways:If your API Management instance hosts APIs for multiple workload teams, useworkspacesto segregate roles, networks, and possibly gateways. This approach ensures that each team has appropriate access and control over the APIs that they manage while restricting access to the APIs of other teams.
Consider network controls:Identify requirements and options for isolating or filtering inbound and outbound gateway traffic by usingvirtual networks. Determine whether access to the gateway can be restricted through Azure Private Link or if public access to the gateway is necessary. Assess whether the architecture should include a web application firewall, such as Azure Web Application Firewall in Azure Application Gateway or Azure Front Door, to achieve the required network isolation and filter network traffic.
Consider network controls:Identify requirements and options for isolating or filtering inbound and outbound gateway traffic by usingvirtual networks. Determine whether access to the gateway can be restricted through Azure Private Link or if public access to the gateway is necessary. Assess whether the architecture should include a web application firewall, such as Azure Web Application Firewall in Azure Application Gateway or Azure Front Door, to achieve the required network isolation and filter network traffic.
Consider capabilities for API authentication and authorization:Evaluate the use of identity providers likeMicrosoft Entra ID, which includes built-in groups, orMicrosoft Entra External IDto screen gateway requests and enable OAuth authorization for back-end APIs.
Consider capabilities for API authentication and authorization:Evaluate the use of identity providers likeMicrosoft Entra ID, which includes built-in groups, orMicrosoft Entra External IDto screen gateway requests and enable OAuth authorization for back-end APIs.
Encrypt network traffic:Identify the most secure Transport Layer Security (TLS)protocol versions and ciphersthat your workloads can support. Don't require insecure TLS versions. Use TLS 1.3 when supported by your clients.
Encrypt network traffic:Identify the most secure Transport Layer Security (TLS)protocol versions and ciphersthat your workloads can support. Don't require insecure TLS versions. Use TLS 1.3 when supported by your clients.
Perform threat modeling on API Management and reduce its surface area:Determine whether specific API Management components, such as the direct management API or public access to the developer portal, can be disabled, restricted, or removed.
Perform threat modeling on API Management and reduce its surface area:Determine whether specific API Management components, such as the direct management API or public access to the developer portal, can be disabled, restricted, or removed.
Identify secrets that workloads require:Gateway operation might require certificates, API keys, or other secret values. Review the requirements and capabilities of Azure Key Vault to store secrets and certificates. Or review the built-in API Management capabilities such asnamed valuesandmanaged certificates.
Identify secrets that workloads require:Gateway operation might require certificates, API keys, or other secret values. Review the requirements and capabilities of Azure Key Vault to store secrets and certificates. Or review the built-in API Management capabilities such asnamed valuesandmanaged certificates.
Recommendations
These security recommendations can apply either to the service itself or to the traffic that flows through APIs and their policies. The(Service)or(API)designators indicate whether a recommendation targets the service or the APIs.
Cost Optimization
Cost Optimization focuses ondetecting spend patterns, prioritizing investments in critical areas, and optimizing in othersto meet the organization's budget while meeting business requirements.
TheCost Optimization design principlesprovide a high-level design strategy for achieving those goals and making tradeoffs as necessary in the technical design related to API Management and its environment.
Design checklist
Consider the API Management cost model:Use theAzure pricing calculatorwith your organization's account benefits and criteria for SLA and scalability to develop accurate cost estimates of using an API Management service tier. Determine whether a charge-back model is necessary and determine how to calculate it based on metrics, tags, and tokens.The service cost model is mainly influenced by the service tier, number of units, and number of gateways. Evaluate the extra costs associated with maintaining a reserve unit or implementing an active-passive DR configuration.If you implementworkspaces, evaluate the costs of using separate versus shared workspace gateways to address the distinct API flow requirements of various API teams or stakeholders.
Consider the API Management cost model:Use theAzure pricing calculatorwith your organization's account benefits and criteria for SLA and scalability to develop accurate cost estimates of using an API Management service tier. Determine whether a charge-back model is necessary and determine how to calculate it based on metrics, tags, and tokens.
The service cost model is mainly influenced by the service tier, number of units, and number of gateways. Evaluate the extra costs associated with maintaining a reserve unit or implementing an active-passive DR configuration.
If you implementworkspaces, evaluate the costs of using separate versus shared workspace gateways to address the distinct API flow requirements of various API teams or stakeholders.
Estimate scaling costs:Develop scaling criteria to maintain high usage of the gateway resources. Evaluate baseline costs in a pre-production environment and perform testing to model costs of scaling out based on anticipated workload traffic.Design a mitigation strategy to prevent misuse of your gateways, which might cause expensive scaling beyond predicated usage.
Estimate scaling costs:Develop scaling criteria to maintain high usage of the gateway resources. Evaluate baseline costs in a pre-production environment and perform testing to model costs of scaling out based on anticipated workload traffic.
Design a mitigation strategy to prevent misuse of your gateways, which might cause expensive scaling beyond predicated usage.
Evaluate service configurations and policies:Capabilities such asrate-limitandlimit-concurrencycan be used as cost optimization techniques to manage request loads.
Evaluate service configurations and policies:Capabilities such asrate-limitandlimit-concurrencycan be used as cost optimization techniques to manage request loads.
Optimize logic placement:Assess whether back-end servers are more cost-effective for processing logic or if the gateway should handle the resource usage. The gateway is a strong component for implementing cross-cutting concerns, but it might perform excessive functions in certain scenarios. Identify resource-heavy request processing tasks that the gateway performs, and determine whether moving that logic to back-end servers can reduce costs.
Optimize logic placement:Assess whether back-end servers are more cost-effective for processing logic or if the gateway should handle the resource usage. The gateway is a strong component for implementing cross-cutting concerns, but it might perform excessive functions in certain scenarios. Identify resource-heavy request processing tasks that the gateway performs, and determine whether moving that logic to back-end servers can reduce costs.
Recommendations
These cost optimization recommendations can apply either to the service itself or to the traffic that flows through APIs and their policies. The(Service)or(API)designators indicate whether a recommendation targets the service or the APIs.
Operational Excellence
Operational Excellence primarily focuses on procedures fordevelopment practices, observability, and release management.
TheOperational Excellence design principlesprovide a high-level design strategy for achieving those goals for the operational requirements of the workload.
Start your design strategy based on thedesign review checklist for Operational Excellencefor defining processes for observability, testing, and deployment related to API Management.
Design checklist
Review key knowledge and skills needed to operate the service:Areas include API lifecycle, DevOps processes, networking and connectivity, monitoring and observability, and software development. This approach encompasses policy configuration, unit testing, and the creation of CI/CD pipelines.
Review key knowledge and skills needed to operate the service:Areas include API lifecycle, DevOps processes, networking and connectivity, monitoring and observability, and software development. This approach encompasses policy configuration, unit testing, and the creation of CI/CD pipelines.
Consider documentation needs:Organizations should commit to documenting processes for service-level and API-level configuration, lifecycle operations, and the different access patterns for API teams.
Consider documentation needs:Organizations should commit to documenting processes for service-level and API-level configuration, lifecycle operations, and the different access patterns for API teams.
Evaluate standard toolingto support service operations. For example, adoptAPIOpsmethods, such as GitOps and CI/CD, to publish APIs and manage API configurations. Use IaC tooling for service-level configuration changes. Design reusable artifacts that can seamlessly transition from development environments to production. Consider integrating a linter likeSpectral, either self-managed or as integrated into an Azure service likeAzure API Center, into API approval pipelines.
Evaluate standard toolingto support service operations. For example, adoptAPIOpsmethods, such as GitOps and CI/CD, to publish APIs and manage API configurations. Use IaC tooling for service-level configuration changes. Design reusable artifacts that can seamlessly transition from development environments to production. Consider integrating a linter likeSpectral, either self-managed or as integrated into an Azure service likeAzure API Center, into API approval pipelines.
Determine key operational metrics and logs:Review themetricsfor production. These metrics include gateway capacity, CPU usage, memory usage, and the number of requests. Review logs andobservability tools, such as Azure Monitor and Application Insights. Determine the strategies and tools needed to effectively manage large volumes of observational data in production environments. Determine queries that deliver actionable insights for both the gateway operator and stakeholders that monitor specific hosted APIs.
Determine key operational metrics and logs:Review themetricsfor production. These metrics include gateway capacity, CPU usage, memory usage, and the number of requests. Review logs andobservability tools, such as Azure Monitor and Application Insights. Determine the strategies and tools needed to effectively manage large volumes of observational data in production environments. Determine queries that deliver actionable insights for both the gateway operator and stakeholders that monitor specific hosted APIs.
Plan regular testing of production workloadsby using load testing.
Plan regular testing of production workloadsby using load testing.
Identify operational tasks beyond CI/CD or IaC processesthat require automation. Plan automation in areas such as API Management policy source management, Azure policies, and specific developer portal configurations.
Identify operational tasks beyond CI/CD or IaC processesthat require automation. Plan automation in areas such as API Management policy source management, Azure policies, and specific developer portal configurations.
Recommendations
These operational excellence recommendations can apply to either the service itself or to the traffic that flows through APIs and their policies. The(Service)or(API)designators indicate whether a recommendation targets the service or the APIs.
APICreated
Performance Efficiency
Performance Efficiency is aboutmaintaining user experience even when there's an increase in loadby managing capacity. The strategy includes scaling resources, identifying and optimizing potential bottlenecks, and optimizing for peak performance.
ThePerformance Efficiency design principlesprovide a high-level design strategy for achieving those capacity goals against the expected usage.
Start your design strategy based on thedesign review checklist for Performance Efficiencyfor defining a baseline based on key performance indicators for API Management.
Design checklist
Define performance targets:Key metrics to evaluate the performance of the API Management gateway include capacity metrics, such as CPU and memory usage percentages for gateway infrastructure, request duration, and request throughput. In multiregion deployments, define performance targets for each region. The customer needs to define appropriate scaling thresholds based on traffic patterns, API workloads, and scaling times.
Define performance targets:Key metrics to evaluate the performance of the API Management gateway include capacity metrics, such as CPU and memory usage percentages for gateway infrastructure, request duration, and request throughput. In multiregion deployments, define performance targets for each region. The customer needs to define appropriate scaling thresholds based on traffic patterns, API workloads, and scaling times.
Collect performance data:Review capabilities of built-in analytics, Azure Monitor metrics, Azure Monitor logs, Application Insights, and Event Hubs to collect and analyze performance at different levels of granularity.
Collect performance data:Review capabilities of built-in analytics, Azure Monitor metrics, Azure Monitor logs, Application Insights, and Event Hubs to collect and analyze performance at different levels of granularity.
Review how to identify live performance problems:Indicators for live performance problems include Azure service availability, HTTP response errors, and errors raised in theDiagnose and solve problemssection in the portal. Troubleshoot performance and availability problems by using Application Insights, Kusto queries, and recommendations from API Management Diagnostics in the Azure portal.
Review how to identify live performance problems:Indicators for live performance problems include Azure service availability, HTTP response errors, and errors raised in theDiagnose and solve problemssection in the portal. Troubleshoot performance and availability problems by using Application Insights, Kusto queries, and recommendations from API Management Diagnostics in the Azure portal.
Test performance:Test performance under production conditions by using load testing.
Test performance:Test performance under production conditions by using load testing.
Evaluate adjacent services that might improve performance:Caching policies or an external cache might improve the performance of specific API operations. Azure Front Door and Application Gateway are common choices for TLS offloading.
Evaluate adjacent services that might improve performance:Caching policies or an external cache might improve the performance of specific API operations. Azure Front Door and Application Gateway are common choices for TLS offloading.
Review the documented limits and constraints:API Management has limits and constraints. Review the documented constraints and compare them against your workload's requirements to see if you need to design a solution that avoids these constraints.
Review the documented limits and constraints:API Management has limits and constraints. Review the documented constraints and compare them against your workload's requirements to see if you need to design a solution that avoids these constraints.
Recommendations
These performance efficiency recommendations can apply either to the service itself or to the traffic that flows through APIs and their policies. The(Service)or(API)designators indicate whether a recommendation targets the service or the APIs.
Azure policies
Azure provides an extensive set of built-in policies related to API Management and its dependencies. Some of the preceding recommendations can be audited through Azure Policy. For example, you can check whether:
The gateway is configured for zone redundancy.
Proper network controls are in place for the API Management gateway, such as deployment in a virtual network.
The service configuration endpoints aren't publicly accessible.
The direct Management REST API is disabled.
For comprehensive governance, review theAzure Policy built-in definitionsand other policies that might affect the security of the API Management gateway.
Azure Advisor recommendations
Azure Advisor is a personalized cloud consultant that helps you follow best practices to optimize your Azure deployments.
For more information, seeAzure Advisor.
Advisor might surface other recommendations in your production system as well, such as:
Failure to require long JWT key sizes in the validate-jwt policy.
You used a legacy Resource Manager API version to deploy the resource.
API key tokens are close to their expiration date.
Failure in a certificate rotation operation.
Tradeoffs
You might have to make design tradeoffs if you use the approaches in the pillar checklists. Here are some examples of advantages and drawbacks.
High availability through redundancy and isolation
High availability.Adding redundancy to an architecture affects costs. For example, provisioning at least three units to avoid zonal outages might not be financially feasible for your workload. Costs increase further with a multiregion architecture, which requires at least six units, or three units per region. A multiregion setup also adds operational costs for coordinating safe deployments, reliable scaling, and failover coordination with back ends.
High availability.Adding redundancy to an architecture affects costs. For example, provisioning at least three units to avoid zonal outages might not be financially feasible for your workload. Costs increase further with a multiregion architecture, which requires at least six units, or three units per region. A multiregion setup also adds operational costs for coordinating safe deployments, reliable scaling, and failover coordination with back ends.
Isolation.Isolating workloads across workspaces or API Management instances adds operational complexity because it includes managing a multitenant system that has compute isolation.
Isolation.Isolating workloads across workspaces or API Management instances adds operational complexity because it includes managing a multitenant system that has compute isolation.
Scale to match demand
When you automatically scale out to meet the demand from well-behaved clients, those costs are already factored into your cost models. However, this scaling capability also allows the service to scale to handle traffic from nuisance and malicious traffic.
When you automatically scale out to meet the demand from well-behaved clients, those costs are already factored into your cost models. However, this scaling capability also allows the service to scale to handle traffic from nuisance and malicious traffic.
Mitigating undesired traffic incurs costs. Adding services like a web application firewall and DDoS protection increases expenses. Scaling your service to handle traffic increases costs because of added units. Setting upper scaling limits can cap spending but might result in reliability problems for legitimate users if malicious or harmful traffic overwhelms your API.
Mitigating undesired traffic incurs costs. Adding services like a web application firewall and DDoS protection increases expenses. Scaling your service to handle traffic increases costs because of added units. Setting upper scaling limits can cap spending but might result in reliability problems for legitimate users if malicious or harmful traffic overwhelms your API.
Federated versus distributed approach
A fundamental decision in API Management is whether to colocate disparate workloads within a single API Management instance or to isolate workloads across multiple instances in a fully autonomous topology.
API Management workspaces enable efficient operation as a multitenant colocation platform for multiple API teams. The tiered pricing models are designed to allow service costs to be shared across all tenants that use the gateways. However, like any colocation platform, outages or misconfigurations can result in widespread effects on unrelated workloads that share the same infrastructure.
A fully distributed model, where each workload team manages its own instances, introduces duplicative costs and redundancy in routine operations. However, it provides inherent blast radius mitigation for reliability, security, and performance-related incidents.
Next steps
API Management is often combined with the following services. Be sure to review their service guides or product documentation if your workload includes the following services.
Application Gateway
Azure Cache for Redis
Azure Front Door
Key Vault
Azure OpenAI Service
Azure Virtual Network
Web Application Firewall
The following articles demonstrate some of the recommendations discussed in this article.
Access Azure OpenAI and other language models through a gateway
Automated API deployments using APIOps
API Management architecture in an application landing zoneandAzure landing zone platform considerationsfor API Management deployments
Feedback
Was this page helpful?
Additional resources