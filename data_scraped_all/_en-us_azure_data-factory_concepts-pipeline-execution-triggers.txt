Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Pipeline execution and triggers in Azure Data Factory or Azure Synapse Analytics
Article
2025-04-08
28 contributors
In this article
APPLIES TO:Azure Data FactoryAzure Synapse Analytics
Tip
Try outData Factory in Microsoft Fabric, an all-in-one analytics solution for enterprises.Microsoft Fabriccovers everything from data movement to data science, real-time analytics, business intelligence, and reporting. Learn how tostart a new trialfor free!
Apipeline runin Azure Data Factory and Azure Synapse defines an instance of a pipeline execution. For example, say you have a pipeline that executes at 8:00 AM, 9:00 AM, and 10:00 AM. In this case, there are three separate runs of the pipeline or pipeline runs. Each pipeline run has a unique pipeline run ID. A run ID is a GUID that uniquely defines that particular pipeline run.
Pipeline runs are typically instantiated by passing arguments to parameters that you define in the pipeline. You can execute a pipeline either manually or by using atrigger. This article provides details about both ways of executing a pipeline.
Create triggers with UI
To manually trigger a pipeline or configure a new scheduled, tumbling window, storage event, or custom event trigger, select Add trigger at the top of the pipeline editor.

If you choose to manually trigger the pipeline, it will execute immediately.  Otherwise if you choose New/Edit, you will be prompted with the add triggers window to either choose an existing trigger to edit, or create a new trigger.

You will see the trigger configuration window, allowing you to choose the trigger type.

Read more aboutscheduled,tumbling window,storage event, andcustom eventtriggers below.
Manual execution
The manual execution of a pipeline is also referred to ason-demandexecution.
For example, say you have a basic pipeline namedcopyPipelinethat you want to execute. The pipeline has a single activity that copies from an Azure Blob storage source folder to a destination folder in the same storage. The following JSON definition shows this sample pipeline:
{
    "name": "copyPipeline",
    "properties": {
        "activities": [
            {
                "type": "Copy",
                "typeProperties": {
                    "source": {
                        "type": "BlobSource"
                    },
                    "sink": {
                        "type": "BlobSink"
                    }
                },
                "name": "CopyBlobtoBlob",
                "inputs": [
                    {
                        "referenceName": "sourceBlobDataset",
                        "type": "DatasetReference"
                    }
                ],
                "outputs": [
                    {
                        "referenceName": "sinkBlobDataset",
                        "type": "DatasetReference"
                    }
                ]
            }
        ],
        "parameters": {
            "sourceBlobContainer": {
                "type": "String"
            },
            "sinkBlobContainer": {
                "type": "String"
            }
        }
    }
}
{
    "name": "copyPipeline",
    "properties": {
        "activities": [
            {
                "type": "Copy",
                "typeProperties": {
                    "source": {
                        "type": "BlobSource"
                    },
                    "sink": {
                        "type": "BlobSink"
                    }
                },
                "name": "CopyBlobtoBlob",
                "inputs": [
                    {
                        "referenceName": "sourceBlobDataset",
                        "type": "DatasetReference"
                    }
                ],
                "outputs": [
                    {
                        "referenceName": "sinkBlobDataset",
                        "type": "DatasetReference"
                    }
                ]
            }
        ],
        "parameters": {
            "sourceBlobContainer": {
                "type": "String"
            },
            "sinkBlobContainer": {
                "type": "String"
            }
        }
    }
}
In the JSON definition, the pipeline takes two parameters:sourceBlobContainerandsinkBlobContainer. You pass values to these parameters at runtime.
Manual execution with other APIs/SDKs
You can manually run your pipeline by using one of the following methods:
.NET SDK
Azure PowerShell module
REST API
Python SDK
.NET SDK
The following sample call shows you how to run your pipeline by using the .NET SDK manually:
client.Pipelines.CreateRunWithHttpMessagesAsync(resourceGroup, dataFactoryName, pipelineName, parameters)
client.Pipelines.CreateRunWithHttpMessagesAsync(resourceGroup, dataFactoryName, pipelineName, parameters)
For a complete sample, seeQuickstart: Create a data factory by using the .NET SDK.
Note
You can use the .NET SDK to invoke pipelines from Azure Functions, from your web services, and so on.
Azure PowerShell
Note
We recommend that you use the Azure Az PowerShell module to interact with Azure. To get started, seeInstall Azure PowerShell. To learn how to migrate to the Az PowerShell module, seeMigrate Azure PowerShell from AzureRM to Az.
The following sample command shows you how to manually run your pipeline by using Azure PowerShell:
Invoke-AzDataFactoryV2Pipeline -DataFactory $df -PipelineName "Adfv2QuickStartPipeline" -ParameterFile .\PipelineParameters.json -ResourceGroupName "myResourceGroup"
Invoke-AzDataFactoryV2Pipeline -DataFactory $df -PipelineName "Adfv2QuickStartPipeline" -ParameterFile .\PipelineParameters.json -ResourceGroupName "myResourceGroup"
You pass parameters in the body of the request payload. In the .NET SDK, Azure PowerShell, and the Python SDK, you pass values in a dictionary that's passed as an argument to the call:
{
  "sourceBlobContainer": "MySourceFolder",
  "sinkBlobContainer": "MySinkFolder"
}
{
  "sourceBlobContainer": "MySourceFolder",
  "sinkBlobContainer": "MySinkFolder"
}
The response payload is a unique ID of the pipeline run:
{
  "runId": "0448d45a-a0bd-23f3-90a5-bfeea9264aed"
}
{
  "runId": "0448d45a-a0bd-23f3-90a5-bfeea9264aed"
}
For a complete sample, seeQuickstart: Create a data factory by using Azure PowerShell.
Python SDK
For a complete sample, seeQuickstart: Create a data factory and pipeline using Python
REST API
The following sample command shows you how to run your pipeline by using the REST API manually:
POST
https://management.azure.com/subscriptions/mySubId/resourceGroups/myResourceGroup/providers/Microsoft.DataFactory/factories/myDataFactory/pipelines/copyPipeline/createRun?api-version=2017-03-01-preview
POST
https://management.azure.com/subscriptions/mySubId/resourceGroups/myResourceGroup/providers/Microsoft.DataFactory/factories/myDataFactory/pipelines/copyPipeline/createRun?api-version=2017-03-01-preview
For a complete sample, seeQuickstart: Create a data factory by using the REST API.
Trigger Types
Triggers are another way that you can execute a pipeline run. Triggers represent a unit of processing that determines when a pipeline execution needs to be kicked off. Currently, the service supports three types of triggers:
Schedule trigger: A trigger that invokes a pipeline on a wall-clock schedule.
Schedule trigger: A trigger that invokes a pipeline on a wall-clock schedule.
Tumbling window trigger: A trigger that operates on a periodic interval, while also retaining state.
Tumbling window trigger: A trigger that operates on a periodic interval, while also retaining state.
Event-based trigger: A trigger that responds to an event.
Event-based trigger: A trigger that responds to an event.
Pipelines and triggers have a many-to-many relationship (except for the tumbling window trigger). Multiple triggers can kick off a single pipeline, or a single trigger can kick off multiple pipelines. In the following trigger definition, thepipelinesproperty refers to a list of pipelines that are triggered by the particular trigger. The property definition includes values for the pipeline parameters.
Basic trigger definition
{
    "properties": {
        "name": "MyTrigger",
        "type": "<type of trigger>",
        "typeProperties": {...},
        "pipelines": [
            {
                "pipelineReference": {
                    "type": "PipelineReference",
                    "referenceName": "<Name of your pipeline>"
                },
                "parameters": {
                    "<parameter 1 Name>": {
                        "type": "Expression",
                        "value": "<parameter 1 Value>"
                    },
                    "<parameter 2 Name>": "<parameter 2 Value>"
                }
            }
        ]
    }
}
{
    "properties": {
        "name": "MyTrigger",
        "type": "<type of trigger>",
        "typeProperties": {...},
        "pipelines": [
            {
                "pipelineReference": {
                    "type": "PipelineReference",
                    "referenceName": "<Name of your pipeline>"
                },
                "parameters": {
                    "<parameter 1 Name>": {
                        "type": "Expression",
                        "value": "<parameter 1 Value>"
                    },
                    "<parameter 2 Name>": "<parameter 2 Value>"
                }
            }
        ]
    }
}
Schedule trigger
A schedule trigger runs pipelines on a wall-clock schedule. This trigger supports periodic and advanced calendar options. For example, the trigger supports intervals like "weekly" or "Monday at 5:00 PM and Thursday at 9:00 PM." The schedule trigger is flexible because the dataset pattern is agnostic, and the trigger doesn't discern between time-series and non-time-series data.
For more information about schedule triggers and, for examples, seeCreate a trigger that runs a pipeline on a schedule.
Schedule trigger definition
When you create a schedule trigger, you specify scheduling and recurrence by using a JSON definition.
To have your schedule trigger kick off a pipeline run, include a pipeline reference of the particular pipeline in the trigger definition. Pipelines and triggers have a many-to-many relationship. Multiple triggers can kick off a single pipeline. A single trigger can kick off multiple pipelines.
{
  "properties": {
    "type": "ScheduleTrigger",
    "typeProperties": {
      "recurrence": {
        "frequency": <<Minute, Hour, Day, Week>>,
        "interval": <<int>>, // How often to fire
        "startTime": <<datetime>>,
        "endTime": <<datetime>>,
        "timeZone": "UTC",
        "schedule": { // Optional (advanced scheduling specifics)
          "hours": [<<0-24>>],
          "weekDays": [<<Monday-Sunday>>],
          "minutes": [<<0-60>>],
          "monthDays": [<<1-31>>],
          "monthlyOccurrences": [
            {
              "day": <<Monday-Sunday>>,
              "occurrence": <<1-5>>
            }
          ]
        }
      }
    },
  "pipelines": [
    {
      "pipelineReference": {
        "type": "PipelineReference",
        "referenceName": "<Name of your pipeline>"
      },
      "parameters": {
        "<parameter 1 Name>": {
          "type": "Expression",
          "value": "<parameter 1 Value>"
        },
        "<parameter 2 Name>": "<parameter 2 Value>"
      }
    }
  ]}
}
{
  "properties": {
    "type": "ScheduleTrigger",
    "typeProperties": {
      "recurrence": {
        "frequency": <<Minute, Hour, Day, Week>>,
        "interval": <<int>>, // How often to fire
        "startTime": <<datetime>>,
        "endTime": <<datetime>>,
        "timeZone": "UTC",
        "schedule": { // Optional (advanced scheduling specifics)
          "hours": [<<0-24>>],
          "weekDays": [<<Monday-Sunday>>],
          "minutes": [<<0-60>>],
          "monthDays": [<<1-31>>],
          "monthlyOccurrences": [
            {
              "day": <<Monday-Sunday>>,
              "occurrence": <<1-5>>
            }
          ]
        }
      }
    },
  "pipelines": [
    {
      "pipelineReference": {
        "type": "PipelineReference",
        "referenceName": "<Name of your pipeline>"
      },
      "parameters": {
        "<parameter 1 Name>": {
          "type": "Expression",
          "value": "<parameter 1 Value>"
        },
        "<parameter 2 Name>": "<parameter 2 Value>"
      }
    }
  ]}
}
Important
Theparametersproperty is a mandatory property of thepipelineselement. If your pipeline doesn't take any parameters, you must include an empty JSON definition for theparametersproperty.
Schema overview
The following table provides a high-level overview of the major schema elements that are related to recurrence and scheduling a trigger:
Note
For time zones that observe daylight saving, trigger time auto-adjusts for the twice-a-year change, if the recurrence is set toDaysor above. To opt out of the daylight saving change, select a time zone that doesn't observe daylight saving, for instance, UTC.
Daylight saving adjustment only happens for a trigger with the recurrence set toDaysor above. If the trigger is set toHoursorMinutesfrequency, it continues to fire at regular intervals.
Schedule trigger example
{
  "properties": {
    "name": "MyTrigger",
    "type": "ScheduleTrigger",
    "typeProperties": {
      "recurrence": {
        "frequency": "Hour",
        "interval": 1,
        "startTime": "2017-11-01T09:00:00-08:00",
        "endTime": "2017-11-02T22:00:00-08:00"
      }
    },
    "pipelines": [{
        "pipelineReference": {
          "type": "PipelineReference",
          "referenceName": "SQLServerToBlobPipeline"
        },
        "parameters": {}
      },
      {
        "pipelineReference": {
          "type": "PipelineReference",
          "referenceName": "SQLServerToAzureSQLPipeline"
        },
        "parameters": {}
      }
    ]
  }
}
{
  "properties": {
    "name": "MyTrigger",
    "type": "ScheduleTrigger",
    "typeProperties": {
      "recurrence": {
        "frequency": "Hour",
        "interval": 1,
        "startTime": "2017-11-01T09:00:00-08:00",
        "endTime": "2017-11-02T22:00:00-08:00"
      }
    },
    "pipelines": [{
        "pipelineReference": {
          "type": "PipelineReference",
          "referenceName": "SQLServerToBlobPipeline"
        },
        "parameters": {}
      },
      {
        "pipelineReference": {
          "type": "PipelineReference",
          "referenceName": "SQLServerToAzureSQLPipeline"
        },
        "parameters": {}
      }
    ]
  }
}
Schema defaults, limits, and examples
"startTime" : "2013-01-09T09:30:00-08:00"
"recurrence" : { "frequency" : "monthly", "interval" : 1 }
"interval":10
"endTime" : "2013-02-09T09:30:00-08:00"
"schedule" : { "minute" : [30], "hour" : [8,17] }
startTime property
The following table shows you how thestartTimeproperty controls a trigger run:
Let's look at an example of what happens when the start time is in the past, with a recurrence, but no schedule. Assume that the current time is 2017-04-08 13:00, the start time is 2017-04-07 14:00, and the recurrence is every two days. (Therecurrencevalue is defined by setting thefrequencyproperty to "day" and theintervalproperty to 2.) Notice that thestartTimevalue is in the past and occurs before the current time.
Under these conditions, the first execution is 2017-04-09 at 14:00. The Scheduler engine calculates execution occurrences from the start time. Any instances in the past are discarded. The engine uses the next instance that occurs in the future. In this scenario, the start time is 2017-04-07 at 2:00 PM. The next instance is two days from that time, which is on 2017-04-09 at 2:00 PM.
The first execution time is the same even whetherstartTimeis 2017-04-05 14:00 or 2017-04-01 14:00. After the first execution, subsequent executions are calculated by using the schedule. Therefore, the subsequent executions are on 2017-04-11 at 2:00 PM, then on 2017-04-13 at 2:00 PM, then on 2017-04-15 at 2:00 PM, and so on.
Finally, when hours or minutes aren't set in the schedule for a trigger, the hours or minutes of the first execution are used as defaults.
schedule property
You can usescheduletolimitthe number of trigger executions. For example, if a trigger with a monthly frequency is scheduled to run only on day 31, the trigger runs only in those months that have a thirty-first day.
You can also usescheduletoexpandthe number of trigger executions. For example, a trigger with a monthly frequency that's scheduled to run on month days 1 and 2, runs on the first and second days of the month, rather than once a month.
If multiplescheduleelements are specified, the order of evaluation is from the largest to the smallest schedule setting: week number, month day, weekday, hour, minute.
The following table describes thescheduleelements in detail:
{ "day": day, "occurrence": occurrence }
{Sunday}
{Sunday, -1}
Tumbling window trigger
Tumbling window triggers are a type of trigger that fires at a periodic time interval from a specified start time, while retaining state. Tumbling windows are a series of fixed-sized, non-overlapping, and contiguous time intervals.
For more information about tumbling window triggers and, for examples, seeCreate a tumbling window trigger.
Examples of trigger recurrence schedules
This section provides examples of recurrence schedules. It focuses on thescheduleobject and its elements.
The examples assume that theintervalvalue is 1 and that thefrequencyvalue is correct according to the schedule definition. For example, you can't have afrequencyvalue of "day" and also have amonthDaysmodification in thescheduleobject. These kinds of restrictions are described in the table in the preceding section.
{"hours":[5]}
{"minutes":[15], "hours":[5]}
{"minutes":[15], "hours":[5,17]}
{"minutes":[15,45], "hours":[5,17]}
{"minutes":[0,15,30,45]}
{hours":[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]}
{"minutes":[0]}
{"minutes":[15]}
{"hours":[17], "weekDays":["saturday"]}
{"hours":[17], "weekDays":["monday", "wednesday", "friday"]}
{"minutes":[15,45], "hours":[17], "weekDays":["monday", "wednesday", "friday"]}
{"minutes":[0,15,30,45], "weekDays":["monday", "tuesday", "wednesday", "thursday", "friday"]}
{"minutes":[0,15,30,45], "hours": [9, 10, 11, 12, 13, 14, 15, 16] "weekDays":["monday", "tuesday", "wednesday", "thursday", "friday"]}
{"weekDays":["tuesday", "thursday"]}
{"minutes":[0], "hours":[6], "monthDays":[28]}
{"minutes":[0], "hours":[6], "monthDays":[-1]}
{"minutes":[0], "hours":[6], "monthDays":[1,-1]}
{monthDays":[1,14]}
{"minutes":[0], "hours":[5], "monthlyOccurrences":[{"day":"friday", "occurrence":1}]}
{"monthlyOccurrences":[{"day":"friday", "occurrence":1}]}
{"monthlyOccurrences":[{"day":"friday", "occurrence":-3}]}
{"minutes":[15], "hours":[5], "monthlyOccurrences":[{"day":"friday", "occurrence":1},{"day":"friday", "occurrence":-1}]}
{"monthlyOccurrences":[{"day":"friday", "occurrence":1},{"day":"friday", "occurrence":-1}]}
{"monthlyOccurrences":[{"day":"friday", "occurrence":5}]}
{"minutes":[0,15,30,45], "monthlyOccurrences":[{"day":"friday", "occurrence":-1}]}
{"minutes":[15,45], "hours":[5,17], "monthlyOccurrences":[{"day":"wednesday", "occurrence":3}]}
Event-based trigger
An event-based trigger runs pipelines in response to an event. From behavior perspective, if you stop and start an event-based trigger, it resumes old trigger pattern which may result in unwanted trigger of the pipeline. In this case, you should delete and create new event based trigger. The new trigger starts fresh without history. There are two flavors of event-based triggers.
Storage event triggerruns a pipeline against events happening in a Storage account, such as the arrival of a file, or the deletion of a file in Azure Blob Storage account.
Custom event triggerprocesses and handlescustom articlesin Event Grid
For more information about event-based triggers, seeStorage Event TriggerandCustom Event Trigger.
Trigger type comparison
The tumbling window trigger and the schedule trigger both operate on time heartbeats. How are they different?
Note
The tumbling window trigger runwaits for the triggered pipeline runto finish. Its run state reflects the state of the triggered pipeline run. For example, if a triggered pipeline run is cancelled, the corresponding tumbling window trigger run is marked cancelled. This is different from the "fire and forget" behavior of the schedule trigger, which is marked successful as long as a pipeline run started.
The following table provides a comparison of the tumbling window trigger and schedule trigger:
trigger().outputs.windowStartTime
trigger().outputs.windowEndTime
trigger().outputs.windowStartTime = 2017-09-01T01:00:00Z
trigger().outputs.windowEndTime = 2017-09-01T02:00:00Z
Related content
See the following tutorials:
Quickstart: Create a data factory by using the .NET SDK
Create a schedule trigger
Create a tumbling window trigger
Feedback
Was this page helpful?
Additional resources