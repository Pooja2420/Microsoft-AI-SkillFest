Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Get started: Query and visualize data from a notebook
Article
2025-02-13
6 contributors
In this article
This get started article walks you through using an Azure Databricks notebook to query sample data stored in Unity Catalog using SQL, Python, Scala, and R and then visualize the query results in the notebook.
Requirements
To complete the tasks in this article, you must meet the following requirements:
Your workspace must haveUnity Catalogenabled. For information on getting started with Unity Catalog, seeSet up and manage Unity Catalog.
You must have permission to use an existing compute resource or create a new compute resource. SeeGet started with Azure Databricksor see your Databricks administrator.
Step 1: Create a new notebook
To create a notebook in your workspace, clickNewin the sidebar, and then clickNotebook. A blank notebook opens in the workspace.
To learn more about creating and managing notebooks, seeManage notebooks.
Step 2: Query a table
Query thesamples.nyctaxi.tripstable in Unity Catalog using the language of your choice.
samples.nyctaxi.trips
Copy and paste the following code into the new empty notebook cell. This code displays the results from querying thesamples.nyctaxi.tripstable in Unity Catalog.SQLSELECT * FROM samples.nyctaxi.tripsPythondisplay(spark.read.table("samples.nyctaxi.trips"))Scaladisplay(spark.read.table("samples.nyctaxi.trips"))Rlibrary(SparkR)
display(sql("SELECT * FROM samples.nyctaxi.trips"))
Copy and paste the following code into the new empty notebook cell. This code displays the results from querying thesamples.nyctaxi.tripstable in Unity Catalog.
samples.nyctaxi.trips
SQL
SELECT * FROM samples.nyctaxi.trips
SELECT * FROM samples.nyctaxi.trips
Python
display(spark.read.table("samples.nyctaxi.trips"))
display(spark.read.table("samples.nyctaxi.trips"))
Scala
display(spark.read.table("samples.nyctaxi.trips"))
display(spark.read.table("samples.nyctaxi.trips"))
R
library(SparkR)
display(sql("SELECT * FROM samples.nyctaxi.trips"))
library(SparkR)
display(sql("SELECT * FROM samples.nyctaxi.trips"))
PressShift+Enterto run the cell and then move to the next cell.The query results appear in the notebook.
PressShift+Enterto run the cell and then move to the next cell.
Shift+Enter
The query results appear in the notebook.
Step 3: Display the data
Display the average fare amount by trip distance, grouped by the pickup zip code.
Next to theTabletab, click+and then clickVisualization.The visualization editor displays.
Next to theTabletab, click+and then clickVisualization.
The visualization editor displays.
In theVisualization Typedrop-down, verify thatBaris selected.
In theVisualization Typedrop-down, verify thatBaris selected.
Selectfare_amountfor theX column.
Selectfare_amountfor theX column.
fare_amount
Selecttrip_distancefor theY column.
Selecttrip_distancefor theY column.
trip_distance
SelectAverageas the aggregation type.
SelectAverageas the aggregation type.
Average
Selectpickup_zipas theGroup bycolumn.
Selectpickup_zipas theGroup bycolumn.
pickup_zip

ClickSave.
ClickSave.
Next steps
To learn about adding data from CSV file to Unity Catalog and visualize data, seeGet started: Import and visualize CSV data from a notebook.
To learn how to load data into Databricks using Apache Spark, seeTutorial: Load and transform data using Apache Spark DataFrames.
To learn more about ingesting data into Databricks, seeIngest data into an Azure Databricks lakehouse.
To learn more about querying data with Databricks, seeQuery data.
To learn more about visualizations, seeVisualizations in Databricks notebooks.
To learn more about exploratory data analysis (EDA) techniques, seeTutorial: EDA techniques using Databricks notebooks.
Feedback
Was this page helpful?
Additional resources