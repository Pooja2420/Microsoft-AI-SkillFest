Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Expand virtual hard disks on a Linux VM
Article
2024-10-29
28 contributors
In this article
Applies to:âï¸ Linux VMs âï¸ Flexible scale sets
This article covers expanding OS disks and data disks for a Linux virtual machine (VM). You canadd data disksto provide for more storage space, and you can also expand an existing data disk. The default virtual hard disk size for the operating system (OS) is typically 30 GB on a Linux VM in Azure. This article covers expanding either OS disks or data disks. You can't expand the size of striped volumes.
An OS disk has a maximum capacity of 4,095 GiB. However, many operating systems are partitioned withmaster boot record (MBR)by default. MBR limits the usable size to 2 TiB. If you need more than 2 TiB, consider attaching data disks for data storage. If you do need to store data on the OS disk and require extra space, convert it to GUID Partition Table (GPT).
Warning
Always make sure that your filesystem is in a healthy state, your disk partition table type (GPT or MBR) will support the new size, and ensure your data is backed up before you perform disk expansion operations. For more information, see theAzure Backup quickstart.
Identify Azure data disk object within the operating system
When expanding a data disk, when there are several data disks present on the VM, it may be difficult to relate the Azure LUNs to the Linux devices.  If the OS disk needs expansion, it is clearly labeled in the Azure portal as the OS disk.
Start by identifying the relationship between disk utilization, mount point, and device, with thedfcommand.
df
df -Th
df -Th
Filesystem                Type      Size  Used Avail Use% Mounted on
/dev/sda1                 xfs        97G  1.8G   95G   2% /
<truncated>
/dev/sdd1                 ext4       32G   30G  727M  98% /opt/db/data
/dev/sde1                 ext4       32G   49M   30G   1% /opt/db/log
Filesystem                Type      Size  Used Avail Use% Mounted on
/dev/sda1                 xfs        97G  1.8G   95G   2% /
<truncated>
/dev/sdd1                 ext4       32G   30G  727M  98% /opt/db/data
/dev/sde1                 ext4       32G   49M   30G   1% /opt/db/log
Here we can see, for example, the/opt/db/datafilesystem is nearly full, and is located on the/dev/sdd1partition. The output ofdfshows the device path whether the disk is mounted using the device path or the (preferred) UUID in the fstab.  Also take note of the Type column, indicating the format of the filesystem. The format is important later.
/opt/db/data
/dev/sdd1
df
Now locate the LUN that correlates to/dev/sddby examining the contents of/dev/disk/azure/scsi1. The output of the followinglscommand shows that the device known as/dev/sddwithin the Linux OS is located at LUN1 when looking in the Azure portal.
/dev/sdd
/dev/disk/azure/scsi1
ls
/dev/sdd
sudo ls -alF /dev/disk/azure/scsi1/
sudo ls -alF /dev/disk/azure/scsi1/
total 0
drwxr-xr-x. 2 root root 140 Sep  9 21:54 ./
drwxr-xr-x. 4 root root  80 Sep  9 21:48 ../
lrwxrwxrwx. 1 root root  12 Sep  9 21:48 lun0 -> ../../../sdc
lrwxrwxrwx. 1 root root  12 Sep  9 21:48 lun1 -> ../../../sdd
lrwxrwxrwx. 1 root root  13 Sep  9 21:48 lun1-part1 -> ../../../sdd1
lrwxrwxrwx. 1 root root  12 Sep  9 21:54 lun2 -> ../../../sde
lrwxrwxrwx. 1 root root  13 Sep  9 21:54 lun2-part1 -> ../../../sde1
total 0
drwxr-xr-x. 2 root root 140 Sep  9 21:54 ./
drwxr-xr-x. 4 root root  80 Sep  9 21:48 ../
lrwxrwxrwx. 1 root root  12 Sep  9 21:48 lun0 -> ../../../sdc
lrwxrwxrwx. 1 root root  12 Sep  9 21:48 lun1 -> ../../../sdd
lrwxrwxrwx. 1 root root  13 Sep  9 21:48 lun1-part1 -> ../../../sdd1
lrwxrwxrwx. 1 root root  12 Sep  9 21:54 lun2 -> ../../../sde
lrwxrwxrwx. 1 root root  13 Sep  9 21:54 lun2-part1 -> ../../../sde1
Expand an Azure Managed Disk
Expand without downtime
You can expand your managed disks without deallocating your VM. The host cache setting of your disk doesn't change whether or not you can expand a data disk without deallocating your VM.
This feature has the following limitations:
Important
This limitation doesn't apply to Premium SSD v2 or Ultra Disks:
If a Standard HDD, Standard SSD, or Premium SSD disk is 4 TiB or less, deallocate your VM and detach the disk before expanding it beyond 4 TiB. If one of those disk types is already greater than 4 TiB, you can expand it without deallocating the VM and detaching the disk.
Only supported for data disks.
Not supported for shared disks.
Install and use either:Thelatest Azure CLIThelatest Azure PowerShell moduleTheAzure portalOr an Azure Resource Manager template with an API version that's2021-04-01or newer.
Thelatest Azure CLI
Thelatest Azure PowerShell module
TheAzure portal
Or an Azure Resource Manager template with an API version that's2021-04-01or newer.
2021-04-01
Not available on some classic VMs. Usethis scriptto get a list of classic VM SKUs that support expanding without downtime.
Expand with Ultra Disk and Premium SSD v2
Expanding Ultra Disks and Premium SSD v2 disks have the following additional limitations:
You can't expand a disk while abackground copyof data is also occurring on that disk, like when a disk is being backfilled fromsnapshots.
You can't expand a VM that's usingNVMe controllersfor Ultra Disks or Premium SSD v2 disks without downtime.
Important
Allow up to 10 minutes for the correct size to be reflected in Windows VMs and Linux VMs. For Linux VMs, you must perform aLinux rescan function. For Windows VM that doesn't have a workload, you must perform aWindows rescan function. You can rescan immediately, but if it's within 10 minutes, you might need to rescan again to display the correct size.
Resizing Ultra Disks and Premium SSD v2 disks is currently available in all Premium SSD v2 and Ultra supported regions.
Expand Azure Managed Disk
Make sure that you have the latestAzure CLIinstalled and are signed in to an Azure account by usingaz login.
This article requires an existing VM in Azure with at least one data disk attached and prepared. If you don't already have a VM that you can use, seeCreate and prepare a VM with data disks.
In the following samples, replace example parameter names such asmyResourceGroupandmyVMwith your own values.
Important
If your disk meets the requirements inExpand without downtime, you can skip step 1 and 3.
Shrinking an existing disk isnât supported and may result in data loss.
After expanding the disks, you need to expand the volume in the operating system to take advantage of the larger disk.
Operations on virtual hard disks can't be performed with the VM running. Deallocate your VM withaz vm deallocate. The following example deallocates the VM namedmyVMin the resource group namedmyResourceGroup:az vm deallocate --resource-group myResourceGroup --name myVMNoteThe VM must be deallocated to expand the virtual hard disk. Stopping the VM withaz vm stopdoesn't release the compute resources. To release compute resources, useaz vm deallocate.
Operations on virtual hard disks can't be performed with the VM running. Deallocate your VM withaz vm deallocate. The following example deallocates the VM namedmyVMin the resource group namedmyResourceGroup:
az vm deallocate --resource-group myResourceGroup --name myVM
az vm deallocate --resource-group myResourceGroup --name myVM
Note
The VM must be deallocated to expand the virtual hard disk. Stopping the VM withaz vm stopdoesn't release the compute resources. To release compute resources, useaz vm deallocate.
az vm stop
az vm deallocate
View a list of managed disks in a resource group withaz disk list. The following example displays a list of managed disks in the resource group namedmyResourceGroup:az disk list \
    --resource-group myResourceGroup  \
    --query '[*].{Name:name,size:diskSizeGB,Tier:sku.tier}' \
    --output tableExpand the required disk withaz disk update. The following example expands the managed disk namedmyDataDiskto200GB:az disk update \
    --resource-group myResourceGroup \
    --name myDataDisk \
    --size-gb 200NoteWhen you expand a managed disk, the updated size is rounded up to the nearest managed disk size. For a table of the available managed disk sizes and tiers, seeUnderstand Azure Disk Storage billing.
View a list of managed disks in a resource group withaz disk list. The following example displays a list of managed disks in the resource group namedmyResourceGroup:
az disk list \
    --resource-group myResourceGroup  \
    --query '[*].{Name:name,size:diskSizeGB,Tier:sku.tier}' \
    --output table
az disk list \
    --resource-group myResourceGroup  \
    --query '[*].{Name:name,size:diskSizeGB,Tier:sku.tier}' \
    --output table
Expand the required disk withaz disk update. The following example expands the managed disk namedmyDataDiskto200GB:
az disk update \
    --resource-group myResourceGroup \
    --name myDataDisk \
    --size-gb 200
az disk update \
    --resource-group myResourceGroup \
    --name myDataDisk \
    --size-gb 200
Note
When you expand a managed disk, the updated size is rounded up to the nearest managed disk size. For a table of the available managed disk sizes and tiers, seeUnderstand Azure Disk Storage billing.
Start your VM withaz vm start. The following example starts the VM namedmyVMin the resource group namedmyResourceGroup:az vm start --resource-group myResourceGroup --name myVM
Start your VM withaz vm start. The following example starts the VM namedmyVMin the resource group namedmyResourceGroup:
az vm start --resource-group myResourceGroup --name myVM
az vm start --resource-group myResourceGroup --name myVM
Expand a disk partition and filesystem
Note
While there are many tools that may be used for performing the partition resizing, the tools detailed in the remainder of this document are the same tools used by certain automated processes such as cloud-init. As described here, thegrowparttool with thegdiskpackage provides universal compatibility with GUID Partition Table (GPT) disks, as older versions of some tools such asfdiskdid not support GPT.
growpart
gdisk
fdisk
Detecting a changed disk size
If a data disk was expanded without downtime using the procedure mentioned previously, the reported disk size doesn't change until the device is rescanned, which normally only happens during the boot process. This rescan can be called on-demand with the following procedure. In this example, we find using the methods in this document that the data disk is currently/dev/sdaand was resized from 256 GiB to 512 GiB.
/dev/sda
Identify the currently recognized size on the first line of output fromfdisk -l /dev/sdasudo fdisk -l /dev/sdaDisk /dev/sda: 256 GiB, 274877906944 bytes, 536870912 sectors
Disk model: Virtual Disk
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 4096 bytes
I/O size (minimum/optimal): 4096 bytes / 4096 bytes
Disklabel type: dos
Disk identifier: 0x43d10aad

Device     Boot Start       End   Sectors  Size Id Type
/dev/sda1        2048 536870878 536868831  256G 83 Linux
Identify the currently recognized size on the first line of output fromfdisk -l /dev/sda
fdisk -l /dev/sda
sudo fdisk -l /dev/sda
sudo fdisk -l /dev/sda
Disk /dev/sda: 256 GiB, 274877906944 bytes, 536870912 sectors
Disk model: Virtual Disk
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 4096 bytes
I/O size (minimum/optimal): 4096 bytes / 4096 bytes
Disklabel type: dos
Disk identifier: 0x43d10aad

Device     Boot Start       End   Sectors  Size Id Type
/dev/sda1        2048 536870878 536868831  256G 83 Linux
Disk /dev/sda: 256 GiB, 274877906944 bytes, 536870912 sectors
Disk model: Virtual Disk
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 4096 bytes
I/O size (minimum/optimal): 4096 bytes / 4096 bytes
Disklabel type: dos
Disk identifier: 0x43d10aad

Device     Boot Start       End   Sectors  Size Id Type
/dev/sda1        2048 536870878 536868831  256G 83 Linux
Insert a1character into the rescan file for this device. Note the reference to sda in the example. The disk identifier would change if a different disk device was resized.echo 1 | sudo tee /sys/class/block/sda/device/rescan
Insert a1character into the rescan file for this device. Note the reference to sda in the example. The disk identifier would change if a different disk device was resized.
1
echo 1 | sudo tee /sys/class/block/sda/device/rescan
echo 1 | sudo tee /sys/class/block/sda/device/rescan
Verify that the new disk size is now recognizedsudo fdisk -l /dev/sdaDisk /dev/sda: 512 GiB, 549755813888 bytes, 1073741824 sectors
Disk model: Virtual Disk
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 4096 bytes
I/O size (minimum/optimal): 4096 bytes / 4096 bytes
Disklabel type: dos
Disk identifier: 0x43d10aad

Device     Boot Start       End   Sectors  Size Id Type
/dev/sda1        2048 536870878 536868831  256G 83 Linux
Verify that the new disk size is now recognized
sudo fdisk -l /dev/sda
sudo fdisk -l /dev/sda
Disk /dev/sda: 512 GiB, 549755813888 bytes, 1073741824 sectors
Disk model: Virtual Disk
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 4096 bytes
I/O size (minimum/optimal): 4096 bytes / 4096 bytes
Disklabel type: dos
Disk identifier: 0x43d10aad

Device     Boot Start       End   Sectors  Size Id Type
/dev/sda1        2048 536870878 536868831  256G 83 Linux
Disk /dev/sda: 512 GiB, 549755813888 bytes, 1073741824 sectors
Disk model: Virtual Disk
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 4096 bytes
I/O size (minimum/optimal): 4096 bytes / 4096 bytes
Disklabel type: dos
Disk identifier: 0x43d10aad

Device     Boot Start       End   Sectors  Size Id Type
/dev/sda1        2048 536870878 536868831  256G 83 Linux
The remainder of this article uses the OS disk for the examples of the procedure for increasing the size of a volume at the OS level. If the expanded disk is a data disk, use theprevious guidance for identifying the data disk device, and follow these instructions as a guideline, substituting the data disk device (for example/dev/sda), partition numbers, volume names, mount points, and filesystem formats, as necessary.
/dev/sda
All Linux OS guidance should be viewed as generic and may apply on any distribution, but generally matches the conventions of the named marketplace publisher. Reference the Red Hat documents for the package requirements on any distribution based on Red Hat or claiming Red Hat compatibility.
Increase the size of the OS disk
The following instructions apply to endorsed Linux distributions.
Note
Before you proceed, make a full backup copy of your VM, or at a minimum take a snapshot of your OS disk.
Ubuntu
SUSE
Red Hat with LVM
Red Hat without LVM
On Ubuntu 16.x and newer, the root partition of the OS disk and filesystems are automatically expanded to utilize all free contiguous space on the root disk by cloud-init, provided there's a small bit of free space for the resize operation. In this case, the sequence is simply
Increase the size of the OS disk as detailed previously
Restart the VM, and then access the VM using therootuser account.
Verify that the OS disk now displays an increased file system size.
As shown in the following example, the OS disk was resized from the portal to 100 GB. The/dev/sda1file system mounted on/now displays 97 GB.
df -Th
df -Th
Filesystem     Type      Size  Used Avail Use% Mounted on
udev           devtmpfs  314M     0  314M   0% /dev
tmpfs          tmpfs      65M  2.3M   63M   4% /run
/dev/sda1      ext4       97G  1.8G   95G   2% /
tmpfs          tmpfs     324M     0  324M   0% /dev/shm
tmpfs          tmpfs     5.0M     0  5.0M   0% /run/lock
tmpfs          tmpfs     324M     0  324M   0% /sys/fs/cgroup
/dev/sda15     vfat      105M  3.6M  101M   4% /boot/efi
/dev/sdb1      ext4       20G   44M   19G   1% /mnt
tmpfs          tmpfs      65M     0   65M   0% /run/user/1000
user@ubuntu:~#
Filesystem     Type      Size  Used Avail Use% Mounted on
udev           devtmpfs  314M     0  314M   0% /dev
tmpfs          tmpfs      65M  2.3M   63M   4% /run
/dev/sda1      ext4       97G  1.8G   95G   2% /
tmpfs          tmpfs     324M     0  324M   0% /dev/shm
tmpfs          tmpfs     5.0M     0  5.0M   0% /run/lock
tmpfs          tmpfs     324M     0  324M   0% /sys/fs/cgroup
/dev/sda15     vfat      105M  3.6M  101M   4% /boot/efi
/dev/sdb1      ext4       20G   44M   19G   1% /mnt
tmpfs          tmpfs      65M     0   65M   0% /run/user/1000
user@ubuntu:~#
To increase the OS disk size in SUSE 12 SP4, SUSE SLES 12 for SAP, SUSE SLES 15, and SUSE SLES 15 for SAP:
Follow the procedure previously described to expand the disk in the Azure infrastructure.
Follow the procedure previously described to expand the disk in the Azure infrastructure.
Access your VM as therootuser by using thesudocommand after logging in as another user:sudo -i
Access your VM as therootuser by using thesudocommand after logging in as another user:
sudo
sudo -i
sudo -i
Use the following command to install thegrowpartpackage, which is used to resize the partition, if it isn't already present:zypper install growpart
Use the following command to install thegrowpartpackage, which is used to resize the partition, if it isn't already present:
zypper install growpart
zypper install growpart
Use thelsblkcommand to find the partition mounted on the root of the file system (/). In this case, we see that partition 4 of devicesdais mounted on/:lsblkNAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
sda      8:0    0   48G  0 disk
ââsda1   8:1    0    2M  0 part
ââsda2   8:2    0  512M  0 part /boot/efi
ââsda3   8:3    0    1G  0 part /boot
ââsda4   8:4    0 28.5G  0 part /
sdb      8:16   0    4G  0 disk
ââsdb1   8:17   0    4G  0 part /mnt/resource
Use thelsblkcommand to find the partition mounted on the root of the file system (/). In this case, we see that partition 4 of devicesdais mounted on/:
lsblk
lsblk
lsblk
NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
sda      8:0    0   48G  0 disk
ââsda1   8:1    0    2M  0 part
ââsda2   8:2    0  512M  0 part /boot/efi
ââsda3   8:3    0    1G  0 part /boot
ââsda4   8:4    0 28.5G  0 part /
sdb      8:16   0    4G  0 disk
ââsdb1   8:17   0    4G  0 part /mnt/resource
NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
sda      8:0    0   48G  0 disk
ââsda1   8:1    0    2M  0 part
ââsda2   8:2    0  512M  0 part /boot/efi
ââsda3   8:3    0    1G  0 part /boot
ââsda4   8:4    0 28.5G  0 part /
sdb      8:16   0    4G  0 disk
ââsdb1   8:17   0    4G  0 part /mnt/resource
Resize the required partition by using thegrowpartcommand and the partition number determined in the preceding step:growpart /dev/sda 4CHANGED: partition=4 start=3151872 old: size=59762655 end=62914527 new: size=97511391 end=100663263
Resize the required partition by using thegrowpartcommand and the partition number determined in the preceding step:
growpart
growpart /dev/sda 4
growpart /dev/sda 4
CHANGED: partition=4 start=3151872 old: size=59762655 end=62914527 new: size=97511391 end=100663263
CHANGED: partition=4 start=3151872 old: size=59762655 end=62914527 new: size=97511391 end=100663263
Run thelsblkcommand again to check whether the partition was increased.The following output shows that the/dev/sda4partition was resized to 46.5 GB:lsblkNAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
sda      8:0    0   48G  0 disk
ââsda1   8:1    0    2M  0 part
ââsda2   8:2    0  512M  0 part /boot/efi
ââsda3   8:3    0    1G  0 part /boot
ââsda4   8:4    0 46.5G  0 part /
sdb      8:16   0    4G  0 disk
ââsdb1   8:17   0    4G  0 part /mnt/resource
Run thelsblkcommand again to check whether the partition was increased.
lsblk
The following output shows that the/dev/sda4partition was resized to 46.5 GB:
lsblk
lsblk
NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
sda      8:0    0   48G  0 disk
ââsda1   8:1    0    2M  0 part
ââsda2   8:2    0  512M  0 part /boot/efi
ââsda3   8:3    0    1G  0 part /boot
ââsda4   8:4    0 46.5G  0 part /
sdb      8:16   0    4G  0 disk
ââsdb1   8:17   0    4G  0 part /mnt/resource
NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
sda      8:0    0   48G  0 disk
ââsda1   8:1    0    2M  0 part
ââsda2   8:2    0  512M  0 part /boot/efi
ââsda3   8:3    0    1G  0 part /boot
ââsda4   8:4    0 46.5G  0 part /
sdb      8:16   0    4G  0 disk
ââsdb1   8:17   0    4G  0 part /mnt/resource
Identify the type of file system on the OS disk by using thelsblkcommand with the-fflag:lsblk -fNAME   FSTYPE LABEL UUID                                 MOUNTPOINT
sda
ââsda1
ââsda2 vfat   EFI   AC67-D22D                            /boot/efi
ââsda3 xfs    BOOT  5731a128-db36-4899-b3d2-eb5ae8126188 /boot
ââsda4 xfs    ROOT  70f83359-c7f2-4409-bba5-37b07534af96 /
sdb
ââsdb1 ext4         8c4ca904-cd93-4939-b240-fb45401e2ec6 /mnt/resource
Identify the type of file system on the OS disk by using thelsblkcommand with the-fflag:
lsblk
-f
lsblk -f
lsblk -f
NAME   FSTYPE LABEL UUID                                 MOUNTPOINT
sda
ââsda1
ââsda2 vfat   EFI   AC67-D22D                            /boot/efi
ââsda3 xfs    BOOT  5731a128-db36-4899-b3d2-eb5ae8126188 /boot
ââsda4 xfs    ROOT  70f83359-c7f2-4409-bba5-37b07534af96 /
sdb
ââsdb1 ext4         8c4ca904-cd93-4939-b240-fb45401e2ec6 /mnt/resource
NAME   FSTYPE LABEL UUID                                 MOUNTPOINT
sda
ââsda1
ââsda2 vfat   EFI   AC67-D22D                            /boot/efi
ââsda3 xfs    BOOT  5731a128-db36-4899-b3d2-eb5ae8126188 /boot
ââsda4 xfs    ROOT  70f83359-c7f2-4409-bba5-37b07534af96 /
sdb
ââsdb1 ext4         8c4ca904-cd93-4939-b240-fb45401e2ec6 /mnt/resource
Based on the file system type, use the appropriate commands to resize the file system.Forxfs, use this command:xfs_growfs /Example output:meta-data=/dev/sda4              isize=512    agcount=4, agsize=1867583 blks
         =                       sectsz=512   attr=2, projid32bit=1
         =                       crc=1        finobt=0 spinodes=0 rmapbt=0
         =                       reflink=0
data     =                       bsize=4096   blocks=7470331, imaxpct=25
         =                       sunit=0      swidth=0 blks
naming   =version 2              bsize=4096   ascii-ci=0 ftype=1
log      =internal               bsize=4096   blocks=3647, version=2
         =                       sectsz=512   sunit=0 blks, lazy-count=1
realtime =none                   extsz=4096   blocks=0, rtextents=0
data blocks changed from 7470331 to 12188923Forext4, use this command:resize2fs /dev/sda4
Based on the file system type, use the appropriate commands to resize the file system.
Forxfs, use this command:
xfs_growfs /
xfs_growfs /
Example output:
meta-data=/dev/sda4              isize=512    agcount=4, agsize=1867583 blks
         =                       sectsz=512   attr=2, projid32bit=1
         =                       crc=1        finobt=0 spinodes=0 rmapbt=0
         =                       reflink=0
data     =                       bsize=4096   blocks=7470331, imaxpct=25
         =                       sunit=0      swidth=0 blks
naming   =version 2              bsize=4096   ascii-ci=0 ftype=1
log      =internal               bsize=4096   blocks=3647, version=2
         =                       sectsz=512   sunit=0 blks, lazy-count=1
realtime =none                   extsz=4096   blocks=0, rtextents=0
data blocks changed from 7470331 to 12188923
meta-data=/dev/sda4              isize=512    agcount=4, agsize=1867583 blks
         =                       sectsz=512   attr=2, projid32bit=1
         =                       crc=1        finobt=0 spinodes=0 rmapbt=0
         =                       reflink=0
data     =                       bsize=4096   blocks=7470331, imaxpct=25
         =                       sunit=0      swidth=0 blks
naming   =version 2              bsize=4096   ascii-ci=0 ftype=1
log      =internal               bsize=4096   blocks=3647, version=2
         =                       sectsz=512   sunit=0 blks, lazy-count=1
realtime =none                   extsz=4096   blocks=0, rtextents=0
data blocks changed from 7470331 to 12188923
Forext4, use this command:
resize2fs /dev/sda4
resize2fs /dev/sda4
Verify the increased file system size fordf -Thby using this command:df -ThlExample output:Filesystem     Type      Size  Used Avail Use% Mounted on
devtmpfs       devtmpfs  445M  4.0K  445M   1% /dev
tmpfs          tmpfs     458M     0  458M   0% /dev/shm
tmpfs          tmpfs     458M   14M  445M   3% /run
tmpfs          tmpfs     458M     0  458M   0% /sys/fs/cgroup
/dev/sda4      xfs        47G  2.2G   45G   5% /
/dev/sda3      xfs      1014M   86M  929M   9% /boot
/dev/sda2      vfat      512M  1.1M  511M   1% /boot/efi
/dev/sdb1      ext4      3.9G   16M  3.7G   1% /mnt/resource
tmpfs          tmpfs      92M     0   92M   0% /run/user/1000
tmpfs          tmpfs      92M     0   92M   0% /run/user/490In the preceding example, we can see that the file system size for the OS disk was increased.
Verify the increased file system size fordf -Thby using this command:
df -Thl
df -Thl
Example output:
Filesystem     Type      Size  Used Avail Use% Mounted on
devtmpfs       devtmpfs  445M  4.0K  445M   1% /dev
tmpfs          tmpfs     458M     0  458M   0% /dev/shm
tmpfs          tmpfs     458M   14M  445M   3% /run
tmpfs          tmpfs     458M     0  458M   0% /sys/fs/cgroup
/dev/sda4      xfs        47G  2.2G   45G   5% /
/dev/sda3      xfs      1014M   86M  929M   9% /boot
/dev/sda2      vfat      512M  1.1M  511M   1% /boot/efi
/dev/sdb1      ext4      3.9G   16M  3.7G   1% /mnt/resource
tmpfs          tmpfs      92M     0   92M   0% /run/user/1000
tmpfs          tmpfs      92M     0   92M   0% /run/user/490
Filesystem     Type      Size  Used Avail Use% Mounted on
devtmpfs       devtmpfs  445M  4.0K  445M   1% /dev
tmpfs          tmpfs     458M     0  458M   0% /dev/shm
tmpfs          tmpfs     458M   14M  445M   3% /run
tmpfs          tmpfs     458M     0  458M   0% /sys/fs/cgroup
/dev/sda4      xfs        47G  2.2G   45G   5% /
/dev/sda3      xfs      1014M   86M  929M   9% /boot
/dev/sda2      vfat      512M  1.1M  511M   1% /boot/efi
/dev/sdb1      ext4      3.9G   16M  3.7G   1% /mnt/resource
tmpfs          tmpfs      92M     0   92M   0% /run/user/1000
tmpfs          tmpfs      92M     0   92M   0% /run/user/490
In the preceding example, we can see that the file system size for the OS disk was increased.
Follow the procedure previously described to expand the disk in the Azure infrastructure.
Follow the procedure previously described to expand the disk in the Azure infrastructure.
Access your VM as therootuser by using thesudocommand after logging in as another user:sudo -i
Access your VM as therootuser by using thesudocommand after logging in as another user:
sudo
sudo -i
sudo -i
Use thelsblkcommand to determine which logical volume (LV) is mounted on the root of the file system (/). In this case, we see thatrootvg-rootlvis mounted on/. If a different filesystem is in need of resizing, substitute the LV and mount point throughout this section.lsblk -fNAME                  FSTYPE      LABEL   UUID                                   MOUNTPOINT
fd0
sda
ââsda1                vfat                C13D-C339                              /boot/efi
ââsda2                xfs                 8cc4c23c-fa7b-4a4d-bba8-4108b7ac0135   /boot
ââsda3
ââsda4                LVM2_member         zx0Lio-2YsN-ukmz-BvAY-LCKb-kRU0-ReRBzh
   âârootvg-tmplv      xfs                 174c3c3a-9e65-409a-af59-5204a5c00550   /tmp
   âârootvg-usrlv      xfs                 a48dbaac-75d4-4cf6-a5e6-dcd3ffed9af1   /usr
   âârootvg-optlv      xfs                 85fe8660-9acb-48b8-98aa-bf16f14b9587   /opt
   âârootvg-homelv     xfs                 b22432b1-c905-492b-a27f-199c1a6497e7   /home
   âârootvg-varlv      xfs                 24ad0b4e-1b6b-45e7-9605-8aca02d20d22   /var
   âârootvg-rootlv     xfs                 4f3e6f40-61bf-4866-a7ae-5c6a94675193   /
Use thelsblkcommand to determine which logical volume (LV) is mounted on the root of the file system (/). In this case, we see thatrootvg-rootlvis mounted on/. If a different filesystem is in need of resizing, substitute the LV and mount point throughout this section.
lsblk
lsblk -f
lsblk -f
NAME                  FSTYPE      LABEL   UUID                                   MOUNTPOINT
fd0
sda
ââsda1                vfat                C13D-C339                              /boot/efi
ââsda2                xfs                 8cc4c23c-fa7b-4a4d-bba8-4108b7ac0135   /boot
ââsda3
ââsda4                LVM2_member         zx0Lio-2YsN-ukmz-BvAY-LCKb-kRU0-ReRBzh
   âârootvg-tmplv      xfs                 174c3c3a-9e65-409a-af59-5204a5c00550   /tmp
   âârootvg-usrlv      xfs                 a48dbaac-75d4-4cf6-a5e6-dcd3ffed9af1   /usr
   âârootvg-optlv      xfs                 85fe8660-9acb-48b8-98aa-bf16f14b9587   /opt
   âârootvg-homelv     xfs                 b22432b1-c905-492b-a27f-199c1a6497e7   /home
   âârootvg-varlv      xfs                 24ad0b4e-1b6b-45e7-9605-8aca02d20d22   /var
   âârootvg-rootlv     xfs                 4f3e6f40-61bf-4866-a7ae-5c6a94675193   /
NAME                  FSTYPE      LABEL   UUID                                   MOUNTPOINT
fd0
sda
ââsda1                vfat                C13D-C339                              /boot/efi
ââsda2                xfs                 8cc4c23c-fa7b-4a4d-bba8-4108b7ac0135   /boot
ââsda3
ââsda4                LVM2_member         zx0Lio-2YsN-ukmz-BvAY-LCKb-kRU0-ReRBzh
   âârootvg-tmplv      xfs                 174c3c3a-9e65-409a-af59-5204a5c00550   /tmp
   âârootvg-usrlv      xfs                 a48dbaac-75d4-4cf6-a5e6-dcd3ffed9af1   /usr
   âârootvg-optlv      xfs                 85fe8660-9acb-48b8-98aa-bf16f14b9587   /opt
   âârootvg-homelv     xfs                 b22432b1-c905-492b-a27f-199c1a6497e7   /home
   âârootvg-varlv      xfs                 24ad0b4e-1b6b-45e7-9605-8aca02d20d22   /var
   âârootvg-rootlv     xfs                 4f3e6f40-61bf-4866-a7ae-5c6a94675193   /
Check whether there's free space in the LVM volume group (VG) containing the root partition. If there's free space, skip to step 12.vgdisplay rootvg--- Volume group ---
VG Name               rootvg
System ID
Format                lvm2
Metadata Areas        1
Metadata Sequence No  7
VG Access             read/write
VG Status             resizable
MAX LV                0
Cur LV                6
Open LV               6
Max PV                0
Cur PV                1
Act PV                1
VG Size               <63.02 GiB
PE Size               4.00 MiB
Total PE              16132
Alloc PE / Size       6400 / 25.00 GiB
Free  PE / Size       9732 / <38.02 GiB
VG UUID               lPUfnV-3aYT-zDJJ-JaPX-L2d7-n8sL-A9AgJbIn this example, the lineFree  PE / Sizeshows that there's 38.02 GB free in the volume group, as the disk has already been resized.
Check whether there's free space in the LVM volume group (VG) containing the root partition. If there's free space, skip to step 12.
vgdisplay rootvg
vgdisplay rootvg
--- Volume group ---
VG Name               rootvg
System ID
Format                lvm2
Metadata Areas        1
Metadata Sequence No  7
VG Access             read/write
VG Status             resizable
MAX LV                0
Cur LV                6
Open LV               6
Max PV                0
Cur PV                1
Act PV                1
VG Size               <63.02 GiB
PE Size               4.00 MiB
Total PE              16132
Alloc PE / Size       6400 / 25.00 GiB
Free  PE / Size       9732 / <38.02 GiB
VG UUID               lPUfnV-3aYT-zDJJ-JaPX-L2d7-n8sL-A9AgJb
--- Volume group ---
VG Name               rootvg
System ID
Format                lvm2
Metadata Areas        1
Metadata Sequence No  7
VG Access             read/write
VG Status             resizable
MAX LV                0
Cur LV                6
Open LV               6
Max PV                0
Cur PV                1
Act PV                1
VG Size               <63.02 GiB
PE Size               4.00 MiB
Total PE              16132
Alloc PE / Size       6400 / 25.00 GiB
Free  PE / Size       9732 / <38.02 GiB
VG UUID               lPUfnV-3aYT-zDJJ-JaPX-L2d7-n8sL-A9AgJb
In this example, the lineFree  PE / Sizeshows that there's 38.02 GB free in the volume group, as the disk has already been resized.
Install thecloud-utils-growpartpackage to provide thegrowpartcommand, which is required to increase the size of the OS disk and the gdisk handler for GPT disk layouts This package is preinstalled on most marketplace imagesdnf install cloud-utils-growpart gdiskIn Red Hat versions 7 and below you can useyumcommand instead ofdnf.
Install thecloud-utils-growpartpackage to provide thegrowpartcommand, which is required to increase the size of the OS disk and the gdisk handler for GPT disk layouts This package is preinstalled on most marketplace images
dnf install cloud-utils-growpart gdisk
dnf install cloud-utils-growpart gdisk
In Red Hat versions 7 and below you can useyumcommand instead ofdnf.
yum
dnf
Determine which disk and partition holds the LVM physical volume (PV) or volumes in the volume group namedrootvgby using thepvscancommand. Note the size and free space listed between the brackets ([and]).pvscanPV /dev/sda4   VG rootvg          lvm2 [<63.02 GiB / <38.02 GiB free]
Determine which disk and partition holds the LVM physical volume (PV) or volumes in the volume group namedrootvgby using thepvscancommand. Note the size and free space listed between the brackets ([and]).
pvscan
pvscan
PV /dev/sda4   VG rootvg          lvm2 [<63.02 GiB / <38.02 GiB free]
PV /dev/sda4   VG rootvg          lvm2 [<63.02 GiB / <38.02 GiB free]
Verify the size of the partition by usinglsblk.lsblk /dev/sda4NAME            MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
sda4              8:4    0  63G  0 part
âârootvg-tmplv  253:1    0   2G  0 lvm  /tmp
âârootvg-usrlv  253:2    0  10G  0 lvm  /usr
âârootvg-optlv  253:3    0   2G  0 lvm  /opt
âârootvg-homelv 253:4    0   1G  0 lvm  /home
âârootvg-varlv  253:5    0   8G  0 lvm  /var
âârootvg-rootlv 253:6    0   2G  0 lvm  /
Verify the size of the partition by usinglsblk.
lsblk
lsblk /dev/sda4
lsblk /dev/sda4
NAME            MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
sda4              8:4    0  63G  0 part
âârootvg-tmplv  253:1    0   2G  0 lvm  /tmp
âârootvg-usrlv  253:2    0  10G  0 lvm  /usr
âârootvg-optlv  253:3    0   2G  0 lvm  /opt
âârootvg-homelv 253:4    0   1G  0 lvm  /home
âârootvg-varlv  253:5    0   8G  0 lvm  /var
âârootvg-rootlv 253:6    0   2G  0 lvm  /
NAME            MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
sda4              8:4    0  63G  0 part
âârootvg-tmplv  253:1    0   2G  0 lvm  /tmp
âârootvg-usrlv  253:2    0  10G  0 lvm  /usr
âârootvg-optlv  253:3    0   2G  0 lvm  /opt
âârootvg-homelv 253:4    0   1G  0 lvm  /home
âârootvg-varlv  253:5    0   8G  0 lvm  /var
âârootvg-rootlv 253:6    0   2G  0 lvm  /
Expand the partition containing this PV usinggrowpart, the device name, and partition number. Doing so expands the specified partition to use all the free contiguous space on the device.growpart /dev/sda 4CHANGED: partition=4 start=2054144 old: size=132161536 end=134215680 new: size=199272414 end=201326558
Expand the partition containing this PV usinggrowpart, the device name, and partition number. Doing so expands the specified partition to use all the free contiguous space on the device.
growpart /dev/sda 4
growpart /dev/sda 4
CHANGED: partition=4 start=2054144 old: size=132161536 end=134215680 new: size=199272414 end=201326558
CHANGED: partition=4 start=2054144 old: size=132161536 end=134215680 new: size=199272414 end=201326558
Verify that the partition has resized to the expected size by using thelsblkcommand again. Notice that in the examplesda4changed from 63G to 95G.lsblk /dev/sda4NAME            MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
sda4              8:4    0  95G  0 part
âârootvg-tmplv  253:1    0   2G  0 lvm  /tmp
âârootvg-usrlv  253:2    0  10G  0 lvm  /usr
âârootvg-optlv  253:3    0   2G  0 lvm  /opt
âârootvg-homelv 253:4    0   1G  0 lvm  /home
âârootvg-varlv  253:5    0   8G  0 lvm  /var
âârootvg-rootlv 253:6    0   2G  0 lvm  /
Verify that the partition has resized to the expected size by using thelsblkcommand again. Notice that in the examplesda4changed from 63G to 95G.
lsblk
lsblk /dev/sda4
lsblk /dev/sda4
NAME            MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
sda4              8:4    0  95G  0 part
âârootvg-tmplv  253:1    0   2G  0 lvm  /tmp
âârootvg-usrlv  253:2    0  10G  0 lvm  /usr
âârootvg-optlv  253:3    0   2G  0 lvm  /opt
âârootvg-homelv 253:4    0   1G  0 lvm  /home
âârootvg-varlv  253:5    0   8G  0 lvm  /var
âârootvg-rootlv 253:6    0   2G  0 lvm  /
NAME            MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
sda4              8:4    0  95G  0 part
âârootvg-tmplv  253:1    0   2G  0 lvm  /tmp
âârootvg-usrlv  253:2    0  10G  0 lvm  /usr
âârootvg-optlv  253:3    0   2G  0 lvm  /opt
âârootvg-homelv 253:4    0   1G  0 lvm  /home
âârootvg-varlv  253:5    0   8G  0 lvm  /var
âârootvg-rootlv 253:6    0   2G  0 lvm  /
Expand the PV to use the rest of the newly expanded partitionpvresize /dev/sda4Physical volume "/dev/sda4" changed
1 physical volume(s) resized or updated / 0 physical volume(s) not resized
Expand the PV to use the rest of the newly expanded partition
pvresize /dev/sda4
pvresize /dev/sda4
Physical volume "/dev/sda4" changed
1 physical volume(s) resized or updated / 0 physical volume(s) not resized
Physical volume "/dev/sda4" changed
1 physical volume(s) resized or updated / 0 physical volume(s) not resized
Verify the new size of the PV is the expected size, comparing to original[size / free]values.pvscanPV /dev/sda4   VG rootvg          lvm2 [<95.02 GiB / <70.02 GiB free]
Verify the new size of the PV is the expected size, comparing to original[size / free]values.
pvscan
pvscan
PV /dev/sda4   VG rootvg          lvm2 [<95.02 GiB / <70.02 GiB free]
PV /dev/sda4   VG rootvg          lvm2 [<95.02 GiB / <70.02 GiB free]
Expand the LV by the required amount, which doesn't need to be all the free space in the volume group. In the following example,/dev/mapper/rootvg-rootlvis resized from 2 GB to 12 GB (an increase of 10 GB) through the following command. This command also resizes the file system on the LV.lvresize -r -L +10G /dev/mapper/rootvg-rootlvExample output:Size of logical volume rootvg/rootlv changed from 2.00 GiB (512 extents) to 12.00 GiB (3072 extents).
Logical volume rootvg/rootlv successfully resized.
meta-data=/dev/mapper/rootvg-rootlv isize=512    agcount=4, agsize=131072 blks
         =                       sectsz=4096  attr=2, projid32bit=1
         =                       crc=1        finobt=0 spinodes=0
data     =                       bsize=4096   blocks=524288, imaxpct=25
         =                       sunit=0      swidth=0 blks
naming   =version 2              bsize=4096   ascii-ci=0 ftype=1
log      =internal               bsize=4096   blocks=2560, version=2
         =                       sectsz=4096  sunit=1 blks, lazy-count=1
realtime =none                   extsz=4096   blocks=0, rtextents=0
data blocks changed from 524288 to 3145728
Expand the LV by the required amount, which doesn't need to be all the free space in the volume group. In the following example,/dev/mapper/rootvg-rootlvis resized from 2 GB to 12 GB (an increase of 10 GB) through the following command. This command also resizes the file system on the LV.
lvresize -r -L +10G /dev/mapper/rootvg-rootlv
lvresize -r -L +10G /dev/mapper/rootvg-rootlv
Example output:
Size of logical volume rootvg/rootlv changed from 2.00 GiB (512 extents) to 12.00 GiB (3072 extents).
Logical volume rootvg/rootlv successfully resized.
meta-data=/dev/mapper/rootvg-rootlv isize=512    agcount=4, agsize=131072 blks
         =                       sectsz=4096  attr=2, projid32bit=1
         =                       crc=1        finobt=0 spinodes=0
data     =                       bsize=4096   blocks=524288, imaxpct=25
         =                       sunit=0      swidth=0 blks
naming   =version 2              bsize=4096   ascii-ci=0 ftype=1
log      =internal               bsize=4096   blocks=2560, version=2
         =                       sectsz=4096  sunit=1 blks, lazy-count=1
realtime =none                   extsz=4096   blocks=0, rtextents=0
data blocks changed from 524288 to 3145728
Size of logical volume rootvg/rootlv changed from 2.00 GiB (512 extents) to 12.00 GiB (3072 extents).
Logical volume rootvg/rootlv successfully resized.
meta-data=/dev/mapper/rootvg-rootlv isize=512    agcount=4, agsize=131072 blks
         =                       sectsz=4096  attr=2, projid32bit=1
         =                       crc=1        finobt=0 spinodes=0
data     =                       bsize=4096   blocks=524288, imaxpct=25
         =                       sunit=0      swidth=0 blks
naming   =version 2              bsize=4096   ascii-ci=0 ftype=1
log      =internal               bsize=4096   blocks=2560, version=2
         =                       sectsz=4096  sunit=1 blks, lazy-count=1
realtime =none                   extsz=4096   blocks=0, rtextents=0
data blocks changed from 524288 to 3145728
Thelvresizecommand automatically calls the appropriate resize command for the filesystem in the LV. Verify whether/dev/mapper/rootvg-rootlv, which is mounted on/, has an increased file system size by using thedf -Thcommand:Example output:df -Th /Filesystem                Type  Size  Used Avail Use% Mounted on
/dev/mapper/rootvg-rootlv xfs    12G   71M   12G   1% /
Thelvresizecommand automatically calls the appropriate resize command for the filesystem in the LV. Verify whether/dev/mapper/rootvg-rootlv, which is mounted on/, has an increased file system size by using thedf -Thcommand:
lvresize
df -Th
Example output:
df -Th /
df -Th /
Filesystem                Type  Size  Used Avail Use% Mounted on
/dev/mapper/rootvg-rootlv xfs    12G   71M   12G   1% /
Filesystem                Type  Size  Used Avail Use% Mounted on
/dev/mapper/rootvg-rootlv xfs    12G   71M   12G   1% /
Note
To use the same procedure to resize any other logical volume, change thelvname in step12.
Follow the procedure previously described to expand the disk in the Azure infrastructure.
Follow the procedure previously described to expand the disk in the Azure infrastructure.
Access your VM as therootuser by using thesudocommand after logging in as another user:sudo -i
Access your VM as therootuser by using thesudocommand after logging in as another user:
sudo
sudo -i
sudo -i
Install thecloud-utils-growpartpackage to provide thegrowpartcommand, which is required to increase the size of the OS disk and the gdisk handler for GPT disk layouts. This package is preinstalled on most marketplace imagesdnf install cloud-utils-growpart gdiskIn Red Hat versions 7 and below you can useyumcommand instead ofdnf.
Install thecloud-utils-growpartpackage to provide thegrowpartcommand, which is required to increase the size of the OS disk and the gdisk handler for GPT disk layouts. This package is preinstalled on most marketplace images
dnf install cloud-utils-growpart gdisk
dnf install cloud-utils-growpart gdisk
In Red Hat versions 7 and below you can useyumcommand instead ofdnf.
yum
dnf
Use thelsblk -fcommand to verify the partition and filesystem type holding the root (/) partitionlsblk -fNAME    FSTYPE LABEL UUID                                 MOUNTPOINT
sda
ââsda1  xfs          2a7bb59d-6a71-4841-a3c6-cba23413a5d2 /boot
ââsda2  xfs          148be922-e3ec-43b5-8705-69786b522b05 /
ââsda14
ââsda15 vfat         788D-DC65                            /boot/efi
sdb
ââsdb1  ext4         923f51ff-acbd-4b91-b01b-c56140920098 /mnt/resource
Use thelsblk -fcommand to verify the partition and filesystem type holding the root (/) partition
lsblk -f
lsblk -f
NAME    FSTYPE LABEL UUID                                 MOUNTPOINT
sda
ââsda1  xfs          2a7bb59d-6a71-4841-a3c6-cba23413a5d2 /boot
ââsda2  xfs          148be922-e3ec-43b5-8705-69786b522b05 /
ââsda14
ââsda15 vfat         788D-DC65                            /boot/efi
sdb
ââsdb1  ext4         923f51ff-acbd-4b91-b01b-c56140920098 /mnt/resource
NAME    FSTYPE LABEL UUID                                 MOUNTPOINT
sda
ââsda1  xfs          2a7bb59d-6a71-4841-a3c6-cba23413a5d2 /boot
ââsda2  xfs          148be922-e3ec-43b5-8705-69786b522b05 /
ââsda14
ââsda15 vfat         788D-DC65                            /boot/efi
sdb
ââsdb1  ext4         923f51ff-acbd-4b91-b01b-c56140920098 /mnt/resource
For verification, start by listing the partition table of the sda disk withgdisk. In this example, we see a 48.0 GiB disk with partition #2 sized 29.0 GiB. The disk was expanded from 30 GB to 48 GB in the Azure portal.gdisk -l /dev/sdaGPT fdisk (gdisk) version 0.8.10

Partition table scan:
MBR: protective
BSD: not present
APM: not present
GPT: present

Found valid GPT with protective MBR; using GPT.
Disk /dev/sda: 100663296 sectors, 48.0 GiB
Logical sector size: 512 bytes
Disk identifier (GUID): 78CDF84D-9C8E-4B9F-8978-8C496A1BEC83
Partition table holds up to 128 entries
First usable sector is 34, last usable sector is 62914526
Partitions will be aligned on 2048-sector boundaries
Total free space is 6076 sectors (3.0 MiB)

Number  Start (sector)    End (sector)  Size       Code  Name
1         1026048         2050047   500.0 MiB   0700
2         2050048        62912511   29.0 GiB    0700
14            2048           10239   4.0 MiB     EF02
15           10240         1024000   495.0 MiB   EF00  EFI System Partition
For verification, start by listing the partition table of the sda disk withgdisk. In this example, we see a 48.0 GiB disk with partition #2 sized 29.0 GiB. The disk was expanded from 30 GB to 48 GB in the Azure portal.
gdisk -l /dev/sda
gdisk -l /dev/sda
GPT fdisk (gdisk) version 0.8.10

Partition table scan:
MBR: protective
BSD: not present
APM: not present
GPT: present

Found valid GPT with protective MBR; using GPT.
Disk /dev/sda: 100663296 sectors, 48.0 GiB
Logical sector size: 512 bytes
Disk identifier (GUID): 78CDF84D-9C8E-4B9F-8978-8C496A1BEC83
Partition table holds up to 128 entries
First usable sector is 34, last usable sector is 62914526
Partitions will be aligned on 2048-sector boundaries
Total free space is 6076 sectors (3.0 MiB)

Number  Start (sector)    End (sector)  Size       Code  Name
1         1026048         2050047   500.0 MiB   0700
2         2050048        62912511   29.0 GiB    0700
14            2048           10239   4.0 MiB     EF02
15           10240         1024000   495.0 MiB   EF00  EFI System Partition
GPT fdisk (gdisk) version 0.8.10

Partition table scan:
MBR: protective
BSD: not present
APM: not present
GPT: present

Found valid GPT with protective MBR; using GPT.
Disk /dev/sda: 100663296 sectors, 48.0 GiB
Logical sector size: 512 bytes
Disk identifier (GUID): 78CDF84D-9C8E-4B9F-8978-8C496A1BEC83
Partition table holds up to 128 entries
First usable sector is 34, last usable sector is 62914526
Partitions will be aligned on 2048-sector boundaries
Total free space is 6076 sectors (3.0 MiB)

Number  Start (sector)    End (sector)  Size       Code  Name
1         1026048         2050047   500.0 MiB   0700
2         2050048        62912511   29.0 GiB    0700
14            2048           10239   4.0 MiB     EF02
15           10240         1024000   495.0 MiB   EF00  EFI System Partition
Expand the partition for root, in this case sda2 by using thegrowpartcommand. Using this command expands the partition to use all of the contiguous space on the disk.growpart /dev/sda 2CHANGED: partition=2 start=2050048 old: size=60862464 end=62912512 new: size=98613214 end=100663262
Expand the partition for root, in this case sda2 by using thegrowpartcommand. Using this command expands the partition to use all of the contiguous space on the disk.
growpart /dev/sda 2
growpart /dev/sda 2
CHANGED: partition=2 start=2050048 old: size=60862464 end=62912512 new: size=98613214 end=100663262
CHANGED: partition=2 start=2050048 old: size=60862464 end=62912512 new: size=98613214 end=100663262
Now print the new partition table withgdiskagain. Notice that partition 2 has is now sized 47.0 GiBgdisk -l /dev/sdaGPT fdisk (gdisk) version 0.8.10

Partition table scan:
MBR: protective
BSD: not present
APM: not present
GPT: present

Found valid GPT with protective MBR; using GPT.
Disk /dev/sda: 100663296 sectors, 48.0 GiB
Logical sector size: 512 bytes
Disk identifier (GUID): 78CDF84D-9C8E-4B9F-8978-8C496A1BEC83
Partition table holds up to 128 entries
First usable sector is 34, last usable sector is 100663262
Partitions will be aligned on 2048-sector boundaries
Total free space is 4062 sectors (2.0 MiB)

Number  Start (sector)    End (sector)  Size       Code  Name
   1         1026048         2050047   500.0 MiB   0700
   2         2050048       100663261   47.0 GiB    0700
14            2048           10239   4.0 MiB     EF02
15           10240         1024000   495.0 MiB   EF00  EFI System Partition
Now print the new partition table withgdiskagain. Notice that partition 2 has is now sized 47.0 GiB
gdisk -l /dev/sda
gdisk -l /dev/sda
GPT fdisk (gdisk) version 0.8.10

Partition table scan:
MBR: protective
BSD: not present
APM: not present
GPT: present

Found valid GPT with protective MBR; using GPT.
Disk /dev/sda: 100663296 sectors, 48.0 GiB
Logical sector size: 512 bytes
Disk identifier (GUID): 78CDF84D-9C8E-4B9F-8978-8C496A1BEC83
Partition table holds up to 128 entries
First usable sector is 34, last usable sector is 100663262
Partitions will be aligned on 2048-sector boundaries
Total free space is 4062 sectors (2.0 MiB)

Number  Start (sector)    End (sector)  Size       Code  Name
   1         1026048         2050047   500.0 MiB   0700
   2         2050048       100663261   47.0 GiB    0700
14            2048           10239   4.0 MiB     EF02
15           10240         1024000   495.0 MiB   EF00  EFI System Partition
GPT fdisk (gdisk) version 0.8.10

Partition table scan:
MBR: protective
BSD: not present
APM: not present
GPT: present

Found valid GPT with protective MBR; using GPT.
Disk /dev/sda: 100663296 sectors, 48.0 GiB
Logical sector size: 512 bytes
Disk identifier (GUID): 78CDF84D-9C8E-4B9F-8978-8C496A1BEC83
Partition table holds up to 128 entries
First usable sector is 34, last usable sector is 100663262
Partitions will be aligned on 2048-sector boundaries
Total free space is 4062 sectors (2.0 MiB)

Number  Start (sector)    End (sector)  Size       Code  Name
   1         1026048         2050047   500.0 MiB   0700
   2         2050048       100663261   47.0 GiB    0700
14            2048           10239   4.0 MiB     EF02
15           10240         1024000   495.0 MiB   EF00  EFI System Partition
Expand the filesystem on the partition withxfs_growfs, which is appropriate for a standard marketplace-generated RedHat system:xfs_growfs /meta-data=/dev/sda2              isize=512    agcount=4, agsize=1901952 blks
         =                       sectsz=4096  attr=2, projid32bit=1
         =                       crc=1        finobt=0 spinodes=0
data     =                       bsize=4096   blocks=7607808, imaxpct=25
         =                       sunit=0      swidth=0 blks
naming   =version 2              bsize=4096   ascii-ci=0 ftype=1
log      =internal               bsize=4096   blocks=3714, version=2
         =                       sectsz=4096  sunit=1 blks, lazy-count=1
realtime =none                   extsz=4096   blocks=0, rtextents=0
data blocks changed from 7607808 to 12326651
Expand the filesystem on the partition withxfs_growfs, which is appropriate for a standard marketplace-generated RedHat system:
xfs_growfs /
xfs_growfs /
meta-data=/dev/sda2              isize=512    agcount=4, agsize=1901952 blks
         =                       sectsz=4096  attr=2, projid32bit=1
         =                       crc=1        finobt=0 spinodes=0
data     =                       bsize=4096   blocks=7607808, imaxpct=25
         =                       sunit=0      swidth=0 blks
naming   =version 2              bsize=4096   ascii-ci=0 ftype=1
log      =internal               bsize=4096   blocks=3714, version=2
         =                       sectsz=4096  sunit=1 blks, lazy-count=1
realtime =none                   extsz=4096   blocks=0, rtextents=0
data blocks changed from 7607808 to 12326651
meta-data=/dev/sda2              isize=512    agcount=4, agsize=1901952 blks
         =                       sectsz=4096  attr=2, projid32bit=1
         =                       crc=1        finobt=0 spinodes=0
data     =                       bsize=4096   blocks=7607808, imaxpct=25
         =                       sunit=0      swidth=0 blks
naming   =version 2              bsize=4096   ascii-ci=0 ftype=1
log      =internal               bsize=4096   blocks=3714, version=2
         =                       sectsz=4096  sunit=1 blks, lazy-count=1
realtime =none                   extsz=4096   blocks=0, rtextents=0
data blocks changed from 7607808 to 12326651
Verify the new size is reflected with thedfcommanddf -hlFilesystem      Size  Used Avail Use% Mounted on
devtmpfs        452M     0  452M   0% /dev
tmpfs           464M     0  464M   0% /dev/shm
tmpfs           464M  6.8M  457M   2% /run
tmpfs           464M     0  464M   0% /sys/fs/cgroup
/dev/sda2        48G  2.1G   46G   5% /
/dev/sda1       494M   65M  430M  13% /boot
/dev/sda15      495M   12M  484M   3% /boot/efi
/dev/sdb1       3.9G   16M  3.7G   1% /mnt/resource
tmpfs            93M     0   93M   0% /run/user/1000
Verify the new size is reflected with thedfcommand
df -hl
df -hl
Filesystem      Size  Used Avail Use% Mounted on
devtmpfs        452M     0  452M   0% /dev
tmpfs           464M     0  464M   0% /dev/shm
tmpfs           464M  6.8M  457M   2% /run
tmpfs           464M     0  464M   0% /sys/fs/cgroup
/dev/sda2        48G  2.1G   46G   5% /
/dev/sda1       494M   65M  430M  13% /boot
/dev/sda15      495M   12M  484M   3% /boot/efi
/dev/sdb1       3.9G   16M  3.7G   1% /mnt/resource
tmpfs            93M     0   93M   0% /run/user/1000
Filesystem      Size  Used Avail Use% Mounted on
devtmpfs        452M     0  452M   0% /dev
tmpfs           464M     0  464M   0% /dev/shm
tmpfs           464M  6.8M  457M   2% /run
tmpfs           464M     0  464M   0% /sys/fs/cgroup
/dev/sda2        48G  2.1G   46G   5% /
/dev/sda1       494M   65M  430M  13% /boot
/dev/sda15      495M   12M  484M   3% /boot/efi
/dev/sdb1       3.9G   16M  3.7G   1% /mnt/resource
tmpfs            93M     0   93M   0% /run/user/1000
Expanding without downtime classic VM SKU support
If you're using a classic VM SKU, it might not support expanding disks without downtime.
Use the following PowerShell script to determine which VM SKUs it's available with:
Connect-AzAccount
$subscriptionId="yourSubID"
$location="desiredRegion"
Set-AzContext -Subscription $subscriptionId
$vmSizes=Get-AzComputeResourceSku -Location $location | where{$_.ResourceType -eq 'virtualMachines'}

foreach($vmSize in $vmSizes){
    foreach($capability in $vmSize.Capabilities)
    {
       if(($capability.Name -eq "EphemeralOSDiskSupported" -and $capability.Value -eq "True") -or ($capability.Name -eq "PremiumIO" -and $capability.Value -eq "True") -or ($capability.Name -eq "HyperVGenerations" -and $capability.Value -match "V2"))
        {
            $vmSize.Name
       }
   }
}
Connect-AzAccount
$subscriptionId="yourSubID"
$location="desiredRegion"
Set-AzContext -Subscription $subscriptionId
$vmSizes=Get-AzComputeResourceSku -Location $location | where{$_.ResourceType -eq 'virtualMachines'}

foreach($vmSize in $vmSizes){
    foreach($capability in $vmSize.Capabilities)
    {
       if(($capability.Name -eq "EphemeralOSDiskSupported" -and $capability.Value -eq "True") -or ($capability.Name -eq "PremiumIO" -and $capability.Value -eq "True") -or ($capability.Name -eq "HyperVGenerations" -and $capability.Value -match "V2"))
        {
            $vmSize.Name
       }
   }
}
Feedback
Was this page helpful?
Additional resources