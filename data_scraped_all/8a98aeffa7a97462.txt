Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Install & use the CLI (v1)
Article
2024-08-28
4 contributors
In this article
APPLIES TO:Azure CLI ml extensionv1
Important
Some of the Azure CLI commands in this article use theazure-cli-ml, or v1, extension for Azure Machine Learning. Support for the v1 extension will end on September 30, 2025. You're able to install and use the v1 extension until that date.
azure-cli-ml
We recommend that you transition to theml, or v2, extension before September 30, 2025. For more information on the v2 extension, seeAzure Machine Learning CLI extension and Python SDK v2.
ml
The Azure Machine Learning CLI is an extension to theAzure CLI, a cross-platform command-line interface for the Azure platform. This extension provides commands for working with Azure Machine Learning. It allows you to automate your machine learning activities. The following list provides some example actions that you can do with the CLI extension:
Run experiments to create machine learning models
Run experiments to create machine learning models
Register machine learning models for customer usage
Register machine learning models for customer usage
Package, deploy, and track the lifecycle of your machine learning models
Package, deploy, and track the lifecycle of your machine learning models
The CLI isn't a replacement for the Azure Machine Learning SDK. It's a complementary tool that is optimized to handle highly parameterized tasks which suit themselves well to automation.
Prerequisites
To use the CLI, you must have an Azure subscription. If you don't have an Azure subscription, create a free account before you begin. Try thefree or paid version of Azure Machine Learningtoday.
To use the CLI, you must have an Azure subscription. If you don't have an Azure subscription, create a free account before you begin. Try thefree or paid version of Azure Machine Learningtoday.
To use the CLI commands in this document from yourlocal environment, you need theAzure CLI.If you use theAzure Cloud Shell, the CLI is accessed through the browser and lives in the cloud.
To use the CLI commands in this document from yourlocal environment, you need theAzure CLI.
If you use theAzure Cloud Shell, the CLI is accessed through the browser and lives in the cloud.
Full reference docs
Find thefull reference docs for the azure-cli-ml extension of Azure CLI.
Connect the CLI to your Azure subscription
Important
If you are using the Azure Cloud Shell, you can skip this section. The cloud shell automatically authenticates you using the account you log into your Azure subscription.
There are several ways that you can authenticate to your Azure subscription from the CLI. The most basic is to interactively authenticate using a browser. To authenticate interactively, open a command line or terminal and use the following command:
az login
az login
If the CLI can open your default browser, it will do so and load a sign-in page. Otherwise, you need to open a browser and follow the instructions on the command line. The instructions involve browsing tohttps://aka.ms/deviceloginand entering an authorization code.
Tip
After you sign in, you see a list of subscriptions associated with your Azure account. The subscription information withisDefault: trueis the currently activated subscription for Azure CLI commands. This subscription must be the same one that contains your Azure Machine Learning workspace. You can find the subscription information on the overview page for your workspace in theAzure portal.
isDefault: true
To select another subscription to use for Azure CLI commands, run theaz account set -s <subscription>command and specify the subscription name or ID to switch to. For more information about subscription selection, seeUse multiple Azure subscriptions.
az account set -s <subscription>
For other methods of authenticating, seeSign in with Azure CLI.
Install the extension
To install the CLI (v1) extension:
az extension add -n azure-cli-ml
az extension add -n azure-cli-ml
Update the extension
To update the Machine Learning CLI extension, use the following command:
az extension update -n azure-cli-ml
az extension update -n azure-cli-ml
Remove the extension
To remove the CLI extension, use the following command:
az extension remove -n azure-cli-ml
az extension remove -n azure-cli-ml
Resource management
The following commands demonstrate how to use the CLI to manage resources used by Azure Machine Learning.
If you don't already have one, create a resource group:az group create -n myresourcegroup -l westus2
If you don't already have one, create a resource group:
az group create -n myresourcegroup -l westus2
az group create -n myresourcegroup -l westus2
Create an Azure Machine Learning workspace:az ml workspace create -w myworkspace -g myresourcegroupFor more information, seeaz ml workspace create.
Create an Azure Machine Learning workspace:
az ml workspace create -w myworkspace -g myresourcegroup
az ml workspace create -w myworkspace -g myresourcegroup
For more information, seeaz ml workspace create.
Attach a workspace configuration to a folder to enable CLI contextual awareness.az ml folder attach -w myworkspace -g myresourcegroupThis command creates a.azuremlsubdirectory that contains example runconfig and conda environment files. It also contains aconfig.jsonfile that is used to communicate with your Azure Machine Learning workspace.For more information, seeaz ml folder attach.
Attach a workspace configuration to a folder to enable CLI contextual awareness.
az ml folder attach -w myworkspace -g myresourcegroup
az ml folder attach -w myworkspace -g myresourcegroup
This command creates a.azuremlsubdirectory that contains example runconfig and conda environment files. It also contains aconfig.jsonfile that is used to communicate with your Azure Machine Learning workspace.
.azureml
config.json
For more information, seeaz ml folder attach.
Attach an Azure blob container as a Datastore.az ml datastore attach-blob  -n datastorename -a accountname -c containernameFor more information, seeaz ml datastore attach-blob.
Attach an Azure blob container as a Datastore.
az ml datastore attach-blob  -n datastorename -a accountname -c containername
az ml datastore attach-blob  -n datastorename -a accountname -c containername
For more information, seeaz ml datastore attach-blob.
Upload files to a Datastore.az ml datastore upload  -n datastorename -p sourcepathFor more information, seeaz ml datastore upload.
Upload files to a Datastore.
az ml datastore upload  -n datastorename -p sourcepath
az ml datastore upload  -n datastorename -p sourcepath
For more information, seeaz ml datastore upload.
Attach an AKS cluster as a Compute Target.az ml computetarget attach aks -n myaks -i myaksresourceid -g myresourcegroup -w myworkspaceFor more information, seeaz ml computetarget attach aks
Attach an AKS cluster as a Compute Target.
az ml computetarget attach aks -n myaks -i myaksresourceid -g myresourcegroup -w myworkspace
az ml computetarget attach aks -n myaks -i myaksresourceid -g myresourcegroup -w myworkspace
For more information, seeaz ml computetarget attach aks
Compute clusters
Create a new managed compute cluster.az ml computetarget create amlcompute -n cpu --min-nodes 1 --max-nodes 1 -s STANDARD_D3_V2
Create a new managed compute cluster.
az ml computetarget create amlcompute -n cpu --min-nodes 1 --max-nodes 1 -s STANDARD_D3_V2
az ml computetarget create amlcompute -n cpu --min-nodes 1 --max-nodes 1 -s STANDARD_D3_V2
Create a new managed compute cluster with managed identityUser-assigned managed identityaz ml computetarget create amlcompute --name cpu-cluster --vm-size Standard_NC6 --max-nodes 5 --assign-identity '/subscriptions/<subcription_id>/resourcegroups/<resource_group>/providers/Microsoft.ManagedIdentity/userAssignedIdentities/<user_assigned_identity>'System-assigned managed identityaz ml computetarget create amlcompute --name cpu-cluster --vm-size Standard_NC6 --max-nodes 5 --assign-identity '[system]'
Create a new managed compute cluster with managed identity
User-assigned managed identityaz ml computetarget create amlcompute --name cpu-cluster --vm-size Standard_NC6 --max-nodes 5 --assign-identity '/subscriptions/<subcription_id>/resourcegroups/<resource_group>/providers/Microsoft.ManagedIdentity/userAssignedIdentities/<user_assigned_identity>'
User-assigned managed identity
az ml computetarget create amlcompute --name cpu-cluster --vm-size Standard_NC6 --max-nodes 5 --assign-identity '/subscriptions/<subcription_id>/resourcegroups/<resource_group>/providers/Microsoft.ManagedIdentity/userAssignedIdentities/<user_assigned_identity>'
az ml computetarget create amlcompute --name cpu-cluster --vm-size Standard_NC6 --max-nodes 5 --assign-identity '/subscriptions/<subcription_id>/resourcegroups/<resource_group>/providers/Microsoft.ManagedIdentity/userAssignedIdentities/<user_assigned_identity>'
System-assigned managed identityaz ml computetarget create amlcompute --name cpu-cluster --vm-size Standard_NC6 --max-nodes 5 --assign-identity '[system]'
System-assigned managed identity
az ml computetarget create amlcompute --name cpu-cluster --vm-size Standard_NC6 --max-nodes 5 --assign-identity '[system]'
az ml computetarget create amlcompute --name cpu-cluster --vm-size Standard_NC6 --max-nodes 5 --assign-identity '[system]'
Add a managed identity to an existing cluster:User-assigned managed identityaz ml computetarget amlcompute identity assign --name cpu-cluster '/subscriptions/<subcription_id>/resourcegroups/<resource_group>/providers/Microsoft.ManagedIdentity/userAssignedIdentities/<user_assigned_identity>'System-assigned managed identityaz ml computetarget amlcompute identity assign --name cpu-cluster '[system]'
Add a managed identity to an existing cluster:
User-assigned managed identityaz ml computetarget amlcompute identity assign --name cpu-cluster '/subscriptions/<subcription_id>/resourcegroups/<resource_group>/providers/Microsoft.ManagedIdentity/userAssignedIdentities/<user_assigned_identity>'
User-assigned managed identity
az ml computetarget amlcompute identity assign --name cpu-cluster '/subscriptions/<subcription_id>/resourcegroups/<resource_group>/providers/Microsoft.ManagedIdentity/userAssignedIdentities/<user_assigned_identity>'
az ml computetarget amlcompute identity assign --name cpu-cluster '/subscriptions/<subcription_id>/resourcegroups/<resource_group>/providers/Microsoft.ManagedIdentity/userAssignedIdentities/<user_assigned_identity>'
System-assigned managed identityaz ml computetarget amlcompute identity assign --name cpu-cluster '[system]'
System-assigned managed identity
az ml computetarget amlcompute identity assign --name cpu-cluster '[system]'
az ml computetarget amlcompute identity assign --name cpu-cluster '[system]'
For more information, seeaz ml computetarget create amlcompute.
Note
Azure Machine Learning compute clusters support onlyone system-assigned identityormultiple user-assigned identities, not both concurrently.

Compute instance
Manage compute instances.  In all the examples below, the name of the compute instance iscpu
Create a new computeinstance.az ml computetarget create computeinstance -n cpu -s "STANDARD_D3_V2" -vFor more information, seeaz ml computetarget create computeinstance.
Create a new computeinstance.
az ml computetarget create computeinstance -n cpu -s "STANDARD_D3_V2" -v
az ml computetarget create computeinstance -n cpu -s "STANDARD_D3_V2" -v
For more information, seeaz ml computetarget create computeinstance.
Stop a computeinstance.az ml computetarget computeinstance stop -n cpu -vFor more information, seeaz ml computetarget computeinstance stop.
Stop a computeinstance.
az ml computetarget computeinstance stop -n cpu -v
az ml computetarget computeinstance stop -n cpu -v
For more information, seeaz ml computetarget computeinstance stop.
Start a computeinstance.az ml computetarget computeinstance start -n cpu -vFor more information, seeaz ml computetarget computeinstance start.
Start a computeinstance.
az ml computetarget computeinstance start -n cpu -v
az ml computetarget computeinstance start -n cpu -v
For more information, seeaz ml computetarget computeinstance start.
Restart a computeinstance.az ml computetarget computeinstance restart -n cpu -vFor more information, seeaz ml computetarget computeinstance restart.
Restart a computeinstance.
az ml computetarget computeinstance restart -n cpu -v
az ml computetarget computeinstance restart -n cpu -v
For more information, seeaz ml computetarget computeinstance restart.
Delete a computeinstance.az ml computetarget delete -n cpu -vFor more information, seeaz ml computetarget delete computeinstance.
Delete a computeinstance.
az ml computetarget delete -n cpu -v
az ml computetarget delete -n cpu -v
For more information, seeaz ml computetarget delete computeinstance.
Run experiments
Start a run of your experiment. When using this command, specify the name of the runconfig file (the text before *.runconfig if you're looking at your file system) against the -c parameter.az ml run submit-script -c sklearn -e testexperiment train.pyTipTheaz ml folder attachcommand creates a.azuremlsubdirectory, which contains two example runconfig files.If you have a Python script that creates a run configuration object programmatically, you can useRunConfig.save()to save it as a runconfig file.The full runconfig schema can be found in thisJSON file. The schema is self-documenting through thedescriptionkey of each object. Additionally, there are enums for possible values, and a template snippet at the end.For more information, seeaz ml run submit-script.
Start a run of your experiment. When using this command, specify the name of the runconfig file (the text before *.runconfig if you're looking at your file system) against the -c parameter.
az ml run submit-script -c sklearn -e testexperiment train.py
az ml run submit-script -c sklearn -e testexperiment train.py
Tip
Theaz ml folder attachcommand creates a.azuremlsubdirectory, which contains two example runconfig files.
az ml folder attach
.azureml
If you have a Python script that creates a run configuration object programmatically, you can useRunConfig.save()to save it as a runconfig file.
The full runconfig schema can be found in thisJSON file. The schema is self-documenting through thedescriptionkey of each object. Additionally, there are enums for possible values, and a template snippet at the end.
description
For more information, seeaz ml run submit-script.
View a list of experiments:az ml experiment listFor more information, seeaz ml experiment list.
View a list of experiments:
az ml experiment list
az ml experiment list
For more information, seeaz ml experiment list.
HyperDrive run
You can use HyperDrive with Azure CLI to perform parameter tuning runs. First, create a HyperDrive configuration file in the following format. SeeTune hyperparameters for your modelarticle for details on hyperparameter tuning parameters.
# hdconfig.yml
sampling: 
    type: random # Supported options: Random, Grid, Bayesian
    parameter_space: # specify a name|expression|values tuple for each parameter.
    - name: --penalty # The name of a script parameter to generate values for.
      expression: choice # supported options: choice, randint, uniform, quniform, loguniform, qloguniform, normal, qnormal, lognormal, qlognormal
      values: [0.5, 1, 1.5] # The list of values, the number of values is dependent on the expression specified.
policy: 
    type: BanditPolicy # Supported options: BanditPolicy, MedianStoppingPolicy, TruncationSelectionPolicy, NoTerminationPolicy
    evaluation_interval: 1 # Policy properties are policy specific. See the above link for policy specific parameter details.
    slack_factor: 0.2
primary_metric_name: Accuracy # The metric used when evaluating the policy
primary_metric_goal: Maximize # Maximize|Minimize
max_total_runs: 8 # The maximum number of runs to generate
max_concurrent_runs: 2 # The number of runs that can run concurrently.
max_duration_minutes: 100 # The maximum length of time to run the experiment before cancelling.
# hdconfig.yml
sampling: 
    type: random # Supported options: Random, Grid, Bayesian
    parameter_space: # specify a name|expression|values tuple for each parameter.
    - name: --penalty # The name of a script parameter to generate values for.
      expression: choice # supported options: choice, randint, uniform, quniform, loguniform, qloguniform, normal, qnormal, lognormal, qlognormal
      values: [0.5, 1, 1.5] # The list of values, the number of values is dependent on the expression specified.
policy: 
    type: BanditPolicy # Supported options: BanditPolicy, MedianStoppingPolicy, TruncationSelectionPolicy, NoTerminationPolicy
    evaluation_interval: 1 # Policy properties are policy specific. See the above link for policy specific parameter details.
    slack_factor: 0.2
primary_metric_name: Accuracy # The metric used when evaluating the policy
primary_metric_goal: Maximize # Maximize|Minimize
max_total_runs: 8 # The maximum number of runs to generate
max_concurrent_runs: 2 # The number of runs that can run concurrently.
max_duration_minutes: 100 # The maximum length of time to run the experiment before cancelling.
Add this file alongside the run configuration files. Then submit a HyperDrive run using:
az ml run submit-hyperdrive -e <experiment> -c <runconfig> --hyperdrive-configuration-name <hdconfig> my_train.py
az ml run submit-hyperdrive -e <experiment> -c <runconfig> --hyperdrive-configuration-name <hdconfig> my_train.py
Note theargumentssection in runconfig andparameter spacein HyperDrive config. They contain the command-line arguments to be passed to training script. The value in runconfig stays the same for each iteration, while the range in HyperDrive config is iterated over. Don't specify the same argument in both files.
Dataset management
The following commands demonstrate how to work with datasets in Azure Machine Learning:
Register a dataset:az ml dataset register -f mydataset.jsonFor information on the format of the JSON file used to define the dataset, useaz ml dataset register --show-template.For more information, seeaz ml dataset register.
Register a dataset:
az ml dataset register -f mydataset.json
az ml dataset register -f mydataset.json
For information on the format of the JSON file used to define the dataset, useaz ml dataset register --show-template.
az ml dataset register --show-template
For more information, seeaz ml dataset register.
List all datasets in a workspace:az ml dataset listFor more information, seeaz ml dataset list.
List all datasets in a workspace:
az ml dataset list
az ml dataset list
For more information, seeaz ml dataset list.
Get details of a dataset:az ml dataset show -n dataset-nameFor more information, seeaz ml dataset show.
Get details of a dataset:
az ml dataset show -n dataset-name
az ml dataset show -n dataset-name
For more information, seeaz ml dataset show.
Unregister a dataset:az ml dataset unregister -n dataset-nameFor more information, seeaz ml dataset unregister.
Unregister a dataset:
az ml dataset unregister -n dataset-name
az ml dataset unregister -n dataset-name
For more information, seeaz ml dataset unregister.
Environment management
The following commands demonstrate how to create, register, and list Azure Machine Learningenvironmentsfor your workspace:
Create scaffolding files for an environment:az ml environment scaffold -n myenv -d myenvdirectoryFor more information, seeaz ml environment scaffold.
Create scaffolding files for an environment:
az ml environment scaffold -n myenv -d myenvdirectory
az ml environment scaffold -n myenv -d myenvdirectory
For more information, seeaz ml environment scaffold.
Register an environment:az ml environment register -d myenvdirectoryFor more information, seeaz ml environment register.
Register an environment:
az ml environment register -d myenvdirectory
az ml environment register -d myenvdirectory
For more information, seeaz ml environment register.
List registered environments:az ml environment listFor more information, seeaz ml environment list.
List registered environments:
az ml environment list
az ml environment list
For more information, seeaz ml environment list.
Download a registered environment:az ml environment download -n myenv -d downloaddirectoryFor more information, seeaz ml environment download.
Download a registered environment:
az ml environment download -n myenv -d downloaddirectory
az ml environment download -n myenv -d downloaddirectory
For more information, seeaz ml environment download.
Environment configuration schema
If you used theaz ml environment scaffoldcommand, it generates a templateazureml_environment.jsonfile that can be modified and used to create custom environment configurations with the CLI. The top level object loosely maps to theEnvironmentclass in the Python SDK.
az ml environment scaffold
azureml_environment.json
Environment
{
    "name": "testenv",
    "version": null,
    "environmentVariables": {
        "EXAMPLE_ENV_VAR": "EXAMPLE_VALUE"
    },
    "python": {
        "userManagedDependencies": false,
        "interpreterPath": "python",
        "condaDependenciesFile": null,
        "baseCondaEnvironment": null
    },
    "docker": {
        "enabled": false,
        "baseImage": "mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210615.v1",
        "baseDockerfile": null,
        "sharedVolumes": true,
        "shmSize": "2g",
        "arguments": [],
        "baseImageRegistry": {
            "address": null,
            "username": null,
            "password": null
        }
    },
    "spark": {
        "repositories": [],
        "packages": [],
        "precachePackages": true
    },
    "databricks": {
        "mavenLibraries": [],
        "pypiLibraries": [],
        "rcranLibraries": [],
        "jarLibraries": [],
        "eggLibraries": []
    },
    "inferencingStackVersion": null
}
{
    "name": "testenv",
    "version": null,
    "environmentVariables": {
        "EXAMPLE_ENV_VAR": "EXAMPLE_VALUE"
    },
    "python": {
        "userManagedDependencies": false,
        "interpreterPath": "python",
        "condaDependenciesFile": null,
        "baseCondaEnvironment": null
    },
    "docker": {
        "enabled": false,
        "baseImage": "mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210615.v1",
        "baseDockerfile": null,
        "sharedVolumes": true,
        "shmSize": "2g",
        "arguments": [],
        "baseImageRegistry": {
            "address": null,
            "username": null,
            "password": null
        }
    },
    "spark": {
        "repositories": [],
        "packages": [],
        "precachePackages": true
    },
    "databricks": {
        "mavenLibraries": [],
        "pypiLibraries": [],
        "rcranLibraries": [],
        "jarLibraries": [],
        "eggLibraries": []
    },
    "inferencingStackVersion": null
}
The following table details each top-level field in the JSON file, its type, and a description. If an object type is linked to a class from the Python SDK, there's a loose 1:1 match between each JSON field and the public variable name in the Python class. In some cases, the field may map to a constructor argument rather than a class variable. For example, theenvironmentVariablesfield maps to theenvironment_variablesvariable in theEnvironmentclass.
environmentVariables
environment_variables
Environment
name
string
version
string
environmentVariables
{string: string}
python
PythonSection
docker
DockerSection
spark
SparkSection
databricks
DatabricksSection
inferencingStackVersion
string
null
ML pipeline management
The following commands demonstrate how to work with machine learning pipelines:
Create a machine learning pipeline:az ml pipeline create -n mypipeline -y mypipeline.ymlFor more information, seeaz ml pipeline create.For more information on the pipeline YAML file, seeDefine machine learning pipelines in YAML.
Create a machine learning pipeline:
az ml pipeline create -n mypipeline -y mypipeline.yml
az ml pipeline create -n mypipeline -y mypipeline.yml
For more information, seeaz ml pipeline create.
For more information on the pipeline YAML file, seeDefine machine learning pipelines in YAML.
Run a pipeline:az ml run submit-pipeline -n myexperiment -y mypipeline.ymlFor more information, seeaz ml run submit-pipeline.For more information on the pipeline YAML file, seeDefine machine learning pipelines in YAML.
Run a pipeline:
az ml run submit-pipeline -n myexperiment -y mypipeline.yml
az ml run submit-pipeline -n myexperiment -y mypipeline.yml
For more information, seeaz ml run submit-pipeline.
For more information on the pipeline YAML file, seeDefine machine learning pipelines in YAML.
Schedule a pipeline:az ml pipeline create-schedule -n myschedule -e myexperiment -i mypipelineid -y myschedule.ymlFor more information, seeaz ml pipeline create-schedule.
Schedule a pipeline:
az ml pipeline create-schedule -n myschedule -e myexperiment -i mypipelineid -y myschedule.yml
az ml pipeline create-schedule -n myschedule -e myexperiment -i mypipelineid -y myschedule.yml
For more information, seeaz ml pipeline create-schedule.
Model registration, profiling, deployment
The following commands demonstrate how to register a trained model, and then deploy it as a production service:
Register a model with Azure Machine Learning:az ml model register -n mymodel -p sklearn_regression_model.pklFor more information, seeaz ml model register.
Register a model with Azure Machine Learning:
az ml model register -n mymodel -p sklearn_regression_model.pkl
az ml model register -n mymodel -p sklearn_regression_model.pkl
For more information, seeaz ml model register.
OPTIONALProfile your model to get optimal CPU and memory values for deployment.az ml model profile -n myprofile -m mymodel:1 --ic inferenceconfig.json -d "{\"data\": [[1,2,3,4,5,6,7,8,9,10],[10,9,8,7,6,5,4,3,2,1]]}" -t myprofileresult.jsonFor more information, seeaz ml model profile.
OPTIONALProfile your model to get optimal CPU and memory values for deployment.
az ml model profile -n myprofile -m mymodel:1 --ic inferenceconfig.json -d "{\"data\": [[1,2,3,4,5,6,7,8,9,10],[10,9,8,7,6,5,4,3,2,1]]}" -t myprofileresult.json
az ml model profile -n myprofile -m mymodel:1 --ic inferenceconfig.json -d "{\"data\": [[1,2,3,4,5,6,7,8,9,10],[10,9,8,7,6,5,4,3,2,1]]}" -t myprofileresult.json
For more information, seeaz ml model profile.
Deploy your model to AKSaz ml model deploy -n myservice -m mymodel:1 --ic inferenceconfig.json --dc deploymentconfig.json --ct akscomputetargetFor more information on the inference configuration file schema, seeInference configuration schema.For more information on the deployment configuration file schema, seeDeployment configuration schema.For more information, seeaz ml model deploy.
Deploy your model to AKS
az ml model deploy -n myservice -m mymodel:1 --ic inferenceconfig.json --dc deploymentconfig.json --ct akscomputetarget
az ml model deploy -n myservice -m mymodel:1 --ic inferenceconfig.json --dc deploymentconfig.json --ct akscomputetarget
For more information on the inference configuration file schema, seeInference configuration schema.
For more information on the deployment configuration file schema, seeDeployment configuration schema.
For more information, seeaz ml model deploy.

Inference configuration schema
The entries in theinferenceconfig.jsondocument map to the parameters for theInferenceConfigclass. The following table describes the mapping between entities in the JSON document and the parameters for the method:
inferenceconfig.json
entryScript
entry_script
sourceDirectory
source_directory
environment
environment
You can include full specifications of an Azure Machine Learningenvironmentin the inference configuration file. If this environment doesn't exist in your workspace, Azure Machine Learning will create it. Otherwise, Azure Machine Learning will update the environment if necessary. The following JSON is an example:
{
    "entryScript": "score.py",
    "environment": {
        "docker": {
            "arguments": [],
            "baseDockerfile": null,
            "baseImage": "mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu18.04",
            "enabled": false,
            "sharedVolumes": true,
            "shmSize": null
        },
        "environmentVariables": {
            "EXAMPLE_ENV_VAR": "EXAMPLE_VALUE"
        },
        "name": "my-deploy-env",
        "python": {
            "baseCondaEnvironment": null,
            "condaDependencies": {
                "channels": [
                    "conda-forge"
                ],
                "dependencies": [
                    "python=3.7",
                    {
                        "pip": [
                            "azureml-defaults",
                            "azureml-telemetry",
                            "scikit-learn==0.22.1",
                            "inference-schema[numpy-support]"
                        ]
                    }
                ],
                "name": "project_environment"
            },
            "condaDependenciesFile": null,
            "interpreterPath": "python",
            "userManagedDependencies": false
        },
        "version": "1"
    }
}
{
    "entryScript": "score.py",
    "environment": {
        "docker": {
            "arguments": [],
            "baseDockerfile": null,
            "baseImage": "mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu18.04",
            "enabled": false,
            "sharedVolumes": true,
            "shmSize": null
        },
        "environmentVariables": {
            "EXAMPLE_ENV_VAR": "EXAMPLE_VALUE"
        },
        "name": "my-deploy-env",
        "python": {
            "baseCondaEnvironment": null,
            "condaDependencies": {
                "channels": [
                    "conda-forge"
                ],
                "dependencies": [
                    "python=3.7",
                    {
                        "pip": [
                            "azureml-defaults",
                            "azureml-telemetry",
                            "scikit-learn==0.22.1",
                            "inference-schema[numpy-support]"
                        ]
                    }
                ],
                "name": "project_environment"
            },
            "condaDependenciesFile": null,
            "interpreterPath": "python",
            "userManagedDependencies": false
        },
        "version": "1"
    }
}
You can also use an existing Azure Machine Learningenvironmentin separated CLI parameters and remove the "environment" key from the inference configuration file. Use -e for the environment name, and --ev for the environment version. If you don't specify --ev, the latest version will be used. Here is an example of an inference configuration file:
{
    "entryScript": "score.py",
    "sourceDirectory": null
}
{
    "entryScript": "score.py",
    "sourceDirectory": null
}
The following command demonstrates how to deploy a model using the previous inference configuration file (named myInferenceConfig.json).
It also uses the latest version of an existing Azure Machine Learningenvironment(named AzureML-Minimal).
az ml model deploy -m mymodel:1 --ic myInferenceConfig.json -e AzureML-Minimal --dc deploymentconfig.json
az ml model deploy -m mymodel:1 --ic myInferenceConfig.json -e AzureML-Minimal --dc deploymentconfig.json

Deployment configuration schema
Local deployment configuration schema
The entries in thedeploymentconfig.jsondocument map to the parameters forLocalWebservice.deploy_configuration. The following table describes the mapping between the entities in the JSON document and the parameters for the method:
deploymentconfig.json
computeType
local
port
port
This JSON is an example deployment configuration for use with the CLI:
{
    "computeType": "local",
    "port": 32267
}
{
    "computeType": "local",
    "port": 32267
}
Save this JSON as a file calleddeploymentconfig.json.
deploymentconfig.json
Azure Container Instance deployment configuration schema
The entries in thedeploymentconfig.jsondocument map to the parameters forAciWebservice.deploy_configuration. The following table describes the mapping between the entities in the JSON document and the parameters for the method:
deploymentconfig.json
computeType
ACI
containerResourceRequirements
cpu
cpu_cores
0.1
memoryInGB
memory_gb
0.5
location
location
authEnabled
auth_enabled
sslEnabled
ssl_enabled
appInsightsEnabled
enable_app_insights
sslCertificate
ssl_cert_pem_file
sslKey
ssl_key_pem_file
cname
ssl_cname
dnsNameLabel
dns_name_label
The following JSON is an example deployment configuration for use with the CLI:
{
    "computeType": "aci",
    "containerResourceRequirements":
    {
        "cpu": 0.5,
        "memoryInGB": 1.0
    },
    "authEnabled": true,
    "sslEnabled": false,
    "appInsightsEnabled": false
}
{
    "computeType": "aci",
    "containerResourceRequirements":
    {
        "cpu": 0.5,
        "memoryInGB": 1.0
    },
    "authEnabled": true,
    "sslEnabled": false,
    "appInsightsEnabled": false
}
Azure Kubernetes Service deployment configuration schema
The entries in thedeploymentconfig.jsondocument map to the parameters forAksWebservice.deploy_configuration. The following table describes the mapping between the entities in the JSON document and the parameters for the method:
deploymentconfig.json
computeType
aks
autoScaler
autoscaleEnabled
autoscale_enabled
numReplicas
0
True
False
minReplicas
autoscale_min_replicas
1
maxReplicas
autoscale_max_replicas
10
refreshPeriodInSeconds
autoscale_refresh_seconds
1
targetUtilization
autoscale_target_utilization
70
dataCollection
storageEnabled
collect_model_data
False
authEnabled
auth_enabled
tokenAuthEnabled
authEnabled
True
True
tokenAuthEnabled
token_auth_enabled
tokenAuthEnabled
authEnabled
True
False
containerResourceRequirements
cpu
cpu_cores
0.1
memoryInGB
memory_gb
0.5
appInsightsEnabled
enable_app_insights
False
scoringTimeoutMs
scoring_timeout_ms
60000
maxConcurrentRequestsPerContainer
replica_max_concurrent_requests
1
maxQueueWaitMs
max_request_wait_time
500
numReplicas
num_replicas
keys
primaryKey
primary_key
secondaryKey
secondary_key
gpuCores
gpu_cores
livenessProbeRequirements
periodSeconds
period_seconds
initialDelaySeconds
initial_delay_seconds
timeoutSeconds
timeout_seconds
successThreshold
success_threshold
failureThreshold
failure_threshold
namespace
namespace
The following JSON is an example deployment configuration for use with the CLI:
{
    "computeType": "aks",
    "autoScaler":
    {
        "autoscaleEnabled": true,
        "minReplicas": 1,
        "maxReplicas": 3,
        "refreshPeriodInSeconds": 1,
        "targetUtilization": 70
    },
    "dataCollection":
    {
        "storageEnabled": true
    },
    "authEnabled": true,
    "containerResourceRequirements":
    {
        "cpu": 0.5,
        "memoryInGB": 1.0
    }
}
{
    "computeType": "aks",
    "autoScaler":
    {
        "autoscaleEnabled": true,
        "minReplicas": 1,
        "maxReplicas": 3,
        "refreshPeriodInSeconds": 1,
        "targetUtilization": 70
    },
    "dataCollection":
    {
        "storageEnabled": true
    },
    "authEnabled": true,
    "containerResourceRequirements":
    {
        "cpu": 0.5,
        "memoryInGB": 1.0
    }
}
Next steps
Command reference for the Machine Learning CLI extension.
Command reference for the Machine Learning CLI extension.
Train and deploy machine learning models using Azure Pipelines
Train and deploy machine learning models using Azure Pipelines
Feedback
Was this page helpful?
Additional resources