Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Enable Hive metastore table access control on a cluster (legacy)
Article
2025-02-14
4 contributors
In this article
This article describes how to enable table access control for the built-in Hive metastore on a cluster.
For information about how to set privileges on Hive metastore securable objects once table access control has been enabled on a cluster, seeHive metastore privileges and securable objects (legacy).
Note
Hive metastore table access control is a legacy data governance model. Databricks recommends that you use Unity Catalog instead for its simplicity and account-centered governance model. You canupgrade the tables managed by the Hive metastore to the Unity Catalog metastore.
Enable table access control for a cluster
Table access control is available in two versions:
SQL-only table access control, which restricts users to SQL commands.
Python and SQL table access control, which allows users to run SQL, Python, and PySpark commands.
Table access control is not supported withMachine Learning Runtime.
Important
Even if table access control is enabled for a cluster, Azure Databricks workspace administrators have access to file-level data.
SQL-only table access control
This version of table access control restricts users to SQL commands only.
To enable SQL-only table access control on a cluster and restrict that cluster to use only SQL commands, set
the following flag in the clusterâsSpark conf:
spark.databricks.acl.sqlOnly true
spark.databricks.acl.sqlOnly true
Note
Access to SQL-only table access control is not affected by theEnable Table Access Controlsetting in the admin settings page. That setting controls only the workspace-wide enablement of Python and SQL table access control.
Python and SQL table access control
This version of table access control lets users run Python commands that use the DataFrame API as well as SQL. When
it is enabled on a cluster, users on that cluster:
Can access Spark only using the Spark SQL API or DataFrame API. In both cases, access to tables and views is restricted by administrators according to the Azure DatabricksPrivileges you can grant on Hive metastore objects.
Must run their commands on cluster nodes as a low-privilege user forbidden from accessing sensitive parts of the filesystem or creating network connections to ports other than 80 and 443.Only built-in Spark functions can create network connections on ports other than 80 and 443.Only workspace admin users or users withANY FILEprivilege can read data from external databases through thePySpark JDBC connector.If you want Python processes to be able to access additional outbound ports, you can set theSpark configspark.databricks.pyspark.iptable.outbound.whitelisted.portsto the ports you want to allow access. The supported format of the configuration value is[port[:port][,port[:port]]...], for example:21,22,9000:9999. The port must be within the valid range, that is,0-65535.
Only built-in Spark functions can create network connections on ports other than 80 and 443.
Only workspace admin users or users withANY FILEprivilege can read data from external databases through thePySpark JDBC connector.
If you want Python processes to be able to access additional outbound ports, you can set theSpark configspark.databricks.pyspark.iptable.outbound.whitelisted.portsto the ports you want to allow access. The supported format of the configuration value is[port[:port][,port[:port]]...], for example:21,22,9000:9999. The port must be within the valid range, that is,0-65535.
spark.databricks.pyspark.iptable.outbound.whitelisted.ports
[port[:port][,port[:port]]...]
21,22,9000:9999
0-65535
Attempts to get around these restrictions will fail with an exception. These restrictions are in place so that users can never access unprivileged data through the cluster.
Enable table access control for your workspace
Before users can configure Python and SQL table access control, an Azure Databricks workspace admin must enable table access control for the Azure Databricks workspace and deny users access to clusters that are not enabled for table access control.
Go to thesettings page.
Click theSecuritytab.
Turn on theTable Access Controloption.
Enforce table access control
To ensure that your users access only the data that you want them to, you must restrict your users to clusters with table access control enabled. In particular, you should ensure that:
Users do not have permission to create clusters. If they create a cluster without table access control, they can access any data from that cluster.
Users do not have CAN ATTACH TO permission for any cluster that is not enabled for table access control.
SeeCompute permissionsfor more information.
Create a cluster enabled for table access control
Table access control is enabled by default in clusters withStandard access mode.
To create the cluster using the REST API, seeCreate new cluster.
Set privileges on a data object
SeeHive metastore privileges and securable objects (legacy).
Feedback
Was this page helpful?
Additional resources