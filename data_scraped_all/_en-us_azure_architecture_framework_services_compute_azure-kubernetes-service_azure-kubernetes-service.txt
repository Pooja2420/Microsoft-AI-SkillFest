Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Architecture best practices for Azure Kubernetes Service (AKS)
Article
2025-02-06
13 contributors
In this article
Azure Kubernetes Service (AKS) is a managed Kubernetes service that you can use to deploy and manage containerized applications. Similar to other managed services, AKS offloads much of the operational overhead to Azure while providing high availability, scalability, and portability features to the workload.
This article assumes that, as an architect, you reviewed thecompute decision treeand chose AKS as the compute for your workload. The guidance in this article provides architectural recommendations that are mapped to the principles of theAzure Well-Architected Framework pillars.
Important
How to use this guide
Each section has adesign checklistthat presents architectural areas of concern along with design strategies localized to the technology scope.
Also included are recommendations for the technology capabilities that can help materialize those strategies. The recommendations don't represent an exhaustive list of all configurations that are available for AKS and its dependencies. Instead, they list the key recommendations mapped to the design perspectives. Use the recommendations to build your proof-of-concept or to optimize your existing environments.
Foundational architecture that demonstrates the key recommendations:AKS baseline architecture.
Technology scope
This review focuses on the interrelated decisions for the following Azure resources:
AKS
When you discuss the Well-Architected Framework pillars' best practices for AKS, it's important to distinguish betweenclusterandworkload. Cluster best practices are a shared responsibility between the cluster admin and their resource provider, while workload best practices are the domain of a developer. This article has considerations and recommendations for each of these roles.
Note
The following pillars include adesign checklistand alist of recommendationsthat indicate whether each choice is applicable toclusterarchitecture,workloadarchitecture, or both.
Reliability
The purpose of the Reliability pillar is to provide continued functionality bybuilding enough resilience and the ability to recover fast from failures.
Reliability design principlesprovide a high-level design strategy applied for individual components, system flows, and the system as a whole.
Design checklist
Start your design strategy based on thedesign review checklist for Reliability. Determine its relevance to your business requirements while keeping in mind the features of AKS and its dependencies. Extend the strategy to include more approaches as needed.
(Cluster)Build redundancy to improve resiliency.Use availability zones for your AKS clusters as part of your resiliency strategy to increase availability when you deploy to a single region. Many Azure regions provide availability zones. The zones are close enough to have low-latency connections among them, but far enough apart to reduce the likelihood that local outages will affect more than one zone.For critical workloads, deploy multiple clusters across different Azure regions. By geographically distributing AKS clusters, you can achieve higher resiliency and minimize the effects of regional failures. A multiregion strategy helps maximize availability and provide business continuity.
Internet-facing workloads should useAzure Front DoororAzure Traffic Managerto route traffic globally across AKS clusters. For more information, seeMultiregion strategy.Plan the IP address space to ensure that your cluster can reliably scale and handle failover traffic in multiple-cluster topologies.
(Cluster)Build redundancy to improve resiliency.Use availability zones for your AKS clusters as part of your resiliency strategy to increase availability when you deploy to a single region. Many Azure regions provide availability zones. The zones are close enough to have low-latency connections among them, but far enough apart to reduce the likelihood that local outages will affect more than one zone.
For critical workloads, deploy multiple clusters across different Azure regions. By geographically distributing AKS clusters, you can achieve higher resiliency and minimize the effects of regional failures. A multiregion strategy helps maximize availability and provide business continuity.
Internet-facing workloads should useAzure Front DoororAzure Traffic Managerto route traffic globally across AKS clusters. For more information, seeMultiregion strategy.
Plan the IP address space to ensure that your cluster can reliably scale and handle failover traffic in multiple-cluster topologies.
(Cluster and workload)Monitor reliability and overall health indicators of the cluster and workloads.Collect logs and metrics to monitor workload health, identify performance and reliability trends, and troubleshoot problems.
ReviewBest practices for monitoring Kubernetes with Azure Monitorand the Well-ArchitectedHealth modeling for workloadsguide for help designing the reliability and health monitoring solution for your AKS solution.Ensure that workloads are built to support horizontal scaling and report application readiness and health.
(Cluster and workload)Monitor reliability and overall health indicators of the cluster and workloads.Collect logs and metrics to monitor workload health, identify performance and reliability trends, and troubleshoot problems.
ReviewBest practices for monitoring Kubernetes with Azure Monitorand the Well-ArchitectedHealth modeling for workloadsguide for help designing the reliability and health monitoring solution for your AKS solution.
Ensure that workloads are built to support horizontal scaling and report application readiness and health.
(Cluster and workload)Host application pods in user node pools.By isolating system pods from application workloads, you help ensure that AKS essential services are unaffected by the resource demands or potential problems caused by a workload that runs user node pools.Ensure that your workload runs on user node pools and choose the right size SKU. At a minimum, include two nodes for user node pools and three nodes for the system node pool.
(Cluster and workload)Host application pods in user node pools.By isolating system pods from application workloads, you help ensure that AKS essential services are unaffected by the resource demands or potential problems caused by a workload that runs user node pools.
Ensure that your workload runs on user node pools and choose the right size SKU. At a minimum, include two nodes for user node pools and three nodes for the system node pool.
(Cluster and workload)Factor the AKS uptime service-level agreement (SLA) into your availability and recovery targets.To define the reliability and recovery targets for your cluster and workload, follow the guidance inRecommendations for defining reliability targets. Then formulate a design that meets those targets.
(Cluster and workload)Factor the AKS uptime service-level agreement (SLA) into your availability and recovery targets.To define the reliability and recovery targets for your cluster and workload, follow the guidance inRecommendations for defining reliability targets. Then formulate a design that meets those targets.
(Cluster and workload) Protect the AKS cluster service using Azure Backup by storing recovery points in a Backup vault and perform restore during any disaster scenario. To back up and restore the containerized applications and data running in AKS clusters, follow the guidance in the AKS backup overview for configuring protection.
(Cluster and workload) Protect the AKS cluster service using Azure Backup by storing recovery points in a Backup vault and perform restore during any disaster scenario. To back up and restore the containerized applications and data running in AKS clusters, follow the guidance in the AKS backup overview for configuring protection.
Recommendations
Security
The purpose of the Security pillar is to provideconfidentiality, integrity, and availabilityguarantees to the workload.
TheSecurity design principlesprovide a high-level design strategy for achieving those goals by applying approaches to the technical design of AKS.
Design checklist
Start your design strategy based on thedesign review checklist for Securityand identify vulnerabilities and controls to improve the security posture. Familiarize yourself withAKS security conceptsand evaluate the security hardening recommendations based on theCIS Kubernetes benchmark. Extend the strategy to include more approaches as needed.
(Cluster)Integrate with  Microsoft Entra ID foridentity and access mangement.Centralize identity management for your cluster by using Microsoft Entra ID. Any change in user account or group status is automatically updated in access to the AKS cluster.Establish identity as the primary security perimeter. The developers and application owners of your Kubernetes cluster need access to different resources.Use Kubernetes role-based access control (RBAC) with Microsoft Entra ID forleast privilege access. Protect configuration and secrets by minimizing the allocation of administrator privileges.
(Cluster)Integrate with  Microsoft Entra ID foridentity and access mangement.Centralize identity management for your cluster by using Microsoft Entra ID. Any change in user account or group status is automatically updated in access to the AKS cluster.Establish identity as the primary security perimeter. The developers and application owners of your Kubernetes cluster need access to different resources.
Use Kubernetes role-based access control (RBAC) with Microsoft Entra ID forleast privilege access. Protect configuration and secrets by minimizing the allocation of administrator privileges.
(Cluster)Integrate with security monitoring and security information and event management tools.Use Microsoft Defender for Containers withMicrosoft Sentinelto detect and quickly respond to threats across your clusters and the workloads that run on them. EnableAKS connector for Microsoft Sentinelto stream your AKS diagnostics logs into Microsoft Sentinel.
(Cluster)Integrate with security monitoring and security information and event management tools.Use Microsoft Defender for Containers withMicrosoft Sentinelto detect and quickly respond to threats across your clusters and the workloads that run on them. EnableAKS connector for Microsoft Sentinelto stream your AKS diagnostics logs into Microsoft Sentinel.
(Cluster and workload)Implement segmentation and network controls.To prevent data exfiltration, ensure that only authorized and safe traffic is allowed, and contain the blast radius of a security breach.Consider using a private AKS cluster to help ensure that cluster-management traffic to your API server remains on your private network. Or use the API server allowlist for public clusters.
(Cluster and workload)Implement segmentation and network controls.To prevent data exfiltration, ensure that only authorized and safe traffic is allowed, and contain the blast radius of a security breach.
Consider using a private AKS cluster to help ensure that cluster-management traffic to your API server remains on your private network. Or use the API server allowlist for public clusters.
(Workload)Use a web application firewall (WAF) to scan incoming traffic for potential attacks.WAF can detect and mitigate threats in real time to help block malicious traffic before it reaches your applications. It provides robust protection against common web-based attacks, such as SQL injection, cross-site scripting, and other Open Web Application Security Project vulnerabilities. Some load balancers, such asAzure Application GatewayorAzure Front Doorhave an integrated WAF.
(Workload)Use a web application firewall (WAF) to scan incoming traffic for potential attacks.WAF can detect and mitigate threats in real time to help block malicious traffic before it reaches your applications. It provides robust protection against common web-based attacks, such as SQL injection, cross-site scripting, and other Open Web Application Security Project vulnerabilities. Some load balancers, such asAzure Application GatewayorAzure Front Doorhave an integrated WAF.
(Workload)Maintain a hardened workload's software supply chain.Ensure that your continuous integration and continuous delivery pipeline is hardened with container-aware scanning.
(Workload)Maintain a hardened workload's software supply chain.Ensure that your continuous integration and continuous delivery pipeline is hardened with container-aware scanning.
(Cluster and workload)Implement extra protection for specialized secure workloads.If your cluster needs to run a sensitive workload, you might need to deploy a private cluster. Here are some examples:Payment Card Industry Data Security Standard (PCI-DSS 3.2.1):AKS regulated cluster for PCI-DSS 3.2.1DoD Impact Level 5 (IL5) support and requirements with AKS:Azure Government IL5 isolation requirements.
(Cluster and workload)Implement extra protection for specialized secure workloads.If your cluster needs to run a sensitive workload, you might need to deploy a private cluster. Here are some examples:
Payment Card Industry Data Security Standard (PCI-DSS 3.2.1):AKS regulated cluster for PCI-DSS 3.2.1
DoD Impact Level 5 (IL5) support and requirements with AKS:Azure Government IL5 isolation requirements.
Recommendations
imagePullSecrets
Cost Optimization
Cost Optimization focuses ondetecting spend patterns, prioritizing investments in critical areas, and optimizing in othersto meet the organization's budget while meeting business requirements.
TheCost Optimization design principlesprovide a high-level design strategy for achieving those goals and making tradeoffs as necessary in the technical design related to AKS and its environment.
Design checklist
Start your design strategy based on thedesign review checklist for Cost Optimizationfor investments. Fine-tune the design so that the workload is aligned with the budget that's allocated for the workload. Your design should use the right Azure capabilities, monitor investments, and find opportunities to optimize over time.
(Cluster)Include thepricing tiers for AKSin your cost model.To estimate costs, use theAzure pricing calculatorand test different configuration and payment plans in the calculator.
(Cluster)Include thepricing tiers for AKSin your cost model.To estimate costs, use theAzure pricing calculatorand test different configuration and payment plans in the calculator.
(Cluster)Get the best rates for your workload.Use the appropriate VM SKU for each node pool because it directly affects the cost to run your workloads. Choosing a high-performance VM without proper utilization can lead to wasteful spending. Selecting a less powerful VM can cause performance problems and increased downtime.If you properly planned for capacity and your workload is predictable and will exist for an extended period of time, sign up forAzure Reservationsor asavings planto reduce your resource costs.ChooseAzure Spot Virtual Machinesto use unutilized Azure capacity with significant discounts. These discounts can reach up to 90% of pay-as-you-go prices. If Azure needs capacity back, the Azure infrastructure evicts the Spot nodes.If you run AKS on-premises or at the edge, you can also useAzure Hybrid Benefitto reduce costs when you run containerized applications in those scenarios.
(Cluster)Get the best rates for your workload.Use the appropriate VM SKU for each node pool because it directly affects the cost to run your workloads. Choosing a high-performance VM without proper utilization can lead to wasteful spending. Selecting a less powerful VM can cause performance problems and increased downtime.
If you properly planned for capacity and your workload is predictable and will exist for an extended period of time, sign up forAzure Reservationsor asavings planto reduce your resource costs.
ChooseAzure Spot Virtual Machinesto use unutilized Azure capacity with significant discounts. These discounts can reach up to 90% of pay-as-you-go prices. If Azure needs capacity back, the Azure infrastructure evicts the Spot nodes.
If you run AKS on-premises or at the edge, you can also useAzure Hybrid Benefitto reduce costs when you run containerized applications in those scenarios.
(Cluster and workload)Optimize workload components costs.Choose the most cost-effective region for your workload. Evaluate the cost, latency, and compliance requirements to ensure that you run your workload cost-effectively and that it doesn't affect your customers or create extra networking charges. The region where you deploy your workload in Azure can significantly affect the cost. Because of many factors, the cost of resources varies for each region in Azure.Maintain small and optimized images to help reduce costs because new nodes need to download those images. User request failures or timeouts when the application is starting up can lead to overprovisioning. Build images in a way that allows the container to start as soon as possible to help avoid failures and timeouts.Review the Cost Optimization recommendations inBest practices for monitoring Kubernetes with Azure Monitorto determine the best monitoring strategy for your workloads. Analyze performance metrics, starting with CPU, memory, storage, and network, to identify cost optimization opportunities by cluster, nodes, and namespace.
(Cluster and workload)Optimize workload components costs.Choose the most cost-effective region for your workload. Evaluate the cost, latency, and compliance requirements to ensure that you run your workload cost-effectively and that it doesn't affect your customers or create extra networking charges. The region where you deploy your workload in Azure can significantly affect the cost. Because of many factors, the cost of resources varies for each region in Azure.
Maintain small and optimized images to help reduce costs because new nodes need to download those images. User request failures or timeouts when the application is starting up can lead to overprovisioning. Build images in a way that allows the container to start as soon as possible to help avoid failures and timeouts.
Review the Cost Optimization recommendations inBest practices for monitoring Kubernetes with Azure Monitorto determine the best monitoring strategy for your workloads. Analyze performance metrics, starting with CPU, memory, storage, and network, to identify cost optimization opportunities by cluster, nodes, and namespace.
(Cluster and workload)Optimize workload scaling costs.Consider alternative vertical and horizontal scaling configurations to reduce scaling costs while still meeting all workload requirements. Use autoscalers to scale in when workloads are less active.
(Cluster and workload)Optimize workload scaling costs.Consider alternative vertical and horizontal scaling configurations to reduce scaling costs while still meeting all workload requirements. Use autoscalers to scale in when workloads are less active.
(Cluster and workload)Collect and analyze cost data.The foundation of enabling cost optimization is the spread of a cost-saving cluster. Develop a cost-efficiency mindset that includes collaboration between finance, operations, and engineering teams to drive alignment on cost-saving goals and bring transparency to cloud costs.
(Cluster and workload)Collect and analyze cost data.The foundation of enabling cost optimization is the spread of a cost-saving cluster. Develop a cost-efficiency mindset that includes collaboration between finance, operations, and engineering teams to drive alignment on cost-saving goals and bring transparency to cloud costs.
Recommendations
Operational Excellence
Operational Excellence primarily focuses on procedures fordevelopment practices, observability, and release management.
TheOperational Excellence design principlesprovide a high-level design strategy for achieving those goals for the operational requirements of the workload.
Design checklist
Start your design strategy based on thedesign review checklist for Operational Excellencefor defining processes for observability, testing, and deployment. SeeAKS best practicesandDay-2 operations guideto learn about key considerations to understand and implement.
(Cluster)Implement an infrastructure as code (IaC) deployment approach.Use a declarative, template-based deployment approach by using Bicep, Terraform, or similar tools. Make sure that all deployments are repeatable, traceable, and stored in a source code repo. For more information, see thequickstartsin the AKS product documentation.
(Cluster)Implement an infrastructure as code (IaC) deployment approach.Use a declarative, template-based deployment approach by using Bicep, Terraform, or similar tools. Make sure that all deployments are repeatable, traceable, and stored in a source code repo. For more information, see thequickstartsin the AKS product documentation.
(Cluster and workload)Automate infrastructure and workload deployments.Use standard software solutions to manage, integrate, and automate the deployment of your cluster and workloads. Integrate deployment pipelines with your source control system and incorporate automated tests.Build an automated process to help ensure that your clusters are bootstrapped with the necessary cluster-wide configurations and deployments. This process is typically performed by using GitOps.Use a repeatable and automated deployment processes for your workload within your software development lifecycle.
(Cluster and workload)Automate infrastructure and workload deployments.Use standard software solutions to manage, integrate, and automate the deployment of your cluster and workloads. Integrate deployment pipelines with your source control system and incorporate automated tests.
Build an automated process to help ensure that your clusters are bootstrapped with the necessary cluster-wide configurations and deployments. This process is typically performed by using GitOps.
Use a repeatable and automated deployment processes for your workload within your software development lifecycle.
(Cluster and workload)Implement a comprehensive monitoring strategy.Collect logs and metrics to monitor the health of the workload, identify trends in performance and reliability, and troubleshoot problems. Review theBest practices for monitoring Kubernetes with Azure Monitorand the Well-ArchitectedRecommendations for designing and creating a monitoring systemto determine the best monitoring strategy for your workloads.Enable diagnostics settings to ensure that control plane or core API server interactions are logged.The workload should be designed to emit telemetry that can be collected, which should also include liveness and readiness statuses.
(Cluster and workload)Implement a comprehensive monitoring strategy.Collect logs and metrics to monitor the health of the workload, identify trends in performance and reliability, and troubleshoot problems. Review theBest practices for monitoring Kubernetes with Azure Monitorand the Well-ArchitectedRecommendations for designing and creating a monitoring systemto determine the best monitoring strategy for your workloads.
Enable diagnostics settings to ensure that control plane or core API server interactions are logged.
The workload should be designed to emit telemetry that can be collected, which should also include liveness and readiness statuses.
(Cluster and workload)Implement testing in production strategies.Testing in production uses real deployments to validate and measure an application's behavior and performance in the production environment. Use chaos engineering practices that target Kubernetes to identify application or platform reliability issues.Azure Chaos Studiocan help simulate faults and trigger disaster recovery situations.
(Cluster and workload)Implement testing in production strategies.Testing in production uses real deployments to validate and measure an application's behavior and performance in the production environment. Use chaos engineering practices that target Kubernetes to identify application or platform reliability issues.
Azure Chaos Studiocan help simulate faults and trigger disaster recovery situations.
(Cluster and workload)Enforce workload governance.Azure Policy helps ensure consistent compliance with organizational standards, automates policy enforcement, and provides centralized visibility and control over your cluster resources.Review theAzure policiessection to learn more about the available built-in policies for AKS.
(Cluster and workload)Enforce workload governance.Azure Policy helps ensure consistent compliance with organizational standards, automates policy enforcement, and provides centralized visibility and control over your cluster resources.
Review theAzure policiessection to learn more about the available built-in policies for AKS.
(Cluster and workload)Usestamp-level, blue-green deploymentsfor mission-critical workloads.A stamp-level, blue-green deployment approach can increase confidence in releasing changes and enables zero-downtime upgrades because compatibilities with downstream dependencies like the Azure platform, resource providers, and IaC modules can be validated.Kubernetes and ingress controllers support many advanced deployment patterns for inclusion in your release engineering process. Consider patterns like blue-green deployments or canary releases.
(Cluster and workload)Usestamp-level, blue-green deploymentsfor mission-critical workloads.A stamp-level, blue-green deployment approach can increase confidence in releasing changes and enables zero-downtime upgrades because compatibilities with downstream dependencies like the Azure platform, resource providers, and IaC modules can be validated.
Kubernetes and ingress controllers support many advanced deployment patterns for inclusion in your release engineering process. Consider patterns like blue-green deployments or canary releases.
(Cluster and workload)Make workloads more sustainable.Making workloads moresustainable and cloud efficientrequires combining efforts aroundcost optimization,reducing carbon emissions, andoptimizing energy consumption. Optimizing the application's cost is the initial step in making workloads more sustainable.SeeSustainable software engineering principles in AKSto learn how to build sustainable and efficient AKS workloads.
(Cluster and workload)Make workloads more sustainable.Making workloads moresustainable and cloud efficientrequires combining efforts aroundcost optimization,reducing carbon emissions, andoptimizing energy consumption. Optimizing the application's cost is the initial step in making workloads more sustainable.
SeeSustainable software engineering principles in AKSto learn how to build sustainable and efficient AKS workloads.
Recommendations
Performance Efficiency
Performance Efficiency is aboutmaintaining user experience even when there's an increase in loadby managing capacity. The strategy includes scaling resources, identifying and optimizing potential bottlenecks, and optimizing for peak performance.
ThePerformance Efficiency design principlesprovide a high-level design strategy for achieving those capacity goals against the expected usage.
Design checklist
Start your design strategy based on thedesign review checklist for Performance Efficiencyfor defining a baseline based on key performance indicators for AKS.
(Cluster and workload)Conduct capacity planning.Perform and iterate on a detailed capacity plan exercise that includes SKU, autoscale settings, IP addressing, and failover considerations.After you formalize your capacity plan, frequently update the plan by continuously observing the resource utilization of the cluster.
(Cluster and workload)Conduct capacity planning.Perform and iterate on a detailed capacity plan exercise that includes SKU, autoscale settings, IP addressing, and failover considerations.
After you formalize your capacity plan, frequently update the plan by continuously observing the resource utilization of the cluster.
(Cluster)Define a scaling strategy.Configure scaling to ensure that resources are adjusted efficiently to meet workload demands without overuse or waste. Use AKS features like cluster autoscaling and HorizontalPodAutoscaler to dynamically meet your workload needs with less strain on operations. Optimize your workload to operate and deploy efficiently in a container.Review theScaling and partitioningguide to understand the various aspects of scaling configuration.
(Cluster)Define a scaling strategy.Configure scaling to ensure that resources are adjusted efficiently to meet workload demands without overuse or waste. Use AKS features like cluster autoscaling and HorizontalPodAutoscaler to dynamically meet your workload needs with less strain on operations. Optimize your workload to operate and deploy efficiently in a container.
Review theScaling and partitioningguide to understand the various aspects of scaling configuration.
(Cluster and workload)Conduct performance testing.Perform ongoing load testing activities that exercise both the pod and cluster autoscaler. Compare results against the performance targets and the established baselines.
(Cluster and workload)Conduct performance testing.Perform ongoing load testing activities that exercise both the pod and cluster autoscaler. Compare results against the performance targets and the established baselines.
(Cluster and workload)Scale workloads and flows independently.Separate workloads and flows into different node pools to allow independent scaling. Follow the guidance inOptimize workload design using flowsto identify and prioritize your flows.
(Cluster and workload)Scale workloads and flows independently.Separate workloads and flows into different node pools to allow independent scaling. Follow the guidance inOptimize workload design using flowsto identify and prioritize your flows.
Recommendations
Azure policies
Azure provides an extensive set of built-in policies related to AKS that apply to the Azure resource, like typical Azure policies and the Azure Policy add-on for Kubernetes, and within the cluster. Many of the Azure resource policies come in bothAudit/Denyand aDeploy If Not Existsvariants. In addition to the built-in Azure Policy definitions, you can create custom policies for both the AKS resource and for the Azure Policy add-on for Kubernetes.
Some of the recommendations in this article can be audited through Azure Policy. For example, you can check the following cluster policies:
Clusters have readiness or liveness health probes configured for your pod spec.
Microsoft Defender for cloud-based policies.
Authentication mode and configuration policies, like Microsoft Entra ID, RBAC, and disable local authentication.
API server network access policies, including private cluster.
GitOps configuration policies.
Diagnostics settings policies.
AKS version restrictions.
Prevent command invoke.
You can also check the following cluster and workload policies:
Kubernetes cluster pod security initiatives for Linux-based workloads.
Include pod and container capability policies, such as AppArmor, sysctl, security caps, SELinux, seccomp, privileged containers, and automount cluster API credentials.
Mount, volume drivers, and filesystem policies.
Pod and container networking policies, such as host network, port, allowed external IPs, HTTPs, and internal load balancers.
Namespace deployment restrictions.
CPU and memory resource limits.
For comprehensive governance, review theAzure Policy built-in definitions for Kubernetesand other policies that might affect the security of the compute layer.
Azure Advisor recommendations
Azure Advisor is a personalized cloud consultant that helps you follow best practices to optimize your Azure deployments. Here are some recommendations that can help you improve the reliability, security, cost effectiveness, performance, and operational excellence of AKS.
Reliability
Security
Cost Optimization
Operational Excellence
Performance
Related content
Consider the following articles as resources that demonstrate the recommendations highlighted in this article.
AKS baseline architecture
Advanced AKS microservices architecture
AKS cluster for a PCI-DSS workload
AKS baseline for multiregion clusters
AKS Landing Zone Accelerator
Build implementation expertise by using the following product documentation:
AKS product documentation
Feedback
Was this page helpful?
Additional resources