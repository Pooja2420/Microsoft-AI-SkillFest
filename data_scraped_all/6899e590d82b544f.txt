Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Use Azure Monitor to Analyze Azure Files metrics
Article
2025-03-28
3 contributors
In this article
Understanding how to monitor file share performance is critical to ensuring that your application is running as efficiently as possible. This article shows you how to useAzure Monitorto analyze Azure Files metrics such as availability, latency, and utilization.
SeeMonitor Azure Filesfor details on the monitoring data you can collect for Azure Files and how to use it.
Applies to
Supported metrics
Metrics for Azure Files are in these namespaces:
Microsoft.Storage/storageAccounts
Microsoft.Storage/storageAccounts/fileServices
For a list of available metrics for Azure Files, seeAzure Files monitoring data reference.
For a list of all Azure Monitor supported metrics, which includes Azure Files, seeAzure Monitor supported metrics.
View Azure Files metrics data
You can view Azure Files metrics by using the Azure portal, PowerShell, Azure CLI, or .NET.
Azure portal
PowerShell
Azure CLI
.NET
You can analyze metrics for Azure Storage with metrics from other Azure services by using Azure Monitor Metrics Explorer. Open metrics explorer by choosingMetricsfrom theAzure Monitormenu. For details on using this tool, seeAnalyze metrics with Azure Monitor metrics explorer.
For metrics that support dimensions, you can filter the metric with the desired dimension value.  For a complete list of the dimensions that Azure Storage supports, seeMetrics dimensions.
You can list the metric definition of your storage account or the Azure Files service. Use theGet-AzMetricDefinitioncmdlet.
In this example, replace the<resource-ID>placeholder with the resource ID of the entire storage account or the resource ID of the Azure Files service.  You can find these resource IDs on thePropertiespages of your storage account in the Azure portal.
<resource-ID>
$resourceId = "<resource-ID>"
   Get-AzMetricDefinition -ResourceId $resourceId
$resourceId = "<resource-ID>"
   Get-AzMetricDefinition -ResourceId $resourceId
You can read account-level metric values of your storage account or the Azure Files service. Use theGet-AzMetriccmdlet.
$resourceId = "<resource-ID>"
   Get-AzMetric -ResourceId $resourceId -MetricNames "UsedCapacity" -TimeGrain 01:00:00
$resourceId = "<resource-ID>"
   Get-AzMetric -ResourceId $resourceId -MetricNames "UsedCapacity" -TimeGrain 01:00:00
When a metric supports dimensions, you can read metric values and filter them by using dimension values. Use theGet-AzMetriccmdlet.
$resourceId = "<resource-ID>"
   Get-AzMetric -ResourceId $resourceId -MetricNames "UsedCapacity" -TimeGrain 01:00:00
$resourceId = "<resource-ID>"
   Get-AzMetric -ResourceId $resourceId -MetricNames "UsedCapacity" -TimeGrain 01:00:00
$resourceId = "<resource-ID>"
$dimFilter = [String](New-AzMetricFilter -Dimension ApiName -Operator eq -Value "GetFile" 3> $null)
Get-AzMetric -ResourceId $resourceId -MetricName Transactions -TimeGrain 01:00:00 -MetricFilter $dimFilter -AggregationType "Total"
$resourceId = "<resource-ID>"
$dimFilter = [String](New-AzMetricFilter -Dimension ApiName -Operator eq -Value "GetFile" 3> $null)
Get-AzMetric -ResourceId $resourceId -MetricName Transactions -TimeGrain 01:00:00 -MetricFilter $dimFilter -AggregationType "Total"
You can list the metric definition of your storage account or the Azure Files service. Use theaz monitor metrics list-definitionscommand.
In this example, replace the<resource-ID>placeholder with the resource ID of the entire storage account or the resource ID of the Azure Files service. You can find these resource IDs on thePropertiespages of your storage account in the Azure portal.
<resource-ID>
az monitor metrics list-definitions --resource <resource-ID>
az monitor metrics list-definitions --resource <resource-ID>
You can read the metric values of your storage account or the Azure Files service. Use theaz monitor metrics listcommand.
az monitor metrics list --resource <resource-ID> --metric "UsedCapacity" --interval PT1H
az monitor metrics list --resource <resource-ID> --metric "UsedCapacity" --interval PT1H
When a metric supports dimensions, you can read metric values and filter them by using dimension values. Use theaz monitor metrics listcommand.
az monitor metrics list --resource <resource-ID> --metric "Transactions" --interval PT1H --filter "ApiName eq 'GetFile' " --aggregation "Total"
az monitor metrics list --resource <resource-ID> --metric "Transactions" --interval PT1H --filter "ApiName eq 'GetFile' " --aggregation "Total"
Azure Monitor provides the.NET SDKto read metric definition and values. Thesample codeshows how to use the SDK with different parameters. You need to use0.18.0-previewor a later version for storage metrics.
0.18.0-preview
In these examples, replace the<resource-ID>placeholder with the resource ID of the entire storage account or the Azure Files service. You can find these resource IDs on thePropertiespages of your storage account in the Azure portal.
<resource-ID>
Replace the<subscription-ID>variable with the ID of your subscription. For guidance on how to obtain values for<tenant-ID>,<application-ID>, and<AccessKey>, seeUse the portal to create a Microsoft Entra application and service principal that can access resources.
<subscription-ID>
<tenant-ID>
<application-ID>
<AccessKey>
List the account-level metric definition
The following example shows how to list a metric definition at the account level:
public static async Task ListStorageMetricDefinition()
    {
        var resourceId = "<resource-ID>";
        var subscriptionId = "<subscription-ID>";
        var tenantId = "<tenant-ID>";
        var applicationId = "<application-ID>";
        var accessKey = "<AccessKey>";


        MonitorManagementClient readOnlyClient = AuthenticateWithReadOnlyClient(tenantId, applicationId, accessKey, subscriptionId).Result;
        IEnumerable<MetricDefinition> metricDefinitions = await readOnlyClient.MetricDefinitions.ListAsync(resourceUri: resourceId, cancellationToken: new CancellationToken());

        foreach (var metricDefinition in metricDefinitions)
        {
            // Enumerate metric definition:
            //    Id
            //    ResourceId
            //    Name
            //    Unit
            //    MetricAvailabilities
            //    PrimaryAggregationType
            //    Dimensions
            //    IsDimensionRequired
        }
    }
public static async Task ListStorageMetricDefinition()
    {
        var resourceId = "<resource-ID>";
        var subscriptionId = "<subscription-ID>";
        var tenantId = "<tenant-ID>";
        var applicationId = "<application-ID>";
        var accessKey = "<AccessKey>";


        MonitorManagementClient readOnlyClient = AuthenticateWithReadOnlyClient(tenantId, applicationId, accessKey, subscriptionId).Result;
        IEnumerable<MetricDefinition> metricDefinitions = await readOnlyClient.MetricDefinitions.ListAsync(resourceUri: resourceId, cancellationToken: new CancellationToken());

        foreach (var metricDefinition in metricDefinitions)
        {
            // Enumerate metric definition:
            //    Id
            //    ResourceId
            //    Name
            //    Unit
            //    MetricAvailabilities
            //    PrimaryAggregationType
            //    Dimensions
            //    IsDimensionRequired
        }
    }
Reading account-level metric values
The following example shows how to readUsedCapacitydata at the account level:
UsedCapacity
public static async Task ReadStorageMetricValue()
    {
        var resourceId = "<resource-ID>";
        var subscriptionId = "<subscription-ID>";
        var tenantId = "<tenant-ID>";
        var applicationId = "<application-ID>";
        var accessKey = "<AccessKey>";

        MonitorClient readOnlyClient = AuthenticateWithReadOnlyClient(tenantId, applicationId, accessKey, subscriptionId).Result;

        Microsoft.Azure.Management.Monitor.Models.Response Response;

        string startDate = DateTime.Now.AddHours(-3).ToUniversalTime().ToString("o");
        string endDate = DateTime.Now.ToUniversalTime().ToString("o");
        string timeSpan = startDate + "/" + endDate;

        Response = await readOnlyClient.Metrics.ListAsync(
            resourceUri: resourceId,
            timespan: timeSpan,
            interval: System.TimeSpan.FromHours(1),
            metricnames: "UsedCapacity",

            aggregation: "Average",
            resultType: ResultType.Data,
            cancellationToken: CancellationToken.None);

        foreach (var metric in Response.Value)
        {
            // Enumerate metric value
            //    Id
            //    Name
            //    Type
            //    Unit
            //    Timeseries
            //        - Data
            //        - Metadatavalues
        }
    }
public static async Task ReadStorageMetricValue()
    {
        var resourceId = "<resource-ID>";
        var subscriptionId = "<subscription-ID>";
        var tenantId = "<tenant-ID>";
        var applicationId = "<application-ID>";
        var accessKey = "<AccessKey>";

        MonitorClient readOnlyClient = AuthenticateWithReadOnlyClient(tenantId, applicationId, accessKey, subscriptionId).Result;

        Microsoft.Azure.Management.Monitor.Models.Response Response;

        string startDate = DateTime.Now.AddHours(-3).ToUniversalTime().ToString("o");
        string endDate = DateTime.Now.ToUniversalTime().ToString("o");
        string timeSpan = startDate + "/" + endDate;

        Response = await readOnlyClient.Metrics.ListAsync(
            resourceUri: resourceId,
            timespan: timeSpan,
            interval: System.TimeSpan.FromHours(1),
            metricnames: "UsedCapacity",

            aggregation: "Average",
            resultType: ResultType.Data,
            cancellationToken: CancellationToken.None);

        foreach (var metric in Response.Value)
        {
            // Enumerate metric value
            //    Id
            //    Name
            //    Type
            //    Unit
            //    Timeseries
            //        - Data
            //        - Metadatavalues
        }
    }
Reading multidimensional metric values
For multidimensional metrics, you need to define metadata filters if you want to read metric data on specific dimension values.
The following example shows how to read metric data on the metric supporting multidimension:
public static async Task ReadStorageMetricValueTest()
    {
        // Resource ID for Azure Files
        var resourceId = "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.Storage/storageAccounts/{storageAccountName}/fileServices/default";
        var subscriptionId = "<subscription-ID}";
        // How to identify Tenant ID, Application ID and Access Key: https://azure.microsoft.com/documentation/articles/resource-group-create-service-principal-portal/
        var tenantId = "<tenant-ID>";
        var applicationId = "<application-ID>";
        var accessKey = "<AccessKey>";

        MonitorManagementClient readOnlyClient = AuthenticateWithReadOnlyClient(tenantId, applicationId, accessKey, subscriptionId).Result;

        Microsoft.Azure.Management.Monitor.Models.Response Response;

        string startDate = DateTime.Now.AddHours(-3).ToUniversalTime().ToString("o");
        string endDate = DateTime.Now.ToUniversalTime().ToString("o");
        string timeSpan = startDate + "/" + endDate;
        // It's applicable to define meta data filter when a metric support dimension
        // More conditions can be added with the 'or' and 'and' operators, example: BlobType eq 'BlockBlob' or BlobType eq 'PageBlob'
        ODataQuery<MetadataValue> odataFilterMetrics = new ODataQuery<MetadataValue>(
            string.Format("BlobType eq '{0}'", "BlockBlob"));

        Response = readOnlyClient.Metrics.List(
                        resourceUri: resourceId,
                        timespan: timeSpan,
                        interval: System.TimeSpan.FromHours(1),
                        metricnames: "BlobCapacity",
                        odataQuery: odataFilterMetrics,
                        aggregation: "Average",
                        resultType: ResultType.Data);

        foreach (var metric in Response.Value)
        {
            //Enumerate metric value
            //    Id
            //    Name
            //    Type
            //    Unit
            //    Timeseries
            //        - Data
            //        - Metadatavalues
        }
    }
public static async Task ReadStorageMetricValueTest()
    {
        // Resource ID for Azure Files
        var resourceId = "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.Storage/storageAccounts/{storageAccountName}/fileServices/default";
        var subscriptionId = "<subscription-ID}";
        // How to identify Tenant ID, Application ID and Access Key: https://azure.microsoft.com/documentation/articles/resource-group-create-service-principal-portal/
        var tenantId = "<tenant-ID>";
        var applicationId = "<application-ID>";
        var accessKey = "<AccessKey>";

        MonitorManagementClient readOnlyClient = AuthenticateWithReadOnlyClient(tenantId, applicationId, accessKey, subscriptionId).Result;

        Microsoft.Azure.Management.Monitor.Models.Response Response;

        string startDate = DateTime.Now.AddHours(-3).ToUniversalTime().ToString("o");
        string endDate = DateTime.Now.ToUniversalTime().ToString("o");
        string timeSpan = startDate + "/" + endDate;
        // It's applicable to define meta data filter when a metric support dimension
        // More conditions can be added with the 'or' and 'and' operators, example: BlobType eq 'BlockBlob' or BlobType eq 'PageBlob'
        ODataQuery<MetadataValue> odataFilterMetrics = new ODataQuery<MetadataValue>(
            string.Format("BlobType eq '{0}'", "BlockBlob"));

        Response = readOnlyClient.Metrics.List(
                        resourceUri: resourceId,
                        timespan: timeSpan,
                        interval: System.TimeSpan.FromHours(1),
                        metricnames: "BlobCapacity",
                        odataQuery: odataFilterMetrics,
                        aggregation: "Average",
                        resultType: ResultType.Data);

        foreach (var metric in Response.Value)
        {
            //Enumerate metric value
            //    Id
            //    Name
            //    Type
            //    Unit
            //    Timeseries
            //        - Data
            //        - Metadatavalues
        }
    }
Monitor workload performance
You can use Azure Monitor to analyze workloads that utilize Azure Files. Follow these steps.
Navigate to your storage account in theAzure portal.
In the service menu, underMonitoring, selectMetrics.
UnderMetric namespace, selectFile.

Now you can select a metric depending on what you want to monitor.
Monitor availability
In Azure Monitor, theAvailabilitymetric can be useful when something is visibly wrong from either an application or user perspective, or when troubleshooting alerts.
When using this metric with Azure Files, it's important to always view the aggregation asAverageas opposed toMaxorMin. UsingAverageshows you what percentage of your requests are experiencing errors, and if they are within theSLA for Azure Files.

Monitor latency
The two most important latency metrics areSuccess E2E LatencyandSuccess Server Latency. These are ideal metrics to select when starting any performance investigation.Averageis the recommended aggregation. As previously mentioned, Max and Min can sometimes be misleading.
In the following charts, the blue line indicates how much time is spent in total latency (Success E2E Latency), and the pink line indicates time spent only in the Azure Files service (Success Server Latency).
This chart shows an on-premises client with a mounted Azure file share, representing, for example, a typical user connecting from a remote location. The physical distance between the client and Azure region is closely correlated to the corresponding client-side latency, which represents the difference between the E2E and Server latency.

In comparison, the following chart shows a situation where both the client and the Azure file share are located within the same region. Note that the client-side latency is only 0.17ms compared to 43.9ms in the first chart. This illustrates why minimizing client-side latency is imperative in order to achieve optimal performance.

Another latency indicator to look that for might suggest a problem is an increased frequency or abnormal spikes inSuccess Server Latency.  This is commonly due to throttling due to exceeding the provisioned limit for a provisioned file share (or an overall scale limit a pay-as-you-go file share). SeeUnderstanding Azure Files billingand theScalability and performance targets for Azure Files.
For more information, seeTroubleshoot high latency, low throughput, or low IOPS.
Monitor utilization
Utilization metrics that measure the amount of data being transmitted (throughput) or operations being serviced (IOPS) are commonly used to determine how much work is being performed by the application or workload. Transaction metrics can determine the number of operations or requests against the Azure Files service over various time granularity.
If you're using theEgressorIngressmetrics to determine the volume of inbound or outbound data, use theSumaggregation to determine the total amount of data being transmitted to and from the file share over a 1 minute to 1 day time granularity. Other aggregations such asAverage,Max, andMinonly display the value of the individual I/O size. This is why most customers typically see 1 MiB when using theMaxaggregation.  While it can be useful to understand the size of your largest, smallest, or even average I/O size, it isn't possible to display the distribution of I/O size generated by the workload's usage pattern.
You can also selectApply splittingon response types (success, failures, errors) or API operations (read, write, create, close) to display additional details as shown in the following chart.

To determine the average I/O per second (IOPS) for your workload, first determine the total number of transactions over a minute and then divide that number by 60 seconds. For example, 120,000 transactions in 1 minute / 60 seconds = 2,000 average IOPS.
To determine the average throughput for your workload, take the total amount of transmitted data by combining theIngressandEgressmetrics (total throughput) and divide that by 60 seconds. For example, 1 GiB total throughput over 1 minute / 60 seconds = 17 MiB average throughput.
Monitor utilization by maximum IOPS and bandwidth (provisioned only)
Provisioned file shares provideTransactions by Max IOPSandBandwidth by Max MiB/smetrics to display what your workload is achieving at peak times. Using these metrics to analyze your workload help you understand true capability at scale, as well as establish a baseline to understand the impact of more throughput and IOPS so you can optimally provision your Azure file share.
The following chart shows a workload that generated 2.63 million transactions over 1 hour. When 2.63 million transactions is divided by 3,600 seconds, we get an average of 730 IOPS.

Now when we compare the average IOPS against theTransactions by Max IOPS, we see that under peak load we were achieving 1,840 IOPS, which is a better representation of the workload's ability at scale.

SelectAdd metricto combine theIngressandEgress metricson a single graph. This displays that 76.2 GiB (78,028 MiB) was transferred over one hour, which gives us an average throughput of 21.67 MiB over that same hour.

Compared against theBandwidth by Max MiB/s, we achieved 123 MiB/s at peak.

Monitor utilization by metadata IOPS
On Azure file shares scale up to 12K metadata IOPS. This means that running a metadata-heavy workload with a high volume of open, close, or delete operations increases the likelihood of metadata IOPS throttling. This limitation is independent of the file share's overall provisioned IOPS.
Because no two metadata-heavy workloads follow the same usage pattern, it can be challenging for customers to proactively monitor their workload and set accurate alerts.
To address this, we've introduced two metadata-specific metrics for Azure file shares:
Success with Metadata Warning:Indicates that metadata IOPS are approaching their limit and might be throttled if they remain high or continue increasing. A rise in the volume or frequency of these warnings suggests an increasing risk of metadata throttling.
Success with Metadata Warning:Indicates that metadata IOPS are approaching their limit and might be throttled if they remain high or continue increasing. A rise in the volume or frequency of these warnings suggests an increasing risk of metadata throttling.
Success with Metadata Throttling:Indicates that metadata IOPS have exceeded the file share's capacity, resulting in throttling. While IOPS operations never fail and eventually succeed after retries, latency is impacted during throttling.
Success with Metadata Throttling:Indicates that metadata IOPS have exceeded the file share's capacity, resulting in throttling. While IOPS operations never fail and eventually succeed after retries, latency is impacted during throttling.
To view in Azure Monitor, select theTransactionsmetric andApply splittingon response types. The Metadata response types only appear in the drop-down if the activity occurs within the timeframe selected.
The following chart illustrates a workload that experienced a sudden increase in metadata IOPS (transactions), triggering Success with Metadata Warnings, which indicates a risk of metadata throttling. In this example, the workload subsequently reduced its transaction volume, preventing metadata throttling from occurring.

If your workload encountersSuccess with Metadata WarningsorSuccess with Metadata Throttlingresponse types, consider implementing one or more of the following recommendations:
For SSD SMB file shares, enableMetadata Caching.
Distribute (shard) your workload across multiple file shares.
Reduce the volume of metadata IOPS.
Related content
Monitor Azure Files
Azure Files monitoring data reference
Create monitoring alerts for Azure Files
Monitor Azure resources with Azure Monitor
Understand Azure Files performance
Troubleshoot ClientOtherErrors
Feedback
Was this page helpful?
Additional resources