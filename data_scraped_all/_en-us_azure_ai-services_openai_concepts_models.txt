Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Azure OpenAI Service models
Article
2025-04-23
23 contributors
In this article
Azure OpenAI Service is powered by a diverse set of models with different capabilities and price points. Model availability varies by region and cloud. For Azure Government model availability, please refer toAzure Government OpenAI Service.
GPT 4.1 series
Region Availability
gpt-4.1
gpt-4.1-nano
gpt-4.1-mini
Capabilities
gpt-4.1
gpt-4.1-nano
gpt-4.1-mini
computer-use-preview
An experimental model trained for use with theResponses APIcomputer use tool. It can be used in conjunction with 3rd-party libraries to allow the model to control mouse & keyboard input while getting context from screenshots of the current environment.
Caution
We don't recommend using preview models in production. We will upgrade all deployments of preview models to either future preview versions or to the latest stable GA version. Models that are designated preview don't follow the standard Azure OpenAI model lifecycle.
Availability
For access tocomputer-use-previewregistration is required, and access will be granted based on Microsoft's eligibility criteria. Customers who have access to other limited access models will still need to request access for this model.
computer-use-preview
Request access:computer-use-previewlimited access model application
computer-use-preview
Once access has been granted, you will need to create a deployment for the model.
Region Availability
computer-use-preview
Capabilities
computer-use-preview
GPT-4.5 Preview
Region Availability
gpt-4.5-preview
Capabilities
gpt-4.5-preview
Note
It is expected behavior that the model cannot answer questions about itself. If you want to know when the knowledge cutoff for the model's training data is, or other details about the model you should refer to the model documentation above.
o-series models
The Azure OpenAI o*series models are specifically designed to tackle reasoning and problem-solving tasks with increased focus and capability. These models spend more time processing and understanding the user's request, making them exceptionally strong in areas like science, coding, and math compared to previous iterations.
o4-mini
o3
o3-mini
o1
o1-preview
o1-mini
o1-preview
Availability
To learn more about the advancedo-seriesmodels see,getting started with reasoning models.
o-series
Region availability
o4-mini
o3
o3-mini
o1
o1-preview
o1-mini
GPT-4o and GPT-4 Turbo
GPT-4o integrates text and images in a single model, enabling it to handle multiple data types simultaneously. This multimodal approach enhances accuracy and responsiveness in human-computer interactions. GPT-4o matches GPT-4 Turbo in English text and coding tasks while offering superior performance in non-English languages and vision tasks, setting new benchmarks for AI capabilities.
How do I access the GPT-4o and GPT-4o mini models?
GPT-4o and GPT-4o mini are available forstandardandglobal-standardmodel deployment.
You need tocreateor use an existing resource in asupported standardorglobal standardregion where the model is available.
When your resource is created, you candeploythe GPT-4o models. If you are performing a programmatic deployment, themodelnames are:
gpt-4oVersion2024-11-20
gpt-4o
2024-11-20
gpt-4oVersion2024-08-06
gpt-4o
2024-08-06
gpt-4oVersion2024-05-13
gpt-4o
2024-05-13
gpt-4o-miniVersion2024-07-18
gpt-4o-mini
2024-07-18
GPT-4 Turbo
GPT-4 Turbo is a large multimodal model (accepting text or image inputs and generating text) that can solve difficult problems with greater accuracy than any of OpenAI's previous models. Like GPT-3.5 Turbo, and older GPT-4 models GPT-4 Turbo is optimized for chat and works well for traditional completions tasks.
The latest GA release of GPT-4 Turbo is:
gpt-4Version:turbo-2024-04-09
gpt-4
turbo-2024-04-09
This is the replacement for the following preview models:
gpt-4Version:1106-Preview
gpt-4
1106-Preview
gpt-4Version:0125-Preview
gpt-4
0125-Preview
gpt-4Version:vision-preview
gpt-4
vision-preview
Differences between OpenAI and Azure OpenAI GPT-4 Turbo GA Models
OpenAI's version of the latest0409turbo model supports JSON mode and function calling for all inference requests.
0409
Azure OpenAI's version of the latestturbo-2024-04-09currently doesn't support the use of JSON mode and function calling when making inference requests with image (vision) input. Text based input requests (requests withoutimage_urland inline images) do support JSON mode and function calling.
turbo-2024-04-09
image_url
Differences from gpt-4 vision-preview
Azure AI specific Vision enhancements integration with GPT-4 Turbo with Vision isn't supported forgpt-4Version:turbo-2024-04-09. This includes Optical Character Recognition (OCR), object grounding, video prompts, and improved handling of your data with images.
gpt-4
turbo-2024-04-09
Important
Vision enhancements preview features including Optical Character Recognition (OCR), object grounding, video prompts will be retired and no longer available oncegpt-4Version:vision-previewis upgraded toturbo-2024-04-09. If you are currently relying on any of these preview features, this automatic model upgrade will be a breaking change.
gpt-4
vision-preview
turbo-2024-04-09
GPT-4 Turbo provisioned managed availability
gpt-4Version:turbo-2024-04-09is available for both standard and provisioned deployments. Currently the provisioned version of this modeldoesn't support image/vision inference requests. Provisioned deployments of this model only accept text input. Standard model deployments accept both text and image/vision inference requests.
gpt-4
turbo-2024-04-09
Deploying GPT-4 Turbo with Vision GA
To deploy the GA model from the Azure AI Foundry portal, selectGPT-4and then choose theturbo-2024-04-09version from the dropdown menu. The default quota for thegpt-4-turbo-2024-04-09model will be the same as current quota for GPT-4-Turbo. See theregional quota limits.
GPT-4
turbo-2024-04-09
gpt-4-turbo-2024-04-09
GPT-4
GPT-4 is the predecessor to GPT-4 Turbo. Both the GPT-4 and GPT-4 Turbo models have a base model name ofgpt-4. You can distinguish between the GPT-4 and Turbo models by examining the model version.
gpt-4
gpt-4Version0314
gpt-4
0314
gpt-4Version0613
gpt-4
0613
gpt-4-32kVersion0613
gpt-4-32k
0613
You can see the token context length supported by each model in themodel summary table.
GPT-4 and GPT-4 Turbo models
These models can only be used with the Chat Completion API.
Seemodel versionsto learn about how Azure OpenAI Service handles model version upgrades, andworking with modelsto learn how to view and configure the model version settings of your GPT-4 deployments.
gpt-4o
gpt-4o
gpt-4o-mini
gpt-4o
gpt-4
vision-preview
1106-Preview
0125-Preview
gpt-4
gpt-4
gpt-4
gpt-4-32k
gpt-4
gpt-4-32k
gpt-4
Caution
We don't recommend using preview models in production. We will upgrade all deployments of preview models to either future preview versions or to the latest stable GA version. Models that are designated preview don't follow the standard Azure OpenAI model lifecycle.
GPT-4 version 0125-preview is an updated version of the GPT-4 Turbo preview previously released as version 1106-preview.
GPT-4 version 0125-preview completes tasks such as code generation more completely compared to gpt-4-1106-preview. Because of this, depending on the task, customers may find that GPT-4-0125-preview generates more output compared to the gpt-4-1106-preview.  We recommend customers compare the outputs of the new model.  GPT-4-0125-preview also addresses bugs in gpt-4-1106-preview with UTF-8 handling for non-English languages.
GPT-4 versionturbo-2024-04-09is the latest GA release and replaces0125-Preview,1106-preview, andvision-preview.
turbo-2024-04-09
0125-Preview
1106-preview
vision-preview
GPT-3.5
GPT-3.5 models can understand and generate natural language or code. The most capable and cost effective model in the GPT-3.5 family is GPT-3.5 Turbo, which has been optimized for chat and works well for traditional completions tasks as well. GPT-3.5 Turbo is available for use with the Chat Completions API. GPT-3.5 Turbo Instruct has similar capabilities totext-davinci-003using the Completions API instead of the Chat Completions API.  We recommend using GPT-3.5 Turbo and GPT-3.5 Turbo Instruct overlegacy GPT-3.5 and GPT-3 models.
text-davinci-003
gpt-35-turbo
gpt-35-turbo
gpt-35-turbo-instruct
gpt-35-turbo-16k
gpt-35-turbo
gpt-35-turbo
To learn more about how to interact with GPT-3.5 Turbo and the Chat Completions API check out ourin-depth how-to.
1This model will accept requests > 4,096 tokens. It is not recommended to exceed the 4,096 input token limit as the newer version of the model are capped at 4,096 tokens. If you encounter issues when exceeding 4,096 input tokens with this model this configuration is not officially supported.
Embeddings
text-embedding-3-largeis the latest and most capable embedding model. Upgrading between embeddings models is not possible. In order to move from usingtext-embedding-ada-002totext-embedding-3-largeyou would need to generate new embeddings.
text-embedding-3-large
text-embedding-ada-002
text-embedding-3-large
text-embedding-3-large
text-embedding-3-large
text-embedding-3-small
text-embedding-3-small
text-embedding-ada-002
text-embedding-ada-002
In testing, OpenAI reports both the large and small third generation embeddings models offer better average multi-language retrieval performance with theMIRACLbenchmark while still maintaining performance for English tasks with theMTEBbenchmark.
text-embedding-ada-002
text-embedding-3-small
text-embedding-3-large
The third generation embeddings models support reducing the size of the embedding via a newdimensionsparameter. Typically larger embeddings are more expensive from a compute, memory, and storage perspective. Being able to adjust the number of dimensions allows more control over overall cost and performance. Thedimensionsparameter is not supported in all versions of the OpenAI 1.x Python library, to take advantage of this parameter  we recommend upgrading to the latest version:pip install openai --upgrade.
dimensions
dimensions
pip install openai --upgrade
OpenAI's MTEB benchmark testing found that even when the third generation model's dimensions are reduced to less thantext-embeddings-ada-0021,536 dimensions performance remains slightly better.
text-embeddings-ada-002
Image generation models
The image generation models generate images from text prompts that the user provides. GPT-image-1 is in limited access public preview. DALL-E 3 is generally available for use with the REST APIs. DALL-E 2 and DALL-E 3 with client SDKs are in preview.
Availability
For access togpt-image-1registration is required, and access will be granted based on Microsoft's eligibility criteria. Customers who have access to other limited access models will still need to request access for this model.
gpt-image-1
Request access:gpt-image-1limited access model application
gpt-image-1
Once access has been granted, you will need to create a deployment for the model.
Region availability
dall-e-3
gpt-image-1
Audio models
Audio models in Azure OpenAI are available via therealtime,completions, andaudioAPIs.
realtime
completions
audio
GPT-4o audio models
The GPT 4o audio models are part of the GPT-4o model family and support either low-latency, "speech in, speech out" conversational interactions or audio generation.
Caution
We don't recommend using preview models in production. We will upgrade all deployments of preview models to either future preview versions or to the latest stable GA version. Models that are designated preview don't follow the standard Azure OpenAI model lifecycle.
Details about maximum request tokens and training data are available in the following table.
gpt-4o-mini-audio-preview
gpt-4o-mini-realtime-preview
gpt-4o-audio-preview
gpt-4o-realtime-preview
gpt-4o-realtime-preview
To compare the availability of GPT-4o audio models across all regions, see themodels table.
Audio API
The audio models via the/audioAPI can be used for speech to text, translation, and text to speech.
/audio
whisper
gpt-4o-transcribe
gpt-4o-mini-transcribe
whisper
tts
tts-hd
gpt-4o-mini-tts
For more information seeAudio models region availabilityin this article.
Model summary table and region availability
Models by deployment type
Azure OpenAI provides customers with choices on the hosting structure that fits their business and usage patterns. The service offers two main types of deployment:
Standardis offered with a global deployment option, routing traffic globally to provide higher throughput.
Provisionedis also offered with a global deployment option, allowing customers to purchase and deploy provisioned throughput units across Azure global infrastructure.
All deployments can perform the exact same inference operations, however the billing, scale, and performance are substantially different. To learn more about Azure OpenAI deployment types see ourdeployment types guide.
Global Standard
Global Provisioned Managed
Global Batch
Data Zone Standard
Data Zone Provisioned Managed
Data Zone Batch
Standard
Provisioned Managed
Global standard model availability
Note
o1-miniis currently available to all customers for global standard deployment.
o1-mini
Select customers were granted standard (regional) deployment access too1-minias part of theo1-previewlimited access release. At this time access too1-ministandard (regional) deployments is not being expanded.
o1-mini
o1-preview
o1-mini
Global provisioned managed model availability
Global batch model availability
Data zone standard model availability
Note
o1-miniis currently available to all customers for global standard deployment.
o1-mini
Select customers were granted standard (regional) deployment access too1-minias part of theo1-previewlimited access release. At this time access too1-ministandard (regional) deployments is not being expanded.
o1-mini
o1-preview
o1-mini
Data zone provisioned managed model availability
Data zone batch model availability
Standard deployment model availability
Note
o1-miniis currently available to all customers for global standard deployment.
o1-mini
Select customers were granted standard (regional) deployment access too1-minias part of theo1-previewlimited access release. At this time access too1-ministandard (regional) deployments is not being expanded.
o1-mini
o1-preview
o1-mini
Provisioned deployment model availability
Note
The provisioned version ofgpt-4Version:turbo-2024-04-09is currently limited to text only.
gpt-4
turbo-2024-04-09
For more information on Provisioned deployments, see ourProvisioned guidance.
This table doesn't include fine-tuning regional availability information.  Consult thefine-tuning sectionfor this information.
Standard deployment (regional) models by endpoint
Chat Completions
Embeddings
Image Generation
Audio
Completions (Legacy)
Chat completions
Note
o1-miniis currently available to all customers for global standard deployment.
o1-mini
Select customers were granted standard (regional) deployment access too1-minias part of theo1-previewlimited access release. At this time access too1-ministandard (regional) deployments is not being expanded.
o1-mini
o1-preview
o1-mini
GPT-4 and GPT-4 Turbo model availability
In addition to the regions above which are available to all Azure OpenAI customers, some select preexisting customers have been granted access to versions of GPT-4 in additional regions:
gpt-4
gpt-4-32k
gpt-4
gpt-4-32k
GPT-3.5 models
Seemodel versionsto learn about how Azure OpenAI Service handles model version upgrades, andworking with modelsto learn how to view and configure the model version settings of your GPT-3.5 Turbo deployments.
Embeddings models
These models can only be used with Embedding API requests.
Note
text-embedding-3-largeis the latest and most capable embedding model. Upgrading between embedding models is not possible. In order to migrate from usingtext-embedding-ada-002totext-embedding-3-largeyou would need to generate new embeddings.
text-embedding-3-large
text-embedding-ada-002
text-embedding-3-large
text-embedding-ada-002
text-embedding-ada-002
text-embedding-3-large
text-embedding-3-small
Note
When sending an array of inputs for embedding, the max number of input items in the array per call to the embedding endpoint is 2048.
Image generation models
Image generation models
Audio models
Completions models
Fine-tuning models
Note
gpt-35-turbo- Fine-tuning of this model is limited to a subset of regions, and isn't available in every region the base model is available.
gpt-35-turbo
The supported regions for fine-tuning might vary if you use Azure OpenAI models in an Azure AI Foundry project versus outside a project.
gpt-35-turbo
gpt-35-turbo
gpt-4o-mini
gpt-4o
gpt-4.1
gpt-4.1-mini
Assistants (Preview)
For Assistants you need a combination of a supported model, and a supported region. Certain tools and capabilities require the latest models. The following models are available in the Assistants API, SDK, and Azure AI Foundry. The following table is for pay-as-you-go. For information on Provisioned Throughput Unit (PTU) availability, seeprovisioned throughput. The listed models and regions can be used with both Assistants v1 and v2. You can useglobal standard modelsif they are supported in the regions listed below.
Model retirement
For the latest information on model retirements, refer to themodel retirement guide.
Next steps
Model retirement and deprecation
Learn more about working with Azure OpenAI models
Learn more about Azure OpenAI
Learn more about fine-tuning Azure OpenAI models
Feedback
Was this page helpful?
Additional resources