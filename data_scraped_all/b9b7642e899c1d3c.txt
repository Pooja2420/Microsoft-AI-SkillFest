Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
How to switch between OpenAI and Azure OpenAI endpoints with Python
How-to
2025-03-27
4 contributors
In this article
While OpenAI and Azure OpenAI Service rely on acommon Python client library, there are small changes you need to make to your code in order to swap back and forth between endpoints. This article walks you through the common changes and differences you'll experience when working across OpenAI and Azure OpenAI.
This article only shows examples with the new OpenAI Python 1.x API library. For information on migrating from0.28.1to1.xrefer to ourmigration guide.
0.28.1
1.x
Prerequisites
Authentication
We recommend using Microsoft Entra ID or Azure Key Vault. You can use environment variables for testing outside of your production environment. If you haven't done this before, ourPython quickstartswalks you through this configuration.
API key
import os
from openai import OpenAI

client = OpenAI(
    api_key=os.getenv("OPENAI_API_KEY")
)
import os
from openai import OpenAI

client = OpenAI(
    api_key=os.getenv("OPENAI_API_KEY")
)
import os
from openai import AzureOpenAI
    
client = AzureOpenAI(
    api_key=os.getenv("AZURE_OPENAI_API_KEY"),  
    api_version="2024-07-01-preview",
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT")
)
import os
from openai import AzureOpenAI
    
client = AzureOpenAI(
    api_key=os.getenv("AZURE_OPENAI_API_KEY"),  
    api_version="2024-07-01-preview",
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT")
)

Microsoft Entra ID authentication
import os
from openai import OpenAI

client = OpenAI(
    api_key=os.getenv("OPENAI_API_KEY")
)
import os
from openai import OpenAI

client = OpenAI(
    api_key=os.getenv("OPENAI_API_KEY")
)
from azure.identity import DefaultAzureCredential, get_bearer_token_provider
from openai import AzureOpenAI

token_provider = get_bearer_token_provider(
    DefaultAzureCredential(), "https://cognitiveservices.azure.com/.default"
)

api_version = "2024-07-01-preview"
endpoint = "https://my-resource.openai.azure.com"

client = AzureOpenAI(
    api_version=api_version,
    azure_endpoint=endpoint,
    azure_ad_token_provider=token_provider,
)
from azure.identity import DefaultAzureCredential, get_bearer_token_provider
from openai import AzureOpenAI

token_provider = get_bearer_token_provider(
    DefaultAzureCredential(), "https://cognitiveservices.azure.com/.default"
)

api_version = "2024-07-01-preview"
endpoint = "https://my-resource.openai.azure.com"

client = AzureOpenAI(
    api_version=api_version,
    azure_endpoint=endpoint,
    azure_ad_token_provider=token_provider,
)
Keyword argument for model
OpenAI uses themodelkeyword argument to specify what model to use. Azure OpenAI has the concept of unique modeldeployments. When you use Azure OpenAI,modelshould refer to the underlying deployment name you chose when you deployed the model.
model
model
Important
When you access the model via the API in Azure OpenAI, you need to refer to the deployment name rather than the underlying model name in API calls, which is one of thekey differencesbetween OpenAI and Azure OpenAI. OpenAI only requires the model name. Azure OpenAI always requires deployment name, even when using the model parameter. In our docs, we often have examples where deployment names are represented as identical to model names to help indicate which model works with a particular API endpoint. Ultimately your deployment names can follow whatever naming convention is best for your use case.
completion = client.completions.create(
    model="gpt-3.5-turbo-instruct",
    prompt="<prompt>"
)

chat_completion = client.chat.completions.create(
    model="gpt-4o",
    messages="<messages>"
)

embedding = client.embeddings.create(
    model="text-embedding-3-large",
    input="<input>"
)
completion = client.completions.create(
    model="gpt-3.5-turbo-instruct",
    prompt="<prompt>"
)

chat_completion = client.chat.completions.create(
    model="gpt-4o",
    messages="<messages>"
)

embedding = client.embeddings.create(
    model="text-embedding-3-large",
    input="<input>"
)
completion = client.completions.create(
    model="gpt-35-turbo-instruct", # This must match the custom deployment name you chose for your model.
    prompt="<prompt>"
)

chat_completion = client.chat.completions.create(
    model="gpt-4o", # model = "deployment_name".
    messages="<messages>"
)

embedding = client.embeddings.create(
    model="text-embedding-3-large", # model = "deployment_name".
    input="<input>"
)
completion = client.completions.create(
    model="gpt-35-turbo-instruct", # This must match the custom deployment name you chose for your model.
    prompt="<prompt>"
)

chat_completion = client.chat.completions.create(
    model="gpt-4o", # model = "deployment_name".
    messages="<messages>"
)

embedding = client.embeddings.create(
    model="text-embedding-3-large", # model = "deployment_name".
    input="<input>"
)
Azure OpenAI embeddings multiple input support
OpenAI and Azure OpenAI currently support input arrays up to 2,048 input items for text-embedding-ada-002. Both require the max input token limit per API request to remain under 8,191 for this model.
inputs = ["A", "B", "C"] 

embedding = client.embeddings.create(
    input=inputs,
    model="text-embedding-3-large"
)
inputs = ["A", "B", "C"] 

embedding = client.embeddings.create(
    input=inputs,
    model="text-embedding-3-large"
)
inputs = ["A", "B", "C"] #max array size=2048

embedding = client.embeddings.create(
    input=inputs,
    model="text-embedding-3-large" # This must match the custom deployment name you chose for your model.
    # engine="text-embedding-ada-002"
)
inputs = ["A", "B", "C"] #max array size=2048

embedding = client.embeddings.create(
    input=inputs,
    model="text-embedding-3-large" # This must match the custom deployment name you chose for your model.
    # engine="text-embedding-ada-002"
)
Related content
Learn more about how to work with chat completions models with our how-to guide
For more examples, check out the Azure OpenAI Samples GitHub repository
Feedback
Was this page helpful?