Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Set up your own infrastructure for Standard logic apps using hybrid deployment (Preview)
Article
2025-03-13
1 contributor
In this article
Applies to:Azure Logic Apps (Standard)
Note
This capability is in preview, incurs charges for usage, and is subject to theSupplemental Terms of Use for Microsoft Azure Previews.
Sometimes you have to set up and manage your own infrastructure to meet specific needs for regulatory compliance, data privacy, or network restrictions. Azure Logic Apps offers ahybrid deployment modelso that you can deploy and host Standard logic app workflows in on-premises, private cloud, or public cloud scenarios. This model gives you the capabilities to host integration solutions in partially connected environments when you need to use local processing, data storage, and network access. With the hybrid option, you have the freedom and flexibility to choose the best environment for your workflows.
How hybrid deployment works
Standard logic app workflows with the hybrid deployment option are powered by an Azure Logic Apps runtime that is hosted in an Azure Container Apps extension. In your workflow, anybuilt-in operationsrun locally with the runtime so that you get higher throughput for access to local data sources. If you need access to non-local data resources, for example, cloud-based services such as Microsoft Office 365, Microsoft Teams, Salesforce, GitHub, LinkedIn, or ServiceNow, you can choose operations from1,000+ connectors hosted in Azureto include in your workflows. For more information, seeManaged (shared) connectors. Although you need to have internet connectivity to manage your logic app in the Azure portal, the semi-connected nature of this platform lets you absorb any temporary internet connectivity issues.
For example, if you have an on-premises scenario, the following architectural overview shows where Standard logic app workflows are hosted and run in the hybrid model. The partially connected environment includes the following resources for hosting and working with your Standard logic apps, which deploy as Azure Container Apps resources:
Azure Arc-enabled Azure Kubernetes Service (AKS) clusters
A SQL database to locally store workflow run history, inputs, and outputs for processing
A Server Message Block (SMB) file share to locally store artifacts used by your workflows

For hosting, you can also set up and useAzure Arc-enabled Kubernetes clusters on Azure LocalorAzure Arc-enabled Kubernetes clusters on Windows Server.
For more information, see the following documentation:
What is Azure Kubernetes Service?
Core concepts for Azure Kubernetes Service (AKS)
Custom locations for Azure Arc-enabled Kubernetes clusters
What is Azure Container Apps?
Azure Container Apps on Azure Arc
This how-to guide shows how to set up the necessary on-premises resources in your infrastructure so that you can create, deploy, and host a Standard logic app workflow using the hybrid deployment model.

How billing works
The hybrid option uses a billing model where you pay only for what you need and can scale resources for dynamic workloads without having to buy for peak usage. You're responsible for the following items:
Your Azure Arc-enabled Kubernetes infrastructure
Your Azure Arc-enabled Kubernetes infrastructure
Your SQL Server license
Your SQL Server license
Billing charges for vCPU usage to support Standard logic app workloadsFor more information, see the following sections:vCPU usage calculationBilling charge calculation
Billing charges for vCPU usage to support Standard logic app workloads
For more information, see the following sections:
vCPU usage calculation
Billing charge calculation
Billing charges for anymanaged (shared) connector operations, such as Microsoft Teams or Microsoft Office 365, in your logic app workflows.These operation executions followStandard pricing.
Billing charges for anymanaged (shared) connector operations, such as Microsoft Teams or Microsoft Office 365, in your logic app workflows.
These operation executions followStandard pricing.

vCPU usage calculation
The vCPU usage for your Standard logic app affects your billing charges. AvCPUrefers to the number of CPU cores, but this ratio isn't necessarily 1:1. The following formula calculates the vCPU usage for your logic app:
vCPU usage= (# of allocated vCPUs) x (# of replicas)

Billing charge calculation
The following formula calculates your billing charge per hour, which is based on vCPU usage and at the rate of $0.18 USD per hour while your logic app is enabled:
Charge per hour= (vCPU usage) x (rate per hour)
For example, the following table shows some example billing charge calculations:
Limitations
Hybrid deployment is currently available and supported only for the following Azure Arc-enabled Kubernetes clusters:Azure Arc-enabled Kubernetes clustersAzure Arc-enabled Kubernetes clusters on Azure Local (formerly Azure Stack HCI)Azure Arc-enabled Kubernetes clusters on Windows Server
Hybrid deployment is currently available and supported only for the following Azure Arc-enabled Kubernetes clusters:
Azure Arc-enabled Kubernetes clusters
Azure Arc-enabled Kubernetes clusters on Azure Local (formerly Azure Stack HCI)
Azure Arc-enabled Kubernetes clusters on Windows Server
Prerequisites
An Azure account and subscription. If you don't have a subscription,sign up for a free Azure account.
An Azure account and subscription. If you don't have a subscription,sign up for a free Azure account.
Basic understanding aboutcore AKS concepts
Basic understanding aboutcore AKS concepts
Technical requirements for working with Azure CLI
Technical requirements for working with Azure CLI
Technical requirements for Azure Container Apps on Azure Arc-enabled Kubernetes, including access to a public or private container registry, such as theAzure Container Registry.
Technical requirements for Azure Container Apps on Azure Arc-enabled Kubernetes, including access to a public or private container registry, such as theAzure Container Registry.
Create a Kubernetes cluster
Before you can deploy your Standard logic app as on-premises resource to an Azure Arc-enabled Kubernetes cluster in an Azure Container Apps connected environment, you first need aKubernetes cluster. You'll later connect this cluster to Azure Arc so that you have anAzure Arc-enabled Kubernetes cluster.
Your Kubernetes cluster requires inbound and outbound connectivity with theSQL database that you later create as the storage providerand with theServer Message Block file share that you later create for artifacts storage. These resources must exist within the same network.
Note
You can also create aKubernetes cluster on Azure LocalorKubernetes cluster on Windows Serverand apply the steps in this guide
to connect your cluster to Azure Arc and set up your connected environment. For more information about
Azure Local and AKS on Windows Server, see the following resources:
About Azure Local deployment
Deployment prerequisites for Azure Local
Create Kubernetes clusters using Azure CLI
Set up an Azure Kubernetes Service host on Azure Local and Windows Server and deploy a workload cluster using PowerShell
Set the following environment variables for the Kubernetes cluster that you want to create:SUBSCRIPTION="<Azure-subscription-ID>"
AKS_CLUSTER_GROUP_NAME="<aks-cluster-resource-group-name>"
AKS_NAME="<aks-cluster-name>"
LOCATION="eastus"ParameterRequiredValueDescriptionSUBSCRIPTIONYes<Azure-subscription-ID>The ID for your Azure subscriptionAKS_CLUSTER_GROUP_NAMEYes<aks-cluster-resource-group-name>The name for the Azure resource group to use with your Kubernetes cluster. This name must be unique across regions and can contain only letters, numbers, hyphens (-), underscores (_), parentheses (()), and periods (.).This example usesHybrid-RG.AKS_NAMEYes<aks-cluster-name>The name for your Kubernetes cluster.LOCATIONYes<Azure-region>An Azure region thatsupports Azure container apps on Azure Arc-enabled Kubernetes.This example useseastus.
Set the following environment variables for the Kubernetes cluster that you want to create:
SUBSCRIPTION="<Azure-subscription-ID>"
AKS_CLUSTER_GROUP_NAME="<aks-cluster-resource-group-name>"
AKS_NAME="<aks-cluster-name>"
LOCATION="eastus"
SUBSCRIPTION="<Azure-subscription-ID>"
AKS_CLUSTER_GROUP_NAME="<aks-cluster-resource-group-name>"
AKS_NAME="<aks-cluster-name>"
LOCATION="eastus"
Run the following commands either by using the Bash environment inAzure Cloud Shellor locally usingAzure CLI installed on your computer:NoteMake sure to change themax-countandmin-countnode values based on your load requirements.az login
az account set --subscription $SUBSCRIPTION
az provider register --namespace Microsoft.KubernetesConfiguration --wait
az provider register --namespace Microsoft.Kubernetes --wait
az extension add --name k8s-extension --upgrade --yes
az group create \
   --name $AKS_CLUSTER_GROUP_NAME \
   --location $LOCATION
az aks create \
   --resource-group $AKS_CLUSTER_GROUP_NAME \
   --name $AKS_NAME \
   --enable-aad \
   --generate-ssh-keys \
   --enable-cluster-autoscaler \
   --max-count 6 \
   --min-count 1ParameterRequiredValueDescriptionmax countNo<max-nodes-value>The maximum number of nodes to use for the autoscaler when you include theenable-cluster-autoscaleroption. This value ranges from1to1000.min countNo<min-nodes-value>The minimum number of nodes to use for the autoscaler when you include theenable-cluster-autoscaleroption. This value ranges from1to1000.For more information, see the following resources:Quickstart: Deploy an Azure Kubernetes Service (AKS) cluster using Azure CLIaz extension addRegister the required namespacesaz account setaz provider registeraz group createaz aks create
Run the following commands either by using the Bash environment inAzure Cloud Shellor locally usingAzure CLI installed on your computer:
Note
Make sure to change themax-countandmin-countnode values based on your load requirements.
az login
az account set --subscription $SUBSCRIPTION
az provider register --namespace Microsoft.KubernetesConfiguration --wait
az provider register --namespace Microsoft.Kubernetes --wait
az extension add --name k8s-extension --upgrade --yes
az group create \
   --name $AKS_CLUSTER_GROUP_NAME \
   --location $LOCATION
az aks create \
   --resource-group $AKS_CLUSTER_GROUP_NAME \
   --name $AKS_NAME \
   --enable-aad \
   --generate-ssh-keys \
   --enable-cluster-autoscaler \
   --max-count 6 \
   --min-count 1
az login
az account set --subscription $SUBSCRIPTION
az provider register --namespace Microsoft.KubernetesConfiguration --wait
az provider register --namespace Microsoft.Kubernetes --wait
az extension add --name k8s-extension --upgrade --yes
az group create \
   --name $AKS_CLUSTER_GROUP_NAME \
   --location $LOCATION
az aks create \
   --resource-group $AKS_CLUSTER_GROUP_NAME \
   --name $AKS_NAME \
   --enable-aad \
   --generate-ssh-keys \
   --enable-cluster-autoscaler \
   --max-count 6 \
   --min-count 1
max count
enable-cluster-autoscaler
min count
enable-cluster-autoscaler
For more information, see the following resources:
Quickstart: Deploy an Azure Kubernetes Service (AKS) cluster using Azure CLI
az extension add
Register the required namespaces
az account set
az provider register
az group create
az aks create
Connect Kubernetes cluster to Azure Arc
To create your Azure Arc-enabled Kubernetes cluster, connect your Kubernetes cluster to Azure Arc.
Note
You can find the steps in this section and onwards through to creating your connected
environment in a script namedEnvironmentSetup.ps1, which you can find in theGitHub repo namedAzure/logicapps.
You can modify and use this script to meet your requirements and scenarios.
The script is unsigned, so before you run the script, run the following Azure
PowerShell command as an administrator to set the execution policy:
Set-ExecutionPolicy -ExecutionPolicy Unrestricted
Set-ExecutionPolicy -ExecutionPolicy Unrestricted
For more information, seeSet-ExecutionPolicy.
Install the following Azure CLI extensions:az extension add --name connectedk8s --upgrade --yes 
az extension add --name k8s-extension --upgrade --yes 
az extension add --name customlocation --upgrade --yes 
az extension add --name containerapp --upgrade --yesFor more information, see the following resources:Install Azure CLI extensionsaz extension add
Install the following Azure CLI extensions:
az extension add --name connectedk8s --upgrade --yes 
az extension add --name k8s-extension --upgrade --yes 
az extension add --name customlocation --upgrade --yes 
az extension add --name containerapp --upgrade --yes
az extension add --name connectedk8s --upgrade --yes 
az extension add --name k8s-extension --upgrade --yes 
az extension add --name customlocation --upgrade --yes 
az extension add --name containerapp --upgrade --yes
For more information, see the following resources:
Install Azure CLI extensions
az extension add
Register the following required namespaces:az provider register --namespace Microsoft.ExtendedLocation --wait
az provider register --namespace Microsoft.Kubernetes --wait
az provider register --namespace Microsoft.KubernetesConfiguration --wait
az provider register --namespace Microsoft.App --wait
az provider register --namespace Microsoft.OperationalInsights --waitFor more information, see the following resources:Register the required namespacesaz provider register
Register the following required namespaces:
az provider register --namespace Microsoft.ExtendedLocation --wait
az provider register --namespace Microsoft.Kubernetes --wait
az provider register --namespace Microsoft.KubernetesConfiguration --wait
az provider register --namespace Microsoft.App --wait
az provider register --namespace Microsoft.OperationalInsights --wait
az provider register --namespace Microsoft.ExtendedLocation --wait
az provider register --namespace Microsoft.Kubernetes --wait
az provider register --namespace Microsoft.KubernetesConfiguration --wait
az provider register --namespace Microsoft.App --wait
az provider register --namespace Microsoft.OperationalInsights --wait
For more information, see the following resources:
Register the required namespaces
az provider register
Install the Kubernetes command line interface (CLI) namedkubectl:Set-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString('https://chocolatey.org/install.ps1'))

choco install kubernetes-cli -yFor more information, see the following resources:Command line tool (kubectl)Set-ExecutionPolicychoco install kubernetes-cli
Install the Kubernetes command line interface (CLI) namedkubectl:
Set-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString('https://chocolatey.org/install.ps1'))

choco install kubernetes-cli -y
Set-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString('https://chocolatey.org/install.ps1'))

choco install kubernetes-cli -y
For more information, see the following resources:
Command line tool (kubectl)
Set-ExecutionPolicy
choco install kubernetes-cli
Test your connection to your cluster by getting thekubeconfigfile:az aks get-credentials \
   --resource-group $AKS_CLUSTER_GROUP_NAME \
   --name $AKS_NAME \
   --admin
kubectl get nsBy default, thekubeconfigfile is saved toâ¯the path,~/.kube/config. This command applies to our example Kubernetes cluster and differs for other kinds of Kubernetes clusters.For more information, see the following resources:Create connected clusteraz aks get-credentialskubectl get
Test your connection to your cluster by getting thekubeconfigfile:
az aks get-credentials \
   --resource-group $AKS_CLUSTER_GROUP_NAME \
   --name $AKS_NAME \
   --admin
kubectl get ns
az aks get-credentials \
   --resource-group $AKS_CLUSTER_GROUP_NAME \
   --name $AKS_NAME \
   --admin
kubectl get ns
By default, thekubeconfigfile is saved toâ¯the path,~/.kube/config. This command applies to our example Kubernetes cluster and differs for other kinds of Kubernetes clusters.
For more information, see the following resources:
Create connected cluster
az aks get-credentials
kubectl get
Install the Kubernetes package manager namedHelm:choco install kubernetes-helmFor more information, see the following resources:Helmchoco install kubernetes-helm
Install the Kubernetes package manager namedHelm:
choco install kubernetes-helm
choco install kubernetes-helm
For more information, see the following resources:
Helm
choco install kubernetes-helm
Install the SMB driver using the following Helm commands:Add the specified chart repository, get the latest information for available charts, and install the specified chart archive.helm repo add csi-driver-smb https://raw.githubusercontent.com/kubernetes-csi/csi-driver-smb/master/charts 
helm repo update
helm install csi-driver-smb csi-driver-smb/csi-driver-smb --namespace kube-system --version v1.15.0For more information, see the following resources:helm repo addhelm repo updatehelm installConfirm that the SMB driver is installed by running the followingkubectlcommand, which should listsmb.csi.k8s.io:kubectl get csidriverFor more information, seekubectl get.
Install the SMB driver using the following Helm commands:
Add the specified chart repository, get the latest information for available charts, and install the specified chart archive.helm repo add csi-driver-smb https://raw.githubusercontent.com/kubernetes-csi/csi-driver-smb/master/charts 
helm repo update
helm install csi-driver-smb csi-driver-smb/csi-driver-smb --namespace kube-system --version v1.15.0For more information, see the following resources:helm repo addhelm repo updatehelm install
Add the specified chart repository, get the latest information for available charts, and install the specified chart archive.
helm repo add csi-driver-smb https://raw.githubusercontent.com/kubernetes-csi/csi-driver-smb/master/charts 
helm repo update
helm install csi-driver-smb csi-driver-smb/csi-driver-smb --namespace kube-system --version v1.15.0
helm repo add csi-driver-smb https://raw.githubusercontent.com/kubernetes-csi/csi-driver-smb/master/charts 
helm repo update
helm install csi-driver-smb csi-driver-smb/csi-driver-smb --namespace kube-system --version v1.15.0
For more information, see the following resources:
helm repo add
helm repo update
helm install
Confirm that the SMB driver is installed by running the followingkubectlcommand, which should listsmb.csi.k8s.io:kubectl get csidriverFor more information, seekubectl get.
Confirm that the SMB driver is installed by running the followingkubectlcommand, which should listsmb.csi.k8s.io:
kubectl get csidriver
kubectl get csidriver
For more information, seekubectl get.
Connect your Kubernetes cluster to Azure Arc
Based on your Kubernetes cluster deployment, set the following environment variable to provide a name to use for the Azure resource group that contains your Azure Arc-enabled cluster and resources:GROUP_NAME="<Azure-Arc-cluster-resource-group-name>"ParameterRequiredValueDescriptionGROUP_NAMEYes<Azure-Arc-cluster-resource-group-name>The name for the Azure resource group to use with your Azure Arc-enabled cluster and other resources, such as your Azure Container Apps extension, custom location, and Azure Container Apps connected environment. This name must be unique across regions and can contain only letters, numbers, hyphens (-), underscores (_), parentheses (()), and periods (.).This example usesHybrid-Arc-RG.
Based on your Kubernetes cluster deployment, set the following environment variable to provide a name to use for the Azure resource group that contains your Azure Arc-enabled cluster and resources:
GROUP_NAME="<Azure-Arc-cluster-resource-group-name>"
GROUP_NAME="<Azure-Arc-cluster-resource-group-name>"
Create the Azure resource group for your Azure Arc-enabled cluster and resources:az group create \
   --name $GROUP_NAME \
   --location $LOCATIONFor more information, see the following resources:Create connected clusteraz group create
Create the Azure resource group for your Azure Arc-enabled cluster and resources:
az group create \
   --name $GROUP_NAME \
   --location $LOCATION
az group create \
   --name $GROUP_NAME \
   --location $LOCATION
For more information, see the following resources:
Create connected cluster
az group create
Set the following environment variable to provide a name for your Azure Arc-enabled Kubernetes cluster:CONNECTED_CLUSTER_NAME="$GROUP_NAME-cluster"ParameterRequiredValueDescriptionCONNECTED_CLUSTER_NAMEYes<Azure-Arc-cluster-resource-group-name>-clusterThe name to use for your Azure Arc-enabled cluster. This name must be unique across regions and can contain only letters, numbers, hyphens (-), underscores (_), parentheses (()), and periods (.).This example usesHybrid-Arc-RG-cluster.
Set the following environment variable to provide a name for your Azure Arc-enabled Kubernetes cluster:
CONNECTED_CLUSTER_NAME="$GROUP_NAME-cluster"
CONNECTED_CLUSTER_NAME="$GROUP_NAME-cluster"
Connect your previously created Kubernetes cluster to Azure Arc:az connectedk8s connect \
   --resource-group $GROUP_NAME \
   --name $CONNECTED_CLUSTER_NAMEFor more information, see the following resources:Create connected clusteraz connectedk8s connect
Connect your previously created Kubernetes cluster to Azure Arc:
az connectedk8s connect \
   --resource-group $GROUP_NAME \
   --name $CONNECTED_CLUSTER_NAME
az connectedk8s connect \
   --resource-group $GROUP_NAME \
   --name $CONNECTED_CLUSTER_NAME
For more information, see the following resources:
Create connected cluster
az connectedk8s connect
Validate the connection between Azure Arc and your Kubernetes cluster:az connectedk8s show \
   --resource-group $GROUP_NAME \
   --name $CONNECTED_CLUSTER_NAMEIf the output shows that theprovisioningStateâ¯property value isn't set toSucceeded, run the command again after one minute.For more information, see the following resources:Create connected clusteraz connectedk8s show
Validate the connection between Azure Arc and your Kubernetes cluster:
az connectedk8s show \
   --resource-group $GROUP_NAME \
   --name $CONNECTED_CLUSTER_NAME
az connectedk8s show \
   --resource-group $GROUP_NAME \
   --name $CONNECTED_CLUSTER_NAME
If the output shows that theprovisioningStateâ¯property value isn't set toSucceeded, run the command again after one minute.
For more information, see the following resources:
Create connected cluster
az connectedk8s show
Create an Azure Log Analytics workspace
You can create an optional, but recommended, Azure Log Analytics workspace, which provides access to logs for apps that run in your Azure Arc-enabled Kubernetes cluster.
Set the following environment variable to provide a name your Log Analytics workspace:WORKSPACE_NAME="$GROUP_NAME-workspace"ParameterRequiredValueDescriptionWORKSPACE_NAMEYes<Azure-Arc-cluster-resource-group-name>-workspaceThe name to use for your Log Analytics workspace. This name must be unique within your resource group.This example usesHybrid-Arc-RG-workspace.
Set the following environment variable to provide a name your Log Analytics workspace:
WORKSPACE_NAME="$GROUP_NAME-workspace"
WORKSPACE_NAME="$GROUP_NAME-workspace"
Create the Log Analytics workspace:az monitor log-analytics workspace create \
   --resource-group $GROUP_NAME \
   --workspace-name $WORKSPACE_NAMEFor more information, see the following resources:Create a Log Analytics workspaceaz monitor log-analytics
Create the Log Analytics workspace:
az monitor log-analytics workspace create \
   --resource-group $GROUP_NAME \
   --workspace-name $WORKSPACE_NAME
az monitor log-analytics workspace create \
   --resource-group $GROUP_NAME \
   --workspace-name $WORKSPACE_NAME
For more information, see the following resources:
Create a Log Analytics workspace
az monitor log-analytics
Get the base64-encoded ID and shared key for your Log Analytics workspace. You need these values for a later step.LOG_ANALYTICS_WORKSPACE_ID=$(az monitor log-analytics workspace show \
   --resource-group $GROUP_NAME \
   --workspace-name $WORKSPACE_NAME \
   --query customerId \
   --output tsv)

LOG_ANALYTICS_WORKSPACE_ID_ENC=[Convert]::ToBase64String([System.Text.Encoding]::UTF8.GetBytes($LOG_ANALYTICS_WORKSPACE_ID))

LOG_ANALYTICS_KEY=$(az monitor log-analytics workspace get-shared-keys \
   --resource-group $GROUP_NAME \
   --workspace-name $WORKSPACE_NAME \
   --query primarySharedKey \
   --output tsv)

LOG_ANALYTICS_KEY_ENC=[Convert]::ToBase64String([System.Text.Encoding]::UTF8.GetBytes($LOG_ANALYTICS_KEY))ParameterRequiredValueDescriptionLOG_ANALYTICS_WORKSPACE_IDYesThe ID for your Log Analytics workspace.LOG_ANALYTICS_WORKSPACE_ID_ENCYesThe base64-encoded ID for your Log Analytics workspace.LOG_ANALYTICS_KEYYesThe shared key for your Log Analytics workspace.LOG_ANALYTICS_ENCYesThe base64-encoded shared key for your Log Analytics workspace.For more information, see the following resources:Create a Log Analytics workspaceaz monitor log-analytics
Get the base64-encoded ID and shared key for your Log Analytics workspace. You need these values for a later step.
LOG_ANALYTICS_WORKSPACE_ID=$(az monitor log-analytics workspace show \
   --resource-group $GROUP_NAME \
   --workspace-name $WORKSPACE_NAME \
   --query customerId \
   --output tsv)

LOG_ANALYTICS_WORKSPACE_ID_ENC=[Convert]::ToBase64String([System.Text.Encoding]::UTF8.GetBytes($LOG_ANALYTICS_WORKSPACE_ID))

LOG_ANALYTICS_KEY=$(az monitor log-analytics workspace get-shared-keys \
   --resource-group $GROUP_NAME \
   --workspace-name $WORKSPACE_NAME \
   --query primarySharedKey \
   --output tsv)

LOG_ANALYTICS_KEY_ENC=[Convert]::ToBase64String([System.Text.Encoding]::UTF8.GetBytes($LOG_ANALYTICS_KEY))
LOG_ANALYTICS_WORKSPACE_ID=$(az monitor log-analytics workspace show \
   --resource-group $GROUP_NAME \
   --workspace-name $WORKSPACE_NAME \
   --query customerId \
   --output tsv)

LOG_ANALYTICS_WORKSPACE_ID_ENC=[Convert]::ToBase64String([System.Text.Encoding]::UTF8.GetBytes($LOG_ANALYTICS_WORKSPACE_ID))

LOG_ANALYTICS_KEY=$(az monitor log-analytics workspace get-shared-keys \
   --resource-group $GROUP_NAME \
   --workspace-name $WORKSPACE_NAME \
   --query primarySharedKey \
   --output tsv)

LOG_ANALYTICS_KEY_ENC=[Convert]::ToBase64String([System.Text.Encoding]::UTF8.GetBytes($LOG_ANALYTICS_KEY))
For more information, see the following resources:
Create a Log Analytics workspace
az monitor log-analytics
Create and install the Azure Container Apps extension
Now, create and install the Azure Container Apps extension with your Azure Arc-enabled Kubernetes cluster as an on-premises resource.
Important
If you want to deploy to AKS on Azure Local, before you create and
install the Azure Container Apps extension, make sure that youset upHAProxyor a custom load balancer.
Set the following environment variables to the following values:EXTENSION_NAME="logicapps-aca-extension"
NAMESPACE="logicapps-aca-ns"
CONNECTED_ENVIRONMENT_NAME="<connected-environment-name>"ParameterRequiredValueDescriptionEXTENSION_NAMEYeslogicapps-aca-extensionThe name for the Azure Container Apps extension.NAMESPACEYeslogicapps-aca-nsThe cluster namespace where you want to provision resources.CONNECTED_ENVIRONMENT_NAMEYes<connected-environment-name>A unique name to use for the Azure Container Apps connected environment. This name becomes part of the domain name for the Standard logic app that you create, deploy, and host in the Azure Container Apps connected environment.
Set the following environment variables to the following values:
EXTENSION_NAME="logicapps-aca-extension"
NAMESPACE="logicapps-aca-ns"
CONNECTED_ENVIRONMENT_NAME="<connected-environment-name>"
EXTENSION_NAME="logicapps-aca-extension"
NAMESPACE="logicapps-aca-ns"
CONNECTED_ENVIRONMENT_NAME="<connected-environment-name>"
Create and install the extension with Log Analytics enabled for your Azure Arc-enabled Kubernetes cluster. You can't later add Log Analytics to the extension.az k8s-extension create \
   --resource-group $GROUP_NAME \
   --name $EXTENSION_NAME \
   --cluster-type connectedClusters \
   --cluster-name $CONNECTED_CLUSTER_NAME \
   --extension-type 'Microsoft.App.Environment' \
   --release-train stable \
   --auto-upgrade-minor-version true \
   --scope cluster \
   --release-namespace $NAMESPACE \
   --configuration-settings "Microsoft.CustomLocation.ServiceAccount=default" \
   --configuration-settings "appsNamespace=${NAMESPACE}" \
   --configuration-settings "keda.enabled=true" \
   --configuration-settings "keda.logicAppsScaler.enabled=true" \
   --configuration-settings "keda.logicAppsScaler.replicaCount=1" \
   --configuration-settings "containerAppController.api.functionsServerEnabled=true" \
   --configuration-settings "envoy.externalServiceAzureILB=false" \
   --configuration-settings "functionsProxyApiConfig.enabled=true" \
   --configuration-settings "clusterName=${CONNECTED_ENVIRONMENT_NAME}" \
   --configuration-settings "envoy.annotations.service.beta.kubernetes.io/azure-load-balancer-resource-group=${GROUP_NAME}" \
   --configuration-settings "logProcessor.appLogs.destination=log-analytics" \
   --configuration-protected-settings "logProcessor.appLogs.logAnalyticsConfig.customerId=${LOG_ANALYTICS_WORKSPACE_ID_ENC}" \
   --configuration-protected-settings "logProcessor.appLogs.logAnalyticsConfig.sharedKey=${LOG_ANALYTICS_KEY_ENC}"ParameterRequiredDescriptionMicrosoft.CustomLocation.ServiceAccountYesThe service account created for the custom location.Recommendation: Set the value todefault.appsNamespaceYesThe namespace to use for creating app definitions and revisions. This value mustâ¯match the release namespace for the Azure Container Apps extension.clusterNameYesThe name for the Azure Container Apps extension Kubernetes environment to create for the extension.keda.enabledYesEnableKubernetes Event-driven Autoscaling (KEDA). This value is required and must be set totrue.keda.logicAppsScaler.enabledYesEnable the Azure Logic Apps scaler in KEDA. This value is required and must be set totrue.keda.logicAppsScaler.replicaCountYesThe initial number of logic app scalers to start. The default value set to1. This value scales up or scales down to0, if no logic apps exist in the environment.containerAppController.api.functionsServerEnabledYesEnable the service responsible for converting logic app workflow triggers to KEDA-scaled objects. This value is required and must be set totrue.envoy.externalServiceAzureILBYesDetermines whether the envoy acts as an internal load balancer orâ¯aâ¯public load balancer.-true: The envoy acts as an internal load balancer. The Azure Logic Apps runtime is accessible only within private network.-false: The envoy acts as a public load balancer. The Azure Logic Apps runtime is accessible over the public network.functionsProxyApiConfig.enabledYesEnable the proxy service that facilitates API access to the Azure Logic Apps runtime from the Azure portal. This value is required and must be set totrue.envoy.annotations.service.beta.kubernetes.io/azure-load-balancer-resource-groupYes, but only when the underlying cluster is Azure Kubernetes Service.The name for the resource group where the Kubernetes cluster exists.logProcessor.appLogs.destinationNoThe destination to use for application logs. The value is eitherlog-analyticsâ¯orâ¯none, which disables logging.logProcessor.appLogs.logAnalyticsConfig.customerIdYes, but only whenâ¯logProcessor.appLogs.destinationâ¯is set toâ¯log-analytics.The base64-encoded ID for your Log Analytics workspace. Make sure to configure this parameter as a protected setting.logProcessor.appLogs.logAnalyticsConfig.sharedKeyYes, but only whenâ¯logProcessor.appLogs.destinationâ¯is set toâ¯log-analytics.The base64-encoded shared key for your Log Analytics workspace. Make sure to configure this parameter as a protected setting.For more information, see the following resources:Install the Azure Container Apps extensionaz k8s-extension create
Create and install the extension with Log Analytics enabled for your Azure Arc-enabled Kubernetes cluster. You can't later add Log Analytics to the extension.
az k8s-extension create \
   --resource-group $GROUP_NAME \
   --name $EXTENSION_NAME \
   --cluster-type connectedClusters \
   --cluster-name $CONNECTED_CLUSTER_NAME \
   --extension-type 'Microsoft.App.Environment' \
   --release-train stable \
   --auto-upgrade-minor-version true \
   --scope cluster \
   --release-namespace $NAMESPACE \
   --configuration-settings "Microsoft.CustomLocation.ServiceAccount=default" \
   --configuration-settings "appsNamespace=${NAMESPACE}" \
   --configuration-settings "keda.enabled=true" \
   --configuration-settings "keda.logicAppsScaler.enabled=true" \
   --configuration-settings "keda.logicAppsScaler.replicaCount=1" \
   --configuration-settings "containerAppController.api.functionsServerEnabled=true" \
   --configuration-settings "envoy.externalServiceAzureILB=false" \
   --configuration-settings "functionsProxyApiConfig.enabled=true" \
   --configuration-settings "clusterName=${CONNECTED_ENVIRONMENT_NAME}" \
   --configuration-settings "envoy.annotations.service.beta.kubernetes.io/azure-load-balancer-resource-group=${GROUP_NAME}" \
   --configuration-settings "logProcessor.appLogs.destination=log-analytics" \
   --configuration-protected-settings "logProcessor.appLogs.logAnalyticsConfig.customerId=${LOG_ANALYTICS_WORKSPACE_ID_ENC}" \
   --configuration-protected-settings "logProcessor.appLogs.logAnalyticsConfig.sharedKey=${LOG_ANALYTICS_KEY_ENC}"
az k8s-extension create \
   --resource-group $GROUP_NAME \
   --name $EXTENSION_NAME \
   --cluster-type connectedClusters \
   --cluster-name $CONNECTED_CLUSTER_NAME \
   --extension-type 'Microsoft.App.Environment' \
   --release-train stable \
   --auto-upgrade-minor-version true \
   --scope cluster \
   --release-namespace $NAMESPACE \
   --configuration-settings "Microsoft.CustomLocation.ServiceAccount=default" \
   --configuration-settings "appsNamespace=${NAMESPACE}" \
   --configuration-settings "keda.enabled=true" \
   --configuration-settings "keda.logicAppsScaler.enabled=true" \
   --configuration-settings "keda.logicAppsScaler.replicaCount=1" \
   --configuration-settings "containerAppController.api.functionsServerEnabled=true" \
   --configuration-settings "envoy.externalServiceAzureILB=false" \
   --configuration-settings "functionsProxyApiConfig.enabled=true" \
   --configuration-settings "clusterName=${CONNECTED_ENVIRONMENT_NAME}" \
   --configuration-settings "envoy.annotations.service.beta.kubernetes.io/azure-load-balancer-resource-group=${GROUP_NAME}" \
   --configuration-settings "logProcessor.appLogs.destination=log-analytics" \
   --configuration-protected-settings "logProcessor.appLogs.logAnalyticsConfig.customerId=${LOG_ANALYTICS_WORKSPACE_ID_ENC}" \
   --configuration-protected-settings "logProcessor.appLogs.logAnalyticsConfig.sharedKey=${LOG_ANALYTICS_KEY_ENC}"
For more information, see the following resources:
Install the Azure Container Apps extension
az k8s-extension create
Save theâ¯IDvalue for the Azure Container Apps extension to use later:EXTENSION_ID=$(az k8s-extension show \
   --cluster-type connectedClusters \
   --cluster-name $CONNECTED_CLUSTER_NAME \
   --resource-group $GROUP_NAME \
   --name $EXTENSION_NAME \
   --query id \
   --output tsv)ParameterRequiredValueDescriptionEXTENSION_IDYes<extension-ID>The ID for the Azure Container Apps extension.For more information, see the following resources:Install the Azure Container Apps extensionaz k8s-extension show
Save theâ¯IDvalue for the Azure Container Apps extension to use later:
EXTENSION_ID=$(az k8s-extension show \
   --cluster-type connectedClusters \
   --cluster-name $CONNECTED_CLUSTER_NAME \
   --resource-group $GROUP_NAME \
   --name $EXTENSION_NAME \
   --query id \
   --output tsv)
EXTENSION_ID=$(az k8s-extension show \
   --cluster-type connectedClusters \
   --cluster-name $CONNECTED_CLUSTER_NAME \
   --resource-group $GROUP_NAME \
   --name $EXTENSION_NAME \
   --query id \
   --output tsv)
For more information, see the following resources:
Install the Azure Container Apps extension
az k8s-extension show
Before you continue, wait for the extension to fully install. To have your terminal session wait until the installation completes, run the following command:az resource wait \
   --ids $EXTENSION_ID \
   --custom "properties.provisioningState!='Pending'" \
   --api-version "2020-07-01-preview"For more information, see the following resources:Install the Azure Container Apps extensionaz resource wait
Before you continue, wait for the extension to fully install. To have your terminal session wait until the installation completes, run the following command:
az resource wait \
   --ids $EXTENSION_ID \
   --custom "properties.provisioningState!='Pending'" \
   --api-version "2020-07-01-preview"
az resource wait \
   --ids $EXTENSION_ID \
   --custom "properties.provisioningState!='Pending'" \
   --api-version "2020-07-01-preview"
For more information, see the following resources:
Install the Azure Container Apps extension
az resource wait
Create your custom location
Set the following environment variables to the specified values:CUSTOM_LOCATION_NAME="my-custom-location"

CONNECTED_CLUSTER_ID=$(az connectedk8s show \
   --resource-group $GROUP_NAME \
   --name $CONNECTED_CLUSTER_NAME \
   --query id \
   --output tsv)ParameterRequiredValueDescriptionCUSTOM_LOCATION_NAMEYesmy-custom-locationThe name to use for your custom location.CONNECTED_CLUSTER_IDYes<Azure-Arc-cluster-ID>The ID for the Azure Arc-enabled Kubernetes cluster.For more information, see the following resources:Create a custom locationaz k8s-extension show
Set the following environment variables to the specified values:
CUSTOM_LOCATION_NAME="my-custom-location"

CONNECTED_CLUSTER_ID=$(az connectedk8s show \
   --resource-group $GROUP_NAME \
   --name $CONNECTED_CLUSTER_NAME \
   --query id \
   --output tsv)
CUSTOM_LOCATION_NAME="my-custom-location"

CONNECTED_CLUSTER_ID=$(az connectedk8s show \
   --resource-group $GROUP_NAME \
   --name $CONNECTED_CLUSTER_NAME \
   --query id \
   --output tsv)
For more information, see the following resources:
Create a custom location
az k8s-extension show
Create the custom location:az customlocation create \
   --resource-group $GROUP_NAME \
   --name $CUSTOM_LOCATION_NAME \
   --host-resource-id $CONNECTED_CLUSTER_ID \
   --namespace $NAMESPACE \
   --cluster-extension-ids $EXTENSION_ID \
   --location $LOCATIONNoteIf you experience issues creating a custom location on your cluster, you might have toenable the custom location feature on your cluster.
This step is required if you signed in to Azure CLI using a service principal, or if
you signed in as a Microsoft Entra user with restricted permissions on the cluster resource.For more information, see the following resources:Create a custom locationaz customlocation create
Create the custom location:
az customlocation create \
   --resource-group $GROUP_NAME \
   --name $CUSTOM_LOCATION_NAME \
   --host-resource-id $CONNECTED_CLUSTER_ID \
   --namespace $NAMESPACE \
   --cluster-extension-ids $EXTENSION_ID \
   --location $LOCATION
az customlocation create \
   --resource-group $GROUP_NAME \
   --name $CUSTOM_LOCATION_NAME \
   --host-resource-id $CONNECTED_CLUSTER_ID \
   --namespace $NAMESPACE \
   --cluster-extension-ids $EXTENSION_ID \
   --location $LOCATION
Note
If you experience issues creating a custom location on your cluster, you might have toenable the custom location feature on your cluster.
This step is required if you signed in to Azure CLI using a service principal, or if
you signed in as a Microsoft Entra user with restricted permissions on the cluster resource.
For more information, see the following resources:
Create a custom location
az customlocation create
Validate that the custom location is successfully created:az customlocation show \
   --resource-group $GROUP_NAME \
   --name $CUSTOM_LOCATION_NAMEIf the output shows that theprovisioningStateâ¯property value isn't set toSucceeded, run the command again after one minute.
Validate that the custom location is successfully created:
az customlocation show \
   --resource-group $GROUP_NAME \
   --name $CUSTOM_LOCATION_NAME
az customlocation show \
   --resource-group $GROUP_NAME \
   --name $CUSTOM_LOCATION_NAME
If the output shows that theprovisioningStateâ¯property value isn't set toSucceeded, run the command again after one minute.
Save the custom location ID for use in a later step:CUSTOM_LOCATION_ID=$(az customlocation show \
   --resource-group $GROUP_NAME \
   --name $CUSTOM_LOCATION_NAME \
   --query id \
   --output tsv)ParameterRequiredValueDescriptionCUSTOM_LOCATION_IDYes<my-custom-location-ID>The ID for your custom location.For more information, see the following resources:Create a custom locationaz customlocation show
Save the custom location ID for use in a later step:
CUSTOM_LOCATION_ID=$(az customlocation show \
   --resource-group $GROUP_NAME \
   --name $CUSTOM_LOCATION_NAME \
   --query id \
   --output tsv)
CUSTOM_LOCATION_ID=$(az customlocation show \
   --resource-group $GROUP_NAME \
   --name $CUSTOM_LOCATION_NAME \
   --query id \
   --output tsv)
For more information, see the following resources:
Create a custom location
az customlocation show
Create the Azure Container Apps connected environment
Now, create your Azure Container Apps connected environment for your Standard logic app to use.
az containerapp connected-env create \
   --resource-group $GROUP_NAME \
   --name $CONNECTED_ENVIRONMENT_NAME \
   --custom-location $CUSTOM_LOCATION_ID \
   --location $LOCATION
az containerapp connected-env create \
   --resource-group $GROUP_NAME \
   --name $CONNECTED_ENVIRONMENT_NAME \
   --custom-location $CUSTOM_LOCATION_ID \
   --location $LOCATION
For more information, see the following resources:
Create a custom location
az containerapp arc setup-core-dns

Update CoreDNS for a Kubernetes cluster in Azure Local
If your Azure Kubernetes cluster is hosted in Azure Local, you must manually update the CoreDNS configuration for your cluster. This step adds a newconfig mapto your Azure Kubernetes namespace. In comparison, Azure Logic Apps automatically completes this step when your Kubernetes cluster is hosted in Azure. However, for a cluster hosted elsewhere, you must manually complete this step.
For more information, see the following documentation:
CoreDNS for Kubernetes
Customize CoreDNS for Azure Kubernetes Service
ConfigMaps in Kubernetes
Namespaces - core concepts for Azure Kubernetes Service
To update the CoreDNS configuration, run the following Azure CLI command using the options for your scenario:
az containerapp arc setup-core-dns
az containerapp arc setup-core-dns
--distro
AksAzureLocal
--kube-config
--kube-context
skip-ssl-verification
--yes -y
For more information, such as global parameters, seeaz containerapp arc setup-core-dns.
Examples
Set up CoreDNS configuration for Azure Local:az containerapp arc setup-core-dns --distro AksAzureLocal
Set up CoreDNS configuration for Azure Local:
az containerapp arc setup-core-dns --distro AksAzureLocal
az containerapp arc setup-core-dns --distro AksAzureLocal
Set up CoreDNS configuration for Azure Local using a Kubernetes configuration file and the Kubernetes context:az containerapp arc setup-core-dns --distro AksAzureLocal --kube-config <kubeconfig-file-path> --kube-context <kubeconfig-context-name>
Set up CoreDNS configuration for Azure Local using a Kubernetes configuration file and the Kubernetes context:
az containerapp arc setup-core-dns --distro AksAzureLocal --kube-config <kubeconfig-file-path> --kube-context <kubeconfig-context-name>
az containerapp arc setup-core-dns --distro AksAzureLocal --kube-config <kubeconfig-file-path> --kube-context <kubeconfig-context-name>

Create SQL Server storage provider
Standard logic app workflows in the hybrid deployment model use a SQL database as the storage provider for the data used by workflows and the Azure Logic Apps runtime, for example, workflow run history, inputs, outputs, and so on.
Your SQL database requires inbound and outbound connectivity with your Kubernetes cluster, so these resources must exist in the same network.
Set up any of the following SQL Server editions:SQL Server on premisesAzure SQL DatabaseAzure SQL Managed InstanceSQL Server enabled by Azure ArcFor more information, seeSet up SQL database storage for Standard logic app workflows.
Set up any of the following SQL Server editions:
SQL Server on premises
Azure SQL Database
Azure SQL Managed Instance
SQL Server enabled by Azure Arc
For more information, seeSet up SQL database storage for Standard logic app workflows.
Confirm that your SQL database is in the same network as your Arc-enabled Kubernetes cluster and SMB file share.
Confirm that your SQL database is in the same network as your Arc-enabled Kubernetes cluster and SMB file share.
Find and save the connection string for the SQL database that you created.
Find and save the connection string for the SQL database that you created.

Set up SMB file share for artifacts storage
To store artifacts such as maps, schemas, and assemblies for your logic app (container app) resource, you need to have a file share that uses theServer Message Block (SMB) protocol.
You need administrator access to set up your SMB file share.
You need administrator access to set up your SMB file share.
Your SMB file share must exist in the same network as your Kubernetes cluster and SQL database.
Your SMB file share must exist in the same network as your Kubernetes cluster and SQL database.
Your SMB file share requires inbound and outbound connectivity with your Kubernetes cluster. If you enabled Azure virtual network restrictions, make sure that your file share exists in the same virtual network as your Kubernetes cluster or in a peered virtual network.
Your SMB file share requires inbound and outbound connectivity with your Kubernetes cluster. If you enabled Azure virtual network restrictions, make sure that your file share exists in the same virtual network as your Kubernetes cluster or in a peered virtual network.
Don't use the same exact file share path for multiple logic apps.
Don't use the same exact file share path for multiple logic apps.
You can use separate SMB file shares for each logic app, or you can use different folders in the same SMB file share as long as those folders aren't nested. For example, don't have a logic app use the root path, and then have another logic app use a subfolder.
You can use separate SMB file shares for each logic app, or you can use different folders in the same SMB file share as long as those folders aren't nested. For example, don't have a logic app use the root path, and then have another logic app use a subfolder.
To deploy your logic app using Visual Studio Code, make sure that the local computer with Visual Studio Code can access the file share.
To deploy your logic app using Visual Studio Code, make sure that the local computer with Visual Studio Code can access the file share.
Set up your SMB file share on Windows
Make sure that your SMB file share exists in the same virtual network as the cluster where you mount your file share.
In Windows, go to the folder that you want to share, open the shortcut menu, selectProperties.
In Windows, go to the folder that you want to share, open the shortcut menu, selectProperties.
On theSharingtab, selectShare.
On theSharingtab, selectShare.
In the box that opens, select a person who you want to have access to the file share.
In the box that opens, select a person who you want to have access to the file share.
SelectShare, and copy the link for the network path.If your local computer isn't connected to a domain, replace the computer name in the network path with the IP address.
SelectShare, and copy the link for the network path.
If your local computer isn't connected to a domain, replace the computer name in the network path with the IP address.
Save the IP address to use later as the host name.
Save the IP address to use later as the host name.
Set up Azure Files as your SMB file share
Alternatively, for testing purposes, you can useAzure Files as an SMB file share. Make sure that your SMB file share exists in the same virtual network as the cluster where you mount your file share.
In theAzure portal,create an Azure storage account.
In theAzure portal,create an Azure storage account.
From the storage account menu, underData storage, selectFile shares.
From the storage account menu, underData storage, selectFile shares.
From theFile sharespage toolbar, select+ File share, and provide the required information for your SMB file share.
From theFile sharespage toolbar, select+ File share, and provide the required information for your SMB file share.
After deployment completes, selectGo to resource.
After deployment completes, selectGo to resource.
On the file share menu, selectOverview, if not selected.
On the file share menu, selectOverview, if not selected.
On theOverviewpage toolbar, selectConnect. On theConnectpane, selectShow script.
On theOverviewpage toolbar, selectConnect. On theConnectpane, selectShow script.
Copy the following values and save them somewhere safe for later use:File share's host name, for example,mystorage.file.core.windows.netFile share pathUsername withoutlocalhost\Password
Copy the following values and save them somewhere safe for later use:
File share's host name, for example,mystorage.file.core.windows.net
File share path
Username withoutlocalhost\
localhost\
Password
On theOverviewpage toolbar, select+ Add directory, and provide a name to use for the directory. Save this name to use later.
On theOverviewpage toolbar, select+ Add directory, and provide a name to use for the directory. Save this name to use later.
You need these saved values to provide your SMB file share information when you deploy your logic app resource.
For more information, seeCreate an SMB Azure file share.
Confirm SMB file share connection
To test the connection between your Arc-enabled Kubernetes cluster and your SMB file share, and to check that your file share is correctly set up, follow these steps:
If your SMB file share isn't on the same cluster, confirm that the ping operation works from your Arc-enabled Kubernetes cluster to the virtual machine that has your SMB file share. To check that the ping operation works, follow these steps:In your Arc-enabled Kubernetes cluster, create a testpodthat runs any Linux image, such as BusyBox or Ubuntu.Go to the container in your pod, and install theiputils-pingpackage by running the following Linux commands:apt-get update
apt-get install iputils-ping
If your SMB file share isn't on the same cluster, confirm that the ping operation works from your Arc-enabled Kubernetes cluster to the virtual machine that has your SMB file share. To check that the ping operation works, follow these steps:
In your Arc-enabled Kubernetes cluster, create a testpodthat runs any Linux image, such as BusyBox or Ubuntu.
In your Arc-enabled Kubernetes cluster, create a testpodthat runs any Linux image, such as BusyBox or Ubuntu.
Go to the container in your pod, and install theiputils-pingpackage by running the following Linux commands:apt-get update
apt-get install iputils-ping
Go to the container in your pod, and install theiputils-pingpackage by running the following Linux commands:
apt-get update
apt-get install iputils-ping
apt-get update
apt-get install iputils-ping
To confirm that your SMB file share is correctly set up, follow these steps:In your test pod with the same Linux image, create a folder that has the pathâ¯namedmnt/smb.Go to the root or home directory that contains themntfolder.Run the following command:-â¯mount -t cifs //{ip-address-smb-computer}/{file-share-name}/mnt/smb -o username={user-name}, password={password}
To confirm that your SMB file share is correctly set up, follow these steps:
In your test pod with the same Linux image, create a folder that has the pathâ¯namedmnt/smb.
In your test pod with the same Linux image, create a folder that has the pathâ¯namedmnt/smb.
Go to the root or home directory that contains themntfolder.
Go to the root or home directory that contains themntfolder.
Run the following command:-â¯mount -t cifs //{ip-address-smb-computer}/{file-share-name}/mnt/smb -o username={user-name}, password={password}
Run the following command:
-â¯mount -t cifs //{ip-address-smb-computer}/{file-share-name}/mnt/smb -o username={user-name}, password={password}
-â¯mount -t cifs //{ip-address-smb-computer}/{file-share-name}/mnt/smb -o username={user-name}, password={password}
To confirm that artifacts correctly upload, connect to the SMB file share path, and check whether artifact files exist in the correct folder that you specify during deployment.
To confirm that artifacts correctly upload, connect to the SMB file share path, and check whether artifact files exist in the correct folder that you specify during deployment.
Next steps
Create Standard logic app workflows for hybrid deployment on your own infrastructure
Feedback
Was this page helpful?
Additional resources