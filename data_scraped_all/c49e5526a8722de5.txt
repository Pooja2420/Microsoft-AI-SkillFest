Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Share models, components, and environments across workspaces with registries
Article
2025-04-07
14 contributors
In this article
Azure Machine Learning registry enables you to collaborate across workspaces within your organization. Using registries, you can share models, components, and environments.
There are two scenarios where you'd want to use the same set of models, components and environments in multiple workspaces:
Cross-workspace MLOps: You're training a model in adevworkspace and need to deploy it totestandprodworkspaces. In this case you, want to have end-to-end lineage between endpoints to which the model is deployed intestorprodworkspaces and the training job, metrics, code, data, and environment that was used to train the model in thedevworkspace.
dev
test
prod
test
prod
dev
Share and reuse models and pipelines across different teams: Sharing and reuse improve collaboration and productivity. In this scenario, you might want to publish a trained model and the associated components and environments used to train it to a central catalog. From there, colleagues from other teams can search and reuse the assets you shared in their own experiments.
In this article, you learn how to:
Create an environment and component in the registry.
Use the component from registry to submit a model training job in a workspace.
Register the trained model in the registry.
Deploy the model from the registry to an online-endpoint in the workspace, then submit an inference request.
Prerequisites
Before following the steps in this article, make sure you have the following prerequisites:
An Azure subscription. If you don't have an Azure subscription, create a free account before you begin. Try thefree or paid version of Azure Machine Learning.
An Azure Machine Learning registry to share models, components, and environments. To create a registry, seeLearn how to create a registry.
An Azure Machine Learning registry to share models, components, and environments. To create a registry, seeLearn how to create a registry.
An Azure Machine Learning workspace. To create one if you don't have one, use the steps in theQuickstart: Create workspace resourcesarticle.ImportantThe Azure region (location) where you create your workspace must be in the list of supported regions for Azure Machine Learning registry
An Azure Machine Learning workspace. To create one if you don't have one, use the steps in theQuickstart: Create workspace resourcesarticle.
Important
The Azure region (location) where you create your workspace must be in the list of supported regions for Azure Machine Learning registry
The Azure CLI and themlextensionorthe Azure Machine Learning Python SDK v2:Azure CLIPython SDKTo install the Azure CLI and extension, seeInstall, set up, and use the CLI (v2).ImportantThe CLI examples in this article assume that you're using the Bash (or compatible) shell. For example, from a Linux system orWindows Subsystem for Linux.The examples also assume that you configured defaults for the Azure CLI so that you don't have to specify the parameters for your subscription, workspace, resource group, or location. To set default settings, use the following commands. Replace the following parameters with the values for your configuration:Replace<subscription>with your Azure subscription ID.Replace<workspace>with your Azure Machine Learning workspace name.Replace<resource-group>with the Azure resource group that contains your workspace.Replace<location>with the Azure region that contains your workspace.az account set --subscription <subscription>
az configure --defaults workspace=<workspace> group=<resource-group> location=<location>You can see what your current defaults are by using theaz configure -lcommand.To install the Python SDK v2, use the following command:pip install --pre --upgrade azure-ai-ml azure-identity
The Azure CLI and themlextensionorthe Azure Machine Learning Python SDK v2:
ml
Azure CLI
Python SDK
To install the Azure CLI and extension, seeInstall, set up, and use the CLI (v2).
Important
The CLI examples in this article assume that you're using the Bash (or compatible) shell. For example, from a Linux system orWindows Subsystem for Linux.
The CLI examples in this article assume that you're using the Bash (or compatible) shell. For example, from a Linux system orWindows Subsystem for Linux.
The examples also assume that you configured defaults for the Azure CLI so that you don't have to specify the parameters for your subscription, workspace, resource group, or location. To set default settings, use the following commands. Replace the following parameters with the values for your configuration:Replace<subscription>with your Azure subscription ID.Replace<workspace>with your Azure Machine Learning workspace name.Replace<resource-group>with the Azure resource group that contains your workspace.Replace<location>with the Azure region that contains your workspace.az account set --subscription <subscription>
az configure --defaults workspace=<workspace> group=<resource-group> location=<location>You can see what your current defaults are by using theaz configure -lcommand.
The examples also assume that you configured defaults for the Azure CLI so that you don't have to specify the parameters for your subscription, workspace, resource group, or location. To set default settings, use the following commands. Replace the following parameters with the values for your configuration:
Replace<subscription>with your Azure subscription ID.
<subscription>
Replace<workspace>with your Azure Machine Learning workspace name.
<workspace>
Replace<resource-group>with the Azure resource group that contains your workspace.
<resource-group>
Replace<location>with the Azure region that contains your workspace.
<location>
az account set --subscription <subscription>
az configure --defaults workspace=<workspace> group=<resource-group> location=<location>
az account set --subscription <subscription>
az configure --defaults workspace=<workspace> group=<resource-group> location=<location>
You can see what your current defaults are by using theaz configure -lcommand.
az configure -l
To install the Python SDK v2, use the following command:
pip install --pre --upgrade azure-ai-ml azure-identity
pip install --pre --upgrade azure-ai-ml azure-identity
Clone examples repository
The code examples in this article are based on thenyc_taxi_data_regressionsample in theexamples repository. To use these files on your development environment, use the following commands to clone the repository and change directories to the example:
nyc_taxi_data_regression
git clone https://github.com/Azure/azureml-examples
cd azureml-examples
git clone https://github.com/Azure/azureml-examples
cd azureml-examples
Azure CLI
Python SDK
For the CLI example, change directories tocli/jobs/pipelines-with-components/nyc_taxi_data_regressionin your local clone of theexamples repository.
cli/jobs/pipelines-with-components/nyc_taxi_data_regression
cd cli/jobs/pipelines-with-components/nyc_taxi_data_regression
cd cli/jobs/pipelines-with-components/nyc_taxi_data_regression
For the Python SDK example, use thenyc_taxi_data_regressionsample from theexamples repository. The sample notebook,share-models-components-environments.ipynb,is available in thesdk/python/assets/assets-in-registryfolder. All the sample YAML for components, model training code, sample data for training and inference is available incli/jobs/pipelines-with-components/nyc_taxi_data_regression. Change to thesdk/resources/registrydirectory and open theshare-models-components-environments.ipynbnotebook if you'd like to step through a notebook to try out the code in this document.
nyc_taxi_data_regression
sdk/python/assets/assets-in-registry
cli/jobs/pipelines-with-components/nyc_taxi_data_regression
sdk/resources/registry
share-models-components-environments.ipynb
Create SDK connection
Tip
This step is only needed when using the Python SDK.
Create a client connection to both the Azure Machine Learning workspace and registry:
ml_client_workspace = MLClient( credential=credential,
    subscription_id = "<workspace-subscription>",
    resource_group_name = "<workspace-resource-group",
    workspace_name = "<workspace-name>")
print(ml_client_workspace)

ml_client_registry = MLClient(credential=credential,
                        registry_name="<REGISTRY_NAME>",
                        registry_location="<REGISTRY_REGION>")
print(ml_client_registry)
ml_client_workspace = MLClient( credential=credential,
    subscription_id = "<workspace-subscription>",
    resource_group_name = "<workspace-resource-group",
    workspace_name = "<workspace-name>")
print(ml_client_workspace)

ml_client_registry = MLClient(credential=credential,
                        registry_name="<REGISTRY_NAME>",
                        registry_location="<REGISTRY_REGION>")
print(ml_client_registry)
Create environment in registry
Environments define the docker container and Python dependencies required to run training jobs or deploy models. For more information on environments, see the following articles:
Environment concepts
How to create environments (CLI)articles.
Azure CLI
Python SDK
Tip
The same CLI commandaz ml environment createcan be used to create environments in a workspace or registry. Running the command with--workspace-namecommand creates the environment in a workspace whereas running the command with--registry-namecreates the environment in the registry.
az ml environment create
--workspace-name
--registry-name
We create an environment that uses thepython:3.8docker image and installs Python packages required to run a training job using the SciKit Learn framework. If you cloned the examples repo and are in the foldercli/jobs/pipelines-with-components/nyc_taxi_data_regression, you should be able to see environment definition fileenv_train.ymlthat references the docker fileenv_train/Dockerfile. The contents ofenv_train.ymlis as follows:
python:3.8
cli/jobs/pipelines-with-components/nyc_taxi_data_regression
env_train.yml
env_train/Dockerfile
env_train.yml
$schema: https://azuremlschemas.azureedge.net/latest/environment.schema.json
name: SKLearnEnv
version: 1
build:
  path: ./env_train
$schema: https://azuremlschemas.azureedge.net/latest/environment.schema.json
name: SKLearnEnv
version: 1
build:
  path: ./env_train
Create the environment using theaz ml environment createas follows
az ml environment create
az ml environment create --file env_train.yml --registry-name <registry-name>
az ml environment create --file env_train.yml --registry-name <registry-name>
If you get an error that an environment with this name and version already exists in the registry, you can either edit theversionfield inenv_train.ymlor specify a different version on the CLI that overrides the version value inenv_train.yml.
version
env_train.yml
env_train.yml
# use shell epoch time as the version
version=$(date +%s)
az ml environment create --file env_train.yml --registry-name <registry-name> --set version=$version
# use shell epoch time as the version
version=$(date +%s)
az ml environment create --file env_train.yml --registry-name <registry-name> --set version=$version
Tip
version=$(date +%s)works only in Linux. Replace$versionwith a random number if this doesn't work.
version=$(date +%s)
$version
Note down thenameandversionof the environment from the output of theaz ml environment createcommand and use them withaz ml environment showcommands as follows. You'll need thenameandversionin the next section when you create a component in the registry.
name
version
az ml environment create
az ml environment show
name
version
az ml environment show --name SKLearnEnv --version 1 --registry-name <registry-name>
az ml environment show --name SKLearnEnv --version 1 --registry-name <registry-name>
Tip
If you used a different environment name or version, replace the--nameand--versionparameters accordingly.
--name
--version
You can also useaz ml environment list --registry-name <registry-name>to list all environments in the registry.
az ml environment list --registry-name <registry-name>
Tip
The sameMLClient.environments.create_or_update()can be used to create environments in either a workspace or a registry depending on the target it was initialized with. Since you work with both workspace and registry in this document, you initializeml_client_workspaceandml_client_registryto work with workspace and registry respectively.
MLClient.environments.create_or_update()
ml_client_workspace
ml_client_registry
We create an environment that uses thepython:3.8docker image and installs Python packages required to run a training job using the SciKit Learn framework. TheDockerfilewith base image and list of Python packages to install is available incli/jobs/pipelines-with-components/nyc_taxi_data_regression/env_train. Initialize the environment object and create the environment.
python:3.8
Dockerfile
cli/jobs/pipelines-with-components/nyc_taxi_data_regression/env_train
env_docker_context = Environment(
    build=BuildContext(path="../../../../cli/jobs/pipelines-with-components/nyc_taxi_data_regression/env_train/"),
    name="SKLearnEnv",
    version=str(1),
    description="Scikit Learn environment",
)
ml_client_registry.environments.create_or_update(env_docker_context)
env_docker_context = Environment(
    build=BuildContext(path="../../../../cli/jobs/pipelines-with-components/nyc_taxi_data_regression/env_train/"),
    name="SKLearnEnv",
    version=str(1),
    description="Scikit Learn environment",
)
ml_client_registry.environments.create_or_update(env_docker_context)
Tip
If you get an error that an environment with the name and version already exists in the registry, specify a different version for theversionparameter.
version
Note down thenameandversionof the environment from the output and pass them to theml_client_registry.environments.get()method to fetch the environment from registry.
name
version
ml_client_registry.environments.get()
You can also useml_client_registry.environments.list()to list all environments in the registry.
ml_client_registry.environments.list()
You can browse all environments in the Azure Machine Learning studio. Make sure you navigate to the global UI and look for theRegistriesentry.

Create a component in registry
Components are reusable building blocks of Machine Learning pipelines in Azure Machine Learning. You can package the code, command, environment, input interface, and output interface of an individual pipeline step into a component. Then you can reuse the component across multiple pipelines without having to worry about porting dependencies and code each time you write a different pipeline.
Creating a component in a workspace allows you to use the component in any pipeline job within that workspace. Creating a component in a registry allows you to use the component in any pipeline in any workspace within your organization. Creating components in a registry is a great way to build modular reusable utilities or shared training tasks that can be used for experimentation by different teams within your organization.
For more information on components, see the following articles:
Component concepts
Component concepts
How to use components in pipelines (CLI)
How to use components in pipelines (CLI)
How to use components in pipelines (SDK)ImportantRegistry only supports named assets (data/model/component/environment). To reference an asset in a registry, you need to create it in the registry first. Especially for pipeline component case, if you want reference component or environment in pipeline component, you need first create the component or environment in the registry.
How to use components in pipelines (SDK)
Important
Registry only supports named assets (data/model/component/environment). To reference an asset in a registry, you need to create it in the registry first. Especially for pipeline component case, if you want reference component or environment in pipeline component, you need first create the component or environment in the registry.
Azure CLI
Python SDK
Make sure you are in the foldercli/jobs/pipelines-with-components/nyc_taxi_data_regression. You find the component definition filetrain.ymlthat packages a Scikit Learn training scripttrain_src/train.pyand thecurated environmentAzureML-sklearn-0.24-ubuntu18.04-py37-cpu. We use the Scikit Learn environment created in pervious step instead of the curated environment. You can editenvironmentfield in thetrain.ymlto refer to your Scikit Learn environment. The resulting component definition filetrain.ymlis similar to the following example:
cli/jobs/pipelines-with-components/nyc_taxi_data_regression
train.yml
train_src/train.py
AzureML-sklearn-0.24-ubuntu18.04-py37-cpu
environment
train.yml
train.yml
# <component>
$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json
name: train_linear_regression_model
display_name: TrainLinearRegressionModel
version: 1
type: command
inputs:
  training_data: 
    type: uri_folder
  test_split_ratio:
    type: number
    min: 0
    max: 1
    default: 0.2
outputs:
  model_output:
    type: mlflow_model
  test_data:
    type: uri_folder
code: ./train_src
environment: azureml://registries/<registry-name>/environments/SKLearnEnv/versions/1`
command: >-
  python train.py 
  --training_data ${{inputs.training_data}} 
  --test_data ${{outputs.test_data}} 
  --model_output ${{outputs.model_output}}
  --test_split_ratio ${{inputs.test_split_ratio}}
# <component>
$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json
name: train_linear_regression_model
display_name: TrainLinearRegressionModel
version: 1
type: command
inputs:
  training_data: 
    type: uri_folder
  test_split_ratio:
    type: number
    min: 0
    max: 1
    default: 0.2
outputs:
  model_output:
    type: mlflow_model
  test_data:
    type: uri_folder
code: ./train_src
environment: azureml://registries/<registry-name>/environments/SKLearnEnv/versions/1`
command: >-
  python train.py 
  --training_data ${{inputs.training_data}} 
  --test_data ${{outputs.test_data}} 
  --model_output ${{outputs.model_output}}
  --test_split_ratio ${{inputs.test_split_ratio}}
If you used different name or version, the more generic representation looks like this:environment: azureml://registries/<registry-name>/environments/<sklearn-environment-name>/versions/<sklearn-environment-version>, so make sure you replace the<registry-name>,<sklearn-environment-name>and<sklearn-environment-version>accordingly. You then run theaz ml component createcommand to create the component as follows.
environment: azureml://registries/<registry-name>/environments/<sklearn-environment-name>/versions/<sklearn-environment-version>
<registry-name>
<sklearn-environment-name>
<sklearn-environment-version>
az ml component create
az ml component create --file train.yml --registry-name <registry-name>
az ml component create --file train.yml --registry-name <registry-name>
Tip
The same CLI commandaz ml component createcan be used to create components in a workspace or registry. Running the command with--workspace-namecommand creates the component in a workspace whereas running the command with--registry-namecreates the component in the registry.
az ml component create
--workspace-name
--registry-name
If you prefer to not edit thetrain.yml, you can override the environment name on the CLI as follows:
train.yml
az ml component create --file train.yml --registry-name <registry-name>` --set environment=azureml://registries/<registry-name>/environments/SKLearnEnv/versions/1
# or if you used a different name or version, replace `<sklearn-environment-name>` and `<sklearn-environment-version>` accordingly
az ml component create --file train.yml --registry-name <registry-name>` --set environment=azureml://registries/<registry-name>/environments/<sklearn-environment-name>/versions/<sklearn-environment-version>
az ml component create --file train.yml --registry-name <registry-name>` --set environment=azureml://registries/<registry-name>/environments/SKLearnEnv/versions/1
# or if you used a different name or version, replace `<sklearn-environment-name>` and `<sklearn-environment-version>` accordingly
az ml component create --file train.yml --registry-name <registry-name>` --set environment=azureml://registries/<registry-name>/environments/<sklearn-environment-name>/versions/<sklearn-environment-version>
Tip
If you get an error that the name of the component already exists in the registry, you can either edit the version intrain.ymlor override the version on the CLI with a random version.
train.yml
Note down thenameandversionof the component from the output of theaz ml component createcommand and use them withaz ml component showcommands as follows. You'll need thenameandversionin the next section when you create submit a training job in the workspace.
name
version
az ml component create
az ml component show
name
version
az ml component show --name <component_name> --version <component_version> --registry-name <registry-name>
az ml component show --name <component_name> --version <component_version> --registry-name <registry-name>
You can also useaz ml component list --registry-name <registry-name>to list all components in the registry.
az ml component list --registry-name <registry-name>
Review the component definition filetrain.ymland the Python codetrain_src/train.pyto train a regression model using Scikit Learn available in thecli/jobs/pipelines-with-components/nyc_taxi_data_regressionfolder. Load the component object from the component definition filetrain.yml.
train.yml
train_src/train.py
cli/jobs/pipelines-with-components/nyc_taxi_data_regression
train.yml
parent_dir = "../../../../cli/jobs/pipelines-with-components/nyc_taxi_data_regression"
train_model = load_component(path=parent_dir + "/train.yml")
print(train_model)
parent_dir = "../../../../cli/jobs/pipelines-with-components/nyc_taxi_data_regression"
train_model = load_component(path=parent_dir + "/train.yml")
print(train_model)
Update theenvironmentto point to theSKLearnEnvenvironment created in the previous section and create the environment.
environment
SKLearnEnv
train_model.environment=env_from_registry
ml_client_registry.components.create_or_update(train_model)
train_model.environment=env_from_registry
ml_client_registry.components.create_or_update(train_model)
Tip
If you get an error that the name of the component already exists in the registry, you can either update the version withtrain_model.version=<unique_version_number>before creating the component.
train_model.version=<unique_version_number>
Note down thenameandversionof the component from the output and pass them to theml_client_registry.components.get()method to fetch the component from registry.
name
version
ml_client_registry.components.get()
You can also useml_client_registry.components.list()to list all components in the registry or browse all components in the Azure Machine Learning studio UI. Make sure you navigate to the global UI and look for the Registries hub.
ml_client_registry.components.list()
You can browse all components in the Azure Machine Learning studio. Make sure you navigate to the global UI and look for theRegistriesentry.

Run a pipeline job in a workspace using component from registry
When running a pipeline job that uses a component from a registry, thecomputeresources andtraining dataare local to the workspace. For more information on running jobs, see the following articles:
Running jobs (CLI)
Running jobs (SDK)
Pipeline jobs with components (CLI)
Pipeline jobs with components (SDK)
Azure CLI
Python SDK
We run a pipeline job with the Scikit Learn training component created in the previous section to train a model. Check that you are in the foldercli/jobs/pipelines-with-components/nyc_taxi_data_regression. The training dataset is located in thedata_transformedfolder. Edit thecomponentsection in under thetrain_jobsection of thesingle-job-pipeline.ymlfile to refer to the training component created in the previous section.  The resultingsingle-job-pipeline.ymlis as follows:
cli/jobs/pipelines-with-components/nyc_taxi_data_regression
data_transformed
component
train_job
single-job-pipeline.yml
single-job-pipeline.yml
$schema: https://azuremlschemas.azureedge.net/latest/pipelineJob.schema.json
type: pipeline
display_name: nyc_taxi_data_regression_single_job
description: Single job pipeline to train regression model based on nyc taxi dataset

jobs:
  train_job:
    type: command
    component: azureml://registries/<registry-name>/component/train_linear_regression_model/versions/1
    compute: azureml:cpu-cluster
    inputs:
      training_data: 
        type: uri_folder
        path: ./data_transformed
    outputs:
      model_output: 
        type: mlflow_model
      test_data:
$schema: https://azuremlschemas.azureedge.net/latest/pipelineJob.schema.json
type: pipeline
display_name: nyc_taxi_data_regression_single_job
description: Single job pipeline to train regression model based on nyc taxi dataset

jobs:
  train_job:
    type: command
    component: azureml://registries/<registry-name>/component/train_linear_regression_model/versions/1
    compute: azureml:cpu-cluster
    inputs:
      training_data: 
        type: uri_folder
        path: ./data_transformed
    outputs:
      model_output: 
        type: mlflow_model
      test_data:
The key aspect is that this pipeline is going to run in a workspace using a component that isn't in the specific workspace. The component is in a registry that can be used with any workspace in your organization. You can run this training job in any workspace you have access to without having worry about making the training code and environment available in that workspace.
Warning
Before running the pipeline job, confirm that the workspace in which you run the job is in an Azure region that is supported by the registry in which you created the component.
Confirm that the workspace has a compute cluster with the namecpu-clusteror edit thecomputefield underjobs.train_job.computewith the name of your compute.
cpu-cluster
compute
jobs.train_job.compute
Run the pipeline job with theaz ml job createcommand.
az ml job create
az ml job create --file single-job-pipeline.yml
az ml job create --file single-job-pipeline.yml
Tip
If you didn't configure the default workspace and resource group as explained in the prerequisites section, you need to specify the--workspace-nameand--resource-groupparameters for theaz ml job createto work.
--workspace-name
--resource-group
az ml job create
Alternatively, ou can skip editingsingle-job-pipeline.ymland override the component name used bytrain_jobin the CLI.
single-job-pipeline.yml
train_job
az ml job create --file single-job-pipeline.yml --set jobs.train_job.component=azureml://registries/<registry-name>/component/train_linear_regression_model/versions/1
az ml job create --file single-job-pipeline.yml --set jobs.train_job.component=azureml://registries/<registry-name>/component/train_linear_regression_model/versions/1
Since the component used in the training job is shared through a registry, you can submit the job to any workspace that you have access to in your organization, even across different subscriptions. For example, if you havedev-workspace,test-workspaceandprod-workspace, running the training job in these three workspaces is as easy as running threeaz ml job createcommands.
dev-workspace
test-workspace
prod-workspace
az ml job create
az ml job create --file single-job-pipeline.yml --workspace-name dev-workspace --resource-group <resource-group-of-dev-workspace>
az ml job create --file single-job-pipeline.yml --workspace-name test-workspace --resource-group <resource-group-of-test-workspace>
az ml job create --file single-job-pipeline.yml --workspace-name prod-workspace --resource-group <resource-group-of-prod-workspace>
az ml job create --file single-job-pipeline.yml --workspace-name dev-workspace --resource-group <resource-group-of-dev-workspace>
az ml job create --file single-job-pipeline.yml --workspace-name test-workspace --resource-group <resource-group-of-test-workspace>
az ml job create --file single-job-pipeline.yml --workspace-name prod-workspace --resource-group <resource-group-of-prod-workspace>
You run a pipeline job with the Scikit Learn training component created in the previous section to train a model. The training dataset is located in thecli/jobs/pipelines-with-components/nyc_taxi_data_regression/data_transformedfolder. Construct the pipeline using the component created in the previous step.
cli/jobs/pipelines-with-components/nyc_taxi_data_regression/data_transformed
The key aspect is that this pipeline is going to run in a workspace using a component that isn't in the specific workspace. The component is in a registry that can be used with any workspace in your organization. You can run this training job in any workspace you have access to without having worry about making the training code and environment available in that workspace.
@pipeline()
def pipeline_with_registered_components(
    training_data
):
    train_job = train_component_from_registry(
        training_data=training_data,
    )
pipeline_job = pipeline_with_registered_components(
    training_data=Input(type="uri_folder", path=parent_dir + "/data_transformed/"),
)
pipeline_job.settings.default_compute = "cpu-cluster"
print(pipeline_job)
@pipeline()
def pipeline_with_registered_components(
    training_data
):
    train_job = train_component_from_registry(
        training_data=training_data,
    )
pipeline_job = pipeline_with_registered_components(
    training_data=Input(type="uri_folder", path=parent_dir + "/data_transformed/"),
)
pipeline_job.settings.default_compute = "cpu-cluster"
print(pipeline_job)
Warning
Confirm that the workspace in which you run this job is in an Azure location that is supported by the registry in which you created the component before you run the pipeline job.
Confirm that the workspace has a compute cluster with the namecpu-clusteror update itpipeline_job.settings.default_compute=<compute-cluster-name>.
cpu-cluster
pipeline_job.settings.default_compute=<compute-cluster-name>
Run the pipeline job and wait for it to complete.
pipeline_job = ml_client_workspace.jobs.create_or_update(
    pipeline_job, experiment_name="sdk_job_component_from_registry" ,  skip_validation=True
)
ml_client_workspace.jobs.stream(pipeline_job.name)
pipeline_job=ml_client_workspace.jobs.get(pipeline_job.name)
pipeline_job
pipeline_job = ml_client_workspace.jobs.create_or_update(
    pipeline_job, experiment_name="sdk_job_component_from_registry" ,  skip_validation=True
)
ml_client_workspace.jobs.stream(pipeline_job.name)
pipeline_job=ml_client_workspace.jobs.get(pipeline_job.name)
pipeline_job
Tip
Notice that you're usingml_client_workspaceto run the pipeline job whereas you previously usedml_client_registryto use create environment and component.
ml_client_workspace
ml_client_registry
Since the component used in the training job is shared through a registry, you can submit the job to any workspace that you have access to in your organization, even across different subscriptions. For example, if you havedev-workspace,test-workspaceandprod-workspace, you can connect to those workspaces and resubmit the job.
dev-workspace
test-workspace
prod-workspace
In Azure Machine Learning studio, select the endpoint link in the job output to view the job. Here you can analyze training metrics, verify that the job is using the component and environment from registry, and review the trained model. Note down thenameof the job from the output or find the same information from the job overview in Azure Machine Learning studio. You'll need this information to download the trained model in the next section on creating models in registry.
name

Create a model in registry
You learn how to create models in a registry in this section. Reviewmanage modelsto learn more about model management in Azure Machine Learning. We look at two different ways to create a model in a registry. First is from local files. Second, is to copy a model registered in the workspace to a registry.
In both the options, you create model with theMLflow format, which helps you todeploy this model for inference without writing any inference code.
Create a model in registry from local files
Azure CLI
Python SDK
Download the model, which is available as output of thetrain_jobby replacing<job-name>with the name from the job from the previous section. The model along with MLflow metadata files should be available in the./artifacts/model/.
train_job
<job-name>
./artifacts/model/
# fetch the name of the train_job by listing all child jobs of the pipeline job
train_job_name=$(az ml job list --parent-job-name <job-name> --query [0].name | sed 's/\"//g')
# download the default outputs of the train_job
az ml job download --name $train_job_name 
# review the model files
ls -l ./artifacts/model/
# fetch the name of the train_job by listing all child jobs of the pipeline job
train_job_name=$(az ml job list --parent-job-name <job-name> --query [0].name | sed 's/\"//g')
# download the default outputs of the train_job
az ml job download --name $train_job_name 
# review the model files
ls -l ./artifacts/model/
Tip
If you didn't configure the default workspace and resource group as explained in the prerequisites section, you need to specify the--workspace-nameand--resource-groupparameters for theaz ml model createto work.
--workspace-name
--resource-group
az ml model create
Warning
The output ofaz ml job listis passed tosed. This works only on Linux shells. If you are on Windows, runaz ml job list --parent-job-name <job-name> --query [0].nameand strip any quotes you see in the train job name.
az ml job list
sed
az ml job list --parent-job-name <job-name> --query [0].name
If you're unable to download the model, you can find sample MLflow model trained by the training job in the previous section incli/jobs/pipelines-with-components/nyc_taxi_data_regression/artifacts/model/folder.
cli/jobs/pipelines-with-components/nyc_taxi_data_regression/artifacts/model/
Create the model in the registry:
# create model in registry
az ml model create --name nyc-taxi-model --version 1 --type mlflow_model --path ./artifacts/model/ --registry-name <registry-name>
# create model in registry
az ml model create --name nyc-taxi-model --version 1 --type mlflow_model --path ./artifacts/model/ --registry-name <registry-name>
Tip
Use a random number for theversionparameter if you get an error that model name and version already exist.
version
The same CLI commandaz ml model createcan be used to create models in a workspace or registry. Running the command with--workspace-namecommand creates the model in a workspace whereas running the command with--registry-namecreates the model in the registry.
az ml model create
--workspace-name
--registry-name
Make sure you use thepipeline_jobobject from the previous section or fetch the pipeline job usingml_client_workspace.jobs.get(name="<pipeline-job-name>")method to get the list of child jobs in the pipeline. You then look for the job withdisplay_nameastrain_joband download the trained model fromtrain_joboutput. The downloaded model along with MLflow metadata files should be available in the./artifacts/model/.
pipeline_job
ml_client_workspace.jobs.get(name="<pipeline-job-name>")
display_name
train_job
train_job
./artifacts/model/
jobs=ml_client_workspace.jobs.list(parent_job_name=pipeline_job.name)
for job in jobs:
    if (job.display_name == "train_job"):
        print (job.name)
        ml_client_workspace.jobs.download(job.name)
jobs=ml_client_workspace.jobs.list(parent_job_name=pipeline_job.name)
for job in jobs:
    if (job.display_name == "train_job"):
        print (job.name)
        ml_client_workspace.jobs.download(job.name)
If you're unable to download the model, you can find sample MLflow model trained by the training job in the previous section insdk/resources/registry/modelfolder.
sdk/resources/registry/model
Create the model in the registry.
mlflow_model = Model(
    path="./artifacts/model/",
    type=AssetTypes.MLFLOW_MODEL,
    name="nyc-taxi-model",
    version=str(1), # use str(int(time.time())) if you want a random model number
    description="MLflow model created from local path",
)
ml_client_registry.models.create_or_update(mlflow_model)
mlflow_model = Model(
    path="./artifacts/model/",
    type=AssetTypes.MLFLOW_MODEL,
    name="nyc-taxi-model",
    version=str(1), # use str(int(time.time())) if you want a random model number
    description="MLflow model created from local path",
)
ml_client_registry.models.create_or_update(mlflow_model)
Share a model from workspace to registry
In this workflow, you first create the model in the workspace and then share it to the registry. This workflow is useful when you want to test the model in the workspace before sharing it. For example, deploy it to endpoints and try out inference with some test data and then copy the model to a registry if everything looks good. This workflow might also be useful when you're developing a series of models using different techniques, frameworks, or parameters and want to promote just one of them to the registry as a production candidate.
Azure CLI
Python SDK
Make sure you have the name of the pipeline job from the previous section and replace that in the command to fetch the training job name. You then register the model from the output of the training job into the workspace. Note how the--pathparameter refers to the outputtrain_joboutput with theazureml://jobs/$train_job_name/outputs/artifacts/paths/modelsyntax.
--path
train_job
azureml://jobs/$train_job_name/outputs/artifacts/paths/model
# fetch the name of the train_job by listing all child jobs of the pipeline job
train_job_name=$(az ml job list --parent-job-name <job-name> --workspace-name <workspace-name> --resource-group <workspace-resource-group> --query [0].name | sed 's/\"//g')
# create model in workspace
az ml model create --name nyc-taxi-model --version 1 --type mlflow_model --path azureml://jobs/$train_job_name/outputs/artifacts/paths/model
# fetch the name of the train_job by listing all child jobs of the pipeline job
train_job_name=$(az ml job list --parent-job-name <job-name> --workspace-name <workspace-name> --resource-group <workspace-resource-group> --query [0].name | sed 's/\"//g')
# create model in workspace
az ml model create --name nyc-taxi-model --version 1 --type mlflow_model --path azureml://jobs/$train_job_name/outputs/artifacts/paths/model
Tip
Use a random number for theversionparameter if you get an error that the model name and version  already exists.
version
If you haven't configured the default workspace and resource group as explained in the prerequisites section, you need to specify the--workspace-nameand--resource-groupparameters for theaz ml model createto work.
--workspace-name
--resource-group
az ml model create
Note down the model name and version. You can validate if the model is registered in the workspace by browsing it in the Studio UI or usingaz ml model show --name nyc-taxi-model --version $model_versioncommand.
az ml model show --name nyc-taxi-model --version $model_version
Next, you share the model from the workspace to the registry.
# share model registered in workspace to registry
az ml model share --name nyc-taxi-model --version 1 --registry-name <registry-name> --share-with-name <new-name> --share-with-version <new-version>
# share model registered in workspace to registry
az ml model share --name nyc-taxi-model --version 1 --registry-name <registry-name> --share-with-name <new-name> --share-with-version <new-version>
Tip
Make sure to use the right model name and version if you changed it in theaz ml model createcommand.
az ml model create
The above command has two optional parameters "--share-with-name" and "--share-with-version". If these are not provided the new model will have the same name and version as the model that is being shared.
Note down thenameandversionof the model from the output of theaz ml model createcommand and use them withaz ml model showcommands as follows. You'll need thenameandversionin the next section when you deploy the model to an online endpoint for inference.
name
version
az ml model create
az ml model show
name
version
az ml model show --name <model_name> --version <model_version> --registry-name <registry-name>
az ml model show --name <model_name> --version <model_version> --registry-name <registry-name>
You can also useaz ml model list --registry-name <registry-name>to list all models in the registry or browse all components in the Azure Machine Learning studio UI. Make sure you navigate to the global UI and look for the Registries hub.
az ml model list --registry-name <registry-name>
Make sure you use thepipeline_jobobject from the previous section or fetch the pipeline job usingml_client_workspace.jobs.get(name="<pipeline-job-name>")method to get the list of child jobs in the pipeline. You'll then look for the job withdisplay_nameastrain_joband use thenameof thetrain_jobto construct the path pointing to the model output, which looks like this:azureml://jobs/<job_name>/outputs/artifacts/paths/model.
pipeline_job
ml_client_workspace.jobs.get(name="<pipeline-job-name>")
display_name
train_job
name
train_job
azureml://jobs/<job_name>/outputs/artifacts/paths/model
jobs=ml_client_workspace.jobs.list(parent_job_name=pipeline_job.name)
for job in jobs:
    if (job.display_name == "train_job"):
        print (job.name)
        model_path_from_job="azureml://jobs/{job_name}/outputs/artifacts/paths/model".format(job_name=job.name)

print(model_path_from_job)
jobs=ml_client_workspace.jobs.list(parent_job_name=pipeline_job.name)
for job in jobs:
    if (job.display_name == "train_job"):
        print (job.name)
        model_path_from_job="azureml://jobs/{job_name}/outputs/artifacts/paths/model".format(job_name=job.name)

print(model_path_from_job)
Register the model from the output of the training job into the workspace using the path constructed previously.
mlflow_model = Model(
    path=model_path_from_job,
    type=AssetTypes.MLFLOW_MODEL,
    name="nyc-taxi-model",
    version=version_timestamp,
    description="MLflow model created from job output",
)
ml_client_workspace.models.create_or_update(mlflow_model)
mlflow_model = Model(
    path=model_path_from_job,
    type=AssetTypes.MLFLOW_MODEL,
    name="nyc-taxi-model",
    version=version_timestamp,
    description="MLflow model created from job output",
)
ml_client_workspace.models.create_or_update(mlflow_model)
Tip
Notice that you are using MLClient objectml_client_workspacesince you are creating the model in the workspace.
ml_client_workspace
Note down the model name and version. You can validate if the model is registered in the workspace by browsing it in the Studio UI or fetching it usingml_client_workspace.model.get()method.
ml_client_workspace.model.get()
Next, you'll now share the model from the workspace to the registry.
# share the model from registry to workspace
ml_client.models.share(name="nyc-taxi-model", version=1, registry_name=<registry_name>, share_with_name=<new-name>, share_with_version=<new-version>)
# share the model from registry to workspace
ml_client.models.share(name="nyc-taxi-model", version=1, registry_name=<registry_name>, share_with_name=<new-name>, share_with_version=<new-version>)
Tip
The above code has two optional parameters "share-with-name" and "share-with-version". If these are not provided the new model will have the same name and version as the model that is being shared.
Note down thenameandversionof the model from the output and use them withml_client_workspace.model.get()commands as follows. You'll need thenameandversionin the next section when you deploy the model to an online endpoint for inference.
name
version
ml_client_workspace.model.get()
name
version
mlflow_model_from_registry = ml_client_registry.models.get(name="nyc-taxi-model", version=str(1))
print(mlflow_model_from_registry)
mlflow_model_from_registry = ml_client_registry.models.get(name="nyc-taxi-model", version=str(1))
print(mlflow_model_from_registry)
You can also useml_client_registry.models.list()to list all models in the registry or browse all components in the Azure Machine Learning studio UI. Make sure you navigate to the global UI and look for the Registries hub.
ml_client_registry.models.list()
The following screenshot shows a model in a registry in Azure Machine Learning studio. If you created a model from the job output and then copied the model from the workspace to registry, you'll see that the model has a link to the job that trained the model. You can use that link to navigate to the training job to review the code, environment and data used to train the model.

Deploy model from registry to online endpoint in workspace
In the last section, you'll deploy a model from registry to an online endpoint in a workspace. You can choose to deploy any workspace you have access to in your organization, provided the location of the workspace is one of the locations supported by the registry. This capability is helpful if you trained a model in adevworkspace and now need to deploy the model totestorprodworkspace, while preserving the lineage information around the code, environment and data used to train the model.
dev
test
prod
Online endpoints let you deploy models and submit inference requests through the REST APIs. For more information, seeHow to deploy and score a machine learning model by using an online endpoint.
Azure CLI
Python SDK
Create an online endpoint.
az ml online-endpoint create --name reg-ep-1234
az ml online-endpoint create --name reg-ep-1234
Update themodel:linedeploy.ymlavailable in thecli/jobs/pipelines-with-components/nyc_taxi_data_regressionfolder to refer the model name and version from the pervious step. Create an online deployment to the online endpoint. Thedeploy.ymlis shown below for reference.
model:
deploy.yml
cli/jobs/pipelines-with-components/nyc_taxi_data_regression
deploy.yml
$schema: https://azuremlschemas.azureedge.net/latest/managedOnlineDeployment.schema.json
name: demo
endpoint_name: reg-ep-1234
model: azureml://registries/<registry-name>/models/nyc-taxi-model/versions/1
instance_type: Standard_DS2_v2
instance_count: 1
$schema: https://azuremlschemas.azureedge.net/latest/managedOnlineDeployment.schema.json
name: demo
endpoint_name: reg-ep-1234
model: azureml://registries/<registry-name>/models/nyc-taxi-model/versions/1
instance_type: Standard_DS2_v2
instance_count: 1
Create the online deployment. The deployment takes several minutes to complete.
az ml online-deployment create --file deploy.yml --all-traffic
az ml online-deployment create --file deploy.yml --all-traffic
Fetch the scoring URI and submit a sample scoring request. Sample data for the scoring request is available in thescoring-data.jsonin thecli/jobs/pipelines-with-components/nyc_taxi_data_regressionfolder.
scoring-data.json
cli/jobs/pipelines-with-components/nyc_taxi_data_regression
ENDPOINT_KEY=$(az ml online-endpoint get-credentials -n reg-ep-1234 -o tsv --query primaryKey)
SCORING_URI=$(az ml online-endpoint show -n reg-ep-1234 -o tsv --query scoring_uri)
curl --request POST "$SCORING_URI" --header "Authorization: Bearer $ENDPOINT_KEY" --header 'Content-Type: application/json' --data @./scoring-data.json
ENDPOINT_KEY=$(az ml online-endpoint get-credentials -n reg-ep-1234 -o tsv --query primaryKey)
SCORING_URI=$(az ml online-endpoint show -n reg-ep-1234 -o tsv --query scoring_uri)
curl --request POST "$SCORING_URI" --header "Authorization: Bearer $ENDPOINT_KEY" --header 'Content-Type: application/json' --data @./scoring-data.json
Tip
curlcommand works only on Linux.
curl
If you have not configured the default workspace and resource group as explained in the prerequisites section, you will need to specify the--workspace-nameand--resource-groupparameters for theaz ml online-endpointandaz ml online-deploymentcommands to work.
--workspace-name
--resource-group
az ml online-endpoint
az ml online-deployment
Create an online endpoint.
online_endpoint_name = "endpoint-" + datetime.datetime.now().strftime("%m%d%H%M%f")
endpoint = ManagedOnlineEndpoint(
    name=online_endpoint_name,
    description="this is a sample online endpoint for mlflow model",
    auth_mode="key"
)
ml_client_workspace.begin_create_or_update(endpoint)
online_endpoint_name = "endpoint-" + datetime.datetime.now().strftime("%m%d%H%M%f")
endpoint = ManagedOnlineEndpoint(
    name=online_endpoint_name,
    description="this is a sample online endpoint for mlflow model",
    auth_mode="key"
)
ml_client_workspace.begin_create_or_update(endpoint)
Make sure you have themlflow_model_from_registrymodel object from the previous section or fetch the model from the registry usingml_client_registry.models.get()method. Pass it to the deployment configuration object and create the online deployment. The deployment takes several minutes to complete. Set all traffic to be routed to the new deployment.
mlflow_model_from_registry
ml_client_registry.models.get()
demo_deployment = ManagedOnlineDeployment(
    name="demo",
    endpoint_name=online_endpoint_name,
    model=mlflow_model_from_registry,
    instance_type="Standard_F4s_v2",
    instance_count=1
)
ml_client_workspace.online_deployments.begin_create_or_update(demo_deployment)

endpoint.traffic = {"demo": 100}
ml_client_workspace.begin_create_or_update(endpoint)
demo_deployment = ManagedOnlineDeployment(
    name="demo",
    endpoint_name=online_endpoint_name,
    model=mlflow_model_from_registry,
    instance_type="Standard_F4s_v2",
    instance_count=1
)
ml_client_workspace.online_deployments.begin_create_or_update(demo_deployment)

endpoint.traffic = {"demo": 100}
ml_client_workspace.begin_create_or_update(endpoint)
Submit a sample scoring request using the sample data filescoring-data.json. This file is available in thecli/jobs/pipelines-with-components/nyc_taxi_data_regressionfolder.
scoring-data.json
cli/jobs/pipelines-with-components/nyc_taxi_data_regression
# test the  deployment with some sample data
ml_client_workspace.online_endpoints.invoke(
    endpoint_name=online_endpoint_name,
    deployment_name="demo",
    request_file=parent_dir + "/scoring-data.json"
)
# test the  deployment with some sample data
ml_client_workspace.online_endpoints.invoke(
    endpoint_name=online_endpoint_name,
    deployment_name="demo",
    request_file=parent_dir + "/scoring-data.json"
)
Clean up resources
If you aren't going use the deployment, you should delete it to reduce costs. The following example deletes the endpoint and all the underlying deployments:
Azure CLI
Python SDK
az ml online-endpoint delete --name reg-ep-1234 --yes --no-wait
az ml online-endpoint delete --name reg-ep-1234 --yes --no-wait
ml_client_workspace.online_endpoints.begin_delete(name=online_endpoint_name)
ml_client_workspace.online_endpoints.begin_delete(name=online_endpoint_name)
Next steps
How to share data assets using registries
How to create and manage registries
How to manage environments
How to train models
How to create pipelines using components
Feedback
Was this page helpful?
Additional resources