Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Configure LVM on a Linux VM in Azure
Article
2018-09-27
1 contributor
In this article
This document will discuss how to configure Logical Volume Manager (LVM) in your Azure virtual machine. LVM may be used on the OS disk or data disks in Azure VMs, however, by default most cloud images will not have LVM configured on the OS disk. The steps below will focus on configuring LVM for your data disks.
Linear vs. striped logical volumes
LVM can be used to combine a number of physical disks into a single storage volume. By default LVM will usually create linear logical volumes, which means that the physical storage is concatenated together. In this case read/write operations will typically only be sent to a single disk. In contrast, we can also create striped logical volumes where reads and writes are distributed to multiple disks contained in the volume group (similar to RAID0). For performance reasons, it is likely you will want to stripe your logical volumes so that reads and writes utilize all your attached data disks.
This document will describe how to combine several data disks into a single volume group, and then create a striped logical volume. The steps below are generalized to work with most distributions. In most cases the utilities and workflows for managing LVM on Azure are not fundamentally different than other environments. As usual, also consult your Linux vendor for documentation and best practices for using LVM with your particular distribution.
Attaching data disks
One will usually want to start with two or more empty data disks when using LVM. Based on your IO needs, you can choose to attach disks that are stored in our Standard Storage, with up to 500 IO/ps per disk or our Premium storage with up to 5000 IO/ps per disk. This article will not go into detail on how to provision and attach data disks to a Linux virtual machine. See the Microsoft Azure articleattach a diskfor detailed instructions on how to attach an empty data disk to a Linux virtual machine on Azure.
Install the LVM utilities
Ubuntusudo apt-get update
sudo apt-get install lvm2
Ubuntu
sudo apt-get update
sudo apt-get install lvm2
sudo apt-get update
sudo apt-get install lvm2
RHEL, CentOS & Oracle Linuxsudo yum install lvm2
RHEL, CentOS & Oracle Linux
sudo yum install lvm2
sudo yum install lvm2
SLES 12 and openSUSEsudo zypper install lvm2
SLES 12 and openSUSE
sudo zypper install lvm2
sudo zypper install lvm2
SLES 11sudo zypper install lvm2On SLES11, you must also edit/etc/sysconfig/lvmand setLVM_ACTIVATED_ON_DISCOVEREDto "enable":LVM_ACTIVATED_ON_DISCOVERED="enable"
SLES 11
sudo zypper install lvm2
sudo zypper install lvm2
On SLES11, you must also edit/etc/sysconfig/lvmand setLVM_ACTIVATED_ON_DISCOVEREDto "enable":
/etc/sysconfig/lvm
LVM_ACTIVATED_ON_DISCOVERED
LVM_ACTIVATED_ON_DISCOVERED="enable"
LVM_ACTIVATED_ON_DISCOVERED="enable"
Configure LVM
In this guide we will assume you have attached three data disks, which we'll refer to as/dev/sdc,/dev/sddand/dev/sde. These paths may not match the disk path names in your VM. You can run 'sudo fdisk -l' or similar command to list your available disks.
/dev/sdc
/dev/sdd
/dev/sde
sudo fdisk -l
Prepare the physical volumes:sudo pvcreate /dev/sd[cde]
Physical volume "/dev/sdc" successfully created
Physical volume "/dev/sdd" successfully created
Physical volume "/dev/sde" successfully created
Prepare the physical volumes:
sudo pvcreate /dev/sd[cde]
Physical volume "/dev/sdc" successfully created
Physical volume "/dev/sdd" successfully created
Physical volume "/dev/sde" successfully created
sudo pvcreate /dev/sd[cde]
Physical volume "/dev/sdc" successfully created
Physical volume "/dev/sdd" successfully created
Physical volume "/dev/sde" successfully created
Create a volume group. In this example we are calling the volume groupdata-vg01:sudo vgcreate data-vg01 /dev/sd[cde]
Volume group "data-vg01" successfully created
Create a volume group. In this example we are calling the volume groupdata-vg01:
data-vg01
sudo vgcreate data-vg01 /dev/sd[cde]
Volume group "data-vg01" successfully created
sudo vgcreate data-vg01 /dev/sd[cde]
Volume group "data-vg01" successfully created
Create the logical volume(s). The command below we will create a single logical volume calleddata-lv01to span the entire volume group, but note that it is also feasible to create multiple logical volumes in the volume group.sudo lvcreate --extents 100%FREE --stripes 3 --name data-lv01 data-vg01
Logical volume "data-lv01" created.
Create the logical volume(s). The command below we will create a single logical volume calleddata-lv01to span the entire volume group, but note that it is also feasible to create multiple logical volumes in the volume group.
data-lv01
sudo lvcreate --extents 100%FREE --stripes 3 --name data-lv01 data-vg01
Logical volume "data-lv01" created.
sudo lvcreate --extents 100%FREE --stripes 3 --name data-lv01 data-vg01
Logical volume "data-lv01" created.
Format the logical volumesudo mkfs -t ext4 /dev/data-vg01/data-lv01NoteWith SLES11 use-t ext3instead of ext4. SLES11 only supports read-only access to ext4 filesystems.
Format the logical volume
sudo mkfs -t ext4 /dev/data-vg01/data-lv01
sudo mkfs -t ext4 /dev/data-vg01/data-lv01
Note
With SLES11 use-t ext3instead of ext4. SLES11 only supports read-only access to ext4 filesystems.
-t ext3
Add the new file system to /etc/fstab
Important
Improperly editing the/etc/fstabfile could result in an unbootable system. If unsure, refer to the distribution's documentation for information on how to properly edit this file. It is also recommended that a backup of the/etc/fstabfile is created before editing.
/etc/fstab
/etc/fstab
Create the desired mount point for your new file system, for example:sudo mkdir /data
Create the desired mount point for your new file system, for example:
sudo mkdir /data
sudo mkdir /data
Locate the logical volume pathlvdisplay
--- Logical volume ---
LV Path                /dev/data-vg01/data-lv01
....
Locate the logical volume path
lvdisplay
--- Logical volume ---
LV Path                /dev/data-vg01/data-lv01
....
lvdisplay
--- Logical volume ---
LV Path                /dev/data-vg01/data-lv01
....
Open/etc/fstabin a text editor and add an entry for the new file system, for example:/dev/data-vg01/data-lv01  /data  ext4  defaults  0  2Then, save and close/etc/fstab.
Open/etc/fstabin a text editor and add an entry for the new file system, for example:
/etc/fstab
/dev/data-vg01/data-lv01  /data  ext4  defaults  0  2
/dev/data-vg01/data-lv01  /data  ext4  defaults  0  2
Then, save and close/etc/fstab.
/etc/fstab
Test that the/etc/fstabentry is correct:sudo mount -aIf this command results in an error message check the syntax in the/etc/fstabfile.Next run themountcommand to ensure the file system is mounted:mount
......
/dev/mapper/data--vg01-data--lv01 on /data type ext4 (rw)
Test that the/etc/fstabentry is correct:
/etc/fstab
sudo mount -a
sudo mount -a
If this command results in an error message check the syntax in the/etc/fstabfile.
/etc/fstab
Next run themountcommand to ensure the file system is mounted:
mount
mount
......
/dev/mapper/data--vg01-data--lv01 on /data type ext4 (rw)
mount
......
/dev/mapper/data--vg01-data--lv01 on /data type ext4 (rw)
(Optional) Failsafe boot parameters in/etc/fstabMany distributions include either thenobootwaitornofailmount parameters that may be added to the/etc/fstabfile. These parameters allow for failures when mounting a particular file system and allow the Linux system to continue to boot even if it is unable to properly mount the RAID file system. Refer to your distribution's documentation for more information on these parameters.Example (Ubuntu):/dev/data-vg01/data-lv01  /data  ext4  defaults,nobootwait  0  2
(Optional) Failsafe boot parameters in/etc/fstab
/etc/fstab
Many distributions include either thenobootwaitornofailmount parameters that may be added to the/etc/fstabfile. These parameters allow for failures when mounting a particular file system and allow the Linux system to continue to boot even if it is unable to properly mount the RAID file system. Refer to your distribution's documentation for more information on these parameters.
nobootwait
nofail
/etc/fstab
Example (Ubuntu):
/dev/data-vg01/data-lv01  /data  ext4  defaults,nobootwait  0  2
/dev/data-vg01/data-lv01  /data  ext4  defaults,nobootwait  0  2
TRIM/UNMAP support
Some Linux kernels support TRIM/UNMAP operations to discard unused blocks on the disk. These operations are primarily useful in standard storage to inform Azure that deleted pages are no longer valid and can be discarded. Discarding pages can save cost if you create large files and then delete them.
There are two ways to enable TRIM support in your Linux VM. As usual, consult your distribution for the recommended approach:
Use thediscardmount option in/etc/fstab, for example:/dev/data-vg01/data-lv01  /data  ext4  defaults,discard  0  2
Use thediscardmount option in/etc/fstab, for example:
discard
/etc/fstab
/dev/data-vg01/data-lv01  /data  ext4  defaults,discard  0  2
/dev/data-vg01/data-lv01  /data  ext4  defaults,discard  0  2
In some cases thediscardoption may have performance implications. Alternatively, you can run thefstrimcommand manually from the command line, or add it to your crontab to run regularly:Ubuntu# sudo apt-get install util-linux
# sudo fstrim /datadriveRHEL, CentOS & Oracle Linux# sudo yum install util-linux
# sudo fstrim /datadrive
In some cases thediscardoption may have performance implications. Alternatively, you can run thefstrimcommand manually from the command line, or add it to your crontab to run regularly:
discard
fstrim
Ubuntu
# sudo apt-get install util-linux
# sudo fstrim /datadrive
# sudo apt-get install util-linux
# sudo fstrim /datadrive
RHEL, CentOS & Oracle Linux
# sudo yum install util-linux
# sudo fstrim /datadrive
# sudo yum install util-linux
# sudo fstrim /datadrive
Additional resources