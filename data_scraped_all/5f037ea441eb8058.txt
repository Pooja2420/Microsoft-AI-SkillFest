Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Use the cluster autoscaler in Azure Kubernetes Service (AKS)
Article
2024-08-01
39 contributors
In this article
To keep up with application demands in AKS, you might need to adjust the number of nodes that run your workloads. The cluster autoscaler component watches for pods in your cluster that can't be scheduled because of resource constraints. When the cluster autoscaler detects issues, it scales up the number of nodes in the node pool to meet the application demands. It also regularly checks nodes for a lack of running pods and scales down the number of nodes as needed.
This article shows you how to enable and manage the cluster autoscaler in AKS, which is based on theopen-source Kubernetes version.
Before you begin
This article requires Azure CLI version 2.0.76 or later. Runaz --versionto find the version. If you need to install or upgrade, seeInstall Azure CLI.
az --version
Use the cluster autoscaler on an AKS cluster
Important
The cluster autoscaler is a Kubernetes component. Although the AKS cluster uses a virtual machine scale set for the nodes, don't manually enable or edit settings for scale set autoscaling. Let the Kubernetes cluster autoscaler manage the required scale settings. For more information, seeCan I modify the AKS resources in the node resource group?
Enable the cluster autoscaler on a new cluster
Create a resource group using theaz group createcommand.az group create --name myResourceGroup --location eastus
Create a resource group using theaz group createcommand.
az group create
az group create --name myResourceGroup --location eastus
az group create --name myResourceGroup --location eastus
Create an AKS cluster using theaz aks createcommand and enable and configure the cluster autoscaler on the node pool for the cluster using the--enable-cluster-autoscalerparameter and specifying a node--min-countand--max-count. The following example command creates a cluster with a single node backed by a virtual machine scale set, enables the cluster autoscaler, sets a minimum of one and maximum of three nodes:az aks create \
--resource-group myResourceGroup \
--name myAKSCluster \
--node-count 1 \
--vm-set-type VirtualMachineScaleSets \
--load-balancer-sku standard \
--enable-cluster-autoscaler \
--min-count 1 \
--max-count 3 \
--generate-ssh-keysIt takes a few minutes to create the cluster and configure the cluster autoscaler settings.
Create an AKS cluster using theaz aks createcommand and enable and configure the cluster autoscaler on the node pool for the cluster using the--enable-cluster-autoscalerparameter and specifying a node--min-countand--max-count. The following example command creates a cluster with a single node backed by a virtual machine scale set, enables the cluster autoscaler, sets a minimum of one and maximum of three nodes:
az aks create
--enable-cluster-autoscaler
--min-count
--max-count
az aks create \
--resource-group myResourceGroup \
--name myAKSCluster \
--node-count 1 \
--vm-set-type VirtualMachineScaleSets \
--load-balancer-sku standard \
--enable-cluster-autoscaler \
--min-count 1 \
--max-count 3 \
--generate-ssh-keys
az aks create \
--resource-group myResourceGroup \
--name myAKSCluster \
--node-count 1 \
--vm-set-type VirtualMachineScaleSets \
--load-balancer-sku standard \
--enable-cluster-autoscaler \
--min-count 1 \
--max-count 3 \
--generate-ssh-keys
It takes a few minutes to create the cluster and configure the cluster autoscaler settings.
Enable the cluster autoscaler on an existing cluster
Update an existing cluster using theaz aks updatecommand and enable and configure the cluster autoscaler on the node pool using the--enable-cluster-autoscalerparameter and specifying a node--min-countand--max-count. The following example command updates an existing AKS cluster to enable the cluster autoscaler on the node pool for the cluster and sets a minimum of one and maximum of three nodes:az aks update \
  --resource-group myResourceGroup \
  --name myAKSCluster \
  --enable-cluster-autoscaler \
  --min-count 1 \
  --max-count 3It takes a few minutes to update the cluster and configure the cluster autoscaler settings.
Update an existing cluster using theaz aks updatecommand and enable and configure the cluster autoscaler on the node pool using the--enable-cluster-autoscalerparameter and specifying a node--min-countand--max-count. The following example command updates an existing AKS cluster to enable the cluster autoscaler on the node pool for the cluster and sets a minimum of one and maximum of three nodes:
az aks update
--enable-cluster-autoscaler
--min-count
--max-count
az aks update \
  --resource-group myResourceGroup \
  --name myAKSCluster \
  --enable-cluster-autoscaler \
  --min-count 1 \
  --max-count 3
az aks update \
  --resource-group myResourceGroup \
  --name myAKSCluster \
  --enable-cluster-autoscaler \
  --min-count 1 \
  --max-count 3
It takes a few minutes to update the cluster and configure the cluster autoscaler settings.
Disable the cluster autoscaler on a cluster
Disable the cluster autoscaler using theaz aks updatecommand and the--disable-cluster-autoscalerparameter.az aks update \
  --resource-group myResourceGroup \
  --name myAKSCluster \
  --disable-cluster-autoscalerNodes aren't removed when the cluster autoscaler is disabled.
Disable the cluster autoscaler using theaz aks updatecommand and the--disable-cluster-autoscalerparameter.
az aks update
--disable-cluster-autoscaler
az aks update \
  --resource-group myResourceGroup \
  --name myAKSCluster \
  --disable-cluster-autoscaler
az aks update \
  --resource-group myResourceGroup \
  --name myAKSCluster \
  --disable-cluster-autoscaler
Nodes aren't removed when the cluster autoscaler is disabled.
Note
You can manually scale your cluster after disabling the cluster autoscaler using theaz aks scalecommand. If you use the horizontal pod autoscaler, it continues to run with the cluster autoscaler disabled, but pods might end up unable to be scheduled if all node resources are in use.
az aks scale
Re-enable the cluster autoscaler on a cluster
You can re-enable the cluster autoscaler on an existing cluster using theaz aks updatecommand and specifying the--enable-cluster-autoscaler,--min-count, and--max-countparameters.
az aks update
--enable-cluster-autoscaler
--min-count
--max-count
Use the cluster autoscaler on node pools
Use the cluster autoscaler on multiple node pools
You can use the cluster autoscaler withmultiple node poolsand can enable the cluster autoscaler on each individual node pool and pass unique autoscaling rules to them.
Update the settings on an existing node pool using theaz aks nodepool updatecommand.az aks nodepool update \
  --resource-group myResourceGroup \
  --cluster-name myAKSCluster \
  --name nodepool1 \
  --update-cluster-autoscaler \
  --min-count 1 \
  --max-count 5
Update the settings on an existing node pool using theaz aks nodepool updatecommand.
az aks nodepool update
az aks nodepool update \
  --resource-group myResourceGroup \
  --cluster-name myAKSCluster \
  --name nodepool1 \
  --update-cluster-autoscaler \
  --min-count 1 \
  --max-count 5
az aks nodepool update \
  --resource-group myResourceGroup \
  --cluster-name myAKSCluster \
  --name nodepool1 \
  --update-cluster-autoscaler \
  --min-count 1 \
  --max-count 5
Disable the cluster autoscaler on a node pool
Disable the cluster autoscaler on a node pool using theaz aks nodepool updatecommand and the--disable-cluster-autoscalerparameter.az aks nodepool update \
  --resource-group myResourceGroup \
  --cluster-name myAKSCluster \
  --name nodepool1 \
  --disable-cluster-autoscaler
Disable the cluster autoscaler on a node pool using theaz aks nodepool updatecommand and the--disable-cluster-autoscalerparameter.
az aks nodepool update
--disable-cluster-autoscaler
az aks nodepool update \
  --resource-group myResourceGroup \
  --cluster-name myAKSCluster \
  --name nodepool1 \
  --disable-cluster-autoscaler
az aks nodepool update \
  --resource-group myResourceGroup \
  --cluster-name myAKSCluster \
  --name nodepool1 \
  --disable-cluster-autoscaler
Re-enable the cluster autoscaler on a node pool
You can re-enable the cluster autoscaler on a node pool using theaz aks nodepool updatecommand and specifying the--enable-cluster-autoscaler,--min-count, and--max-countparameters.
az aks nodepool update
--enable-cluster-autoscaler
--min-count
--max-count
Note
If you plan on using the cluster autoscaler with node pools that span multiple zones and leverage scheduling features related to zones, such as volume topological scheduling, we recommend you have one node pool per zone and enable--balance-similar-node-groupsthrough the autoscaler profile. This ensures the autoscaler can successfully scale up and keep the sizes of the node pools balanced.
--balance-similar-node-groups
Update the cluster autoscaler settings
As your application demands change, you might need to adjust the cluster autoscaler node count to scale efficiently.
Change the node count using theaz aks updatecommand and update the cluster autoscaler using the--update-cluster-autoscalerparameter and specifying your updated node--min-countand--max-count.az aks update \
  --resource-group myResourceGroup \
  --name myAKSCluster \
  --update-cluster-autoscaler \
  --min-count 1 \
  --max-count 5
Change the node count using theaz aks updatecommand and update the cluster autoscaler using the--update-cluster-autoscalerparameter and specifying your updated node--min-countand--max-count.
az aks update
--update-cluster-autoscaler
--min-count
--max-count
az aks update \
  --resource-group myResourceGroup \
  --name myAKSCluster \
  --update-cluster-autoscaler \
  --min-count 1 \
  --max-count 5
az aks update \
  --resource-group myResourceGroup \
  --name myAKSCluster \
  --update-cluster-autoscaler \
  --min-count 1 \
  --max-count 5
Note
The cluster autoscaler enforces the minimum count in cases where the actual count drops below the minimum due to external factors, such as during a spot eviction or when changing the minimum count value from the AKS API.
Use the cluster autoscaler profile
You can configure more granular details of the cluster autoscaler by changing the default values in the cluster-wide autoscaler profile. For example, a scale down event happens after nodes are under-utilized after 10 minutes. If you have workloads that run every 15 minutes, you might want to change the autoscaler profile to scale down under-utilized nodes after 15 or 20 minutes. When you enable the cluster autoscaler, a default profile is used unless you specify different settings.
Important
The cluster autoscaler profile affectsall node poolsthat use the cluster autoscaler. You can't set an autoscaler profile per node pool. When you set the profile, any existing node pools with the cluster autoscaler enabled immediately start using the profile.
Cluster autoscaler profile settings
The following table lists the available settings for the cluster autoscaler profile:
scan-interval
scale-down-delay-after-add
scale-down-delay-after-delete
scan-interval
scale-down-delay-after-failure
scale-down-unneeded-time
scale-down-unready-time
ignore-daemonsets-utilization
false
daemonset-eviction-for-empty-nodes
false
daemonset-eviction-for-occupied-nodes
true
scale-down-utilization-threshold
max-graceful-termination-sec
balance-similar-node-groups
false
expander
most-pods
random
least-waste
priority
random
skip-nodes-with-local-storage
true
false
skip-nodes-with-system-pods
true
true
max-empty-bulk-delete
new-pod-scale-up-delay
max-total-unready-percentage
max-node-provision-time
ok-total-unready-count
Note
The ignore-daemonsets-utilization, daemonset-eviction-for-empty-nodes, and daemonset-eviction-for-occupied-nodes parameters are GA from API version 2024-05-01. If you are using the CLI to update these flags, please ensure you are using version 2.63 or later.
Set the cluster autoscaler profile on a new cluster
Create an AKS cluster using theaz aks createcommand and set the cluster autoscaler profile using thecluster-autoscaler-profileparameter.az aks create \
    --resource-group myResourceGroup \
    --name myAKSCluster \
    --node-count 1 \
    --enable-cluster-autoscaler \
    --min-count 1 \
    --max-count 3 \
    --cluster-autoscaler-profile scan-interval=30s \
    --generate-ssh-keys
Create an AKS cluster using theaz aks createcommand and set the cluster autoscaler profile using thecluster-autoscaler-profileparameter.
az aks create
cluster-autoscaler-profile
az aks create \
    --resource-group myResourceGroup \
    --name myAKSCluster \
    --node-count 1 \
    --enable-cluster-autoscaler \
    --min-count 1 \
    --max-count 3 \
    --cluster-autoscaler-profile scan-interval=30s \
    --generate-ssh-keys
az aks create \
    --resource-group myResourceGroup \
    --name myAKSCluster \
    --node-count 1 \
    --enable-cluster-autoscaler \
    --min-count 1 \
    --max-count 3 \
    --cluster-autoscaler-profile scan-interval=30s \
    --generate-ssh-keys
Set the cluster autoscaler profile on an existing cluster
Set the cluster autoscaler on an existing cluster using theaz aks updatecommand and thecluster-autoscaler-profileparameter. The following example configures the scan interval setting as30s:az aks update \
  --resource-group myResourceGroup \
  --name myAKSCluster \
  --cluster-autoscaler-profile scan-interval=30s
Set the cluster autoscaler on an existing cluster using theaz aks updatecommand and thecluster-autoscaler-profileparameter. The following example configures the scan interval setting as30s:
az aks update
cluster-autoscaler-profile
az aks update \
  --resource-group myResourceGroup \
  --name myAKSCluster \
  --cluster-autoscaler-profile scan-interval=30s
az aks update \
  --resource-group myResourceGroup \
  --name myAKSCluster \
  --cluster-autoscaler-profile scan-interval=30s
Configure cluster autoscaler profile for aggressive scale down
Note
Scaling down aggressively is not recommended for clusters experiencing frequent scale-outs and scale-ins within short intervals, as it could potentially result in extended node provisioning times under these circumstances. Increasingscale-down-delay-after-addcan help in these circumstances by keeping the node around longer to handle incoming workloads.
scale-down-delay-after-add
az aks update \
     --resource-group myResourceGroup \
     --name myAKSCluster \
     --cluster-autoscaler-profile scan-interval=30s,scale-down-delay-after-add=0m,scale-down-delay-after-failure=1m,scale-down-unneeded-time=3m,scale-down-unready-time=3m,max-graceful-termination-sec=30,skip-nodes-with-local-storage=false,max-empty-bulk-delete=1000,max-total-unready-percentage=100,ok-total-unready-count=1000,max-node-provision-time=15m
az aks update \
     --resource-group myResourceGroup \
     --name myAKSCluster \
     --cluster-autoscaler-profile scan-interval=30s,scale-down-delay-after-add=0m,scale-down-delay-after-failure=1m,scale-down-unneeded-time=3m,scale-down-unready-time=3m,max-graceful-termination-sec=30,skip-nodes-with-local-storage=false,max-empty-bulk-delete=1000,max-total-unready-percentage=100,ok-total-unready-count=1000,max-node-provision-time=15m
Configure cluster autoscaler profile for bursty workloads
az aks update \   
     --resource-group "myResourceGroup" \
     --name myAKSCluster \ 
     --cluster-autoscaler-profile scan-interval=20s,scale-down-delay-after-add=10m,scale-down-delay-after-failure=1m,scale-down-unneeded-time=5m,scale-down-unready-time=5m,max-graceful-termination-sec=30,skip-nodes-with-local-storage=false,max-empty-bulk-delete=100,max-total-unready-percentage=100,ok-total-unready-count=1000,max-node-provision-time=15m
az aks update \   
     --resource-group "myResourceGroup" \
     --name myAKSCluster \ 
     --cluster-autoscaler-profile scan-interval=20s,scale-down-delay-after-add=10m,scale-down-delay-after-failure=1m,scale-down-unneeded-time=5m,scale-down-unready-time=5m,max-graceful-termination-sec=30,skip-nodes-with-local-storage=false,max-empty-bulk-delete=100,max-total-unready-percentage=100,ok-total-unready-count=1000,max-node-provision-time=15m
Reset cluster autoscaler profile to default values
Reset the cluster autoscaler profile using theaz aks updatecommand.az aks update \
  --resource-group myResourceGroup \
  --name myAKSCluster \
  --cluster-autoscaler-profile ""
Reset the cluster autoscaler profile using theaz aks updatecommand.
az aks update
az aks update \
  --resource-group myResourceGroup \
  --name myAKSCluster \
  --cluster-autoscaler-profile ""
az aks update \
  --resource-group myResourceGroup \
  --name myAKSCluster \
  --cluster-autoscaler-profile ""
Retrieve cluster autoscaler logs and status
You can retrieve logs and status updates from the cluster autoscaler to help diagnose and debug autoscaler events. AKS manages the cluster autoscaler on your behalf and runs it in the managed control plane. You can enable control plane node to see the logs and operations from the cluster autoscaler.
Azure CLI
Azure portal
Set up a rule for resource logs to push cluster autoscaler logs to Log Analytics using theinstructions here. Make sure you check the box forcluster-autoscalerwhen selecting options forLogs.
Set up a rule for resource logs to push cluster autoscaler logs to Log Analytics using theinstructions here. Make sure you check the box forcluster-autoscalerwhen selecting options forLogs.
cluster-autoscaler
Select theLogsection on your cluster.
Select theLogsection on your cluster.
Enter the following example query into Log Analytics:AzureDiagnostics
| where Category == "cluster-autoscaler"
Enter the following example query into Log Analytics:
AzureDiagnostics
| where Category == "cluster-autoscaler"
AzureDiagnostics
| where Category == "cluster-autoscaler"
View cluster autoscaler scale-up not triggered events on CLI.kubectl get events --field-selector source=cluster-autoscaler,reason=NotTriggerScaleUp
View cluster autoscaler scale-up not triggered events on CLI.
kubectl get events --field-selector source=cluster-autoscaler,reason=NotTriggerScaleUp
kubectl get events --field-selector source=cluster-autoscaler,reason=NotTriggerScaleUp
View cluster autoscaler warning events on CLI.kubectl get events --field-selector source=cluster-autoscaler,type=Warning
View cluster autoscaler warning events on CLI.
kubectl get events --field-selector source=cluster-autoscaler,type=Warning
kubectl get events --field-selector source=cluster-autoscaler,type=Warning
The cluster autoscaler also writes out the health status to aconfigmapnamedcluster-autoscaler-status. You can retrieve these logs using the followingkubectlcommand:kubectl get configmap -n kube-system cluster-autoscaler-status -o yaml
The cluster autoscaler also writes out the health status to aconfigmapnamedcluster-autoscaler-status. You can retrieve these logs using the followingkubectlcommand:
configmap
cluster-autoscaler-status
kubectl
kubectl get configmap -n kube-system cluster-autoscaler-status -o yaml
kubectl get configmap -n kube-system cluster-autoscaler-status -o yaml
In theAzure portal, navigate to your AKS cluster.
In theAzure portal, navigate to your AKS cluster.
In the service menu, underSettings, selectNode pools.
In the service menu, underSettings, selectNode pools.
Select any of the tiles forAutoscale events,Autoscale warnings, orScale-up not triggeredto get more details.
Select any of the tiles forAutoscale events,Autoscale warnings, orScale-up not triggeredto get more details.

For more information, see theKubernetes/autoscaler GitHub project FAQ.
Cluster Autoscaler Metrics
You can enablecontrol plane metrics (Preview)to see the logs and operations from thecluster autoscalerwith theAzure Monitor managed service for Prometheus add-on
Next steps
This article showed you how to automatically scale the number of AKS nodes. You can also use the horizontal pod autoscaler to automatically adjust the number of pods that run your application. For steps on using the horizontal pod autoscaler, seeScale applications in AKS.
To further help improve cluster resource utilization and free up CPU and memory for other pods, seeVertical Pod Autoscaler.
Azure Kubernetes Service

Additional resources