Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Vectors in Azure AI Search
Article
2025-02-25
8 contributors
In this article
Vector search is an approach in information retrieval that supports indexing and query execution over numeric representations of content. Because the content is numeric rather than plain text, matching is based on vectors that are most similar to the query vector, which enables matching across:
semantic or conceptual likeness ("dog" and "canine", conceptually similar yet linguistically distinct)
multilingual content ("dog" in English and "hund" in German)
multiple content types ("dog" in plain text and a photograph of a dog in an image file)
This article providesa high-level introduction to vector supportin Azure AI Search. It also explains integration with other Azure services and coversterminology and conceptsrelated to vector search development.
We recommend this article for background, but if you'd rather get started, follow these steps:
Provide embeddingsfor your index orgenerate embeddingsin an indexer pipeline
Create a vector index
Run vector queries
You could also begin with thevector quickstartor thecode samples on GitHub.
What scenarios can vector search support?
Scenarios for vector search include:
Similarity search. Encode text using embedding models such as OpenAI embeddings or open source models such as SBERT, and retrieve documents with queries that are also encoded as vectors.
Similarity search. Encode text using embedding models such as OpenAI embeddings or open source models such as SBERT, and retrieve documents with queries that are also encoded as vectors.
Search across different content types (multimodal). Encode images and text using multimodal embeddings (for example, withOpenAI CLIPorGPT-4 Turbo with Visionin Azure OpenAI) and query an embedding space composed of vectors from both content types.
Search across different content types (multimodal). Encode images and text using multimodal embeddings (for example, withOpenAI CLIPorGPT-4 Turbo with Visionin Azure OpenAI) and query an embedding space composed of vectors from both content types.
Hybrid search. In Azure AI Search, we define hybrid search as dual vector and keyword query execution in the same request. Vector support is implemented at the field level. If an index contains both vector and non-vector fields, you can write a query that targets both. The queries execute in parallel and the results are merged into a single response and ranked accordingly.
Hybrid search. In Azure AI Search, we define hybrid search as dual vector and keyword query execution in the same request. Vector support is implemented at the field level. If an index contains both vector and non-vector fields, you can write a query that targets both. The queries execute in parallel and the results are merged into a single response and ranked accordingly.
Multilingual search. Azure AI Search is designed for extensibility. If you have embedding models and chat models trained in multiple languages, you can call them through custom or built-in skills on the indexing side, or vectorizers on the query side. If you need more control over text translation, you can supplement with themulti-language capabilitiesthat Azure AI Search supports for nonvector content, in hybrid search scenarios.
Multilingual search. Azure AI Search is designed for extensibility. If you have embedding models and chat models trained in multiple languages, you can call them through custom or built-in skills on the indexing side, or vectorizers on the query side. If you need more control over text translation, you can supplement with themulti-language capabilitiesthat Azure AI Search supports for nonvector content, in hybrid search scenarios.
Filtered vector search. A query request can include a vector query and afilter expression. Filters apply to text and numeric fields, and are useful for metadata filters, and including or excluding search results based on filter criteria. Although a vector field isn't filterable itself, you can set up a filterable text or numeric field. The search engine can process the filter before or after the vector query executes.
Filtered vector search. A query request can include a vector query and afilter expression. Filters apply to text and numeric fields, and are useful for metadata filters, and including or excluding search results based on filter criteria. Although a vector field isn't filterable itself, you can set up a filterable text or numeric field. The search engine can process the filter before or after the vector query executes.
Vector database. Azure AI Search stores the data that you query over. Use it as apure vector storeany time you need long-term memory or a knowledge base, or grounding data forRetrieval Augmented Generation (RAG) architecture, or any app that uses vectors.
Vector database. Azure AI Search stores the data that you query over. Use it as apure vector storeany time you need long-term memory or a knowledge base, or grounding data forRetrieval Augmented Generation (RAG) architecture, or any app that uses vectors.
How vector search works in Azure AI Search
Vector support includes indexing, storing, and querying of vector embeddings from a search index.
The following diagram shows the indexing and query workflows for vector search.

On the indexing side, Azure AI Search takes vector embeddings and uses anearest neighbors algorithmto place similar vectors close together in an index. Internally, it creates vector indexes for each vector field.
How you get embeddings from your source content into Azure AI Search depends on whether you want to perform the work within an Azure AI Search indexing pipeline, or externally.  Azure AI Search offersintegrated data chunking and vectorizationin an indexer pipeline. You still provide the resources (endpoints and connection information to Azure OpenAI), but Azure AI Search makes all of the calls and handles the transitions. This approach requires an indexer, a supported data source, and a skillset that drives chunking and embedding. If you don't want to use indexers, you can handle all vectorization externally, and then push prevectorized content intovector fieldsin the search index.
On the query side, in your client application, you collect the query input from a user, usually through a prompt workflow. You can then add an encoding step that converts the input into a vector, and then send the vector query to your index on Azure AI Search for a similarity search. As with indexing, you can deploy theintegrated vectorizationto convert the question into a vector. For either approach, Azure AI Search returns documents with the requestedknearest neighbors (kNN) in the results.
k
Azure AI Search supportshybrid scenariosthat run vector and keyword search in parallel, returning a unified result set that often provides better results than just vector or keyword search alone. For hybrid, vector and non-vector content is ingested into the same index, for queries that run side by side.
Availability and pricing
Vector search is available as part of all Azure AI Search tiers in all regions at no extra charge.
Newer services created after April 3, 2024 supporthigher quotas for vector indexes. If you have an older service, you might be able toupgrade your servicefor higher vector quotas.
Vector search is available in:
Azure portal: Import and vectorize data wizard
Azure REST APIs
Azure SDKs for .NET,Python, andJavaScript
Other Azure offerings such as Azure AI Foundry.
Note
Some older search services created before January 1, 2019 are deployed on infrastructure that doesn't support vector workloads. If you try to add a vector field to a schema and get an error, it's a result of outdated services. In this situation, you must create a new search service to try out the vector feature.
Azure integration and related services
Azure AI Search is deeply integrated across the Azure AI platform. The following table lists several that are useful in vector workloads.
It's also commonly used in open-source frameworks likeLangChain.
Vector search concepts
If you're new to vectors, this section explains some core concepts.
About vector search
Vector search is a method of information retrieval where documents and queries are represented as vectors instead of plain text. In vector search, machine learning models generate the vector representations of source inputs, which can be text, images, or other content. Having a mathematic representation of content provides a common language for comparing disparate content. If everything is a vector, a query can find a match in vector space, even if the associated original content is in different media or language than the query.
Why use vector search
When searchable content is represented as vectors, a query can find close matches in similar content. The embedding model used for vector generation knows which words and concepts are similar, and it places the resulting vectors close together in the embedding space. For example, vectorized source documents about "clouds" and "fog" are more likely to show up in a query about "mist" because they're semantically similar, even if they aren't a lexical match.
Embeddings and vectorization
Embeddingsare a specific type of vector representation of content or a query, created by machine learning models that capture the semantic meaning of text or representations of other content such as images. Natural language machine learning models are trained on large amounts of data to identify patterns and relationships between words. During training, they learn to represent any input as a vector of real numbers in an intermediary step called theencoder. After training is complete, these language models can be modified so the intermediary vector representation becomes the model's output. The resulting embeddings are high-dimensional vectors, where words with similar meanings are closer together in the vector space, as explained inUnderstand embeddings (Azure OpenAI).
The effectiveness of vector search in retrieving relevant information depends on the effectiveness of the embedding model in distilling the meaning of documents and queries into the resulting vector. The best models are well-trained on the types of data they're representing. You can evaluate existing models such as Azure OpenAI text-embedding-ada-002, bring your own model that's trained directly on the problem space, or fine-tune a general-purpose model. Azure AI Search doesn't impose constraints on which model you choose, so pick the best one for your data.
In order to create effective embeddings for vector search, it's important to take input size limitations into account. We recommend following theguidelines for chunking databefore generating embeddings. This best practice ensures that the embeddings accurately capture the relevant information and enable more efficient vector search.
What is the embedding space?
Embedding spaceis the corpus for vector queries. Within a search index, an embedding space is all of the vector fields populated with embeddings from the same embedding model. Machine learning models create the embedding space by mapping individual words, phrases, or documents (for natural language processing), images, or other forms of data into a representation comprised of a vector of real numbers representing a coordinate in a high-dimensional space. In this embedding space, similar items are located close together, and dissimilar items are located farther apart.
For example, documents that talk about different species of dogs would be clustered close together in the embedding space. Documents about cats would be close together, but farther from the dogs cluster while still being in the neighborhood for animals. Dissimilar concepts such as cloud computing would be much farther away. In practice, these embedding spaces are abstract and don't have well-defined, human-interpretable meanings, but the core idea stays the same.

Nearest neighbors search
In vector search, the search engine scans vectors within the embedding space to identify vectors that are closest to the query vector. This technique is callednearest neighbor search. Nearest neighbors help quantify the similarity between items. A high degree of vector similarity indicates that the original data was similar too. To facilitate fast nearest neighbor search, the search engine performs optimizations, or employs data structures and data partitioning, to reduce the search space. Each vector search algorithm solves the nearest neighbor problems in different ways as they optimize for minimum latency, maximum throughput, recall, and memory. To compute similarity, similarity metrics provide the mechanism for computing distance.
Azure AI Search currently supports the following algorithms:
Hierarchical Navigable Small World (HNSW): HNSW is a leading ANN algorithm optimized for high-recall, low-latency applications where data distribution is unknown or can change frequently. It organizes high-dimensional data points into a hierarchical graph structure that enables fast and scalable similarity search while allowing a tunable a trade-off between search accuracy and computational cost. Because the algorithm requires all data points to reside in memory for fast random access, this algorithm consumesvector index sizequota.
Hierarchical Navigable Small World (HNSW): HNSW is a leading ANN algorithm optimized for high-recall, low-latency applications where data distribution is unknown or can change frequently. It organizes high-dimensional data points into a hierarchical graph structure that enables fast and scalable similarity search while allowing a tunable a trade-off between search accuracy and computational cost. Because the algorithm requires all data points to reside in memory for fast random access, this algorithm consumesvector index sizequota.
Exhaustive K-nearest neighbors (KNN): Calculates the distances between the query vector and all data points. It's computationally intensive, so it works best for smaller datasets. Because the algorithm doesn't require fast random access of data points, this algorithm doesn't consume vector index size quota. However, this algorithm provides the global set of nearest neighbors.
Exhaustive K-nearest neighbors (KNN): Calculates the distances between the query vector and all data points. It's computationally intensive, so it works best for smaller datasets. Because the algorithm doesn't require fast random access of data points, this algorithm doesn't consume vector index size quota. However, this algorithm provides the global set of nearest neighbors.
To use these algorithms, seeCreate a vector fieldfor instructions on specifying the algorithm, vector profiles, and profile assignment.
Algorithm parameters that are used to initialize the index during index creation are immutable and can't be changed after the index is built. However, parameters that affect the query-time characteristics (efSearch) can be modified.
efSearch
In addition, fields that specify HNSW algorithm also support exhaustive KNN search using thequery requestparameter"exhaustive": true. The opposite isn't true however. If a field is indexed forexhaustiveKnn, you can't use HNSW in the query because the extra data structures that enable efficient search donât exist.
"exhaustive": true
exhaustiveKnn
Approximate Nearest Neighbors
Approximate Nearest Neighbor (ANN) search is a class of algorithms for finding matches in vector space. This class of algorithms employs different data structures or data partitioning methods to significantly reduce the search space to accelerate query processing.
ANN algorithms sacrifice some accuracy, but offer scalable and faster retrieval of approximate nearest neighbors, which makes them ideal for balancing accuracy against efficiency in modern information retrieval applications. You can adjust the parameters of your algorithm to fine-tune the recall, latency, memory, and disk footprint requirements of your search application.
Azure AI Search uses HNSW for its ANN algorithm.
Next steps
Try the quickstart
Learn more about vector indexing
Learn more about vector queries
Azure Cognitive Search and LangChain: A Seamless Integration for Enhanced Vector Search Capabilities
Feedback
Was this page helpful?
Additional resources