Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
What are Azure AI containers?
Article
2025-03-31
8 contributors
In this article
Azure AI services provide severalDocker containersthat let you use the same APIs that are available in Azure, on-premises. Using these containers gives you the flexibility to bring Azure AI services closer to your data for compliance, security or other operational reasons. Container support is currently available for a subset of Azure AI services.
Containerization is an approach to software distribution in which an application or service, including its dependencies & configuration, is packaged together as a container image. With little or no modification, a container image can be deployed on a container host. Containers are isolated from each other and the underlying operating system, with a smaller footprint than a virtual machine. Containers can be instantiated from container images for short-term tasks, and removed when no longer needed.
Features and benefits
Immutable infrastructure: Enable DevOps teams to leverage a consistent and reliable set of known system parameters, while being able to adapt to change. Containers provide the flexibility to pivot within a predictable ecosystem and avoid configuration drift.
Control over data: Choose where your data gets processed by Azure AI services. This can be essential if you can't send data to the cloud but need access to Azure AI services APIs. Support consistency in hybrid environments â across data, management, identity, and security.
Control over model updates: Flexibility in versioning and updating of models deployed in their solutions.
Portable architecture: Enables the creation of a portable application architecture that can be deployed on Azure, on-premises and the edge. Containers can be deployed directly toAzure Kubernetes Service,Azure Container Instances, or to aKubernetescluster deployed toAzure Stack. For more information, seeDeploy Kubernetes to Azure Stack.
High throughput / low latency: Provide customers the ability to scale for high throughput and low latency requirements by enabling Azure AI services to run physically close to their application logic and data. Containers don't cap transactions per second (TPS) and can be made to scale both up and out to handle demand if you provide the necessary hardware resources.
Scalability: With the ever growing popularity of containerization and container orchestration software, such as Kubernetes; scalability is at the forefront of technological advancements. Building on a scalable cluster foundation, application development caters to high availability.
Containers in Azure AI services
Azure AI containers provide the following set of Docker containers, each of which contains a subset of functionality from services in Azure AI services. You can find instructions and image locations in the tables below.
Note
SeeInstall and run Document Intelligence containersforAzure AI Document Intelligencecontainer instructions and image locations.
Decision containers
Language containers
Speech containers
Vision containers
Additionally, some containers are supported in theAzure AI services multi-service resourceoffering. You can create one single Azure AI services resource and use the same billing key across supported services for the following services:
Azure AI Vision
LUIS
Language service
Prerequisites
You must satisfy the following prerequisites before using Azure AI containers:
Docker Engine: You must have Docker Engine installed locally. Docker provides packages that configure the Docker environment onmacOS,Linux, andWindows. On Windows, Docker must be configured to support Linux containers. Docker containers can also be deployed directly toAzure Kubernetes ServiceorAzure Container Instances.
Docker must be configured to allow the containers to connect with and send billing data to Azure.
Familiarity with Microsoft Container Registry and Docker: You should have a basic understanding of both Microsoft Container Registry and Docker concepts, like registries, repositories, containers, and container images, as well as knowledge of basicdockercommands.
docker
For a primer on Docker and container basics, see theDocker overview.
Individual containers can have their own requirements, as well, including server and memory allocation requirements.
Azure AI services container security
Security should be a primary focus whenever you're developing applications. The importance of security is a metric for success. When you're architecting a software solution that includes Azure AI containers, it's vital to understand the limitations and capabilities available to you. For more information about network security, seeConfigure Azure AI services virtual networks.
Important
By default there isno securityon the Azure AI services container API. The reason for this is that most often the container will run as part of a pod which is protected from the outside by a network bridge. However, it is possible for users to construct their own authentication infrastructure to approximate the authentication methods used when accessing thecloud-based Azure AI services.
The following diagram illustrates the default andnon-secureapproach:

As an example of an alternative andsecureapproach, consumers of Azure AI containers could augment a container with a front-facing component, keeping the container endpoint private. Let's consider a scenario where we useIstioas an ingress gateway. Istio supports HTTPS/TLS and client-certificate authentication. In this scenario, the Istio frontend exposes the container access, presenting the client certificate that is approved beforehand with Istio.
Nginxis another popular choice in the same category. Both Istio and Nginx act as a service mesh and offer additional features including things like load-balancing, routing, and rate-control.
Container networking
The Azure AI containers are required to submit metering information for billing purposes. Failure to allowlist various network channels that the Azure AI containers rely on will prevent the container from working.
The host should allowlistport 443and the following domains:
*.cognitive.microsoft.com
*.cognitive.microsoft.com
*.cognitiveservices.azure.com
*.cognitiveservices.azure.com
Deep packet inspection (DPI)is a type of data processing that inspects in detail the data sent over a computer network, and usually takes action by blocking, rerouting, or logging it accordingly.
Disable DPI on the secure channels that the Azure AI containers create to Microsoft servers. Failure to do so will prevent the container from functioning correctly.
Developer samples
Developer samples are available at ourGitHub repository.
Next steps
Learn aboutcontainer recipesyou can use with the Azure AI services.
Install and explore the functionality provided by containers in Azure AI services:
Anomaly Detector containers
Azure AI Vision containers
Language Understanding (LUIS) containers
Speech Service API containers
Language service containers
Translator containers
Feedback
Was this page helpful?
Additional resources