Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Quickstart: Import a bacpac file to a database in Azure SQL Database or Azure SQL Managed Instance
Article
2025-02-28
26 contributors
In this article
Applies to:Azure SQL DatabaseAzure SQL Managed Instance
You can import a SQL Server database into Azure SQL Database or SQL Managed Instance using a.bacpacfile. You can import the data from a bacpac file stored in Azure Blob storage (standard storage only) or from local storage in an on-premises location. To maximize import speed by providing more and faster resources, scale your database to a higher service tier and compute size during the import process. You can then scale down after the import is successful.
Note
Import and Export using Private Linkis in preview.
Use Azure portal
Watch this video to see how to import from a bacpac file in the Azure portal or continue reading:
TheAzure portalonlysupports creating a single database in Azure SQL Database andonlyfrom a bacpac file stored in Azure Blob storage.
To migrate a database into anAzure SQL Managed Instancefrom a bacpac file, use SQL Server Management Studio or theSqlPackagecommand-line utility. The Azure portal and Azure PowerShell are not currently supported.
SqlPackage
Warning
Bacpac files over 150 GB generated from SqlPackage may fail to import from the Azure portal or Azure PowerShell with an error message which statesFile contains corrupted data. This is a result of a known issue and the workaround is to use theSqlPackagecommand-line utility to import the bacpac file. For more information, seeSqlPackageand theissue log.
File contains corrupted data
SqlPackage
Note
Machines processing import/export requests submitted through the Azure portal or PowerShell need to store the bacpac file as well as temporary files generated by the Data-Tier Application Framework (DacFX). The disk space required varies significantly among databases with the same size and can require disk space up to three times the size of the database. Machines running the import/export request only have 450GB local disk space. As a result, some requests might fail with the errorThere is not enough space on the disk. In this case, the workaround is to run the SqlPackage command-line utility on a machine with enough local disk space. We encourage using the SqlPackage command-line utility to import/export databases larger than 150GB to avoid this issue.
There is not enough space on the disk
To import from a bacpac file into a new single database using the Azure portal, open the appropriate server page and then, on the toolbar, selectImport database.
To import from a bacpac file into a new single database using the Azure portal, open the appropriate server page and then, on the toolbar, selectImport database.

SelectSelect backup. Choose the storage account hosting your database, and then select the bacpac file from which to import.
SelectSelect backup. Choose the storage account hosting your database, and then select the bacpac file from which to import.
Specify the new database size (usually the same as origin) and provide the destination SQL Server credentials. For a list of possible values for a new database in Azure SQL Database, seeCreate Database.
Specify the new database size (usually the same as origin) and provide the destination SQL Server credentials. For a list of possible values for a new database in Azure SQL Database, seeCreate Database.

SelectOK.
SelectOK.
To monitor an import's progress, open the database's server page, and, underSettings, selectImport/Export history. When successful, the import has aCompletedstatus.
To monitor an import's progress, open the database's server page, and, underSettings, selectImport/Export history. When successful, the import has aCompletedstatus.

To verify the database is live on the server, selectSQL databasesand verify the new database isOnline.
To verify the database is live on the server, selectSQL databasesand verify the new database isOnline.
Use SqlPackage
To import a SQL Server database using theSqlPackagecommand-line utility, seeimport parameters and properties. You can download the latestSqlPackagefor Windows, macOS, or Linux.
For scale and performance, we recommend using SqlPackage in most production environments rather than using the Azure portal. For a SQL Server Customer Advisory Team blog about migrating usingBACPACfiles, seemigrating from SQL Server to Azure SQL Database using BACPAC Files.
BACPAC
The DTU based provisioning model supports select database max size values for each tier. When importing a databaseuse one of these supported values.
The following SqlPackage command imports theAdventureWorks2008R2database from local storage to a logical SQL server namedmynewserver20170403. It creates a new database calledmyMigratedDatabasewith aPremiumservice tier and aP6Service Objective. Change these values as appropriate for your environment.
AdventureWorks2008R2
mynewserver20170403
myMigratedDatabase
SqlPackage /a:import /tcs:"Data Source=<serverName>.database.windows.net;Initial Catalog=<migratedDatabase>;User Id=<userId>;Password=<password>" /sf:AdventureWorks2008R2.bacpac /p:DatabaseEdition=Premium /p:DatabaseServiceObjective=P6
SqlPackage /a:import /tcs:"Data Source=<serverName>.database.windows.net;Initial Catalog=<migratedDatabase>;User Id=<userId>;Password=<password>" /sf:AdventureWorks2008R2.bacpac /p:DatabaseEdition=Premium /p:DatabaseServiceObjective=P6
Important
To connect to Azure SQL Database from behind a corporate firewall, the firewall must have port 1433 open. To connect to SQL Managed Instance, you must have apoint-to-site connectionor an express route connection.
As an alternative to username and password, you can use Microsoft Entra ID (formerly Azure Active Directory). Currently, the Import/Export service does not support Microsoft Entra ID authentication when MFA is required. Substitute the username and password parameters for/ua:trueand/tid:"yourdomain.onmicrosoft.com". This example shows how to import a database using SqlPackage with Microsoft Entra authentication:
/ua:true
/tid:"yourdomain.onmicrosoft.com"
SqlPackage /a:Import /sf:testExport.bacpac /tdn:NewDacFX /tsn:apptestserver.database.windows.net /ua:True /tid:"apptest.onmicrosoft.com"
SqlPackage /a:Import /sf:testExport.bacpac /tdn:NewDacFX /tsn:apptestserver.database.windows.net /ua:True /tid:"apptest.onmicrosoft.com"
Azure Data Studio
Azure Data Studiois a free, open-source tool and is available for Windows, macOS, and Linux.  The "SQL Server dacpac" extension provides a wizard interface to SqlPackage operations including export and import. For more information on installing and using the extension, see theSQL Server dacpac extension documentation.
Use PowerShell
Note
Azure SQL Managed Instancedoes not currently support migrating a database into an instance database from a bacpac file using Azure PowerShell. To import into a SQL managed instance, use SQL Server Management Studio or SQLPackage.
Note
The machines processing import/export requests submitted through portal or PowerShell need to store the bacpac file as well as temporary files generated by Data-Tier Application Framework (DacFX). The disk space required varies significantly among DBs with same size and can take up to three times of the database size. Machines running the import/export request only have  450GB local disk space. As result, some requests might fail with "There is not enough space on the disk" error. In this case, the workaround is to run SqlPackage on a machine with enough local disk space. When importing/exporting databases larger than 150GB, use SqlPackage to avoid this issue.
PowerShell
Azure CLI
Important
The PowerShell Azure Resource Manager (AzureRM) module was deprecated on February 29, 2024. All future development should use the Az.Sql module. Users are advised to migrate from AzureRM to the Az PowerShell module to ensure continued support and updates. The AzureRM module is no longer maintained or supported. The arguments for the commands in the Az PowerShell module and in the AzureRM modules are substantially identical. For more about their compatibility, seeIntroducing the new Az PowerShell module.
Use theNew-AzSqlDatabaseImportcmdlet to submit an import database request to Azure. Depending on database size, the import might take some time to complete. The DTU based provisioning model supports select database max size values for each tier. When importing a databaseuse one of these supported values.
$importRequest = New-AzSqlDatabaseImport -ResourceGroupName "<resourceGroupName>" `
    -ServerName "<serverName>" -DatabaseName "<databaseName>" `
    -DatabaseMaxSizeBytes "<databaseSizeInBytes>" -StorageKeyType "StorageAccessKey" `
    -StorageKey $(Get-AzStorageAccountKey `
        -ResourceGroupName "<resourceGroupName>" -StorageAccountName "<storageAccountName>").Value[0] `
        -StorageUri "https://myStorageAccount.blob.core.windows.net/importsample/sample.bacpac" `
        -Edition "Premium" -ServiceObjectiveName "P6" `
        -AdministratorLogin "<userId>" `
        -AdministratorLoginPassword $(ConvertTo-SecureString -String "<password>" -AsPlainText -Force)
$importRequest = New-AzSqlDatabaseImport -ResourceGroupName "<resourceGroupName>" `
    -ServerName "<serverName>" -DatabaseName "<databaseName>" `
    -DatabaseMaxSizeBytes "<databaseSizeInBytes>" -StorageKeyType "StorageAccessKey" `
    -StorageKey $(Get-AzStorageAccountKey `
        -ResourceGroupName "<resourceGroupName>" -StorageAccountName "<storageAccountName>").Value[0] `
        -StorageUri "https://myStorageAccount.blob.core.windows.net/importsample/sample.bacpac" `
        -Edition "Premium" -ServiceObjectiveName "P6" `
        -AdministratorLogin "<userId>" `
        -AdministratorLoginPassword $(ConvertTo-SecureString -String "<password>" -AsPlainText -Force)
You can use theGet-AzSqlDatabaseImportExportStatuscmdlet to check the import's progress. Running the cmdlet immediately after the request usually returnsStatus: InProgress. The import is complete when you seeStatus: Succeeded.
Status: InProgress
Status: Succeeded
$importStatus = Get-AzSqlDatabaseImportExportStatus -OperationStatusLink $importRequest.OperationStatusLink

[Console]::Write("Importing")
while ($importStatus.Status -eq "InProgress") {
    $importStatus = Get-AzSqlDatabaseImportExportStatus -OperationStatusLink $importRequest.OperationStatusLink
    [Console]::Write(".")
    Start-Sleep -s 10
}

[Console]::WriteLine("")
$importStatus
$importStatus = Get-AzSqlDatabaseImportExportStatus -OperationStatusLink $importRequest.OperationStatusLink

[Console]::Write("Importing")
while ($importStatus.Status -eq "InProgress") {
    $importStatus = Get-AzSqlDatabaseImportExportStatus -OperationStatusLink $importRequest.OperationStatusLink
    [Console]::Write(".")
    Start-Sleep -s 10
}

[Console]::WriteLine("")
$importStatus
Tip
For another script example, seeImport a database from a BACPAC file.
Use theaz-sql-db-importcommand to submit an import database request to Azure. Depending on database size, the import might take some time to complete. The DTU based provisioning model supports select database max size values for each tier. When importing a databaseuse one of these supported values.
# get the storage account key
az storage account keys list --resource-group "<resourceGroup>" --account-name "<storageAccount>"

az sql db import --resource-group "<resourceGroup>" --server "<server>" --name "<database>" `
    --storage-key-type "StorageAccessKey" --storage-key "<storageAccountKey>" `
    --storage-uri "https://myStorageAccount.blob.core.windows.net/importsample/sample.bacpac" `
    -u "<userId>" -p "<password>"
# get the storage account key
az storage account keys list --resource-group "<resourceGroup>" --account-name "<storageAccount>"

az sql db import --resource-group "<resourceGroup>" --server "<server>" --name "<database>" `
    --storage-key-type "StorageAccessKey" --storage-key "<storageAccountKey>" `
    --storage-uri "https://myStorageAccount.blob.core.windows.net/importsample/sample.bacpac" `
    -u "<userId>" -p "<password>"
Cancel the import request
Use theDatabase Operations - Cancel APIor theStop-AzSqlDatabaseActivityPowerShell command, as in the following example:
Stop-AzSqlDatabaseActivity -ResourceGroupName $ResourceGroupName -ServerName $ServerName -DatabaseName $DatabaseName -OperationId $Operation.OperationId
Stop-AzSqlDatabaseActivity -ResourceGroupName $ResourceGroupName -ServerName $ServerName -DatabaseName $DatabaseName -OperationId $Operation.OperationId
Permissions required to cancel import
To cancel the import operation, you need to be a member of one of the following roles:
TheSQL DB Contributorrole or
Acustom Azure role-based access control RBAC rolewithMicrosoft.Sql/servers/databases/operationspermission
Microsoft.Sql/servers/databases/operations
Compatibility level of the new database
The imported database's compatibility level is based on the source database's compatibility level.
After importing your database, you can choose to operate the database at its current compatibility level or at a higher level. For more information on the implications and options for operating a database at a specific compatibility level, seeALTER DATABASE Compatibility Level. See alsoALTER DATABASE SCOPED CONFIGURATIONfor information about other database-level settings related to compatibility levels.
Limitations
Importing to a database in elastic pool isn't supported through the Azure Portal, Azure PowerShell, or Azure CLI. Instead, create a database in the elastic pool and then useSQLPackage Import, or import data using any method into a single database and then move the database to an elastic pool.
Import Export Service does not work when Allow access to Azure services is set to OFF. However, you can work around the problem by manually running SqlPackage from an Azure VM, or performing the export directly in your code by using the DacFx API.
Import does not support specifying a backup storage redundancy while creating a new database and creates with the default geo-redundant backup storage redundancy. To work around, first create an empty database with desired backup storage redundancy using Azure portal or PowerShell and then import the bacpac into this empty database.
Storage behind a firewall is currently not supported.
During the import process, do not create a database with the same name. The import process creates a new database of the specified name.
Currently, the Import/Export service does not support Microsoft Entra ID authentication when MFA is required.
Import\Export services only support SQL authentication and Microsoft Entra ID. Import\Export is not compatible with Microsoft Identity application registration.
Additional tools
You can also use these wizards.
Import Data-tier Application Wizard in SQL Server Management Studio.
SQL Server Import and Export Wizard.
Related content
To learn how to connect to and query Azure SQL Database from Azure Data Studio, seeQuickstart: Use Azure Data Studio to connect and query Azure SQL Database.
To learn how to connect to and query a database in Azure SQL Database, seeQuickstart: Azure SQL Database: Use SQL Server Management Studio to connect to and query data.
For a SQL Server Customer Advisory Team blog about migrating using .bacpac files, seeMigrating from SQL Server to Azure SQL Database using BACPAC Files.
For a discussion of the entire SQL Server database migration process, including performance recommendations, seeSQL Server database migration to Azure SQL Database.
To learn how to manage and share storage keys and shared access signatures securely, seeAzure Storage Security Guide.
Feedback
Was this page helpful?
Additional resources