Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Ingestion mappings
Article
2025-01-29
19 contributors
In this article
Applies to: 창혵Microsoft Fabric창혵Azure Data Explorer
Ingestion mappings are used during ingestion to map incoming data to columns inside tables.
Data Explorer supports different types of mappings, both row-oriented (CSV, JSON, AVRO and W3CLOGFILE), and column-oriented (Parquet and ORC).
Ingestion mappings can be defined in the ingest command, or can beprecreatedand referenced from the ingest command usingingestionMappingReferenceparameters. Ingestion is possible without specifying a mapping. For more information, seeidentity mapping.
ingestionMappingReference
Each element in the mapping list is constructed from three fields:
Important
For queued ingestion:
If the table referenced in the mapping doesn't exist in the database, it gets created automatically, given that valid data types are specified for all columns.
If a column referenced in the mapping doesn't exist in the table, it gets added automatically to the table as the last column upon the first time data is ingested for that column, given a valid data type is specified for the column. To add new columns to a mapping, use the.alter ingestion mapping command.
Data is batched using Ingestion properties. The more distinct ingestion mapping properties used, such as different ConstValue values, the more fragmented the ingestion becomes, which can lead to performance degradation.
Supported mapping types
The following table defines mapping types to be used when ingesting or querying external data of a specific format.
Ingestion mapping examples
The following examples use theRawEventstable with the following schema:
RawEvents
.create table RawEvents (timestamp: datetime, deviceId: guid, messageId: guid, temperature: decimal, humidity: decimal)
.create table RawEvents (timestamp: datetime, deviceId: guid, messageId: guid, temperature: decimal, humidity: decimal)
Simple mapping
The following example shows ingestion where the mapping is defined in the ingest command. The command ingests a JSON file from a URL into theRawEventstable. The mapping specifies the path to each field in the JSON file.
RawEvents
.ingest into table RawEvents ('https://kustosamplefiles.blob.core.windows.net/jsonsamplefiles/simple.json') 
    with (
            format = "json",
            ingestionMapping =
            ```
            [ 
              {"column":"timestamp","Properties":{"path":"$.timestamp"}},
              {"column":"deviceId","Properties":{"path":"$.deviceId"}},
              {"column":"messageId","Properties":{"path":"$.messageId"}},
              {"column":"temperature","Properties":{"path":"$.temperature"}},
              {"column":"humidity","Properties":{"path":"$.humidity"}}
            ]
            ```
          )
.ingest into table RawEvents ('https://kustosamplefiles.blob.core.windows.net/jsonsamplefiles/simple.json') 
    with (
            format = "json",
            ingestionMapping =
            ```
            [ 
              {"column":"timestamp","Properties":{"path":"$.timestamp"}},
              {"column":"deviceId","Properties":{"path":"$.deviceId"}},
              {"column":"messageId","Properties":{"path":"$.messageId"}},
              {"column":"temperature","Properties":{"path":"$.temperature"}},
              {"column":"humidity","Properties":{"path":"$.humidity"}}
            ]
            ```
          )
Mapping withingestionMappingReference
ingestionMappingReference
To map the same JSON file using a precreated mapping, create theRawEventMappingingestion mapping reference with the following command:
RawEventMapping
.create table RawEvents ingestion json mapping 'RawEventMapping' 
  ```
  [ 
    {"column":"timestamp","Properties":{"path":"$.timestamp"}},
    {"column":"deviceId","Properties":{"path":"$.deviceId"}},
    {"column":"messageId","Properties":{"path":"$.messageId"}},
    {"column":"temperature","Properties":{"path":"$.temperature"}},
    {"column":"humidity","Properties":{"path":"$.humidity"}}
  ]
  ```
.create table RawEvents ingestion json mapping 'RawEventMapping' 
  ```
  [ 
    {"column":"timestamp","Properties":{"path":"$.timestamp"}},
    {"column":"deviceId","Properties":{"path":"$.deviceId"}},
    {"column":"messageId","Properties":{"path":"$.messageId"}},
    {"column":"temperature","Properties":{"path":"$.temperature"}},
    {"column":"humidity","Properties":{"path":"$.humidity"}}
  ]
  ```
Ingest the JSON file using theRawEventMappingingestion mapping reference with the following command:
RawEventMapping
.ingest into table RawEvents ('https://kustosamplefiles.blob.core.windows.net/jsonsamplefiles/simple.json') 
  with (
          format="json",
          ingestionMappingReference="RawEventMapping"
        )
.ingest into table RawEvents ('https://kustosamplefiles.blob.core.windows.net/jsonsamplefiles/simple.json') 
  with (
          format="json",
          ingestionMappingReference="RawEventMapping"
        )
Identity mapping
Ingestion is possible without specifyingingestionMappingoringestionMappingReferenceproperties. The data is mapped using an identity data mapping derived from the table's schema. The table schema remains the same.formatproperty should be specified. Seeingestion formats.
ingestionMapping
ingestionMappingReference
format
Warning
Any mismatch between the table schema and the structure of data, such as column or field data types, column or field names or their number might result in empty or incorrect data ingested.
Mapping transformations
Some of the data format mappings (Parquet, JSON, and AVRO) support simple and useful ingest-time transformations. Where the scenario requires more complex processing at ingest time, useUpdate policy, which allows defining lightweight processing using KQL expression.
{events:[{"n1":"v1"},{"n2":"v2"}]}
{"n1":"v1","n2":"v2"}
JSON
Parquet
AVRO
ORC
CSV
JSON
Parquet
AVRO
ORC
W3CLOGFILE
CSV
JSON
Parquet
AVRO
ORC
W3CLOGFILE
CSV
JSON
Parquet
AVRO
ORC
CSV
JSON
Parquet
AVRO
ORC
CSV
JSON
Parquet
AVRO
ORC
CSV
JSON
Parquet
AVRO
ORC
JSON
Parquet
AVRO
ORC
AVRO
ApacheAvro
bytes
fixed
Avro
null
Mapping transformation examples
DropMappedFields
Given the following JSON contents:
{
    "Time": "2012-01-15T10:45",
    "Props": {
        "EventName": "CustomEvent",
        "Revenue": 0.456
    }
}
{
    "Time": "2012-01-15T10:45",
    "Props": {
        "EventName": "CustomEvent",
        "Revenue": 0.456
    }
}
The following data mapping maps entirePropsobject into dynamic columnPropswhile excluding
already mapped columns (Props.EventNameis already mapped into columnEventName, so it's
excluded).
Props
Props
Props.EventName
EventName
[
    { "Column": "Time", "Properties": { "Path": "$.Time" } },
    { "Column": "EventName", "Properties": { "Path": "$.Props.EventName" } },
    { "Column": "Props", "Properties": { "Path": "$.Props", "Transform":"DropMappedFields" } },
]
[
    { "Column": "Time", "Properties": { "Path": "$.Time" } },
    { "Column": "EventName", "Properties": { "Path": "$.Props.EventName" } },
    { "Column": "Props", "Properties": { "Path": "$.Props", "Transform":"DropMappedFields" } },
]
The ingested data looks as follows:
2012-01-15T10:45
CustomEvent
{"Revenue": 0.456}
BytesAsBase64
Given the following AVRO file contents:
{
    "Time": "2012-01-15T10:45",
    "Props": {
        "id": [227,131,34,92,28,91,65,72,134,138,9,133,51,45,104,52]
    }
}
{
    "Time": "2012-01-15T10:45",
    "Props": {
        "id": [227,131,34,92,28,91,65,72,134,138,9,133,51,45,104,52]
    }
}
The following data mapping maps the ID column twice, with and without the transformation.
[
    { "Column": "ID", "Properties": { "Path": "$.props.id" } },
    { "Column": "Base64EncodedId", "Properties": { "Path": "$.props.id", "Transform":"BytesAsBase64" } },
]
[
    { "Column": "ID", "Properties": { "Path": "$.props.id" } },
    { "Column": "Base64EncodedId", "Properties": { "Path": "$.props.id", "Transform":"BytesAsBase64" } },
]
The ingested data looks as follows:
[227,131,34,92,28,91,65,72,134,138,9,133,51,45,104,52]
44MiXBxbQUiGigmFMy1oNA==
Feedback
Was this page helpful?
Additional resources