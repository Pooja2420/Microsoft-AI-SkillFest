Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Supported programming languages for models in Azure AI Model Inference
Article
2025-04-07
2 contributors
In this article
Models deployed in Azure AI Model Inference can be used with different SDKs and programming models. The following document describes which one to use:
All models
All models deployed to Azure AI model inference support theAzure AI model inference APIand its associated family of SDKs.
To use these SDKs, connect them to theAzure AI model inference URI(usually in the formhttps://<resource-name>.services.ai.azure.com/models).
https://<resource-name>.services.ai.azure.com/models
Azure AI Inference package
The Azure AI Inference package allows you to consume all models deployed to the Azure AI model inference service and easily change among them. Azure AI Inference package is part of the Azure AI Foundry SDK.
Integrations
Azure OpenAI models
Azure OpenAI models can be consumed using the following SDKs and programming languages.
To use these SDKs, connect them to theAzure OpenAI service URI(usually in the formhttps://<resource-name>.openai.azure.com).
https://<resource-name>.openai.azure.com
OpenAI and Azure OpenAI SDK
Integrations
Limitations
Warning
Cohere SDK and Mistral SDK aren't supported in Azure AI Model Inference in Azure AI Foundry.
Next steps
To see what models are currently supported, check out theModelssection
Feedback
Was this page helpful?
Additional resources