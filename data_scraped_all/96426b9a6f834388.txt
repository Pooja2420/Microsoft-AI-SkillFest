Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Speech service in sovereign clouds
Article
2025-03-21
4 contributors
In this article
Azure Government (United States)
Available to US government entities and their partners only. See more information about Azure Governmenthereandhere.
Azure portal:https://portal.azure.us/
https://portal.azure.us/
Regions:US Gov ArizonaUS Gov Virginia
US Gov Arizona
US Gov Virginia
Available pricing tiers:Free (F0) and Standard (S0). See more detailshere
Free (F0) and Standard (S0). See more detailshere
Supported features:Speech to textCustom speech (Acoustic Model (AM) and Language Model (LM) adaptation)Speech StudioText to speechStandard voiceNeural voiceSpeech translation
Speech to textCustom speech (Acoustic Model (AM) and Language Model (LM) adaptation)Speech Studio
Custom speech (Acoustic Model (AM) and Language Model (LM) adaptation)Speech Studio
Speech Studio
Text to speechStandard voiceNeural voice
Standard voice
Neural voice
Speech translation
Unsupported features:Custom commandsCustom neural voicePersonal voiceText to speech avatar
Custom commands
Custom neural voice
Personal voice
Text to speech avatar
Supported languages:See the list of supported languageshere
See the list of supported languageshere
Endpoint information
This section contains Speech service endpoint information for the usage withSpeech SDK,Speech to text REST API, andText to speech REST API.
Speech service REST API endpoints in Azure Government have the following format:
https://<REGION_IDENTIFIER>.api.cognitive.microsoft.us/sts/v1.0/issueToken
https://<REGION_IDENTIFIER>.api.cognitive.microsoft.us/<URL_PATH>
https://<REGION_IDENTIFIER>.stt.speech.azure.us/<URL_PATH>
https://<REGION_IDENTIFIER>.tts.speech.azure.us/<URL_PATH>
Replace<REGION_IDENTIFIER>with the identifier matching the region of your subscription from this table:
<REGION_IDENTIFIER>
usgovarizona
usgovvirginia
ForSpeech SDKin sovereign clouds, you need to use "from endpoint / with endpoint" instantiation ofSpeechConfigclass or--endpointoption ofSpeech CLI.
SpeechConfig
--endpoint
SpeechConfigclass should be instantiated like this:
SpeechConfig
C#
C++
Java
Python
Objective-C
var config = SpeechConfig.Endpoint(new Uri(usGovEndpoint), subscriptionKey);
var config = SpeechConfig.Endpoint(new Uri(usGovEndpoint), subscriptionKey);
auto config = SpeechConfig::FromEndpoint(usGovEndpoint, subscriptionKey);
auto config = SpeechConfig::FromEndpoint(usGovEndpoint, subscriptionKey);
SpeechConfig config = SpeechConfig.fromEndpoint(new java.net.URI(usGovEndpoint), subscriptionKey);
SpeechConfig config = SpeechConfig.fromEndpoint(new java.net.URI(usGovEndpoint), subscriptionKey);
import azure.cognitiveservices.speech as speechsdk
speech_config = speechsdk.SpeechConfig(endpoint=usGovEndpoint, subscription=subscriptionKey)
import azure.cognitiveservices.speech as speechsdk
speech_config = speechsdk.SpeechConfig(endpoint=usGovEndpoint, subscription=subscriptionKey)
SPXSpeechConfiguration *speechConfig = [[SPXSpeechConfiguration alloc] initWithEndpoint:usGovEndpoint subscription:subscriptionKey];
SPXSpeechConfiguration *speechConfig = [[SPXSpeechConfiguration alloc] initWithEndpoint:usGovEndpoint subscription:subscriptionKey];
Speech CLI should be used like this (note the--endpointoption):
--endpoint
spx recognize --endpoint "usGovEndpoint" --file myaudio.wav
spx recognize --endpoint "usGovEndpoint" --file myaudio.wav
ReplacesubscriptionKeywith your Speech resource key.
ReplaceusGovEndpointwith the endpoint from the Azure Portal.
subscriptionKey
usGovEndpoint
Microsoft Azure operated by 21Vianet
Available to organizations with a business presence in China. See more information about Microsoft Azure operated by 21Vianethere.
Azure portal:https://portal.azure.cn/
https://portal.azure.cn/
Regions:China East 2China North 2China North 3
China East 2
China North 2
China North 3
Available pricing tiers:Free (F0) and Standard (S0). See more detailshere
Free (F0) and Standard (S0). See more detailshere
Supported features:Speech to textCustom speech (Acoustic Model (AM) and Language Model (LM) adaptation)Speech StudioPronunciation assessmentText to speechStandard voiceNeural voiceSpeech translator
Speech to textCustom speech (Acoustic Model (AM) and Language Model (LM) adaptation)Speech StudioPronunciation assessment
Custom speech (Acoustic Model (AM) and Language Model (LM) adaptation)Speech Studio
Speech Studio
Pronunciation assessment
Text to speechStandard voiceNeural voice
Standard voice
Neural voice
Speech translator
Unsupported features:Custom commandsCustom neural voicePersonal voiceText to speech avatar
Custom commands
Custom neural voice
Personal voice
Text to speech avatar
Supported languages:See the list of supported languageshere
See the list of supported languageshere
Endpoint information
This section contains Speech service endpoint information for the usage withSpeech SDK,Speech to text REST API, andText to speech REST API.
Speech service REST API endpoints in Azure operated by 21Vianet have the following format:
https://<REGION_IDENTIFIER>.api.cognitive.azure.cn/sts/v1.0/issueToken
https://<REGION_IDENTIFIER>.api.cognitive.azure.cn/<URL_PATH>
https://<REGION_IDENTIFIER>.stt.speech.azure.cn/<URL_PATH>
https://<REGION_IDENTIFIER>.tts.speech.azure.cn/<URL_PATH>
Replace<REGION_IDENTIFIER>with the identifier matching the region of your subscription from this table:
<REGION_IDENTIFIER>
chinaeast2
chinanorth2
chinanorth3
ForSpeech SDKin sovereign clouds, you need to use "from endpoint / with endpoint" instantiation ofSpeechConfigclass or--endpointoption ofSpeech CLI.
SpeechConfig
--endpoint
SpeechConfigclass should be instantiated like this:
SpeechConfig
C#
C++
Java
Python
Objective-C
var config = SpeechConfig.Endpoint(new Uri(azCnEndpoint), subscriptionKey);
var config = SpeechConfig.Endpoint(new Uri(azCnEndpoint), subscriptionKey);
auto config = SpeechConfig::FromEndpoint(azCnEndpoint, subscriptionKey);
auto config = SpeechConfig::FromEndpoint(azCnEndpoint, subscriptionKey);
SpeechConfig config = SpeechConfig.fromEndpoint(new java.net.URI(azCnEndpoint), subscriptionKey);
SpeechConfig config = SpeechConfig.fromEndpoint(new java.net.URI(azCnEndpoint), subscriptionKey);
import azure.cognitiveservices.speech as speechsdk
speech_config = speechsdk.SpeechConfig(endpoint=azCnEndpoint, subscription=subscriptionKey)
import azure.cognitiveservices.speech as speechsdk
speech_config = speechsdk.SpeechConfig(endpoint=azCnEndpoint, subscription=subscriptionKey)
SPXSpeechConfiguration *speechConfig = [[SPXSpeechConfiguration alloc] initWithEndpoint:azCnEndpoint subscription:subscriptionKey];
SPXSpeechConfiguration *speechConfig = [[SPXSpeechConfiguration alloc] initWithEndpoint:azCnEndpoint subscription:subscriptionKey];
Speech CLI should be used like this (note the--endpointoption):
--endpoint
spx recognize --endpoint "azCnEndpoint" --file myaudio.wav
spx recognize --endpoint "azCnEndpoint" --file myaudio.wav
ReplacesubscriptionKeywith your Speech resource key. ReplaceazCnEndpointwith the endpoint from the Azure Portal.
subscriptionKey
azCnEndpoint
Feedback
Was this page helpful?
Additional resources