Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Connect to data sources from Azure Databricks
Article
2024-02-05
5 contributors
In this article
This article provides links to all the different data sources in Azure that can be connected to Azure Databricks. Follow the examples in these links to extract data from the Azure data sources (for example, Azure Blob Storage, Azure Event Hubs, etc.) into an Azure Databricks cluster, and run analytical jobs on them.
Prerequisites
You must have an Azure Databricks workspace and a Spark cluster. Follow the instructions atGet started.
Data sources for Azure Databricks
The following list provides the data sources in Azure that you can use with Azure Databricks. For a complete list of data sources that can be used with Azure Databricks, seeData sources for Azure Databricks.
Azure SQL databaseThis link provides the DataFrame API for connecting to SQL databases using JDBC and how to control the parallelism of reads through the JDBC interface. This topic provides detailed examples using the Scala API, with abbreviated Python and Spark SQL examples at the end.
Azure SQL database
This link provides the DataFrame API for connecting to SQL databases using JDBC and how to control the parallelism of reads through the JDBC interface. This topic provides detailed examples using the Scala API, with abbreviated Python and Spark SQL examples at the end.
Azure Data Lake StorageThis link provides examples on how to use the Microsoft Entra ID (formerly Azure Active Directory) service principal to authenticate with Azure Data Lake Storage. It also provides instructions on how to access the data in Azure Data Lake Storage from Azure Databricks.
Azure Data Lake Storage
This link provides examples on how to use the Microsoft Entra ID (formerly Azure Active Directory) service principal to authenticate with Azure Data Lake Storage. It also provides instructions on how to access the data in Azure Data Lake Storage from Azure Databricks.
Azure Blob StorageThis link provides examples on how to directly access Azure Blob Storage from Azure Databricks using access key or the SAS for a given container. The link also provides info on how to access the Azure Blob Storage from Azure Databricks using the RDD API.
Azure Blob Storage
This link provides examples on how to directly access Azure Blob Storage from Azure Databricks using access key or the SAS for a given container. The link also provides info on how to access the Azure Blob Storage from Azure Databricks using the RDD API.
Azure Event HubsThis link provides instructions on how to use the Kafka connector from Azure Databricks to access data in Azure Event Hubs.
Azure Event Hubs
This link provides instructions on how to use the Kafka connector from Azure Databricks to access data in Azure Event Hubs.
Azure Synapse AnalyticsThis link provides instructions on how toquery data in Azure Synapse.
Azure Synapse Analytics
This link provides instructions on how toquery data in Azure Synapse.
Next steps
To learn about sources from where you can import data into Azure Databricks, seeData sources for Azure Databricks.
Feedback
Was this page helpful?
Additional resources