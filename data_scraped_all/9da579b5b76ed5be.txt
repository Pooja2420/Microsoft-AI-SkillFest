Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Azure AI Custom Translator for beginners
Article
2025-04-14
3 contributors
In this article
Azure AI Custom Translatorenables you to a build translation system that reflects your business, industry, and domain-specific terminology and style. Training and deploying a custom system is easy and doesn't require any programming skills. The customized translation system seamlessly integrates into your existing applications, workflows, and websites and is available on Azure through the same cloud-basedMicrosoft Text translation APIservice that powers billions of translations every day.
The platform enables users to build and publish custom translation systems to and from English. The Custom Translator supports more than 60 languages that map directly to the languages available for Neural machine translation (NMT). For a complete list,seeTranslator language support.
Is a custom translation model the right choice for me?
A well-trained custom translation model provides more accurate domain-specific translations because it relies on previously translated in-domain documents to learn preferred translations. Translator uses these terms and phrases in context to produce fluent translations in the target language while respecting context-dependent grammar.
Training a full custom translation model requires a substantial amount of data. If you don't have at least 10,000 sentences of previously trained documents, you can't train a full-language translation model. However, you can either train a dictionary-only model or use the high-quality, out-of-the-box translations available with the Text translation API.

What does training a custom translation model involve?
Building a custom translation model requires:
Understanding your use-case.
Understanding your use-case.
Obtaining in-domain translated data (preferably human translated).
Obtaining in-domain translated data (preferably human translated).
Assessing translation quality or target language translations.
Assessing translation quality or target language translations.
How do I evaluate my use-case?
Having clarity on your use-case and what success looks like is the first step towards sourcing proficient training data. Here are a few considerations:
Is your desired outcome specified and how is it measured?
Is your desired outcome specified and how is it measured?
Is your business domain identified?
Is your business domain identified?
Do you have in-domain sentences of similar terminology and style?
Do you have in-domain sentences of similar terminology and style?
Does your use-case involve multiple domains? If yes, should you build one translation system or multiple systems?
Does your use-case involve multiple domains? If yes, should you build one translation system or multiple systems?
Do you have requirements impacting regional data residency at-rest and in-transit?
Do you have requirements impacting regional data residency at-rest and in-transit?
Are the target users in one or multiple regions?
Are the target users in one or multiple regions?
How should I source my data?
Finding in-domain quality data is often a challenging task that varies based on user classification. Here are some questions you can ask yourself as you evaluate what data is available to you:
Does your company have previous translation data available that you can use? Enterprises often have a wealth of translation data accumulated over many years of using human translation.
Does your company have previous translation data available that you can use? Enterprises often have a wealth of translation data accumulated over many years of using human translation.
Do you have a vast amount of monolingual data? Monolingual data is data in only one language. If so, can you get translations for this data?
Do you have a vast amount of monolingual data? Monolingual data is data in only one language. If so, can you get translations for this data?
Can you crawl online portals to collect source sentences and synthesize target sentences?
Can you crawl online portals to collect source sentences and synthesize target sentences?
What should I use for training material?
What is a BLEU score?
BLEU (Bilingual Evaluation Understudy) is an algorithm for evaluating the precision or accuracy of text that is machine translated from one language to another. Azure AI Custom Translator uses the BLEU metric as one way of conveying translation accuracy.
A BLEU score is a number between zero and 100. A score of zero indicates a low quality translation where nothing in the translation matched the reference. A score of 100 indicates a perfect translation that is identical to the reference. It's not necessary to attain a score of 100 - a BLEU score between 40 and 60 indicates a high-quality translation.
Read more
What happens if I don't submit tuning or testing data?
Tuning and test sentences are optimally representative of what you plan to translate in the future. If you don't submit any tuning or testing data, Azure AI Custom Translator automatically excludes sentences from your training documents to use as tuning and test data.
How is training material processed by Azure AI Custom Translator?
To prepare for training, documents undergo a series of processing and filtering steps. Knowledge of the filtering process can help with understanding the sentence count displayed as well as the steps you can take to prepare training documents for training with Azure AI Custom Translator. The filtering steps are as follows:
Sentence alignmentIf your document isn't inXLIFF,XLSX,TMX, orALIGNformat, Azure AI Custom Translator aligns the sentences of your source and target documents to each other, sentence-by-sentence. Translator doesn't perform document alignmentâit follows your naming convention for the documents to find a matching document in the other language. Within the source text, Azure AI Custom Translator tries to find the corresponding sentence in the target language. It uses document markup like embedded HTML tags to help with the alignment.If you see a large discrepancy between the number of sentences in the source and target documents, your source document can't be parallel, or couldn't be aligned. The document pairs with a large difference (>10%) of sentences on each side warrant a second look to make sure they're indeed parallel.
Sentence alignment
If your document isn't inXLIFF,XLSX,TMX, orALIGNformat, Azure AI Custom Translator aligns the sentences of your source and target documents to each other, sentence-by-sentence. Translator doesn't perform document alignmentâit follows your naming convention for the documents to find a matching document in the other language. Within the source text, Azure AI Custom Translator tries to find the corresponding sentence in the target language. It uses document markup like embedded HTML tags to help with the alignment.
XLIFF
XLSX
TMX
ALIGN
If you see a large discrepancy between the number of sentences in the source and target documents, your source document can't be parallel, or couldn't be aligned. The document pairs with a large difference (>10%) of sentences on each side warrant a second look to make sure they're indeed parallel.
Tuning and testing data extractionTuning and testing data is optional. If you don't provide it, the system removes an appropriate percentage from your training documents to use for tuning and testing. The removal happens dynamically as part of the training process. Since this step occurs as part of training, your uploaded documents aren't affected. You can see the final used sentence counts for each category of dataâtraining, tuning, testing, and dictionaryâon the Model details page after training succeeds.
Tuning and testing data extraction
Tuning and testing data is optional. If you don't provide it, the system removes an appropriate percentage from your training documents to use for tuning and testing. The removal happens dynamically as part of the training process. Since this step occurs as part of training, your uploaded documents aren't affected. You can see the final used sentence counts for each category of dataâtraining, tuning, testing, and dictionaryâon the Model details page after training succeeds.
Length filterRemoves sentences with only one word on either side.Removes sentences with more than 100 words on either side. Chinese, Japanese, Korean are exempt.Removes sentences with fewer than three characters. Chinese, Japanese, Korean are exempt.Removes sentences with more than 2,000 characters for Chinese, Japanese, Korean.Removes sentences with less than 1% alphanumeric characters.Removes dictionary entries containing more than 50 words.
Length filter
Removes sentences with only one word on either side.
Removes sentences with more than 100 words on either side. Chinese, Japanese, Korean are exempt.
Removes sentences with fewer than three characters. Chinese, Japanese, Korean are exempt.
Removes sentences with more than 2,000 characters for Chinese, Japanese, Korean.
Removes sentences with less than 1% alphanumeric characters.
Removes dictionary entries containing more than 50 words.
White spaceReplaces any sequence of white-space characters including tabs and CR/LF sequences with a single space character.Removes leading or trailing space in the sentence.
White space
Replaces any sequence of white-space characters including tabs and CR/LF sequences with a single space character.
Removes leading or trailing space in the sentence.
Sentence end punctuationReplaces multiple sentence-end punctuation characters with a single instance. Japanese character normalization.Converts full width letters and digits to half-width characters.
Sentence end punctuation
Replaces multiple sentence-end punctuation characters with a single instance. Japanese character normalization.
Replaces multiple sentence-end punctuation characters with a single instance. Japanese character normalization.
Converts full width letters and digits to half-width characters.
Converts full width letters and digits to half-width characters.
Unescaped XML tagsTransforms unescaped tags into escaped tags:TagBecomes&lt;&amp;lt;&gt;&amp;gt;&amp;&amp;amp;
Unescaped XML tags
Transforms unescaped tags into escaped tags:
Invalid charactersAzure AI Custom Translator removes sentences that contain Unicode character U+FFFD. The character U+FFFD indicates a failed encoding conversion.
Invalid characters
Azure AI Custom Translator removes sentences that contain Unicode character U+FFFD. The character U+FFFD indicates a failed encoding conversion.
What steps should I take before uploading data?
Remove sentences with invalid encoding.
Remove Unicode control characters.
Align sentences (source-to-target), if feasible.
Remove source and target sentences that don't match the source and target languages.
When source and target sentences have mixed languages, ensure that untranslated words are intentional, for example, names of organizations and products.
Avoid teaching errors to your model by making certain that grammar and typography are correct.
Have one source sentence mapped to one target sentence. Although our training process handles source and target lines containing multiple sentences, one-to-one mapping is a best practice.
How do I evaluate the results?
After your model is successfully trained, you can view the model's BLEU score and baseline model BLEU score on the model details page. We use the same set of test data to generate both the model's BLEU score and the baseline BLEU score. This data helps you make an informed decision regarding which model would be better for your use-case.
Next steps
Try our Quickstart
Feedback
Was this page helpful?
Additional resources