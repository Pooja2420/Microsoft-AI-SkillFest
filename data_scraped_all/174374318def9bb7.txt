Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Supported scenarios for HANA Large Instances
Article
2023-02-10
3 contributors
In this article
This article describes the supported scenarios and architectural details for HANA Large Instances (HLI).
Note
If your scenario isn't mentioned in this article, contact the Microsoft Service Management team to assess your requirements.
Before you set up the HLI unit, validate the design with SAP or your service implementation partner.
Terms and definitions
Let's understand the terms and definitions used in this article:
SID: A system identifier for the HANA system.
HLI: Hana Large Instances.
DR: Disaster recovery (DR).
Normal DR: A system setup with a dedicated resource for DR purposes only.
Multipurpose DR: A DR site system that's configured to use a non-production environment alongside a production instance that's configured for a DR event.
Single-SID: A system with one instance installed.
Multi-SID: A system with multiple instances configured; also called an MCOS environment.
HSR: SAP HANA system replication.
Overview
HANA Large Instances support various architectures to help you accomplish your business requirements. The following sections cover the architectural scenarios and their configuration details.
The derived architectural designs are purely from an infrastructure perspective. Consult SAP or your implementation partners for the HANA deployment. If your scenarios aren't listed in this article, contact the Microsoft account team to review the architecture and derive a solution for you.
Note
These architectures are fully compliant with Tailored Data Integration (TDI) design and are supported by SAP.
This article describes the details of the two components in each supported architecture:
Ethernet
Storage
Ethernet
Each provisioned server comes preconfigured with sets of Ethernet interfaces. The Ethernet interfaces configured on each HLI unit are categorized into four types:
A: Used for or by client access.
B: Used for node-to-node communication. This interface is configured on all servers no matter what topology you request. However, it's used only for scale-out scenarios.
C: Used for node-to-storage connectivity.
D: Used for node-to-iSCSI device connection for fencing setup. This interface is configured only when an HSR setup is requested.
You choose the interface based on the topology that's configured on the HLI unit. For example, interface âBâ is set up for node-to-node communication, which is useful when you have a scale-out topology configured. This interface isn't used for single node scale-up configurations. For more information about interface usage, review your required scenarios (later in this article).
If necessary, you can define more NIC cards on your own. However, the configurations of existing NICscan'tbe changed.
Note
You might find additional interfaces that are physical interfaces or bonding.
Consider only the previously mentioned interfaces for your use case. Ignore any others.
The distribution for units with two assigned IP addresses should look as follows:
Ethernet âAâ should have an assigned IP address that's within the server IP pool address range that you submitted to Microsoft. This IP address should be maintained in the/etc/hostsdirectory of the operating system (OS).
Ethernet âAâ should have an assigned IP address that's within the server IP pool address range that you submitted to Microsoft. This IP address should be maintained in the/etc/hostsdirectory of the operating system (OS).
Ethernet âCâ should have an assigned IP address that's used for communication to NFS. Youdon'tneed to maintain this address in theetc/hostsdirectory to allow instance-to-instance traffic within the tenant.
Ethernet âCâ should have an assigned IP address that's used for communication to NFS. Youdon'tneed to maintain this address in theetc/hostsdirectory to allow instance-to-instance traffic within the tenant.
For HANA system replication or HANA scale-out deployment, a blade configuration with two assigned IP addresses isn't suitable. If you have only two assigned IP addresses, and you want to deploy such a configuration, contact SAP HANA on Azure Service Management. They can assign you a third IP address in a third VLAN. For HANA Large Instances with three assigned IP addresses on three NIC ports, the following usage rules apply:
Ethernet âAâ should have an assigned IP address that's outside of the server IP pool address range that you submitted to Microsoft. This IP address shouldn't be maintained in theetc/hostsdirectory of the OS.
Ethernet âAâ should have an assigned IP address that's outside of the server IP pool address range that you submitted to Microsoft. This IP address shouldn't be maintained in theetc/hostsdirectory of the OS.
Ethernet âBâ should be maintained exclusively in theetc/hostsdirectory for communication between the various instances. Maintain these IP addresses in scale-out HANA configurations as the IP addresses that HANA uses for the inter-node configuration.
Ethernet âBâ should be maintained exclusively in theetc/hostsdirectory for communication between the various instances. Maintain these IP addresses in scale-out HANA configurations as the IP addresses that HANA uses for the inter-node configuration.
Ethernet âCâ should have an assigned IP address that's used for communication to NFS storage. This type of address shouldn't be maintained in theetc/hostsdirectory.
Ethernet âCâ should have an assigned IP address that's used for communication to NFS storage. This type of address shouldn't be maintained in theetc/hostsdirectory.
Ethernet âDâ should be used exclusively for access to fencing devices for Pacemaker. This interface is required when you configure HANA system replication and want to achieve auto failover of the operating system by using an SBD-based device.
Ethernet âDâ should be used exclusively for access to fencing devices for Pacemaker. This interface is required when you configure HANA system replication and want to achieve auto failover of the operating system by using an SBD-based device.
Storage
Storage is preconfigured based on the requested topology. The volume sizes and mount points vary depending on the number of servers and SKUs, and the configured topology. For more information, review your required scenarios (later in this article). If you require more storage, you can purchase it in 1-TB increments.
Note
The mount point /usr/sap/<SID> is a symbolic link to the /hana/shared mount point.
Supported scenarios
The architectural diagrams in the next sections use the following notations:

Here are the supported scenarios:
Single node with one SID
Single node MCOS
Single node with DR (normal)
Single node with DR (multipurpose)
HSR with fencing
HSR with DR (normal/multipurpose)
Host auto failover (1+1)
Scale-out with standby
Scale-out without standby
Scale-out with DR
Single node with one SID
This topology supports one node in a scale-up configuration with one SID.
Architecture diagram

Ethernet
The following network interfaces are preconfigured:
Storage
The following mount points are preconfigured:
Key considerations
/usr/sap/SID is a symbolic link to /hana/shared/SID.
Single node MCOS
This topology supports one node in a scale-up configuration with multiple SIDs.
Architecture diagram

Ethernet
The following network interfaces are preconfigured:
Storage
The following mount points are preconfigured:
Key considerations
/usr/sap/SID is a symbolic link to /hana/shared/SID.
Volume size distribution is based on the database size in memory. To learn what database sizes in memory are supported in a multi-SID environment, seeOverview and architecture.
Single node with DR using storage replication
This topology supports one node in a scale-up configuration with one or multiple SIDs. Storage-based replication to the DR site is used for a primary SID. In the diagram, only a single-SID system is shown at the primary site, but MCOS systems are supported as well.
Architecture diagram

Ethernet
The following network interfaces are preconfigured:
Storage
The following mount points are preconfigured:
Key considerations
/usr/sap/SID is a symbolic link to /hana/shared/SID.
For MCOS: Volume size distribution is based on the database size in memory. To learn what database sizes in memory are supported in a multi-SID environment, seeOverview and architecture.
At the DR site: The volumes and mount points are configured (marked as âRequired for HANA installationâ) for the production HANA instance installation at the DR HLI unit.
At the DR site: The data, log backups, and shared volumes (marked as âStorage Replicationâ) are replicated via snapshot from the production site. These volumes are mounted during failover only. For more information, seeDisaster recovery failover procedure.
The boot volume forSKU Type I classis replicated to the DR node.
Single node with DR (multipurpose) using storage replication
This topology supports one node in a scale-up configuration with one or multiple SIDs. Storage-based replication to the DR site is used for a primary SID.
In the diagram, only a single-SID system is shown at the primary site, but multi-SID (MCOS) systems are supported as well. At the DR site, the HLI unit is used for the QA instance. Production operations run from the primary site. During DR failover (or failover test), the QA instance at the DR site is taken down.
Architecture diagram

Ethernet
The following network interfaces are preconfigured:
Storage
The following mount points are preconfigured:
Key considerations
/usr/sap/SID is a symbolic link to /hana/shared/SID.
For MCOS: Volume size distribution is based on the database size in memory. To learn what database sizes in memory are supported in a multi-SID environment, seeOverview and architecture.
At the DR site: The volumes and mount points are configured (marked as âRequired for HANA installationâ) for the production HANA instance installation at the DR HLI unit.
At the DR site: The data, log backups, and shared volumes (marked as âStorage Replicationâ) are replicated via snapshot from the production site. These volumes are mounted during failover only. For more information, seeDisaster recovery failover procedure.
At the DR site: The data, log backups, log, and shared volumes for QA (marked as âQA instance installationâ) are configured for the QA instance installation.
The boot volume forSKU Type I classis replicated to the DR node.
HSR with fencing for high availability
This topology supports two nodes for the HANA system replication configuration. This configuration is supported only for single HANA instances on a node. MCOS scenariosaren'tsupported.
Note
As of December 2019, this architecture is supported only for the SUSE operating system.
Architecture diagram

Ethernet
The following network interfaces are preconfigured:
Storage
The following mount points are preconfigured:
Key considerations
/usr/sap/SID is a symbolic link to /hana/shared/SID.
For MCOS: Volume size distribution is based on the database size in memory. To learn what database sizes in memory are supported in a multi-SID environment, seeOverview and architecture.
Fencing: An SBD is configured for the fencing device setup. However, the use of fencing is optional.
High availability with HSR and DR with storage replication
This topology supports two nodes for the HANA system replication configuration. Both normal and multipurpose DRs are supported. These configurations are supported only for single HANA instances on a node. MCOS scenariosaren'tsupported with these configurations.
In the diagram, a multipurpose scenario is shown at the DR site, where the HLI unit is used for the QA instance. Production operations run from the primary site. During DR failover (or failover test), the QA instance at the DR site is taken down.
Architecture diagram

Ethernet
The following network interfaces are preconfigured:
Storage
The following mount points are preconfigured:
Key considerations
/usr/sap/SID is a symbolic link to /hana/shared/SID.
For MCOS: Volume size distribution is based on the database size in memory. To learn what database sizes in memory are supported in a multi-SID environment, seeOverview and architecture.
Fencing: An SBD is configured for the fencing setup. However, the use of fencing is optional.
At the DR site:Two sets of storage volumes are requiredfor primary and secondary node replication.
At the DR site: The volumes and mount points are configured (marked as âRequired for HANA installationâ) for the production HANA instance installation at the DR HLI unit.
At the DR site: The data, log backups, and shared volumes (marked as âStorage Replicationâ) are replicated via snapshot from the production site. These volumes are mounted during failover only. For more information, seeDisaster recovery failover procedure.
At the DR site: The data, log backups, log, and shared volumes for QA (marked as âQA instance installationâ) are configured for the QA instance installation.
The boot volume forSKU Type I classis replicated to the DR node.
Host auto failover (1+1)
This topology supports two nodes in a host auto failover configuration. There's one node with a primary/worker role and another as a standby.SAP supports this scenario only for S/4 HANA.For more information, seeOSS note 2408419 - SAP S/4HANA - Multi-Node Support.
Architecture diagram

Ethernet
The following network interfaces are preconfigured:
Storage
The following mount points are preconfigured:
Key considerations
/usr/sap/SID is a symbolic link to /hana/shared/SID.
On standby: The volumes and mount points are configured (marked as âRequired for HANA installationâ) for the HANA instance installation at the standby unit.
Scale-out with standby
This topology supports multiple nodes in a scale-out configuration. There's one node with a primary role, one or more nodes with a worker role, and one or more nodes as standby. However, there can be only one primary node at any given time.
Architecture diagram

Ethernet
The following network interfaces are preconfigured:
Storage
The following mount points are preconfigured:
Scale-out without standby
This topology supports multiple nodes in a scale-out configuration. There's one node with a primary role, and one or more nodes with a worker role. However, there can be only one primary node at any given time.
Architecture diagram

Ethernet
The following network interfaces are preconfigured:
Storage
The following mount points are preconfigured:
Key considerations
/usr/sap/SID is a symbolic link to /hana/shared/SID.
Scale-out with DR using storage replication
This topology supports multiple nodes in a scale-out with a DR. Both normal and multipurpose DRs are supported. In the diagram, only the single purpose DR is shown. You can request this topology with or without the standby node.
Architecture diagram

Ethernet
The following network interfaces are preconfigured:
Storage
The following mount points are preconfigured:
Key considerations
/usr/sap/SID is a symbolic link to /hana/shared/SID.
At the DR site: The volumes and mount points are configured (marked as âRequired for HANA installationâ) for the production HANA instance installation at the DR HLI unit.
At the DR site: The data, log backups, and shared volumes (marked as âStorage Replicationâ) are replicated via snapshot from the production site. These volumes are mounted during failover only. For more information, seeDisaster recovery failover procedure.
The boot volume forSKU Type I classis replicated to the DR node.
Single node with DR using HSR
This topology supports one node in a scale-up configuration with one SID, with HANA system replication to the DR site for a primary SID. In the diagram, only a single-SID system is shown at the primary site, but multi-SID (MCOS) systems are supported as well.
Architecture diagram

Ethernet
The following network interfaces are preconfigured:
Storage
The following mount points are preconfigured on both HLI units (Primary and DR):
Key considerations
/usr/sap/SID is a symbolic link to /hana/shared/SID.
For MCOS: Volume size distribution is based on the database size in memory. To learn what database sizes in memory are supported in a multi-SID environment, seeOverview and architecture.
The primary node syncs with the DR node by using HANA system replication.
Global Reachis used to link the ExpressRoute circuits together to make a private network between your regional networks.
Single node HSR to DR (cost optimized)
This topology supports one node in a scale-up configuration with one SID. HANA system replication to the DR site is used for a primary SID. In the diagram, only a single-SID system is shown at the primary site, but multi-SID (MCOS) systems are supported as well. At the DR site, an HLI unit is used for the QA instance. Production operations run from the primary site. During DR failover (or failover test), the QA instance at the DR site is taken down.
Architecture diagram

Ethernet
The following network interfaces are preconfigured:
Storage
The following mount points are preconfigured:
Key considerations
/usr/sap/SID is a symbolic link to /hana/shared/SID.
For MCOS: Volume size distribution is based on the database size in memory. To learn what database sizes in memory are supported in a multi-SID environment, seeOverview and architecture.
At the DR site: The volumes and mount points are configured (marked as âPROD Instance at DR siteâ) for the production HANA instance installation at the DR HLI unit.
At the DR site: The data, log backups, log, and shared volumes for QA (marked as âQA instance installationâ) are configured for the QA instance installation.
The primary node syncs with the DR node by using HANA system replication.
Global Reachis used to link the ExpressRoute circuits together to make a private network between your regional networks.
High availability and disaster recovery with HSR
This topology support two nodes for the HANA system replication configuration for the local regions' high availability. For the DR, the third node at the DR region syncs with the primary site by using HSR (async mode).
Architecture diagram

Ethernet
The following network interfaces are preconfigured:
Storage
The following mount points are preconfigured:
Key considerations
/usr/sap/SID is a symbolic link to /hana/shared/SID.
At the DR site: The volumes and mount points are configured (marked as âPROD DR instanceâ) for the production HANA instance installation at the DR HLI unit.
The primary site node syncs with the DR node by using HANA system replication.
Global Reachis used to link the ExpressRoute circuits together to make a private network between your regional networks.
High availability and disaster recovery with HSR (cost optimized)
This topology supports two nodes for the HANA system replication configuration for the local regions' high availability. For the DR, the third node at the DR region syncs with the primary site by using HSR (async mode), while another instance (for example, QA) is already running out from the DR node.
Architecture diagram

Ethernet
The following network interfaces are preconfigured:
Storage
The following mount points are preconfigured:
Key considerations
/usr/sap/SID is a symbolic link to /hana/shared/SID.
At the DR site: The volumes and mount points are configured (marked as âPROD DR instanceâ) for the production HANA instance installation at the DR HLI unit.
At the DR site: The data, log backups, log, and shared volumes for QA (marked as âQA instance installationâ) are configured for the QA instance installation.
The primary site node syncs with the DR node by using HANA system replication.
Global Reachis used to link the ExpressRoute circuits together to make a private network between your regional networks.
Scale-out with DR using HSR
This topology supports multiple nodes in a scale-out with a DR. You can request this topology with or without the standby node. The primary site node syncs with the DR site node by using HANA system replication (async mode).
Architecture diagram

Ethernet
The following network interfaces are preconfigured:
Storage
The following mount points are preconfigured:
Key considerations
/usr/sap/SID is a symbolic link to /hana/shared/SID.
At the DR site: The volumes and mount points are configured for the production HANA instance installation at the DR HLI unit.
The primary site node syncs with the DR node by using HANA system replication.
Global Reachis used to link the ExpressRoute circuits together to make a private network between your regional networks.
Next steps
Learn about deploying HANA Large Instances.
SAP HANA (Large Instances) deployment
Feedback
Was this page helpful?
Additional resources