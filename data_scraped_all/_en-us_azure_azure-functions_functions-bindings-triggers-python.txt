Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Azure Functions Python developer guide
Article
2024-12-29
50 contributors
In this article
This guide is an introduction to developing Azure Functions by using Python. The article assumes that you've already read theAzure Functions developers guide.
Important
This article supports both the v1 and v2 programming model for Python in Azure Functions.
The Python v1 model uses afunctions.jsonfile to define functions, and the new v2 model lets you instead use a decorator-based approach. This new approach results in a simpler file structure, and it's more code-centric. Choose thev2selector at the top of the article to learn about this new programming model.
As a Python developer, you might also be interested in these topics:
Get started
Scenarios
Hosting options
Visual Studio Code: Create your first Python app using Visual Studio Code.
Terminal or command prompt: Create your first Python app from the command prompt using Azure Functions Core Tools.
Samples: Review some existing Python apps in the Learn samples browser.
Visual Studio Code: Create your first Python app using Visual Studio Code.
Terminal or command prompt: Create your first Python app from the command prompt using Azure Functions Core Tools.
Samples: Review some existing Python apps in the Learn samples browser.
Machine learning & AI: Features machine learning withPyTorchandTensorFlow. Connect to Azure OpenAI models usingFunctions bindings.
Automation: Use Python functions to automate the management of Azure resources.
Serverless workflows: Create stateful functions in a serverless environment as part of orchestrated workflows.
More...
Machine learning & AI: UseFunctions bindingsto connect to and manipulate Azure OpenAI data models, includingtext completion.
Serverless workflows: Create stateful functions in a serverless environment as part of orchestrated workflows.
More...
Flex Consumption plan: Linux-based serverless hosting option that features full support for managed identities, virtual networks, and flexible deployments.
Container hosting options: Run and deploy your Python functions on Linux in a Docker container, including integratedAzure Container Apps hosting.
Compare hosting options...
Development options
Both Python Functions programming models support local development in one of the following environments:
Python v2 programming model:
Visual Studio Code
Terminal or command prompt
Python v1 programming model:
Visual Studio Code
Terminal or command prompt
You can also create Python functions in the Azure portal.
Tip
Although you can develop your Python-based Azure functions locally on Windows, Python is supported only on a Linux-based hosting plan when it's running in Azure. For more information, see thelist of supported operating system/runtime combinations.
Programming model
Azure Functions expects a function to be a stateless method in your Python script that processes input and produces output. By default, the runtime expects the method to be implemented as a global method calledmain()in the__init__.pyfile. You can alsospecify an alternative entry point.
main()
You bind data to the function from triggers and bindings via method attributes that use thenameproperty that's defined in thefunction.jsonfile. For example, the followingfunction.jsonfile describes a simple function that's triggered by an HTTP request namedreq:
name
req
{
    "scriptFile": "__init__.py",
    "bindings": [
        {
            "authLevel": "function",
            "type": "httpTrigger",
            "direction": "in",
            "name": "req",
            "methods": [
                "get",
                "post"
            ]
        },
        {
            "type": "http",
            "direction": "out",
            "name": "$return"
        }
    ]
}
{
    "scriptFile": "__init__.py",
    "bindings": [
        {
            "authLevel": "function",
            "type": "httpTrigger",
            "direction": "in",
            "name": "req",
            "methods": [
                "get",
                "post"
            ]
        },
        {
            "type": "http",
            "direction": "out",
            "name": "$return"
        }
    ]
}
Based on this definition, the__init__.pyfile that contains the function code might look like the following example:
def main(req):
    user = req.params.get('user')
    return f'Hello, {user}!'
def main(req):
    user = req.params.get('user')
    return f'Hello, {user}!'
You can also explicitly declare the attribute types and return type in the function by using Python type annotations. Doing so helps you to use the IntelliSense and autocomplete features that are provided by many Python code editors.
import azure.functions

def main(req: azure.functions.HttpRequest) -> str:
    user = req.params.get('user')
    return f'Hello, {user}!'
import azure.functions

def main(req: azure.functions.HttpRequest) -> str:
    user = req.params.get('user')
    return f'Hello, {user}!'
Use the Python annotations that are included in theazure.functions.*package to bind the input and outputs to your methods.
Azure Functions expects a function to be a stateless method in your Python script that processes input and produces output. By default, the runtime expects the method to be implemented as a global method in thefunction_app.pyfile.
Triggers and bindings can be declared and used in a function in a decorator based approach. They're defined in the same file,function_app.py, as the functions. As an example, the followingfunction_app.pyfile represents a function trigger by an HTTP request.
@app.function_name(name="HttpTrigger1")
@app.route(route="req")
def main(req):
    user = req.params.get("user")
    return f"Hello, {user}!"
@app.function_name(name="HttpTrigger1")
@app.route(route="req")
def main(req):
    user = req.params.get("user")
    return f"Hello, {user}!"
You can also explicitly declare the attribute types and return type in the function by using Python type annotations. Doing so helps you use the IntelliSense and autocomplete features that are provided by many Python code editors.
import azure.functions as func

app = func.FunctionApp()

@app.function_name(name="HttpTrigger1")
@app.route(route="req")
def main(req: func.HttpRequest) -> str:
    user = req.params.get("user")
    return f"Hello, {user}!"
import azure.functions as func

app = func.FunctionApp()

@app.function_name(name="HttpTrigger1")
@app.route(route="req")
def main(req: func.HttpRequest) -> str:
    user = req.params.get("user")
    return f"Hello, {user}!"
To learn about known limitations with the v2 model and their workarounds, seeTroubleshoot Python errors in Azure Functions.
Alternative entry point
You can change the default behavior of a function by optionally specifying thescriptFileandentryPointproperties in thefunction.jsonfile. For example, the followingfunction.jsontells the runtime to use thecustomentry()method in themain.pyfile as the entry point for your Azure function.
scriptFile
entryPoint
customentry()
{
  "scriptFile": "main.py",
  "entryPoint": "customentry",
  "bindings": [
      ...
  ]
}
{
  "scriptFile": "main.py",
  "entryPoint": "customentry",
  "bindings": [
      ...
  ]
}
The entry point is only in thefunction_app.pyfile. However, you can reference functions within the project infunction_app.pyby usingblueprintsor by importing.
Folder structure
The recommended folder structure for a Python functions project looks like the following example:
<project_root>/
 | - .venv/
 | - .vscode/
 | - my_first_function/
 | | - __init__.py
 | | - function.json
 | | - example.py
 | - my_second_function/
 | | - __init__.py
 | | - function.json
 | - shared_code/
 | | - __init__.py
 | | - my_first_helper_function.py
 | | - my_second_helper_function.py
 | - tests/
 | | - test_my_second_function.py
 | - .funcignore
 | - host.json
 | - local.settings.json
 | - requirements.txt
 | - Dockerfile
<project_root>/
 | - .venv/
 | - .vscode/
 | - my_first_function/
 | | - __init__.py
 | | - function.json
 | | - example.py
 | - my_second_function/
 | | - __init__.py
 | | - function.json
 | - shared_code/
 | | - __init__.py
 | | - my_first_helper_function.py
 | | - my_second_helper_function.py
 | - tests/
 | | - test_my_second_function.py
 | - .funcignore
 | - host.json
 | - local.settings.json
 | - requirements.txt
 | - Dockerfile
The main project folder,<project_root>, can contain the following files:
local.settings.json: Used to store app settings and connection strings when running locally. This file doesn't get published to Azure. To learn more, seelocal.settings.file.
requirements.txt: Contains the list of Python packages the system installs when publishing to Azure.
host.json: Contains configuration options that affect all functions in a function app instance. This file does get published to Azure. Not all options are supported when running locally. To learn more, seehost.json.
.vscode/: (Optional) Contains the stored Visual Studio Code configuration. To learn more, seeVisual Studio Code settings.
.venv/: (Optional) Contains a Python virtual environment used by local development.
Dockerfile: (Optional) Used when publishing your project in acustom container.
tests/: (Optional) Contains the test cases of your function app.
.funcignore: (Optional) Declares files that shouldn't get published to Azure. Usually, this file contains.vscode/to ignore your editor setting,.venv/to ignore the local Python virtual environment,tests/to ignore test cases, andlocal.settings.jsonto prevent local app settings from being published.
Each function has its own code file and binding configuration file,function.json.
The recommended folder structure for a Python functions project looks like the following example:
<project_root>/
 | - .venv/
 | - .vscode/
 | - function_app.py
 | - additional_functions.py
 | - tests/
 | | - test_my_function.py
 | - .funcignore
 | - host.json
 | - local.settings.json
 | - requirements.txt
 | - Dockerfile
<project_root>/
 | - .venv/
 | - .vscode/
 | - function_app.py
 | - additional_functions.py
 | - tests/
 | | - test_my_function.py
 | - .funcignore
 | - host.json
 | - local.settings.json
 | - requirements.txt
 | - Dockerfile
The main project folder,<project_root>, can contain the following files:
.venv/: (Optional) Contains a Python virtual environment that's used by local development.
.vscode/: (Optional) Contains the stored Visual Studio Code configuration. To learn more, seeVisual Studio Code settings.
function_app.py: The default location for all functions and their related triggers and bindings.
additional_functions.py: (Optional) Any other Python files that contain functions (usually for logical grouping) that are referenced infunction_app.pythrough blueprints.
tests/: (Optional) Contains the test cases of your function app.
.funcignore: (Optional) Declares files that shouldn't get published to Azure. Usually, this file contains.vscode/to ignore your editor setting,.venv/to ignore local Python virtual environment,tests/to ignore test cases, andlocal.settings.jsonto prevent local app settings being published.
host.json: Contains configuration options that affect all functions in a function app instance. This file does get published to Azure. Not all options are supported when running locally. To learn more, seehost.json.
local.settings.json: Used to store app settings and connection strings when it's running locally. This file doesn't get published to Azure. To learn more, seelocal.settings.file.
requirements.txt: Contains the list of Python packages the system installs when it publishes to Azure.
Dockerfile: (Optional) Used when publishing your project in acustom container.
When you deploy your project to a function app in Azure, the entire contents of the main project folder,<project_root>, should be included in the package, but not the folder itself, which means thathost.jsonshould be in the package root. We recommend that you maintain your tests in a folder along with other functions (in this example,tests/). For more information, seeUnit testing.
Connect to a database
Azure Functions integrates well withAzure Cosmos DBfor manyuse cases, including IoT, ecommerce, gaming, etc.
For example, forevent sourcing, the two services are integrated to power event-driven architectures using Azure Cosmos DB'schange feedfunctionality. The change feed provides downstream microservices the ability to reliably and incrementally read inserts and updates (for example, order events). This functionality can be used to provide a persistent event store as a message broker for state-changing events and drive order processing workflow between many microservices (which can be implemented asserverless Azure Functions).

To connect to Azure Cosmos DB, firstcreate an account, database, and container. Then you can connect your function code to Azure Cosmos DB usingtrigger and bindings, like thisexample.
To implement more complex app logic, you can also use the Python library for Cosmos DB. An asynchronous I/O implementation looks like this:
pip install azure-cosmos
pip install aiohttp

from azure.cosmos.aio import CosmosClient
from azure.cosmos import exceptions
from azure.cosmos.partition_key import PartitionKey
import asyncio

# Replace these values with your Cosmos DB connection information
endpoint = "https://azure-cosmos-nosql.documents.azure.com:443/"
key = "master_key"
database_id = "cosmicwerx"
container_id = "cosmicontainer"
partition_key = "/partition_key"

# Set the total throughput (RU/s) for the database and container
database_throughput = 1000

# Singleton CosmosClient instance
client = CosmosClient(endpoint, credential=key)

# Helper function to get or create database and container
async def get_or_create_container(client, database_id, container_id, partition_key):
    database = await client.create_database_if_not_exists(id=database_id)
    print(f'Database "{database_id}" created or retrieved successfully.')

    container = await database.create_container_if_not_exists(id=container_id, partition_key=PartitionKey(path=partition_key))
    print(f'Container with id "{container_id}" created')
 
    return container
 
async def create_products():
    container = await get_or_create_container(client, database_id, container_id, partition_key)
    for i in range(10):
        await container.upsert_item({
            'id': f'item{i}',
            'productName': 'Widget',
            'productModel': f'Model {i}'
        })
 
async def get_products():
    items = []
    container = await get_or_create_container(client, database_id, container_id, partition_key)
    async for item in container.read_all_items():
        items.append(item)
    return items

async def query_products(product_name):
    container = await get_or_create_container(client, database_id, container_id, partition_key)
    query = f"SELECT * FROM c WHERE c.productName = '{product_name}'"
    items = []
    async for item in container.query_items(query=query, enable_cross_partition_query=True):
        items.append(item)
    return items

async def main():
    await create_products()
    all_products = await get_products()
    print('All Products:', all_products)

    queried_products = await query_products('Widget')
    print('Queried Products:', queried_products)

if __name__ == "__main__":
    asyncio.run(main())
pip install azure-cosmos
pip install aiohttp

from azure.cosmos.aio import CosmosClient
from azure.cosmos import exceptions
from azure.cosmos.partition_key import PartitionKey
import asyncio

# Replace these values with your Cosmos DB connection information
endpoint = "https://azure-cosmos-nosql.documents.azure.com:443/"
key = "master_key"
database_id = "cosmicwerx"
container_id = "cosmicontainer"
partition_key = "/partition_key"

# Set the total throughput (RU/s) for the database and container
database_throughput = 1000

# Singleton CosmosClient instance
client = CosmosClient(endpoint, credential=key)

# Helper function to get or create database and container
async def get_or_create_container(client, database_id, container_id, partition_key):
    database = await client.create_database_if_not_exists(id=database_id)
    print(f'Database "{database_id}" created or retrieved successfully.')

    container = await database.create_container_if_not_exists(id=container_id, partition_key=PartitionKey(path=partition_key))
    print(f'Container with id "{container_id}" created')
 
    return container
 
async def create_products():
    container = await get_or_create_container(client, database_id, container_id, partition_key)
    for i in range(10):
        await container.upsert_item({
            'id': f'item{i}',
            'productName': 'Widget',
            'productModel': f'Model {i}'
        })
 
async def get_products():
    items = []
    container = await get_or_create_container(client, database_id, container_id, partition_key)
    async for item in container.read_all_items():
        items.append(item)
    return items

async def query_products(product_name):
    container = await get_or_create_container(client, database_id, container_id, partition_key)
    query = f"SELECT * FROM c WHERE c.productName = '{product_name}'"
    items = []
    async for item in container.query_items(query=query, enable_cross_partition_query=True):
        items.append(item)
    return items

async def main():
    await create_products()
    all_products = await get_products()
    print('All Products:', all_products)

    queried_products = await query_products('Widget')
    print('Queried Products:', queried_products)

if __name__ == "__main__":
    asyncio.run(main())
Blueprints
The Python v2 programming model introduces the concept ofblueprints. A blueprint is a new class that's instantiated to register functions outside of the core function application. The functions registered in blueprint instances aren't indexed directly by the function runtime. To get these blueprint functions indexed, the function app needs to register the functions from blueprint instances.
Using blueprints provides the following benefits:
Lets you break up the function app into modular components, which enables you to define functions in multiple Python files and divide them into different components per file.
Provides extensible public function app interfaces to build and reuse your own APIs.
The following example shows how to use blueprints:
First, in anhttp_blueprint.pyfile, an HTTP-triggered function is first defined and added to a blueprint object.
import logging 

import azure.functions as func 

bp = func.Blueprint() 

@bp.route(route="default_template") 
def default_template(req: func.HttpRequest) -> func.HttpResponse: 
    logging.info('Python HTTP trigger function processed a request.') 

    name = req.params.get('name') 
    if not name: 
        try: 
            req_body = req.get_json() 
        except ValueError: 
            pass 
        else: 
            name = req_body.get('name') 

    if name: 
        return func.HttpResponse( 
            f"Hello, {name}. This HTTP-triggered function " 
            f"executed successfully.") 
    else: 
        return func.HttpResponse( 
            "This HTTP-triggered function executed successfully. " 
            "Pass a name in the query string or in the request body for a" 
            " personalized response.", 
            status_code=200 
        )
import logging 

import azure.functions as func 

bp = func.Blueprint() 

@bp.route(route="default_template") 
def default_template(req: func.HttpRequest) -> func.HttpResponse: 
    logging.info('Python HTTP trigger function processed a request.') 

    name = req.params.get('name') 
    if not name: 
        try: 
            req_body = req.get_json() 
        except ValueError: 
            pass 
        else: 
            name = req_body.get('name') 

    if name: 
        return func.HttpResponse( 
            f"Hello, {name}. This HTTP-triggered function " 
            f"executed successfully.") 
    else: 
        return func.HttpResponse( 
            "This HTTP-triggered function executed successfully. " 
            "Pass a name in the query string or in the request body for a" 
            " personalized response.", 
            status_code=200 
        )
Next, in thefunction_app.pyfile, the blueprint object is imported and its functions are registered to the function app.
import azure.functions as func 
from http_blueprint import bp

app = func.FunctionApp() 

app.register_functions(bp)
import azure.functions as func 
from http_blueprint import bp

app = func.FunctionApp() 

app.register_functions(bp)
Note
Durable Functions also supports blueprints. To create blueprints for Durable Functions apps, register your orchestration, activity, and entity triggers and client bindings using theazure-functions-durableBlueprintclass, as
shownhere. The resulting blueprint can then be registered as normal. See oursamplefor an example.
azure-functions-durable
Blueprint
Import behavior
You can import modules in your function code by using both absolute and relative references. Based on the previously described folder structure, the following imports work from within the function file<project_root>\my_first_function\__init__.py:
from shared_code import my_first_helper_function #(absolute)
from shared_code import my_first_helper_function #(absolute)
import shared_code.my_second_helper_function #(absolute)
import shared_code.my_second_helper_function #(absolute)
from . import example #(relative)
from . import example #(relative)
Note
When you're using absolute import syntax, theshared_code/folder needs to contain an__init__.pyfile to mark it as a Python package.
The following __app__ import and beyond top-level relative import are deprecated, because they're not supported by the static type checker and not supported by Python test frameworks:
from __app__.shared_code import my_first_helper_function #(deprecated __app__ import)
from __app__.shared_code import my_first_helper_function #(deprecated __app__ import)
from ..shared_code import my_first_helper_function #(deprecated beyond top-level relative import)
from ..shared_code import my_first_helper_function #(deprecated beyond top-level relative import)
Triggers and inputs
Inputs are divided into two categories in Azure Functions: trigger input and other input. Although they're different in thefunction.jsonfile, their usage is identical in Python code. Connection strings or secrets for trigger and input sources map to values in thelocal.settings.jsonfile when they're running locally, and they map to the application settings when they're running in Azure.
For example, the following code demonstrates the difference between the two inputs:
// function.json
{
  "scriptFile": "__init__.py",
  "bindings": [
    {
      "name": "req",
      "direction": "in",
      "type": "httpTrigger",
      "authLevel": "anonymous",
      "route": "items/{id}"
    },
    {
      "name": "obj",
      "direction": "in",
      "type": "blob",
      "path": "samples/{id}",
      "connection": "STORAGE_CONNECTION_STRING"
    }
  ]
}
// function.json
{
  "scriptFile": "__init__.py",
  "bindings": [
    {
      "name": "req",
      "direction": "in",
      "type": "httpTrigger",
      "authLevel": "anonymous",
      "route": "items/{id}"
    },
    {
      "name": "obj",
      "direction": "in",
      "type": "blob",
      "path": "samples/{id}",
      "connection": "STORAGE_CONNECTION_STRING"
    }
  ]
}
// local.settings.json
{
  "IsEncrypted": false,
  "Values": {
    "FUNCTIONS_WORKER_RUNTIME": "python",
    "STORAGE_CONNECTION_STRING": "<AZURE_STORAGE_CONNECTION_STRING>",
    "AzureWebJobsStorage": "<azure-storage-connection-string>"
  }
}
// local.settings.json
{
  "IsEncrypted": false,
  "Values": {
    "FUNCTIONS_WORKER_RUNTIME": "python",
    "STORAGE_CONNECTION_STRING": "<AZURE_STORAGE_CONNECTION_STRING>",
    "AzureWebJobsStorage": "<azure-storage-connection-string>"
  }
}
# __init__.py
import azure.functions as func
import logging

def main(req: func.HttpRequest, obj: func.InputStream):
    logging.info(f'Python HTTP-triggered function processed: {obj.read()}')
# __init__.py
import azure.functions as func
import logging

def main(req: func.HttpRequest, obj: func.InputStream):
    logging.info(f'Python HTTP-triggered function processed: {obj.read()}')
When the function is invoked, the HTTP request is passed to the function asreq. An entry is retrieved from the Azure Blob Storage account based on theIDin the route URL and made available asobjin the function body. Here, the specified storage account is the connection string that's found in the<*_CONNECTION_STRING>app setting. For more information, see  For more information, seeConnections.
req
obj
<*_CONNECTION_STRING>
Inputs are divided into two categories in Azure Functions: trigger input and other input. Although they're defined using different decorators, their usage is similar in Python code. Connection strings or secrets for trigger and input sources map to values in thelocal.settings.jsonfile when they're running locally, and they map to the application settings when they're running in Azure.
As an example, the following code demonstrates how to define a Blob Storage input binding:
// local.settings.json
{
  "IsEncrypted": false,
  "Values": {
    "FUNCTIONS_WORKER_RUNTIME": "python",
    "STORAGE_CONNECTION_STRING": "<AZURE_STORAGE_CONNECTION_STRING>",
    "AzureWebJobsStorage": "<azure-storage-connection-string>"
  }
}
// local.settings.json
{
  "IsEncrypted": false,
  "Values": {
    "FUNCTIONS_WORKER_RUNTIME": "python",
    "STORAGE_CONNECTION_STRING": "<AZURE_STORAGE_CONNECTION_STRING>",
    "AzureWebJobsStorage": "<azure-storage-connection-string>"
  }
}
# function_app.py
import azure.functions as func
import logging

app = func.FunctionApp()

@app.route(route="req")
@app.read_blob(arg_name="obj", path="samples/{id}", 
               connection="STORAGE_CONNECTION_STRING")
def main(req: func.HttpRequest, obj: func.InputStream):
    logging.info(f'Python HTTP-triggered function processed: {obj.read()}')
# function_app.py
import azure.functions as func
import logging

app = func.FunctionApp()

@app.route(route="req")
@app.read_blob(arg_name="obj", path="samples/{id}", 
               connection="STORAGE_CONNECTION_STRING")
def main(req: func.HttpRequest, obj: func.InputStream):
    logging.info(f'Python HTTP-triggered function processed: {obj.read()}')
When the function is invoked, the HTTP request is passed to the function asreq. An entry is retrieved from the Azure Blob Storage account based on theIDin the route URL and made available asobjin the function body.  Here, the specified storage account is the connection string found in the<*_CONNECTION_STRING>app setting. For more information, see  For more information, seeConnections.
req
obj
<*_CONNECTION_STRING>
For data intensive binding operations, you may want to use a separate storage account. For more information, seeStorage account guidance.
SDK type bindings (preview)
For select triggers and bindings, you can work with data types implemented by the underlying Azure SDKs and frameworks. TheseSDK type bindingslet you interact binding data as if you were using the underlying service SDK.
Important
Support for SDK type bindings requires thePython v2 programming model.
Functions supports Python SDK type bindings for Azure Blob storage, which lets you work with blob data using the underlyingBlobClienttype.
BlobClient
Important
SDK type bindings support for Python is currently in preview:
You must use the Python v2 programming model.
Currently, only synchronous SDK types are supported.
Prerequisites
Azure Functions runtime versionversion 4.34, or a later version.
Pythonversion 3.9, or a latersupported version.
Enable SDK type bindings for the Blob storage extension
Add theazurefunctions-extensions-bindings-blobextension package to therequirements.txtfile in the project, which should include at least these packages:azure-functions
azurefunctions-extensions-bindings-blob
Add theazurefunctions-extensions-bindings-blobextension package to therequirements.txtfile in the project, which should include at least these packages:
azurefunctions-extensions-bindings-blob
requirements.txt
azure-functions
azurefunctions-extensions-bindings-blob
azure-functions
azurefunctions-extensions-bindings-blob
Add this code to thefunction_app.pyfile in the project, which imports the SDK type bindings:app = func.FunctionApp(http_auth_level=func.AuthLevel.ANONYMOUS)
Add this code to thefunction_app.pyfile in the project, which imports the SDK type bindings:
function_app.py
app = func.FunctionApp(http_auth_level=func.AuthLevel.ANONYMOUS)
app = func.FunctionApp(http_auth_level=func.AuthLevel.ANONYMOUS)
SDK type bindings examples
This example shows how to get theBlobClientfrom both a Blob storage trigger (blob_trigger) and from the input binding on an HTTP trigger (blob_input):
BlobClient
blob_trigger
blob_input
import azure.functions as func
import azurefunctions.extensions.bindings.blob as blob

app = func.FunctionApp(http_auth_level=func.AuthLevel.ANONYMOUS)

"""
    arg_name="client", path="PATH/TO/BLOB", connection="AzureWebJobsStorage"
)
def blob_trigger(client: blob.BlobClient):
    logging.info(
        f"Python blob trigger function processed blob \n"
        f"Properties: {client.get_blob_properties()}\n"
        f"Blob content head: {client.download_blob().read(size=1)}"
    )


@app.route(route="file")
@app.blob_input(
    arg_name="client", path="PATH/TO/BLOB", connection="AzureWebJobsStorage"
)
def blob_input(req: func.HttpRequest, client: blob.BlobClient):
    logging.info(
        f"Python blob input function processed blob \n"
        f"Properties: {client.get_blob_properties()}\n"
        f"Blob content head: {client.download_blob().read(size=1)}"
    )
    return "ok"
import azure.functions as func
import azurefunctions.extensions.bindings.blob as blob

app = func.FunctionApp(http_auth_level=func.AuthLevel.ANONYMOUS)

"""
    arg_name="client", path="PATH/TO/BLOB", connection="AzureWebJobsStorage"
)
def blob_trigger(client: blob.BlobClient):
    logging.info(
        f"Python blob trigger function processed blob \n"
        f"Properties: {client.get_blob_properties()}\n"
        f"Blob content head: {client.download_blob().read(size=1)}"
    )


@app.route(route="file")
@app.blob_input(
    arg_name="client", path="PATH/TO/BLOB", connection="AzureWebJobsStorage"
)
def blob_input(req: func.HttpRequest, client: blob.BlobClient):
    logging.info(
        f"Python blob input function processed blob \n"
        f"Properties: {client.get_blob_properties()}\n"
        f"Blob content head: {client.download_blob().read(size=1)}"
    )
    return "ok"
You can view other SDK type bindings samples for Blob storage in the Python extensions repository:
ContainerClient type
StorageStreamDownloader type
HTTP streams (preview)
HTTP streams lets you accept and return data from your HTTP endpoints using FastAPI request and response APIs enabled in your functions. These APIs lets the host process large data in HTTP messages as chunks instead of reading an entire message into memory.
This feature makes it possible to handle large data stream, OpenAI integrations, deliver dynamic content, and support other core HTTP scenarios requiring real-time interactions over HTTP. You can also use FastAPI response types with HTTP streams. Without HTTP streams, the size of your HTTP requests and responses are limited by memory restrictions that can be encountered when processing entire message payloads all in memory.
Important
Support for HTTP streams requires thePython v2 programming model.
Important
HTTP streams support for Python is currently in preview and requires you to use the Python v2 programming model.
Prerequisites
Azure Functions runtimeversion 4.34.1, or a later version.
Pythonversion 3.8, or a latersupported version.
Enable HTTP streams
HTTP streams are disabled by default. You need to enable this feature in your application settings and also update your code to use the FastAPI package. Note that when enabling HTTP streams, the function app will default to using HTTP streaming, and the original HTTP functionality will not work.
Add theazurefunctions-extensions-http-fastapiextension package to therequirements.txtfile in the project, which should include at least these packages:azure-functions
azurefunctions-extensions-http-fastapi
Add theazurefunctions-extensions-http-fastapiextension package to therequirements.txtfile in the project, which should include at least these packages:
azurefunctions-extensions-http-fastapi
requirements.txt
azure-functions
azurefunctions-extensions-http-fastapi
azure-functions
azurefunctions-extensions-http-fastapi
Add this code to thefunction_app.pyfile in the project, which imports the FastAPI extension:from azurefunctions.extensions.http.fastapi import Request, StreamingResponse
Add this code to thefunction_app.pyfile in the project, which imports the FastAPI extension:
function_app.py
from azurefunctions.extensions.http.fastapi import Request, StreamingResponse
from azurefunctions.extensions.http.fastapi import Request, StreamingResponse
When you deploy to Azure, add the followingapplication settingin your function app:"PYTHON_ENABLE_INIT_INDEXING": "1"If you are deploying to Linux Consumption, also add"PYTHON_ISOLATE_WORKER_DEPENDENCIES": "1"When running locally, you also need to add these same settings to thelocal.settings.jsonproject file.
When you deploy to Azure, add the followingapplication settingin your function app:
"PYTHON_ENABLE_INIT_INDEXING": "1"
"PYTHON_ENABLE_INIT_INDEXING": "1"
If you are deploying to Linux Consumption, also add
"PYTHON_ISOLATE_WORKER_DEPENDENCIES": "1"
"PYTHON_ISOLATE_WORKER_DEPENDENCIES": "1"
When running locally, you also need to add these same settings to thelocal.settings.jsonproject file.
local.settings.json
HTTP streams examples
After you enable the HTTP streaming feature, you can create functions that stream data over HTTP.
This example is an HTTP triggered function that streams HTTP response data. You might use these capabilities to support scenarios like sending event data through a pipeline for real time visualization or detecting anomalies in large sets of data and providing instant notifications.
import time

import azure.functions as func
from azurefunctions.extensions.http.fastapi import Request, StreamingResponse

app = func.FunctionApp(http_auth_level=func.AuthLevel.ANONYMOUS)


def generate_sensor_data():
    """Generate real-time sensor data."""
    for i in range(10):
        # Simulate temperature and humidity readings
        temperature = 20 + i
        humidity = 50 + i
        yield f"data: {{'temperature': {temperature}, 'humidity': {humidity}}}\n\n"
        time.sleep(1)


@app.route(route="stream", methods=[func.HttpMethod.GET])
async def stream_sensor_data(req: Request) -> StreamingResponse:
    """Endpoint to stream real-time sensor data."""
    return StreamingResponse(generate_sensor_data(), media_type="text/event-stream")
import time

import azure.functions as func
from azurefunctions.extensions.http.fastapi import Request, StreamingResponse

app = func.FunctionApp(http_auth_level=func.AuthLevel.ANONYMOUS)


def generate_sensor_data():
    """Generate real-time sensor data."""
    for i in range(10):
        # Simulate temperature and humidity readings
        temperature = 20 + i
        humidity = 50 + i
        yield f"data: {{'temperature': {temperature}, 'humidity': {humidity}}}\n\n"
        time.sleep(1)


@app.route(route="stream", methods=[func.HttpMethod.GET])
async def stream_sensor_data(req: Request) -> StreamingResponse:
    """Endpoint to stream real-time sensor data."""
    return StreamingResponse(generate_sensor_data(), media_type="text/event-stream")
This example is an HTTP triggered function that receives and processes streaming data from a client in real time. It demonstrates streaming upload capabilities that can be helpful for scenarios like processing continuous data streams and handling event data from IoT devices.
import azure.functions as func
from azurefunctions.extensions.http.fastapi import JSONResponse, Request

app = func.FunctionApp(http_auth_level=func.AuthLevel.ANONYMOUS)


@app.route(route="streaming_upload", methods=[func.HttpMethod.POST])
async def streaming_upload(req: Request) -> JSONResponse:
    """Handle streaming upload requests."""
    # Process each chunk of data as it arrives
    async for chunk in req.stream():
        process_data_chunk(chunk)

    # Once all data is received, return a JSON response indicating successful processing
    return JSONResponse({"status": "Data uploaded and processed successfully"})


def process_data_chunk(chunk: bytes):
    """Process each data chunk."""
    # Add custom processing logic here
    pass
import azure.functions as func
from azurefunctions.extensions.http.fastapi import JSONResponse, Request

app = func.FunctionApp(http_auth_level=func.AuthLevel.ANONYMOUS)


@app.route(route="streaming_upload", methods=[func.HttpMethod.POST])
async def streaming_upload(req: Request) -> JSONResponse:
    """Handle streaming upload requests."""
    # Process each chunk of data as it arrives
    async for chunk in req.stream():
        process_data_chunk(chunk)

    # Once all data is received, return a JSON response indicating successful processing
    return JSONResponse({"status": "Data uploaded and processed successfully"})


def process_data_chunk(chunk: bytes):
    """Process each data chunk."""
    # Add custom processing logic here
    pass
Calling HTTP streams
You must use an HTTP client library to make streaming calls to a function's FastAPI endpoints. The client tool or browser you're using might not natively support streaming or could only return the first chunk of data.
You can use a client script like this to send streaming data to an HTTP endpoint:
import httpx # Be sure to add 'httpx' to 'requirements.txt'
import asyncio

async def stream_generator(file_path):
    chunk_size = 2 * 1024  # Define your own chunk size
    with open(file_path, 'rb') as file:
        while chunk := file.read(chunk_size):
            yield chunk
            print(f"Sent chunk: {len(chunk)} bytes")

async def stream_to_server(url, file_path):
    timeout = httpx.Timeout(60.0, connect=60.0)
    async with httpx.AsyncClient(timeout=timeout) as client:
        response = await client.post(url, content=stream_generator(file_path))
        return response

async def stream_response(response):
    if response.status_code == 200:
        async for chunk in response.aiter_raw():
            print(f"Received chunk: {len(chunk)} bytes")
    else:
        print(f"Error: {response}")

async def main():
    print('helloworld')
    # Customize your streaming endpoint served from core tool in variable 'url' if different.
    url = 'http://localhost:7071/api/streaming_upload'
    file_path = r'<file path>'

    response = await stream_to_server(url, file_path)
    print(response)

if __name__ == "__main__":
    asyncio.run(main())
import httpx # Be sure to add 'httpx' to 'requirements.txt'
import asyncio

async def stream_generator(file_path):
    chunk_size = 2 * 1024  # Define your own chunk size
    with open(file_path, 'rb') as file:
        while chunk := file.read(chunk_size):
            yield chunk
            print(f"Sent chunk: {len(chunk)} bytes")

async def stream_to_server(url, file_path):
    timeout = httpx.Timeout(60.0, connect=60.0)
    async with httpx.AsyncClient(timeout=timeout) as client:
        response = await client.post(url, content=stream_generator(file_path))
        return response

async def stream_response(response):
    if response.status_code == 200:
        async for chunk in response.aiter_raw():
            print(f"Received chunk: {len(chunk)} bytes")
    else:
        print(f"Error: {response}")

async def main():
    print('helloworld')
    # Customize your streaming endpoint served from core tool in variable 'url' if different.
    url = 'http://localhost:7071/api/streaming_upload'
    file_path = r'<file path>'

    response = await stream_to_server(url, file_path)
    print(response)

if __name__ == "__main__":
    asyncio.run(main())
Outputs
Output can be expressed both in return value and output parameters. If there's only one output, we recommend using the return value. For multiple outputs, you must use output parameters.
To use the return value of a function as the value of an output binding, thenameproperty of the binding should be set to$returnin thefunction.jsonfile.
name
$return
To produce multiple outputs, use theset()method provided by theazure.functions.Outinterface to assign a value to the binding. For example, the following function can push a message to a queue and also return an HTTP response.
set()
azure.functions.Out
{
  "scriptFile": "__init__.py",
  "bindings": [
    {
      "name": "req",
      "direction": "in",
      "type": "httpTrigger",
      "authLevel": "anonymous"
    },
    {
      "name": "msg",
      "direction": "out",
      "type": "queue",
      "queueName": "outqueue",
      "connection": "STORAGE_CONNECTION_STRING"
    },
    {
      "name": "$return",
      "direction": "out",
      "type": "http"
    }
  ]
}
{
  "scriptFile": "__init__.py",
  "bindings": [
    {
      "name": "req",
      "direction": "in",
      "type": "httpTrigger",
      "authLevel": "anonymous"
    },
    {
      "name": "msg",
      "direction": "out",
      "type": "queue",
      "queueName": "outqueue",
      "connection": "STORAGE_CONNECTION_STRING"
    },
    {
      "name": "$return",
      "direction": "out",
      "type": "http"
    }
  ]
}
import azure.functions as func

def main(req: func.HttpRequest,
         msg: func.Out[func.QueueMessage]) -> str:

    message = req.params.get('body')
    msg.set(message)
    return message
import azure.functions as func

def main(req: func.HttpRequest,
         msg: func.Out[func.QueueMessage]) -> str:

    message = req.params.get('body')
    msg.set(message)
    return message
Output can be expressed both in return value and output parameters. If there's only one output, we recommend using the return value. For multiple outputs, you'll have to use output parameters.
To produce multiple outputs, use theset()method provided by theazure.functions.Outinterface to assign a value to the binding. For example, the following function can push a message to a queue and also return an HTTP response.
set()
azure.functions.Out
# function_app.py
import azure.functions as func

app = func.FunctionApp()

@app.write_blob(arg_name="msg", path="output-container/{name}",
                connection="CONNECTION_STRING")
def test_function(req: func.HttpRequest,
                  msg: func.Out[str]) -> str:

    message = req.params.get('body')
    msg.set(message)
    return message
# function_app.py
import azure.functions as func

app = func.FunctionApp()

@app.write_blob(arg_name="msg", path="output-container/{name}",
                connection="CONNECTION_STRING")
def test_function(req: func.HttpRequest,
                  msg: func.Out[str]) -> str:

    message = req.params.get('body')
    msg.set(message)
    return message
Logging
Access to the Azure Functions runtime logger is available via a rootlogginghandler in your function app. This logger is tied to Application Insights and allows you to flag warnings and errors that occur during the function execution.
logging
The following example logs an info message when the function is invoked via an HTTP trigger.
import logging

def main(req):
    logging.info('Python HTTP trigger function processed a request.')
import logging

def main(req):
    logging.info('Python HTTP trigger function processed a request.')
More logging methods are available that let you write to the console at different trace levels:
critical(_message_)
error(_message_)
warning(_message_)
info(_message_)
debug(_message_)
To learn more about logging, seeMonitor Azure Functions.
Logging from created threads
To see logs coming from your created threads, include thecontextargument in the function's signature. This argument contains an attributethread_local_storagethat stores a localinvocation_id. This can be set to the function's currentinvocation_idto ensure the context is changed.
context
thread_local_storage
invocation_id
invocation_id
import azure.functions as func
import logging
import threading


def main(req, context):
    logging.info('Python HTTP trigger function processed a request.')
    t = threading.Thread(target=log_function, args=(context,))
    t.start()


def log_function(context):
    context.thread_local_storage.invocation_id = context.invocation_id
    logging.info('Logging from thread.')
import azure.functions as func
import logging
import threading


def main(req, context):
    logging.info('Python HTTP trigger function processed a request.')
    t = threading.Thread(target=log_function, args=(context,))
    t.start()


def log_function(context):
    context.thread_local_storage.invocation_id = context.invocation_id
    logging.info('Logging from thread.')
Log custom telemetry
By default, the Functions runtime collects logs and other telemetry data that are generated by your functions. This telemetry ends up as traces in Application Insights. Request and dependency telemetry for certain Azure services are also collected by default bytriggers and bindings.
To collect custom request and custom dependency telemetry outside of bindings, you can use theOpenCensus Python Extensions. This extension sends custom telemetry data to your Application Insights instance. You can find a list of supported extensions at theOpenCensus repository.
Note
To use the OpenCensus Python extensions, you need to enablePython worker extensionsin your function app by settingPYTHON_ENABLE_WORKER_EXTENSIONSto1. You also need to switch to using the Application Insights connection string by adding theAPPLICATIONINSIGHTS_CONNECTION_STRINGsetting to yourapplication settings, if it's not already there.
PYTHON_ENABLE_WORKER_EXTENSIONS
1
APPLICATIONINSIGHTS_CONNECTION_STRING
// requirements.txt
...
opencensus-extension-azure-functions
opencensus-ext-requests
// requirements.txt
...
opencensus-extension-azure-functions
opencensus-ext-requests
import json
import logging

import requests
from opencensus.extension.azure.functions import OpenCensusExtension
from opencensus.trace import config_integration

config_integration.trace_integrations(['requests'])

OpenCensusExtension.configure()

def main(req, context):
    logging.info('Executing HttpTrigger with OpenCensus extension')

    # You must use context.tracer to create spans
    with context.tracer.span("parent"):
        response = requests.get(url='http://example.com')

    return json.dumps({
        'method': req.method,
        'response': response.status_code,
        'ctx_func_name': context.function_name,
        'ctx_func_dir': context.function_directory,
        'ctx_invocation_id': context.invocation_id,
        'ctx_trace_context_Traceparent': context.trace_context.Traceparent,
        'ctx_trace_context_Tracestate': context.trace_context.Tracestate,
        'ctx_retry_context_RetryCount': context.retry_context.retry_count,
        'ctx_retry_context_MaxRetryCount': context.retry_context.max_retry_count,
    })
import json
import logging

import requests
from opencensus.extension.azure.functions import OpenCensusExtension
from opencensus.trace import config_integration

config_integration.trace_integrations(['requests'])

OpenCensusExtension.configure()

def main(req, context):
    logging.info('Executing HttpTrigger with OpenCensus extension')

    # You must use context.tracer to create spans
    with context.tracer.span("parent"):
        response = requests.get(url='http://example.com')

    return json.dumps({
        'method': req.method,
        'response': response.status_code,
        'ctx_func_name': context.function_name,
        'ctx_func_dir': context.function_directory,
        'ctx_invocation_id': context.invocation_id,
        'ctx_trace_context_Traceparent': context.trace_context.Traceparent,
        'ctx_trace_context_Tracestate': context.trace_context.Tracestate,
        'ctx_retry_context_RetryCount': context.retry_context.retry_count,
        'ctx_retry_context_MaxRetryCount': context.retry_context.max_retry_count,
    })
HTTP trigger
The HTTP trigger is defined in thefunction.jsonfile. Thenameof the binding must match the named parameter in the function.
In the previous examples, a binding namereqis used. This parameter is anHttpRequestobject, and anHttpResponseobject is returned.
name
req
From theHttpRequestobject, you can get request headers, query parameters, route parameters, and the message body.
The following example is from theHTTP trigger template for Python.
def main(req: func.HttpRequest) -> func.HttpResponse:
    headers = {"my-http-header": "some-value"}

    name = req.params.get('name')
    if not name:
        try:
            req_body = req.get_json()
        except ValueError:
            pass
        else:
            name = req_body.get('name')

    if name:
        return func.HttpResponse(f"Hello {name}!", headers=headers)
    else:
        return func.HttpResponse(
             "Please pass a name on the query string or in the request body",
             headers=headers, status_code=400
        )
def main(req: func.HttpRequest) -> func.HttpResponse:
    headers = {"my-http-header": "some-value"}

    name = req.params.get('name')
    if not name:
        try:
            req_body = req.get_json()
        except ValueError:
            pass
        else:
            name = req_body.get('name')

    if name:
        return func.HttpResponse(f"Hello {name}!", headers=headers)
    else:
        return func.HttpResponse(
             "Please pass a name on the query string or in the request body",
             headers=headers, status_code=400
        )
In this function, you obtain the value of thenamequery parameter from theparamsparameter of theHttpRequestobject. You read the JSON-encoded message body by using theget_jsonmethod.
name
params
get_json
Likewise, you can set thestatus_codeandheadersfor the response message in the returnedHttpResponseobject.
status_code
headers
The HTTP trigger is defined as a method that takes a named binding parameter, which is anHttpRequestobject, and returns anHttpResponseobject. You apply thefunction_namedecorator to the method to define the function name, while the HTTP endpoint is set by applying theroutedecorator.
function_name
route
This example is from the HTTP trigger template for the Python v2 programming model, where the binding parameter name isreq. It's the sample code that's provided when you create a function by using Azure Functions Core Tools or Visual Studio Code.
req
@app.function_name(name="HttpTrigger1")
@app.route(route="hello")
def test_function(req: func.HttpRequest) -> func.HttpResponse:
     logging.info('Python HTTP trigger function processed a request.')

     name = req.params.get('name')
     if not name:
        try:
            req_body = req.get_json()
        except ValueError:
            pass
        else:
            name = req_body.get('name')

     if name:
        return func.HttpResponse(f"Hello, {name}. This HTTP-triggered function executed successfully.")
     else:
        return func.HttpResponse(
             "This HTTP-triggered function executed successfully. Pass a name in the query string or in the request body for a personalized response.",
             status_code=200
        )
@app.function_name(name="HttpTrigger1")
@app.route(route="hello")
def test_function(req: func.HttpRequest) -> func.HttpResponse:
     logging.info('Python HTTP trigger function processed a request.')

     name = req.params.get('name')
     if not name:
        try:
            req_body = req.get_json()
        except ValueError:
            pass
        else:
            name = req_body.get('name')

     if name:
        return func.HttpResponse(f"Hello, {name}. This HTTP-triggered function executed successfully.")
     else:
        return func.HttpResponse(
             "This HTTP-triggered function executed successfully. Pass a name in the query string or in the request body for a personalized response.",
             status_code=200
        )
From theHttpRequestobject, you can get request headers, query parameters, route parameters, and the message body. In this function, you obtain the value of thenamequery parameter from theparamsparameter of theHttpRequestobject. You read the JSON-encoded message body by using theget_jsonmethod.
name
params
get_json
Likewise, you can set thestatus_codeandheadersfor the response message in the returnedHttpResponseobject.
status_code
headers
To pass in a name in this example, paste the URL that's provided when you're running the function, and then append it with"?name={name}".
"?name={name}"
Web frameworks
You can use Web Server Gateway Interface (WSGI)-compatible and Asynchronous Server Gateway Interface (ASGI)-compatible frameworks, such as Flask and FastAPI, with your HTTP-triggered Python functions. This section shows how to modify your functions to support these frameworks.
First, thefunction.jsonfile must be updated to include aroutein the HTTP trigger, as shown in the following example:
route
{
  "scriptFile": "__init__.py",
  "bindings": [
    {
       "authLevel": "anonymous",
       "type": "httpTrigger",
       "direction": "in",
       "name": "req",
       "methods": [
           "get",
           "post"
       ],
       "route": "{*route}"
    },
    {
       "type": "http",
       "direction": "out",
       "name": "$return"
    }
  ]
}
{
  "scriptFile": "__init__.py",
  "bindings": [
    {
       "authLevel": "anonymous",
       "type": "httpTrigger",
       "direction": "in",
       "name": "req",
       "methods": [
           "get",
           "post"
       ],
       "route": "{*route}"
    },
    {
       "type": "http",
       "direction": "out",
       "name": "$return"
    }
  ]
}
Thehost.jsonfile must also be updated to include an HTTProutePrefix, as shown in the following example:
routePrefix
{
  "version": "2.0",
  "logging": 
  {
    "applicationInsights": 
    {
      "samplingSettings": 
      {
        "isEnabled": true,
        "excludedTypes": "Request"
      }
    }
  },
  "extensionBundle": 
  {
    "id": "Microsoft.Azure.Functions.ExtensionBundle",
    "version": "[3.*, 4.0.0)"
  },
  "extensions": 
  {
    "http": 
    {
        "routePrefix": ""
    }
  }
}
{
  "version": "2.0",
  "logging": 
  {
    "applicationInsights": 
    {
      "samplingSettings": 
      {
        "isEnabled": true,
        "excludedTypes": "Request"
      }
    }
  },
  "extensionBundle": 
  {
    "id": "Microsoft.Azure.Functions.ExtensionBundle",
    "version": "[3.*, 4.0.0)"
  },
  "extensions": 
  {
    "http": 
    {
        "routePrefix": ""
    }
  }
}
Update the Python code fileinit.py, depending on the interface that's used by your framework. The following example shows either an ASGI handler approach or a WSGI wrapper approach for Flask:
ASGI
WSGI
app = fastapi.FastAPI()

@app.get("hello/{name}")
async def get_name(name: str):
  return {"name": name}

def main(req: func.HttpRequest, context: func.Context) -> func.HttpResponse:
    return func.AsgiMiddleware(app).handle(req, context)
app = fastapi.FastAPI()

@app.get("hello/{name}")
async def get_name(name: str):
  return {"name": name}

def main(req: func.HttpRequest, context: func.Context) -> func.HttpResponse:
    return func.AsgiMiddleware(app).handle(req, context)
app = Flask("Test")

@app.route("hello/<name>", methods=["GET"])
def hello(name: str):
    return f"hello {name}"

def main(req: func.HttpRequest, context) -> func.HttpResponse:
  logging.info("Python HTTP trigger function processed a request.")
  return func.WsgiMiddleware(app).handle(req, context)
app = Flask("Test")

@app.route("hello/<name>", methods=["GET"])
def hello(name: str):
    return f"hello {name}"

def main(req: func.HttpRequest, context) -> func.HttpResponse:
  logging.info("Python HTTP trigger function processed a request.")
  return func.WsgiMiddleware(app).handle(req, context)
For a full example, seeUsing Flask Framework with Azure Functions.
You can use Asynchronous Server Gateway Interface (ASGI)-compatible and Web Server Gateway Interface (WSGI)-compatible  frameworks, such as Flask and FastAPI, with your HTTP-triggered Python functions. You must first update thehost.jsonfile to include an HTTProutePrefix, as shown in the following example:
routePrefix
{
  "version": "2.0",
  "logging": 
  {
    "applicationInsights": 
    {
      "samplingSettings": 
      {
        "isEnabled": true,
        "excludedTypes": "Request"
      }
    }
  },
  "extensionBundle": 
  {
    "id": "Microsoft.Azure.Functions.ExtensionBundle",
    "version": "[2.*, 3.0.0)"
  },
  "extensions": 
  {
    "http": 
    {
        "routePrefix": ""
    }
  }
}
{
  "version": "2.0",
  "logging": 
  {
    "applicationInsights": 
    {
      "samplingSettings": 
      {
        "isEnabled": true,
        "excludedTypes": "Request"
      }
    }
  },
  "extensionBundle": 
  {
    "id": "Microsoft.Azure.Functions.ExtensionBundle",
    "version": "[2.*, 3.0.0)"
  },
  "extensions": 
  {
    "http": 
    {
        "routePrefix": ""
    }
  }
}
The framework code looks like the following example:
ASGI
WSGI
AsgiFunctionAppis the top-level function app class for constructing ASGI HTTP functions.
AsgiFunctionApp
# function_app.py

import azure.functions as func 
from fastapi import FastAPI, Request, Response 

fast_app = FastAPI() 

@fast_app.get("/return_http_no_body") 
async def return_http_no_body(): 
    return Response(content="", media_type="text/plain") 

app = func.AsgiFunctionApp(app=fast_app, 
                           http_auth_level=func.AuthLevel.ANONYMOUS)
# function_app.py

import azure.functions as func 
from fastapi import FastAPI, Request, Response 

fast_app = FastAPI() 

@fast_app.get("/return_http_no_body") 
async def return_http_no_body(): 
    return Response(content="", media_type="text/plain") 

app = func.AsgiFunctionApp(app=fast_app, 
                           http_auth_level=func.AuthLevel.ANONYMOUS)
WsgiFunctionAppis the top-level function app class for constructing WSGI HTTP functions.
WsgiFunctionApp
# function_app.py

import azure.functions as func 
from flask import Flask, Response 

flask_app = Flask(__name__) 

@flask_app.get("/return_http") 
def return_http(): 
    return Response("<h1>Hello World</h1>", mimetype="text/html") 

app = func.WsgiFunctionApp(app=flask_app.wsgi_app, 
                           http_auth_level=func.AuthLevel.ANONYMOUS)
# function_app.py

import azure.functions as func 
from flask import Flask, Response 

flask_app = Flask(__name__) 

@flask_app.get("/return_http") 
def return_http(): 
    return Response("<h1>Hello World</h1>", mimetype="text/html") 

app = func.WsgiFunctionApp(app=flask_app.wsgi_app, 
                           http_auth_level=func.AuthLevel.ANONYMOUS)
Scaling and performance
For scaling and performance best practices for Python function apps, see thePython scaling and performancearticle.
Context
To get the invocation context of a function when it's running, include thecontextargument in its signature.
context
For example:
import azure.functions


def main(req: azure.functions.HttpRequest,
         context: azure.functions.Context) -> str:
    return f'{context.invocation_id}'
import azure.functions


def main(req: azure.functions.HttpRequest,
         context: azure.functions.Context) -> str:
    return f'{context.invocation_id}'
TheContextclass has the following string attributes:
Context
function_directory
function_name
invocation_id
thread_local_storage
invocation_id
trace_context
Trace Context
retry_context
retry-policies
Global variables
It isn't guaranteed that the state of your app will be preserved for future executions. However, the Azure Functions runtime often reuses the same process for multiple executions of the same app. To cache the results of an expensive computation, declare it as a global variable.
CACHED_DATA = None


def main(req):
    global CACHED_DATA
    if CACHED_DATA is None:
        CACHED_DATA = load_json()

    # ... use CACHED_DATA in code
CACHED_DATA = None


def main(req):
    global CACHED_DATA
    if CACHED_DATA is None:
        CACHED_DATA = load_json()

    # ... use CACHED_DATA in code
Environment variables
In Azure Functions,application settings, such as service connection strings, are exposed as environment variables when they're running. There are two main ways to access these settings in your code.
os.environ["myAppSetting"]
os.getenv("myAppSetting")
None
Both of these ways require you to declareimport os.
import os
The following example usesos.environ["myAppSetting"]to get theapplication setting, with the key namedmyAppSetting:
os.environ["myAppSetting"]
myAppSetting
import logging
import os

import azure.functions as func

def main(req: func.HttpRequest) -> func.HttpResponse:
  # Get the setting named 'myAppSetting'
  my_app_setting_value = os.environ["myAppSetting"]
  logging.info(f'My app setting value:{my_app_setting_value}')
import logging
import os

import azure.functions as func

def main(req: func.HttpRequest) -> func.HttpResponse:
  # Get the setting named 'myAppSetting'
  my_app_setting_value = os.environ["myAppSetting"]
  logging.info(f'My app setting value:{my_app_setting_value}')
For local development, application settings aremaintained in thelocal.settings.jsonfile.
In Azure Functions,application settings, such as service connection strings, are exposed as environment variables when they're running. There are two main ways to access these settings in your code.
os.environ["myAppSetting"]
os.getenv("myAppSetting")
None
Both of these ways require you to declareimport os.
import os
The following example usesos.environ["myAppSetting"]to get theapplication setting, with the key namedmyAppSetting:
os.environ["myAppSetting"]
myAppSetting
import logging
import os

import azure.functions as func

app = func.FunctionApp()

@app.function_name(name="HttpTrigger1")
@app.route(route="req")
def main(req: func.HttpRequest) -> func.HttpResponse:
  # Get the setting named 'myAppSetting'
  my_app_setting_value = os.environ["myAppSetting"]
  logging.info(f'My app setting value:{my_app_setting_value}')
import logging
import os

import azure.functions as func

app = func.FunctionApp()

@app.function_name(name="HttpTrigger1")
@app.route(route="req")
def main(req: func.HttpRequest) -> func.HttpResponse:
  # Get the setting named 'myAppSetting'
  my_app_setting_value = os.environ["myAppSetting"]
  logging.info(f'My app setting value:{my_app_setting_value}')
For local development, application settings aremaintained in thelocal.settings.jsonfile.
Python version
Azure Functions supports the following Python versions:
* Official Python distributions
To request a specific Python version when you create your function app in Azure, use the--runtime-versionoption of theaz functionapp createcommand. The Functions runtime version is set by the--functions-versionoption. The Python version is set when the function app is created, and it can't be changed for apps running in a Consumption plan.
--runtime-version
az functionapp create
--functions-version
The runtime uses the available Python version when you run it locally.
Changing Python version
To set a Python function app to a specific language version, you need to specify the language and the version of the language in theLinuxFxVersionfield in the site configuration. For example, to change the Python app to use Python 3.8, setlinuxFxVersiontopython|3.8.
LinuxFxVersion
linuxFxVersion
python|3.8
To learn how to view and change thelinuxFxVersionsite setting, seeHow to target Azure Functions runtime versions.
linuxFxVersion
For more general information, see theAzure Functions runtime support policyandSupported languages in Azure Functions.
Package management
When you're developing locally by using Core Tools or Visual Studio Code, add the names and versions of the required packages to therequirements.txtfile, and then install them by usingpip.
pip
For example, you can use the followingrequirements.txtfile andpipcommand to install therequestspackage from PyPI.
pip
requests
requests==2.19.1
requests==2.19.1
pip install -r requirements.txt
pip install -r requirements.txt
When running your functions in anApp Service plan, dependencies that you define in requirements.txt are given precedence over built-in Python modules, such aslogging. This precedence can cause conflicts when built-in modules have the same names as directories in your code. When running in aConsumption planor anElastic Premium plan, conflicts are less likely because your dependencies aren't prioritized by default.
logging
To prevent issues running in an App Service plan, don't name your directories the same as any Python native modules and don't include Python native libraries in your project's requirements.txt file.
Publishing to Azure
When you're ready to publish, make sure that all your publicly available dependencies are listed in therequirements.txtfile. You can locate this file at the root of your project directory.
You can find the project files and folders that are excluded from publishing, including the virtual environment folder, in the root directory of your project.
There are three build actions supported for publishing your Python project to Azure: remote build, local build, and builds using custom dependencies.
You can also use Azure Pipelines to build your dependencies and publish by using continuous delivery (CD). To learn more, seeContinuous delivery with Azure Pipelines.
Remote build
When you use remote build, dependencies that are restored on the server and native dependencies match the production environment. This results in a smaller deployment package to upload. Use remote build when you're developing Python apps on Windows. If your project has custom dependencies, you canuse remote build with extra index URL.
Dependencies are obtained remotely based on the contents of therequirements.txtfile.Remote buildis the recommended build method. By default, Core Tools requests a remote build when you use the followingfunc azure functionapp publishcommand to publish your Python project to Azure.
func azure functionapp publish
func azure functionapp publish <APP_NAME>
func azure functionapp publish <APP_NAME>
Remember to replace<APP_NAME>with the name of your function app in Azure.
<APP_NAME>
TheAzure Functions Extension for Visual Studio Codealso requests a remote build by default.
Local build
Dependencies are obtained locally based on the contents of therequirements.txtfile. You can prevent doing a remote build by using the followingfunc azure functionapp publishcommand to publish with a local build:
func azure functionapp publish
func azure functionapp publish <APP_NAME> --build local
func azure functionapp publish <APP_NAME> --build local
Remember to replace<APP_NAME>with the name of your function app in Azure.
<APP_NAME>
When you use the--build localoption, project dependencies are read from therequirements.txtfile, and those dependent packages are downloaded and installed locally. Project files and dependencies are deployed from your local computer to Azure. This results in a larger deployment package being uploaded to Azure. If for some reason you can't get therequirements.txtfile by using Core Tools, you must use the custom dependencies option for publishing.
--build local
We don't recommend using local builds when you're developing locally on Windows.
Custom dependencies
When your project has dependencies that aren't found in thePython Package Index, there are two ways to build the project. The first way, thebuildmethod, depends on how you build the project.
When your packages are available from an accessible custom package index, use a remote build. Before you publish, be sure tocreate an app settingnamedPIP_EXTRA_INDEX_URL. The value for this setting is the URL of your custom package index. Using this setting tells the remote build to runpip installby using the--extra-index-urloption. To learn more, see thePythonpip installdocumentation.
PIP_EXTRA_INDEX_URL
pip install
--extra-index-url
pip install
You can also use basic authentication credentials with your extra package index URLs. To learn more, seeBasic authentication credentialsin the Python documentation.
If your project uses packages that aren't publicly available to our tools, you can make them available to your app by putting them in the__app__/.python_packagesdirectory. Before you publish, run the following command to install the dependencies locally:
pip install  --target="<PROJECT_DIR>/.python_packages/lib/site-packages"  -r requirements.txt
pip install  --target="<PROJECT_DIR>/.python_packages/lib/site-packages"  -r requirements.txt
When you're using custom dependencies, you should use the--no-buildpublishing option, because you've already installed the dependencies into the project folder.
--no-build
func azure functionapp publish <APP_NAME> --no-build
func azure functionapp publish <APP_NAME> --no-build
Remember to replace<APP_NAME>with the name of your function app in Azure.
<APP_NAME>
Unit testing
Functions that are written in Python can be tested like other Python code by using standard testing frameworks. For most bindings, it's possible to create a mock input object by creating an instance of an appropriate class from theazure.functionspackage. Since theazure.functionspackage isn't immediately available, be sure to install it via yourrequirements.txtfile as described in thepackage managementsection above.
azure.functions
azure.functions
Withmy_second_functionas an example, the following is a mock test of an HTTP-triggered function:
First, create a<project_root>/my_second_function/function.jsonfile, and then define this function as an HTTP trigger.
{
  "scriptFile": "__init__.py",
  "entryPoint": "main",
  "bindings": [
    {
      "authLevel": "function",
      "type": "httpTrigger",
      "direction": "in",
      "name": "req",
      "methods": [
        "get",
        "post"
      ]
    },
    {
      "type": "http",
      "direction": "out",
      "name": "$return"
    }
  ]
}
{
  "scriptFile": "__init__.py",
  "entryPoint": "main",
  "bindings": [
    {
      "authLevel": "function",
      "type": "httpTrigger",
      "direction": "in",
      "name": "req",
      "methods": [
        "get",
        "post"
      ]
    },
    {
      "type": "http",
      "direction": "out",
      "name": "$return"
    }
  ]
}
Next, you can implementmy_second_functionandshared_code.my_second_helper_function.
my_second_function
shared_code.my_second_helper_function
# <project_root>/my_second_function/__init__.py
import azure.functions as func
import logging

# Use absolute import to resolve shared_code modules
from shared_code import my_second_helper_function

# Define an HTTP trigger that accepts the ?value=<int> query parameter
# Double the value and return the result in HttpResponse
def main(req: func.HttpRequest) -> func.HttpResponse:
  logging.info('Executing my_second_function.')

  initial_value: int = int(req.params.get('value'))
  doubled_value: int = my_second_helper_function.double(initial_value)

  return func.HttpResponse(
    body=f"{initial_value} * 2 = {doubled_value}",
    status_code=200
    )
# <project_root>/my_second_function/__init__.py
import azure.functions as func
import logging

# Use absolute import to resolve shared_code modules
from shared_code import my_second_helper_function

# Define an HTTP trigger that accepts the ?value=<int> query parameter
# Double the value and return the result in HttpResponse
def main(req: func.HttpRequest) -> func.HttpResponse:
  logging.info('Executing my_second_function.')

  initial_value: int = int(req.params.get('value'))
  doubled_value: int = my_second_helper_function.double(initial_value)

  return func.HttpResponse(
    body=f"{initial_value} * 2 = {doubled_value}",
    status_code=200
    )
# <project_root>/shared_code/__init__.py
# Empty __init__.py file marks shared_code folder as a Python package
# <project_root>/shared_code/__init__.py
# Empty __init__.py file marks shared_code folder as a Python package
# <project_root>/shared_code/my_second_helper_function.py

def double(value: int) -> int:
  return value * 2
# <project_root>/shared_code/my_second_helper_function.py

def double(value: int) -> int:
  return value * 2
You can start writing test cases for your HTTP trigger.
# <project_root>/tests/test_my_second_function.py
import unittest

import azure.functions as func
from my_second_function import main

class TestFunction(unittest.TestCase):
  def test_my_second_function(self):
    # Construct a mock HTTP request.
    req = func.HttpRequest(method='GET',
                           body=None,
                           url='/api/my_second_function',
                           params={'value': '21'})
    # Call the function.
    resp = main(req)

    # Check the output.
    self.assertEqual(resp.get_body(), b'21 * 2 = 42',)
# <project_root>/tests/test_my_second_function.py
import unittest

import azure.functions as func
from my_second_function import main

class TestFunction(unittest.TestCase):
  def test_my_second_function(self):
    # Construct a mock HTTP request.
    req = func.HttpRequest(method='GET',
                           body=None,
                           url='/api/my_second_function',
                           params={'value': '21'})
    # Call the function.
    resp = main(req)

    # Check the output.
    self.assertEqual(resp.get_body(), b'21 * 2 = 42',)
Inside your.venvPython virtual environment folder, install your favorite Python test framework, such aspip install pytest. Then runpytest teststo check the test result.
.venv
pip install pytest
pytest tests
First, create the<project_root>/function_app.pyfile and implement themy_second_functionfunction as the HTTP trigger andshared_code.my_second_helper_function.
my_second_function
shared_code.my_second_helper_function
# <project_root>/function_app.py
import azure.functions as func
import logging

# Use absolute import to resolve shared_code modules
from shared_code import my_second_helper_function

app = func.FunctionApp()

# Define the HTTP trigger that accepts the ?value=<int> query parameter
# Double the value and return the result in HttpResponse
@app.function_name(name="my_second_function")
@app.route(route="hello")
def main(req: func.HttpRequest) -> func.HttpResponse:
    logging.info('Executing my_second_function.')

    initial_value: int = int(req.params.get('value'))
    doubled_value: int = my_second_helper_function.double(initial_value)

    return func.HttpResponse(
        body=f"{initial_value} * 2 = {doubled_value}",
        status_code=200
    )
# <project_root>/function_app.py
import azure.functions as func
import logging

# Use absolute import to resolve shared_code modules
from shared_code import my_second_helper_function

app = func.FunctionApp()

# Define the HTTP trigger that accepts the ?value=<int> query parameter
# Double the value and return the result in HttpResponse
@app.function_name(name="my_second_function")
@app.route(route="hello")
def main(req: func.HttpRequest) -> func.HttpResponse:
    logging.info('Executing my_second_function.')

    initial_value: int = int(req.params.get('value'))
    doubled_value: int = my_second_helper_function.double(initial_value)

    return func.HttpResponse(
        body=f"{initial_value} * 2 = {doubled_value}",
        status_code=200
    )
# <project_root>/shared_code/__init__.py
# Empty __init__.py file marks shared_code folder as a Python package
# <project_root>/shared_code/__init__.py
# Empty __init__.py file marks shared_code folder as a Python package
# <project_root>/shared_code/my_second_helper_function.py

def double(value: int) -> int:
  return value * 2
# <project_root>/shared_code/my_second_helper_function.py

def double(value: int) -> int:
  return value * 2
You can start writing test cases for your HTTP trigger.
# <project_root>/tests/test_my_second_function.py
import unittest
import azure.functions as func

from function_app import main

class TestFunction(unittest.TestCase):
  def test_my_second_function(self):
    # Construct a mock HTTP request.
    req = func.HttpRequest(method='GET',
                           body=None,
                           url='/api/my_second_function',
                           params={'value': '21'})
    # Call the function.
    func_call = main.build().get_user_function()
    resp = func_call(req)
    # Check the output.
    self.assertEqual(
        resp.get_body(),
        b'21 * 2 = 42',
    )
# <project_root>/tests/test_my_second_function.py
import unittest
import azure.functions as func

from function_app import main

class TestFunction(unittest.TestCase):
  def test_my_second_function(self):
    # Construct a mock HTTP request.
    req = func.HttpRequest(method='GET',
                           body=None,
                           url='/api/my_second_function',
                           params={'value': '21'})
    # Call the function.
    func_call = main.build().get_user_function()
    resp = func_call(req)
    # Check the output.
    self.assertEqual(
        resp.get_body(),
        b'21 * 2 = 42',
    )
Inside your.venvPython virtual environment folder, install your favorite Python test framework, such aspip install pytest. Then runpytest teststo check the test result.
pip install pytest
pytest tests
Temporary files
Thetempfile.gettempdir()method returns a temporary folder, which on Linux is/tmp. Your application can use this directory to store temporary files that are generated and used by your functions when they're running.
tempfile.gettempdir()
Important
Files written to the temporary directory aren't guaranteed to persist across invocations. During scale out, temporary files aren't shared between instances.
The following example creates a named temporary file in the temporary directory (/tmp):
import logging
import azure.functions as func
import tempfile

from os import listdir

#---
   tempFilePath = tempfile.gettempdir()
   fp = tempfile.NamedTemporaryFile()
   fp.write(b'Hello world!')
   filesDirListInTemp = listdir(tempFilePath)
import logging
import azure.functions as func
import tempfile

from os import listdir

#---
   tempFilePath = tempfile.gettempdir()
   fp = tempfile.NamedTemporaryFile()
   fp.write(b'Hello world!')
   filesDirListInTemp = listdir(tempFilePath)
We recommend that you maintain your tests in a folder that's separate from the project folder. This action keeps you from deploying test code with your app.
Preinstalled libraries
A few libraries come with the Python functions runtime.
The Python standard library
The Python standard library contains a list of built-in Python modules that are shipped with each Python distribution. Most of these libraries help you access system functionality, such as file input/output (I/O). On Windows systems, these libraries are installed with Python. On Unix-based systems, they're provided by package collections.
To view the library for your Python version, go to:
Python 3.8 standard library
Python 3.9 standard library
Python 3.10 standard library
Python 3.11 standard library
Azure Functions Python worker dependencies
The Azure Functions Python worker requires a specific set of libraries. You can also use these libraries in your functions, but they aren't a part of the Python standard. If your functions rely on any of these libraries, they might be unavailable to your code when it's running outside of Azure Functions.
Note
If your function app'srequirements.txtfile contains anazure-functions-workerentry, remove it. The functions worker is automatically managed by the Azure Functions platform, and we regularly update it with new features and bug fixes. Manually installing an old version of worker in therequirements.txtfile might cause unexpected issues.
azure-functions-worker
Note
If your package contains certain libraries that might collide with worker's dependencies (for example, protobuf, tensorflow, or grpcio), configurePYTHON_ISOLATE_WORKER_DEPENDENCIESto1in app settings to prevent your application from referring to worker's dependencies.
PYTHON_ISOLATE_WORKER_DEPENDENCIES
1
The Azure Functions Python library
Every Python worker update includes a new version of theAzure Functions Python library (azure.functions). This approach makes it easier to continuously update your Python function apps, because each update is backwards-compatible. For a list of releases of this library, go toazure-functions PyPi.
The runtime library version is fixed by Azure, and it can't be overridden byrequirements.txt. Theazure-functionsentry inrequirements.txtis only for linting and customer awareness.
azure-functions
Use the following code to track the actual version of the Python functions library in your runtime:
getattr(azure.functions, '__version__', '< 1.2.1')
getattr(azure.functions, '__version__', '< 1.2.1')
Runtime system libraries
For a list of preinstalled system libraries in Python worker Docker images, see the following:
Python worker extensions
The Python worker process that runs in Azure Functions lets you integrate third-party libraries into your function app. These extension libraries act as middleware that can inject specific operations during the lifecycle of your function's execution.
Extensions are imported in your function code much like a standard Python library module. Extensions are run based on the following scopes:
Review the information for each extension to learn more about the scope in which the extension runs.
Extensions implement a Python worker extension interface. This action lets the Python worker process call into the extension code during the function's execution lifecycle. To learn more, seeCreate extensions.
Using extensions
You can use a Python worker extension library in your Python functions by doing the following:
Add the extension package in therequirements.txtfile for your project.
Install the library into your app.
Add the following application settings:Locally: Enter"PYTHON_ENABLE_WORKER_EXTENSIONS": "1"in theValuessection of yourlocal.settings.jsonfile.Azure: EnterPYTHON_ENABLE_WORKER_EXTENSIONS=1in yourapp settings.
Locally: Enter"PYTHON_ENABLE_WORKER_EXTENSIONS": "1"in theValuessection of yourlocal.settings.jsonfile.
"PYTHON_ENABLE_WORKER_EXTENSIONS": "1"
Values
Azure: EnterPYTHON_ENABLE_WORKER_EXTENSIONS=1in yourapp settings.
PYTHON_ENABLE_WORKER_EXTENSIONS=1
Import the extension module into your function trigger.
Configure the extension instance, if needed. Configuration requirements should be called out in the extension's documentation.
Important
Third-party Python worker extension libraries aren't supported or warrantied by Microsoft. You must make sure that any extensions that you use in your function app is trustworthy, and you bear the full risk of using a malicious or poorly written extension.
Third-parties should provide specific documentation on how to install and consume their extensions in your function app. For a basic example of how to consume an extension, seeConsuming your extension.
Here are examples of using extensions in a function app, by scope:
Application-level
Function-level
# <project_root>/requirements.txt
application-level-extension==1.0.0
# <project_root>/requirements.txt
application-level-extension==1.0.0
# <project_root>/Trigger/__init__.py

from application_level_extension import AppExtension
AppExtension.configure(key=value)

def main(req, context):
  # Use context.app_ext_attributes here
# <project_root>/Trigger/__init__.py

from application_level_extension import AppExtension
AppExtension.configure(key=value)

def main(req, context):
  # Use context.app_ext_attributes here
# <project_root>/requirements.txt
function-level-extension==1.0.0
# <project_root>/requirements.txt
function-level-extension==1.0.0
# <project_root>/Trigger/__init__.py

from function_level_extension import FuncExtension
func_ext_instance = FuncExtension(__file__)

def main(req, context):
  # Use func_ext_instance.attributes here
# <project_root>/Trigger/__init__.py

from function_level_extension import FuncExtension
func_ext_instance = FuncExtension(__file__)

def main(req, context):
  # Use func_ext_instance.attributes here
Creating extensions
Extensions are created by third-party library developers who have created functionality that can be integrated into Azure Functions.  An extension developer designs, implements, and releases Python packages that contain custom logic designed specifically to be run in the context of function execution. These extensions can be published either to the PyPI registry or to GitHub repositories.
To learn how to create, package, publish, and consume a Python worker extension package, seeDevelop Python worker extensions for Azure Functions.
An extension that's inherited fromAppExtensionBaseruns in anapplicationscope.
AppExtensionBase
AppExtensionBaseexposes the following abstract class methods for you to implement:
AppExtensionBase
init
configure
post_function_load_app_level
pre_invocation_app_level
post_invocation_app_level
An extension that inherits fromFuncExtensionBaseruns in a specific function trigger.
FuncExtensionBaseexposes the following abstract class methods for implementations:
FuncExtensionBase
__init__
filename
super().__init__(filename)
post_function_load
pre_invocation
post_invocation
Cross-origin resource sharing
Azure Functions supports cross-origin resource sharing (CORS). CORS is configuredin the portaland through theAzure CLI. The CORS allowed origins list applies at the function app level. With CORS enabled, responses include theAccess-Control-Allow-Originheader. For more information, seeCross-origin resource sharing.
Access-Control-Allow-Origin
Cross-origin resource sharing (CORS) is fully supported for Python function apps.
Async
By default, a host instance for Python can process only one function invocation at a time. This is because Python is a single-threaded runtime. For a function app that processes a large number of I/O events or is being I/O bound, you can significantly improve performance by running functions asynchronously. For more information, seeImprove throughout performance of Python apps in Azure Functions.
Shared memory (preview)
To improve throughput, Azure Functions lets your out-of-process Python language worker share memory with the Functions host process. When your function app is hitting bottlenecks, you can enable shared memory by adding an application setting namedFUNCTIONS_WORKER_SHARED_MEMORY_DATA_TRANSFER_ENABLEDwith a value of1. With shared memory enabled, you can then use theDOCKER_SHM_SIZEsetting to set the shared memory to something like268435456, which is equivalent to 256 MB.
1
268435456
For example, you might enable shared memory to reduce bottlenecks when you're using Blob Storage bindings to transfer payloads larger than 1 MB.
This functionality is available only for function apps that are running in Premium and Dedicated (Azure App Service) plans. To learn more, seeShared memory.
Known issues and FAQ
Here are two troubleshooting guides for common issues:
ModuleNotFoundError and ImportError
Can't import 'cygrpc'
Here are two troubleshooting guides for known issues with the v2 programming model:
Couldn't load file or assembly
Unable to resolve the Azure Storage connection named Storage
All known issues and feature requests are tracked in aGitHub issues list. If you run into a problem and can't find the issue in GitHub, open a new issue, and include a detailed description of the problem.
Next steps
For more information, see the following resources:
Azure Functions package API documentation
Best practices for Azure Functions
Azure Functions triggers and bindings
Blob Storage bindings
HTTP and webhook bindings
Queue Storage bindings
Timer triggers
Having issues with using Python? Tell us what's going on.
Feedback
Was this page helpful?
Additional resources