Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Customize scraping of Prometheus metrics in Azure Monitor managed service for Prometheus
Article
2025-03-10
8 contributors
In this article
This article provides instructions on customizing metrics scraping for a Kubernetes cluster with themetrics addonin Azure Monitor.
Configmaps
Four different configmaps can be configured to provide scrape configuration and other settings for the metrics add-on. All config-maps should be applied tokube-systemnamespace for any cluster.
kube-system
Note
None of the four configmaps exist by default in the cluster when Managed Prometheus is enabled. Depending on what needs to be customized, you need to deploy any or all of these four configmaps with the same name specified, inkube-systemnamespace. AMA-Metrics pods will pick up these configmaps after you deploy them tokube-systemnamespace, and will restart in 2-3 minutes to apply the configuration settings specified in the configmap(s).
kube-system
kube-system
ama-metrics-settings-configmapThis config map has below simple settings that can be configured. You can take the configmap from the above git hub repo, change the settings are required and apply/deploy the configmap tokube-systemnamespace for your clustercluster alias (to change the value ofclusterlabel in every time-series/metric that's ingested from a cluster)enable/disable default scrape targets - Turn ON/OFF default scraping based on targets. Scrape configuration for these default targets are already pre-defined/built-inenable pod annotation based scraping per namespacemetric keep-lists - this setting is used to control which metrics are listed to be allowed from each default target and to change the default behaviorscrape intervals for default/pre-definetargets.30 secsis the default scrape frequency and it can be changed per default target using this configmapdebug-mode - turning this ON helps to debug missing metric/ingestion issues - see more ontroubleshooting
ama-metrics-settings-configmap
kube-system
cluster alias (to change the value ofclusterlabel in every time-series/metric that's ingested from a cluster)
cluster
enable/disable default scrape targets - Turn ON/OFF default scraping based on targets. Scrape configuration for these default targets are already pre-defined/built-in
enable pod annotation based scraping per namespace
metric keep-lists - this setting is used to control which metrics are listed to be allowed from each default target and to change the default behavior
scrape intervals for default/pre-definetargets.30 secsis the default scrape frequency and it can be changed per default target using this configmap
30 secs
debug-mode - turning this ON helps to debug missing metric/ingestion issues - see more ontroubleshooting
ama-metrics-prometheus-configThis config map can be used to provide Prometheus scrape config for addon replica. Addon runs a singleton replica, and any cluster level services can be discovered and scraped by providing scrape jobs in this configmap. You can take the sample configmap from the above git hub repo, add scrape jobs that you  would need and apply/deploy the config map tokube-systemnamespace for your cluster.Although this is supported, please note that the recommended way of scraping custom targets is usingcustom resources
ama-metrics-prometheus-config
kube-system
ama-metrics-prometheus-config-node(Advanced)
This config map can be used to provide Prometheus scrape config for addon DaemonSet that runs on everyLinuxnode in the cluster, and any node level targets on each node can be scraped by providing scrape jobs in this configmap. When you use this configmap, you can use$NODE_IPvariable in your scrape config, which gets substituted by corresponding  node's ip address in DaemonSet pod running on each node. This way you get access to scrape anything that runs on that node from the metrics addon DaemonSet.Please be careful when you use discoveries in scrape config in this node level config map, as every node in the cluster will setup & discover the target(s) and will collect redundant metrics.
You can take the sample configmap from the above git hub repo, add scrape jobs that you  would need and apply/deploy the config map tokube-systemnamespace for your cluster
ama-metrics-prometheus-config-node
$NODE_IP
kube-system
ama-metrics-prometheus-config-node-windows(Advanced)
This config map can be used to provide Prometheus scrape config for addon DaemonSet that runs on everyWindowsnode in the cluster, and node level targets on each node can be scraped by providing scrape jobs in this configmap. When you use this configmap, you can use$NODE_IPvariable in your scrape config, which will be substituted by corresponding  node's ip address in DaemonSet pod running on each node. This way you get access to scrape anything that runs on that node from the metrics addon DaemonSet.Please be careful when you use discoveries in scrape config in this node level config map, as every node in the cluster will setup & discover the target(s) and will collect redundant metrics.
You can take the sample configmap from the above git hub repo, add scrape jobs that you  would need and apply/deploy the config map tokube-systemnamespace for your cluster
ama-metrics-prometheus-config-node-windows
$NODE_IP
kube-system
Custom Resource Definitions
The Azure Monitor metrics add-on supports scraping Prometheus metrics using Prometheus - Pod Monitors and Service Monitors, similar to the OSS Prometheus operator. Enabling the add-on will deploy the Pod and Service Monitor custom resource definitions to allow you to create your own custom resources.
Follow the instructions tocreate and apply custom resourceson your cluster.
Metrics add-on settings configmap
Theama-metrics-settings-configmapcan be downloaded, edited, and applied to the cluster to customize the out-of-the-box features of the metrics add-on.
Enable and disable default targets
The following table has a list of all the default targets that the Azure Monitor metrics add-on can scrape by default and whether it's initially enabled. Default targets are scraped every 30 seconds. A replica is deployed to scrape cluster-wide targets such as kube-state-metrics. A DaemonSet is also deployed to scrape node-wide targets such as kubelet.
true
true
true
true
false
false
false
false
false
false
If you want to turn on the scraping of the default targets that aren't enabled by default, edit theconfigmapama-metrics-settings-configmapto update the targets listed underdefault-scrape-settings-enabledtotrue. Apply the configmap to your cluster.
ama-metrics-settings-configmap
default-scrape-settings-enabled
true
Enable pod annotation-based scraping
To scrape application pods without needing to create a custom Prometheus config, annotations can be added to the pods. The annotationprometheus.io/scrape: "true"is required for the pod to be scraped. The annotationsprometheus.io/pathandprometheus.io/portindicate the path and port that the metrics are hosted at on the pod. The annotations for a pod that is hosting metrics at<pod IP>:8080/metricswould be:
prometheus.io/scrape: "true"
prometheus.io/path
prometheus.io/port
<pod IP>:8080/metrics
metadata:   
  annotations:
    prometheus.io/scrape: 'true'
    prometheus.io/path: '/metrics'
    prometheus.io/port: '8080'
metadata:   
  annotations:
    prometheus.io/scrape: 'true'
    prometheus.io/path: '/metrics'
    prometheus.io/port: '8080'
Scraping these pods with specific annotations is disabled by default. To enable, in theama-metrics-settings-configmap, add the regex for the namespace(s) of the pods with annotations you wish to scrape as the value of the fieldpodannotationnamespaceregex.
ama-metrics-settings-configmap
podannotationnamespaceregex
For example, the following setting scrapes pods with annotations only in the namespaceskube-systemandmy-namespace:
kube-system
my-namespace
pod-annotation-based-scraping: |-
    podannotationnamespaceregex = "kube-system|my-namespace"
pod-annotation-based-scraping: |-
    podannotationnamespaceregex = "kube-system|my-namespace"
Warning
Scraping the pod annotations from many namespaces can generate a very large volume of metrics depending on the number of pods that have annotations.
Customize metrics collected by default targets
By default, for all the default targets, only minimal metrics used in the default recording rules, alerts, and Grafana dashboards are ingested as described inminimal-ingestion-profile. To collect all metrics from default targets, update the keep-lists in the settings configmap underdefault-targets-metrics-keep-list, and setminimalingestionprofiletofalse.
default-targets-metrics-keep-list
minimalingestionprofile
false
To allowlist more metrics in addition to default metrics that are listed to be allowed, for any default targets, edit the settings underdefault-targets-metrics-keep-listfor the corresponding job you want to change.
default-targets-metrics-keep-list
For example,kubeletis the metric filtering setting for the default target kubelet. Use the following script to filterinmetrics collected for the default targets by using regex-based filtering.
kubelet
kubelet = "metricX|metricY"
apiserver = "mymetric.*"
kubelet = "metricX|metricY"
apiserver = "mymetric.*"
Note
If you use quotation marks or backslashes in the regex, you need to escape them by using a backslash like the examples"test\'smetric\"s\""andtestbackslash\\*.
"test\'smetric\"s\""
testbackslash\\*
To further customize the default jobs to change properties like collection frequency or labels, disable the corresponding default target by setting the configmap value for the target tofalse. Then apply the job by using a custom configmap. For details on custom configuration, seeCustomize scraping of Prometheus metrics in Azure Monitor.
false
Cluster alias
The cluster label appended to every time series scraped uses the last part of the full AKS or Azure Arc-enabled Kubernetes cluster's Azure Resource Manager resource ID. For example, if the resource ID is/subscriptions/aaaa0a0a-bb1b-cc2c-dd3d-eeeeee4e4e4e/resourcegroups/rg-name/providers/Microsoft.ContainerService/managedClusters/myclustername, the cluster label ismyclustername.
/subscriptions/aaaa0a0a-bb1b-cc2c-dd3d-eeeeee4e4e4e/resourcegroups/rg-name/providers/Microsoft.ContainerService/managedClusters/myclustername
myclustername
To override the cluster label in the time series scraped, update the settingcluster_aliasto any string underprometheus-collector-settingsin theconfigmapama-metrics-settings-configmap. You can create this configmap if it doesn't exist in the cluster or you can edit the existing one if it already exists in your cluster.
cluster_alias
prometheus-collector-settings
ama-metrics-settings-configmap
The new label also shows up in the cluster parameter dropdown in the Grafana dashboards instead of the default one.
Note
Only alphanumeric characters are allowed. Any other characters are replaced with_. This change is to ensure that different components that consume this label adhere to the basic alphanumeric convention.
If you are enabling recording and alerting rules, please make sure to use the cluster alias name in the cluster name parameter of the rule onboarding template for the rules to work.
_
Debug mode
Warning
This mode can affect performance and should only be enabled for a short time for debugging purposes.
To view every metric that's being scraped for debugging purposes, the metrics add-on agent can be configured to run in debug mode by updating the settingenabledtotrueunder thedebug-modesetting in theconfigmapama-metrics-settings-configmap. You can either create this configmap or edit an existing one. For more information, see theDebug mode section in Troubleshoot collection of Prometheus metrics.
enabled
true
debug-mode
ama-metrics-settings-configmap
Scrape interval settings
To update the scrape interval settings for any target, you can update the duration in the settingdefault-targets-scrape-interval-settingsfor that target in theconfigmapama-metrics-settings-configmap. You have to set the scrape intervals in the correct format specified inthis website. Otherwise, the default value of 30 seconds is applied to the corresponding targets. For example - If you want to update the scrape interval for thekubeletjob to60sthen you can update the following section in the YAML:
default-targets-scrape-interval-settings
ama-metrics-settings-configmap
kubelet
60s
default-targets-scrape-interval-settings: |-
    kubelet = "60s"
    coredns = "30s"
    cadvisor = "30s"
    kubeproxy = "30s"
    apiserver = "30s"
    kubestate = "30s"
    nodeexporter = "30s"
    windowsexporter = "30s"
    windowskubeproxy = "30s"
    kappiebasic = "30s"
    prometheuscollectorhealth = "30s"
    podannotations = "30s"
default-targets-scrape-interval-settings: |-
    kubelet = "60s"
    coredns = "30s"
    cadvisor = "30s"
    kubeproxy = "30s"
    apiserver = "30s"
    kubestate = "30s"
    nodeexporter = "30s"
    windowsexporter = "30s"
    windowskubeproxy = "30s"
    kappiebasic = "30s"
    prometheuscollectorhealth = "30s"
    podannotations = "30s"
Apply the YAML using the following command:kubectl apply -f .\ama-metrics-settings-configmap.yaml.
kubectl apply -f .\ama-metrics-settings-configmap.yaml
Configure custom Prometheus scrape jobs
You can scrape Prometheus metrics using Prometheus - Pod Monitors and Service Monitors(Recommended), similar to the OSS Prometheus operator.
Follow the instructions tocreate and apply custom resourceson your cluster.
Additionally, you can follow the instructions tocreate, validate, and apply the configmapfor your cluster.
The configuration format is similar toPrometheus configuration file.
Prometheus configuration tips and examples
Learn some tips from examples in this section.
Configuration using CRD for custom scrape config
Configuration file for custom scrape config
Use thePod and Service Monitor templatesand follow the API specification to create your custom resources(PodMonitorandService Monitor).Notethat the only change required to the existing OSS CRs for being picked up by the Managed Prometheus is the API group -azmonitoring.coreos.com/v1. Seehereto learn more
The configuration format is the same as thePrometheus configuration file. Currently, the following sections are supported:
global:
  scrape_interval: <duration>
  scrape_timeout: <duration>
  external_labels:
    <labelname1>: <labelvalue>
    <labelname2>: <labelvalue>
scrape_configs:
  - <job-x>
  - <job-y>
global:
  scrape_interval: <duration>
  scrape_timeout: <duration>
  external_labels:
    <labelname1>: <labelvalue>
    <labelname2>: <labelvalue>
scrape_configs:
  - <job-x>
  - <job-y>
Any other unsupported sections must be removed from the config before they're applied as a configmap. Otherwise, the custom configuration fails validation and isn't applied.
See theApply config filesection to create a configmap from the Prometheus config.
Note
When custom scrape configuration fails to apply because of validation errors, default scrape configuration continues to be used.
Global settings
The configuration format for global settings is the same as supported byOSS prometheus configuration
global:
  scrape_interval: <duration>
  scrape_timeout: <duration>
  external_labels:
    <labelname1>: <labelvalue>
    <labelname2>: <labelvalue>
scrape_configs:
  - <job-x>
  - <job-y>
global:
  scrape_interval: <duration>
  scrape_timeout: <duration>
  external_labels:
    <labelname1>: <labelvalue>
    <labelname2>: <labelvalue>
scrape_configs:
  - <job-x>
  - <job-y>
The settings provided in the global section apply to all scrape jobs (both jobs in Configmap and Custom resources) but are overridden if they are specified in the individual jobs.
Note
If you want to use global settings that apply to all the scrape jobs, and only haveCustom Resourcesyou would still need to create a configmap with just the global settings(Settings for each of these in the custom resources will override the ones in the global section)
Scrape configs
Scrape Configs using CRD
Scrape Configs using Config file
Currently, the supported methods of target discovery for custom resources are pod and service monitor
Targets discovered using pod and service monitors have different__meta_*labels depending on what monitor is used. You can use the labels in therelabelingssection to filter targets or replace labels for the targets.
__meta_*
relabelings
See thePod and Service Monitor examplesof pod and service monitors.
Relabelings
Therelabelingssection is applied at the time of target discovery and applies to each target for the job. The following examples show ways to userelabelings.
relabelings
relabelings
Add a new label calledexample_labelwith the valueexample_valueto every metric of the job. Use__address__as the source label only because that label always exists and adds the label for every target of the job.
example_label
example_value
__address__
relabelings:
- sourceLabels: [__address__]
  targetLabel: example_label
  replacement: 'example_value'
relabelings:
- sourceLabels: [__address__]
  targetLabel: example_label
  replacement: 'example_value'
Targets discovered using pod and service monitors have different__meta_*labels depending on what monitor is used. The__*labels are dropped after discovering the targets. To filter by using them at the metrics level, first keep them usingrelabelingsby assigning a label name. Then usemetricRelabelingsto filter.
__meta_*
__*
relabelings
metricRelabelings
# Use the kubernetes namespace as a label called 'kubernetes_namespace'
relabelings:
- sourceLabels: [__meta_kubernetes_namespace]
  action: replace
  targetLabel: kubernetes_namespace

# Keep only metrics with the kubernetes namespace 'default'
metricRelabelings:
- sourceLabels: [kubernetes_namespace]
  action: keep
  regex: 'default'
# Use the kubernetes namespace as a label called 'kubernetes_namespace'
relabelings:
- sourceLabels: [__meta_kubernetes_namespace]
  action: replace
  targetLabel: kubernetes_namespace

# Keep only metrics with the kubernetes namespace 'default'
metricRelabelings:
- sourceLabels: [kubernetes_namespace]
  action: keep
  regex: 'default'
You can change thejobandinstancelabel values based on the source label, just like any other label.
job
instance
# Replace the job name with the pod label 'k8s app'
relabelings:
- sourceLabels: [__meta_kubernetes_pod_label_k8s_app]
  targetLabel: job

# Replace the instance name with the node name. This is helpful to replace a node IP
# and port with a value that is more readable
relabelings:
- sourceLabels: [__meta_kubernetes_node_name]]
  targetLabel: instance
# Replace the job name with the pod label 'k8s app'
relabelings:
- sourceLabels: [__meta_kubernetes_pod_label_k8s_app]
  targetLabel: job

# Replace the instance name with the node name. This is helpful to replace a node IP
# and port with a value that is more readable
relabelings:
- sourceLabels: [__meta_kubernetes_node_name]]
  targetLabel: instance
Note
If you have relabeling configs, ensure that the relabeling does not filter out the targets, and the labels configured correctly match the targets.
Metric Relabelings
Metric relabelings are applied after scraping and before ingestion. Use themetricRelabelingssection to filter metrics after scraping. The following examples show how to do so.
metricRelabelings
# Drop the metric named 'example_metric_name'
metricRelabelings:
- sourceLabels: [__name__]
  action: drop
  regex: 'example_metric_name'
# Drop the metric named 'example_metric_name'
metricRelabelings:
- sourceLabels: [__name__]
  action: drop
  regex: 'example_metric_name'
# Keep only the metric named 'example_metric_name'
metricRelabelings:
- sourceLabels: [__name__]
  action: keep
  regex: 'example_metric_name'
# Keep only the metric named 'example_metric_name'
metricRelabelings:
- sourceLabels: [__name__]
  action: keep
  regex: 'example_metric_name'
# Keep only metrics that start with 'example_'
metricRelabelings:
- sourceLabels: [__name__]
  action: keep
  regex: '(example_.*)'
# Keep only metrics that start with 'example_'
metricRelabelings:
- sourceLabels: [__name__]
  action: keep
  regex: '(example_.*)'
Metric renaming isn't supported.
# Keep metrics only where example_label = 'example'
metricRelabelings:
- sourceLabels: [example_label]
  action: keep
  regex: 'example'
# Keep metrics only where example_label = 'example'
metricRelabelings:
- sourceLabels: [example_label]
  action: keep
  regex: 'example'
# Keep metrics only if `example_label` equals `value_1` or `value_2`
metricRelabelings:
- sourceLabels: [example_label]
  action: keep
  regex: '(value_1|value_2)'
# Keep metrics only if `example_label` equals `value_1` or `value_2`
metricRelabelings:
- sourceLabels: [example_label]
  action: keep
  regex: '(value_1|value_2)'
# Keep metrics only if `example_label_1 = value_1` and `example_label_2 = value_2`
metricRelabelings:
- sourceLabels: [example_label_1, example_label_2]
  separator: ';'
  action: keep
  regex: 'value_1;value_2'
# Keep metrics only if `example_label_1 = value_1` and `example_label_2 = value_2`
metricRelabelings:
- sourceLabels: [example_label_1, example_label_2]
  separator: ';'
  action: keep
  regex: 'value_1;value_2'
# Keep metrics only if `example_label` exists as a label
metricRelabelings:
- sourceLabels: [example_label_1]
  action: keep
  regex: '.+'
# Keep metrics only if `example_label` exists as a label
metricRelabelings:
- sourceLabels: [example_label_1]
  action: keep
  regex: '.+'
Currently, the supported methods of target discovery for ascrape configare eitherstatic_configsorkubernetes_sd_configsfor specifying or discovering targets.
static_configs
kubernetes_sd_configs
A static config has a list of static targets and any extra labels to add to them.
scrape_configs:
  - job_name: example
    - targets: [ '10.10.10.1:9090', '10.10.10.2:9090', '10.10.10.3:9090' ... ]
    - labels: [ label1: value1, label1: value2, ... ]
scrape_configs:
  - job_name: example
    - targets: [ '10.10.10.1:9090', '10.10.10.2:9090', '10.10.10.3:9090' ... ]
    - labels: [ label1: value1, label1: value2, ... ]
Targets discovered usingkubernetes_sd_configseach have different__meta_*labels depending on what role is specified. You can use the labels in therelabel_configssection to filter targets or replace labels for the targets.
kubernetes_sd_configs
__meta_*
relabel_configs
See thePrometheus examplesof scrape configs for a Kubernetes cluster.
Relabel configs
Therelabel_configssection is applied at the time of target discovery and applies to each target for the job. The following examples show ways to userelabel_configs.
relabel_configs
relabel_configs
Add a new label calledexample_labelwith the valueexample_valueto every metric of the job. Use__address__as the source label only because that label always exists and adds the label for every target of the job.
example_label
example_value
__address__
relabel_configs:
- source_labels: [__address__]
  target_label: example_label
  replacement: 'example_value'
relabel_configs:
- source_labels: [__address__]
  target_label: example_label
  replacement: 'example_value'
If a job is usingkubernetes_sd_configsto discover targets, each role has associated__meta_*labels for metrics. The__*labels are dropped after discovering the targets. To filter by using them at the metrics level, first keep them usingrelabel_configsby assigning a label name. Then usemetric_relabel_configsto filter.
kubernetes_sd_configs
__meta_*
__*
relabel_configs
metric_relabel_configs
# Use the kubernetes namespace as a label called 'kubernetes_namespace'
relabel_configs:
- source_labels: [__meta_kubernetes_namespace]
  action: replace
  target_label: kubernetes_namespace

# Keep only metrics with the kubernetes namespace 'default'
metric_relabel_configs:
- source_labels: [kubernetes_namespace]
  action: keep
  regex: 'default'
# Use the kubernetes namespace as a label called 'kubernetes_namespace'
relabel_configs:
- source_labels: [__meta_kubernetes_namespace]
  action: replace
  target_label: kubernetes_namespace

# Keep only metrics with the kubernetes namespace 'default'
metric_relabel_configs:
- source_labels: [kubernetes_namespace]
  action: keep
  regex: 'default'
You can change thejobandinstancelabel values based on the source label, just like any other label.
job
instance
# Replace the job name with the pod label 'k8s app'
relabel_configs:
- source_labels: [__meta_kubernetes_pod_label_k8s_app]
  target_label: job

# Replace the instance name with the node name. This is helpful to replace a node IP
# and port with a value that is more readable
relabel_configs:
- source_labels: [__meta_kubernetes_node_name]]
  target_label: instance
# Replace the job name with the pod label 'k8s app'
relabel_configs:
- source_labels: [__meta_kubernetes_pod_label_k8s_app]
  target_label: job

# Replace the instance name with the node name. This is helpful to replace a node IP
# and port with a value that is more readable
relabel_configs:
- source_labels: [__meta_kubernetes_node_name]]
  target_label: instance
Metric relabel configs
Metric relabel configs are applied after scraping and before ingestion. Use themetric_relabel_configssection to filter metrics after scraping. The following examples show how to do so.
metric_relabel_configs
# Drop the metric named 'example_metric_name'
metric_relabel_configs:
- source_labels: [__name__]
  action: drop
  regex: 'example_metric_name'
# Drop the metric named 'example_metric_name'
metric_relabel_configs:
- source_labels: [__name__]
  action: drop
  regex: 'example_metric_name'
# Keep only the metric named 'example_metric_name'
metric_relabel_configs:
- source_labels: [__name__]
  action: keep
  regex: 'example_metric_name'
# Keep only the metric named 'example_metric_name'
metric_relabel_configs:
- source_labels: [__name__]
  action: keep
  regex: 'example_metric_name'
# Keep only metrics that start with 'example_'
metric_relabel_configs:
- source_labels: [__name__]
  action: keep
  regex: '(example_.*)'
# Keep only metrics that start with 'example_'
metric_relabel_configs:
- source_labels: [__name__]
  action: keep
  regex: '(example_.*)'
Metric renaming isn't supported.
# Keep metrics only where example_label = 'example'
metric_relabel_configs:
- source_labels: [example_label]
  action: keep
  regex: 'example'
# Keep metrics only where example_label = 'example'
metric_relabel_configs:
- source_labels: [example_label]
  action: keep
  regex: 'example'
# Keep metrics only if `example_label` equals `value_1` or `value_2`
metric_relabel_configs:
- source_labels: [example_label]
  action: keep
  regex: '(value_1|value_2)'
# Keep metrics only if `example_label` equals `value_1` or `value_2`
metric_relabel_configs:
- source_labels: [example_label]
  action: keep
  regex: '(value_1|value_2)'
# Keep metrics only if `example_label_1 = value_1` and `example_label_2 = value_2`
metric_relabel_configs:
- source_labels: [example_label_1, example_label_2]
  separator: ';'
  action: keep
  regex: 'value_1;value_2'
# Keep metrics only if `example_label_1 = value_1` and `example_label_2 = value_2`
metric_relabel_configs:
- source_labels: [example_label_1, example_label_2]
  separator: ';'
  action: keep
  regex: 'value_1;value_2'
# Keep metrics only if `example_label` exists as a label
metric_relabel_configs:
- source_labels: [example_label_1]
  action: keep
  regex: '.+'
# Keep metrics only if `example_label` exists as a label
metric_relabel_configs:
- source_labels: [example_label_1]
  action: keep
  regex: '.+'
Note
If you wish to add labels to all the jobs in your custom configuration, explicitly add labels using metrics_relabel_configs for each job. Global external labels are not supported via configmap based prometheus configuration.
relabel_configs:
- source_labels: [__address__]
  target_label: example_label
  replacement: 'example_value'
relabel_configs:
- source_labels: [__address__]
  target_label: example_label
  replacement: 'example_value'
Basic Authentication and Bearer Tokens
Scrape Configs using ConfigMap
Scrape Config using CRD (Pod/Service Monitor)
For using thebasic_authorbearer_tokensettings in your prometheus configuration, follow the steps below:
basic_auth
bearer_token
Create a secret in thekube-systemnamespace namedama-metrics-mtls-secret.The name of the keypassword1can be anything as long as it matches the file name in thepassword_filefilepath in the Prometheus scrape config in the next step. The value for the key needs to be base64-encoded.apiVersion: v1
kind: Secret
metadata:
  name: ama-metrics-mtls-secret
  namespace: kube-system
type: Opaque
data:
  password1: <base64-encoded-string>Theama-metrics-mtls-secretsecret is mounted on to theama-metricspods at the path/etc/prometheus/certs/and is made available to the Prometheus scraper. The key (password1in the above example) will be the file name. The value is base64 decoded and added as the contents of the file within the container.
Create a secret in thekube-systemnamespace namedama-metrics-mtls-secret.
kube-system
ama-metrics-mtls-secret
The name of the keypassword1can be anything as long as it matches the file name in thepassword_filefilepath in the Prometheus scrape config in the next step. The value for the key needs to be base64-encoded.
password1
password_file
apiVersion: v1
kind: Secret
metadata:
  name: ama-metrics-mtls-secret
  namespace: kube-system
type: Opaque
data:
  password1: <base64-encoded-string>
apiVersion: v1
kind: Secret
metadata:
  name: ama-metrics-mtls-secret
  namespace: kube-system
type: Opaque
data:
  password1: <base64-encoded-string>
Theama-metrics-mtls-secretsecret is mounted on to theama-metricspods at the path/etc/prometheus/certs/and is made available to the Prometheus scraper. The key (password1in the above example) will be the file name. The value is base64 decoded and added as the contents of the file within the container.
ama-metrics-mtls-secret
ama-metrics
/etc/prometheus/certs/
password1
Then, in the custom scrape config in the configmap, provide the filepath:Basic AuthTheusernamefield should contain the actual username string. Thepassword_filefield should contain the path to the file that contains the password.# Sets the `Authorization` header on every scrape request with the
# configured username and password.
basic_auth:
  username: <username string>
  password_file: /etc/prometheus/certs/password1Bearer TokenThebearer_token_filefield should contain the path to the file that contains the token.# Sets the `Authorization` header on every scrape request with the bearer token
# read from the configured file. It is mutually exclusive with `bearer_token`.
bearer_token_file: /etc/prometheus/certs/password1
Then, in the custom scrape config in the configmap, provide the filepath:
Theusernamefield should contain the actual username string. Thepassword_filefield should contain the path to the file that contains the password.
username
password_file
# Sets the `Authorization` header on every scrape request with the
# configured username and password.
basic_auth:
  username: <username string>
  password_file: /etc/prometheus/certs/password1
# Sets the `Authorization` header on every scrape request with the
# configured username and password.
basic_auth:
  username: <username string>
  password_file: /etc/prometheus/certs/password1
Thebearer_token_filefield should contain the path to the file that contains the token.
bearer_token_file
# Sets the `Authorization` header on every scrape request with the bearer token
# read from the configured file. It is mutually exclusive with `bearer_token`.
bearer_token_file: /etc/prometheus/certs/password1
# Sets the `Authorization` header on every scrape request with the bearer token
# read from the configured file. It is mutually exclusive with `bearer_token`.
bearer_token_file: /etc/prometheus/certs/password1
More info about these settings can be found in thePrometheus scrape_config documentation.
Scraping targets using basic auth or bearer tokens is currently not supported using PodMonitors or ServiceMonitors. Support for this will be added in an upcoming release. For now, the Pod or Service Monitor should be converted into a Prometheus scrape config and put in the custom scrape config configmap. Then basic auth and bearer tokens is supported.
If you are using both basic auth and TLS auth, refer to thesectionbelow.
For more details, refer to thenote sectionbelow.
TLS-based scraping
If you want to scrape Prometheus metrics from an https endpoint, the Prometheus config, PodMonitor, or ServiceMonitor should have theschemeset tohttpsand extra TLS settings.
scheme
https
Create a secret in thekube-systemnamespace namedama-metrics-mtls-secret. Each key-value pair specified in the data section of the secret object will be mounted as a separate file in this /etc/prometheus/certs location with file names that are the same as the keys specified in the data section. The secret values should be base64-encoded.Below is an example YAML of a secret:apiVersion: v1
kind: Secret
metadata:
  name: ama-metrics-mtls-secret
  namespace: kube-system
type: Opaque
data:
  <certfile>: base64_cert_content    
  <keyfile>: base64_key_contentTheama-metrics-mtls-secretsecret is mounted on to theama-metricspods at the path/etc/prometheus/certs/and is made available to the Prometheus scraper. The key (password1in the above example) will be the file name. The value is base64 decoded and added as the contents of the file within the container.
Create a secret in thekube-systemnamespace namedama-metrics-mtls-secret. Each key-value pair specified in the data section of the secret object will be mounted as a separate file in this /etc/prometheus/certs location with file names that are the same as the keys specified in the data section. The secret values should be base64-encoded.
kube-system
ama-metrics-mtls-secret
Below is an example YAML of a secret:
apiVersion: v1
kind: Secret
metadata:
  name: ama-metrics-mtls-secret
  namespace: kube-system
type: Opaque
data:
  <certfile>: base64_cert_content    
  <keyfile>: base64_key_content
apiVersion: v1
kind: Secret
metadata:
  name: ama-metrics-mtls-secret
  namespace: kube-system
type: Opaque
data:
  <certfile>: base64_cert_content    
  <keyfile>: base64_key_content
Theama-metrics-mtls-secretsecret is mounted on to theama-metricspods at the path/etc/prometheus/certs/and is made available to the Prometheus scraper. The key (password1in the above example) will be the file name. The value is base64 decoded and added as the contents of the file within the container.
ama-metrics-mtls-secret
ama-metrics
/etc/prometheus/certs/
password1
Then, in the Prometheus config, PodMonitor, or ServiceMonitor, provide the filepath:
Then, in the Prometheus config, PodMonitor, or ServiceMonitor, provide the filepath:
Scrape Configs using ConfigMap
Scrape Config using CRD (Pod/Service Monitor)
To provide the TLS config setting in a configmap, follow the below example:
tls_config:
   # CA certificate to validate API server certificate with.
   ca_file: /etc/prometheus/certs/<certfile>

   # Certificate and key files for client cert authentication to the server.
   cert_file: /etc/prometheus/certs/<certfile>
   key_file: /etc/prometheus/certs/<keyfile>

   # Disable validation of the server certificate.
   insecure_skip_verify: false
tls_config:
   # CA certificate to validate API server certificate with.
   ca_file: /etc/prometheus/certs/<certfile>

   # Certificate and key files for client cert authentication to the server.
   cert_file: /etc/prometheus/certs/<certfile>
   key_file: /etc/prometheus/certs/<keyfile>

   # Disable validation of the server certificate.
   insecure_skip_verify: false
To provide the TLS config setting for a PodMonitor or ServiceMonitor, follow the below example:
tlsConfig:
   ca:
     secret:
       key: "<certfile>"
       name: "ama-metrics-mtls-secret"
   cert:
     secret:
       key: "<certfile>"
       name: "ama-metrics-mtls-secret"
   keySecret:
       key: "<keyfile>"
       name: "ama-metrics-mtls-secret"
   insecureSkipVerify: false
tlsConfig:
   ca:
     secret:
       key: "<certfile>"
       name: "ama-metrics-mtls-secret"
   cert:
     secret:
       key: "<certfile>"
       name: "ama-metrics-mtls-secret"
   keySecret:
       key: "<keyfile>"
       name: "ama-metrics-mtls-secret"
   insecureSkipVerify: false
Basic Auth and TLS
If you want to use both basic and TLS authentication settings in your configmap/CRD, ensure that the secretama-metrics-mtls-secretincludes all the keys under the data section with their corresponding base64-encoded values, as shown below:
ama-metrics-mtls-secret
apiVersion: v1
kind: Secret
metadata:
  name: ama-metrics-mtls-secret
  namespace: kube-system
type: Opaque
data:
  certfile: base64_cert_content    # used for TLS
  keyfile: base64_key_content      # used for TLS
  password1: base64-encoded-string # used for basic auth
  password2: base64-encoded-string # used for basic auth
apiVersion: v1
kind: Secret
metadata:
  name: ama-metrics-mtls-secret
  namespace: kube-system
type: Opaque
data:
  certfile: base64_cert_content    # used for TLS
  keyfile: base64_key_content      # used for TLS
  password1: base64-encoded-string # used for basic auth
  password2: base64-encoded-string # used for basic auth
Note
Note
The/etc/prometheus/certs/path is mandatory, butpassword1can be any string and needs to match the key for the data in the secret created above. This is because the secretama-metrics-mtls-secretis mounted in the path/etc/prometheus/certs/within the container.
/etc/prometheus/certs/
password1
ama-metrics-mtls-secret
/etc/prometheus/certs/
The base64-encoded value is automatically decoded by the ama-metrics pods when the secret is mounted as file.
Ensure secret name isama-metrics-mtls-secretand it is inkube-systemnamespace.
ama-metrics-mtls-secret
kube-system
The secret should be created first, and then the configmap, PodMonitor, or ServiceMonitor should be created inkube-systemnamespace. The order of secret creation matters. When there's no secret but a configmap, PodMonitor, or ServiceMonitor pointing to the secret, the following error will be in the ama-metrics prometheus-collector container logs:no file found for cert....
kube-system
no file found for cert....
To read more on TLS configuration settings, please follow thisConfigurations.
Next steps
Setup Alerts on Prometheus metricsQuery Prometheus metricsLearn more about collecting Prometheus metrics
Feedback
Was this page helpful?
Additional resources