Azure AI Content Safety documentation
The cloud-based Azure AI Content Safety API provides developers with access to advanced algorithms for processing images and text and flagging content that is potentially offensive, risky, or otherwise undesirable.
About Azure AI Content Safety
Overview
What is Azure AI Content Safety?
Get started
Content Safety Studio
Concept
Harm categories
What's new
What's new in Azure AI Content Safety
Image moderation
Concept
Harm categories
Custom categories (preview)
Quickstart
Using Content Safety Studio
Using the REST API or client SDKs
How-To Guide
Use custom categories (standard) (preview)
Use custom categories (rapid) (preview)
Text moderation
Concept
Harm categories
Custom categories (preview)
Groundedness detection
Quickstart
Using Content Safety Studio
Using the REST API or client SDKs
Detect groundedness in LLM responses
How-To Guide
Use custom categories (standard) (preview)
Use custom categories (rapid) (preview)
Use a blocklist
User input risk detection
Concept
Prompt Shields
Quickstart
Using the REST API
Reference
Reference
Azure AI Content Safety API
Azure AI Content Safety Python SDK
Azure AI Content Safety C# SDK
Azure PowerShell
Azure Command-Line Interface (CLI)
Help and feedback
Reference
Support and help options