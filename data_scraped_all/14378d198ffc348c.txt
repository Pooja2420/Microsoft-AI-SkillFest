Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Tutorial: Analyze fraudulent call data with Stream Analytics and visualize results in Power BI dashboard
Article
2024-10-01
21 contributors
In this article
This tutorial shows you how to analyze phone call data using Azure Stream Analytics. The phone call data, generated by a client application, contains fraudulent calls, which are detected by the Stream Analytics job. You can use techniques from this tutorial for other types of fraud detection, such as credit card fraud or identity theft.
In this tutorial, you perform the following tasks:
Generate sample phone call data and send it to Azure Event Hubs.
Create a Stream Analytics job.
Configure job input and output.
Define queries to filter fraudulent calls.
Test and start the job.
Visualize results in Power BI.
Prerequisites
Before you start, make sure you've completed the following steps:
If you don't have anAzure subscription, create afree account.
Download thephone call event generator app,TelcoGenerator.zipfrom the Microsoft Download Center or get the source code fromGitHub.
You need aPower BIaccount.
Sign in to Azure
Sign in to theAzure portal.
Create an event hub
You need to send some sample data to an event hub before Stream Analytics can analyze the fraudulent calls data stream. In this tutorial, you send data to Azure by usingAzure Event Hubs.
Use the following steps to create an event hub and send call data to that event hub:
Sign in to theAzure portal.
Sign in to theAzure portal.
SelectAll serviceson the left menu, selectInternet of things, mouse the mouse overEvent Hubs, and then select+ (Add)button.
SelectAll serviceson the left menu, selectInternet of things, mouse the mouse overEvent Hubs, and then select+ (Add)button.

On theCreate Namespacepage, follow these steps:Select anAzure subscriptionwhere you want to create the event hub.ForResource group, selectCreate newand enter a name for the resource group. The Event Hubs namespace is created in this resource group.ForNamespace name, enter a unique name for the Event Hubs namespace.ForLocation, select the region in which you want to create the namespace.ForPricing tier, selectStandard.SelectReview + createat the bottom of the page.On theReview + createpage of the namespace creation wizard, selectCreateat the bottom of the page after reviewing all settings.
On theCreate Namespacepage, follow these steps:
Select anAzure subscriptionwhere you want to create the event hub.
Select anAzure subscriptionwhere you want to create the event hub.
ForResource group, selectCreate newand enter a name for the resource group. The Event Hubs namespace is created in this resource group.
ForResource group, selectCreate newand enter a name for the resource group. The Event Hubs namespace is created in this resource group.
ForNamespace name, enter a unique name for the Event Hubs namespace.
ForNamespace name, enter a unique name for the Event Hubs namespace.
ForLocation, select the region in which you want to create the namespace.
ForLocation, select the region in which you want to create the namespace.
ForPricing tier, selectStandard.
ForPricing tier, selectStandard.
SelectReview + createat the bottom of the page.
SelectReview + createat the bottom of the page.

On theReview + createpage of the namespace creation wizard, selectCreateat the bottom of the page after reviewing all settings.
On theReview + createpage of the namespace creation wizard, selectCreateat the bottom of the page after reviewing all settings.
After the namespace is deployed successfully, selectGo to resourceto navigate to theEvent Hubs Namespacepage.
After the namespace is deployed successfully, selectGo to resourceto navigate to theEvent Hubs Namespacepage.
On theEvent Hubs Namespacepage, select+Event Hubon the command bar.
On theEvent Hubs Namespacepage, select+Event Hubon the command bar.

On theCreate Event Hubpage, enter aNamefor the event hub. Set thePartition Countto 2.  Use the default options in the remaining settings and selectReview + create.
On theCreate Event Hubpage, enter aNamefor the event hub. Set thePartition Countto 2.  Use the default options in the remaining settings and selectReview + create.

On theReview + createpage, selectCreateat the bottom of the page. Then wait for the deployment to succeed.
On theReview + createpage, selectCreateat the bottom of the page. Then wait for the deployment to succeed.
Grant access to the event hub and get a connection string
Before an application can send data to Azure Event Hubs, the event hub must have a policy that allows access. The access policy produces a connection string that includes authorization information.
On theEvent Hubs Namespacepage, selectShared access policieson the left menu.
On theEvent Hubs Namespacepage, selectShared access policieson the left menu.
SelectRootManageSharedAccessKeyfrom the list of policies.
SelectRootManageSharedAccessKeyfrom the list of policies.

Then, select the copy button next toConnection string - primary key.
Then, select the copy button next toConnection string - primary key.
Paste the connection string into a text editor. You need this connection string in the next section.The connection string looks as follows:Endpoint=sb://<Your event hub namespace>.servicebus.windows.net/;SharedAccessKeyName=<Your shared access policy name>;SharedAccessKey=<generated key>Notice that the connection string contains multiple key-value pairs separated with semicolons:Endpoint,SharedAccessKeyName, andSharedAccessKey.
Paste the connection string into a text editor. You need this connection string in the next section.
The connection string looks as follows:
Endpoint=sb://<Your event hub namespace>.servicebus.windows.net/;SharedAccessKeyName=<Your shared access policy name>;SharedAccessKey=<generated key>
Endpoint=sb://<Your event hub namespace>.servicebus.windows.net/;SharedAccessKeyName=<Your shared access policy name>;SharedAccessKey=<generated key>
Notice that the connection string contains multiple key-value pairs separated with semicolons:Endpoint,SharedAccessKeyName, andSharedAccessKey.
Start the event generator application
Before you start the TelcoGenerator app, you should configure it to send data to the Azure Event Hubs you created earlier.
Extract the contents ofTelcoGenerator.zipfile.
Extract the contents ofTelcoGenerator.zipfile.
Open theTelcoGenerator\TelcoGenerator\telcodatagen.exe.configfile in a text editor of your choice There's more than one.configfile, so be sure that you open the correct one.
Open theTelcoGenerator\TelcoGenerator\telcodatagen.exe.configfile in a text editor of your choice There's more than one.configfile, so be sure that you open the correct one.
TelcoGenerator\TelcoGenerator\telcodatagen.exe.config
.config
Update the<appSettings>element in the config file with the following details:Set the value of theEventHubNamekey to the value of theEntityPathat the end of the connection string.Set the value of theMicrosoft.ServiceBus.ConnectionStringkey to the connection string to the namespace. If you use a connection string to an event hub, not a namespace, removeEntityPathvalue (;EntityPath=myeventhub) at the end.Don't forgetto remove the semicolon that precedes the EntityPath  value.
Update the<appSettings>element in the config file with the following details:
<appSettings>
Set the value of theEventHubNamekey to the value of theEntityPathat the end of the connection string.
Set the value of theMicrosoft.ServiceBus.ConnectionStringkey to the connection string to the namespace. If you use a connection string to an event hub, not a namespace, removeEntityPathvalue (;EntityPath=myeventhub) at the end.Don't forgetto remove the semicolon that precedes the EntityPath  value.
EntityPath
;EntityPath=myeventhub
Save the file.
Save the file.
Next open a command window and change to the folder where you unzipped the TelcoGenerator application. Then enter the following command:.\telcodatagen.exe 1000 0.2 2This command takes the following parameters:Number of call data records per hour.Percentage of fraud probability, which is how often the app should simulate a fraudulent call. The value 0.2 means that about 20% of the call records look fraudulent.Duration in hours, which is the number of hours that the app should run. You can also stop the app at any time by ending the process (Ctrl+C) at the command line.After a few seconds, the app starts displaying phone call records on the screen as it sends them to the event hub. The phone call data contains the following fields:RecordDefinitionCallrecTimeThe timestamp for the call start time.SwitchNumThe telephone switch used to connect the call. For this example, the switches are strings that represent the country/region of origin (US, China, UK, Germany, or Australia).CallingNumThe phone number of the caller.CallingIMSIThe International Mobile Subscriber Identity (IMSI). It's a unique identifier of the caller.CalledNumThe phone number of the call recipient.CalledIMSIInternational Mobile Subscriber Identity (IMSI). It's a unique identifier of the call recipient.
Next open a command window and change to the folder where you unzipped the TelcoGenerator application. Then enter the following command:
.\telcodatagen.exe 1000 0.2 2
.\telcodatagen.exe 1000 0.2 2
This command takes the following parameters:
Number of call data records per hour.
Percentage of fraud probability, which is how often the app should simulate a fraudulent call. The value 0.2 means that about 20% of the call records look fraudulent.
Duration in hours, which is the number of hours that the app should run. You can also stop the app at any time by ending the process (Ctrl+C) at the command line.
After a few seconds, the app starts displaying phone call records on the screen as it sends them to the event hub. The phone call data contains the following fields:
Create a Stream Analytics job
Now that you have a stream of call events, you can create a Stream Analytics job that reads data from the event hub.
To create a Stream Analytics job, navigate to theAzure portal.
SelectCreate a resourceand search forStream Analytics job. Select theStream Analytics jobtile and selectCreate.
On theNew Stream Analytics jobpage, follow these steps:ForSubscription, select the subscription that contains the Event Hubs namespace.ForResource group, select the resource group you created earlier.In theInstance detailssection, ForName, enter a unique name for the Stream Analytics job.ForRegion, select the region in which you want to create the Stream Analytics job. We recommend that you place the job and the event hub in the same region for best performance and so that you don't pay to transfer data between regions.ForHosting environment< selectCloudif it's not already selected. Stream Analytics jobs can be deployed to cloud or edge.Cloudallows you to deploy to Azure Cloud, andEdgeallows you to deploy to an IoT Edge device.ForStreaming units, select1. Streaming units represent the computing resources that are required to execute a job. By default, this value is set to 1. To learn about scaling streaming units, seeunderstanding and adjusting streaming unitsarticle.SelectReview + createat the bottom of the page.
ForSubscription, select the subscription that contains the Event Hubs namespace.
ForSubscription, select the subscription that contains the Event Hubs namespace.
ForResource group, select the resource group you created earlier.
ForResource group, select the resource group you created earlier.
In theInstance detailssection, ForName, enter a unique name for the Stream Analytics job.
In theInstance detailssection, ForName, enter a unique name for the Stream Analytics job.
ForRegion, select the region in which you want to create the Stream Analytics job. We recommend that you place the job and the event hub in the same region for best performance and so that you don't pay to transfer data between regions.
ForRegion, select the region in which you want to create the Stream Analytics job. We recommend that you place the job and the event hub in the same region for best performance and so that you don't pay to transfer data between regions.
ForHosting environment< selectCloudif it's not already selected. Stream Analytics jobs can be deployed to cloud or edge.Cloudallows you to deploy to Azure Cloud, andEdgeallows you to deploy to an IoT Edge device.
ForHosting environment< selectCloudif it's not already selected. Stream Analytics jobs can be deployed to cloud or edge.Cloudallows you to deploy to Azure Cloud, andEdgeallows you to deploy to an IoT Edge device.
ForStreaming units, select1. Streaming units represent the computing resources that are required to execute a job. By default, this value is set to 1. To learn about scaling streaming units, seeunderstanding and adjusting streaming unitsarticle.
ForStreaming units, select1. Streaming units represent the computing resources that are required to execute a job. By default, this value is set to 1. To learn about scaling streaming units, seeunderstanding and adjusting streaming unitsarticle.
SelectReview + createat the bottom of the page.
SelectReview + createat the bottom of the page.

On theReview + createpage, review settings, and then selectCreateto create the Stream Analytics job.
After the job is deployed, selectGo to resourceto navigate to theStream Analytics jobpage.
Configure job input
The next step is to define an input source for the job to read data using the event hub you created in the previous section.
On theStream Analytics jobpage, in theJob Topologysection on the left menu, selectInputs.
On theStream Analytics jobpage, in theJob Topologysection on the left menu, selectInputs.
On theInputspage, select+ Add inputandEvent hub.
On theInputspage, select+ Add inputandEvent hub.

On theEvent hubpage, follow these steps:ForInput alias, enterCallStream. Input alias is a friendly name to identify your input. Input alias can only contain alphanumeric characters and hyphens, and must be 3-63 characters long.ForSubscription, select the Azure subscription where you created the event hub. The event hub can be in same or a different subscription as the Stream Analytics job.ForEvent Hubs namespace, select the Event Hubs namespace you created in the previous section. All the namespaces available in your current subscription are listed in the dropdown.ForEvent hub name, select the event hub you created in the previous section. All the event hubs available in the selected namespace are listed in the dropdown.ForEvent hub consumer group, keep theCreate newoption selected so that a new consumer group is created on the event hub. We recommend that you use a distinct consumer group for each Stream Analytics job. If no consumer group is specified, the Stream Analytics job uses the$Defaultconsumer group. When a job contains a self-join or has multiple inputs, some inputs later might be read by more than one reader. This situation affects the number of readers in a single consumer group.ForAuthentication mode, selectConnection string. It's easier to test the tutorial with this option.ForEvent hub policy name, selectUse existing, and then select the policy you created earlier.SelectSaveat the bottom of the page.
On theEvent hubpage, follow these steps:
ForInput alias, enterCallStream. Input alias is a friendly name to identify your input. Input alias can only contain alphanumeric characters and hyphens, and must be 3-63 characters long.
ForInput alias, enterCallStream. Input alias is a friendly name to identify your input. Input alias can only contain alphanumeric characters and hyphens, and must be 3-63 characters long.
ForSubscription, select the Azure subscription where you created the event hub. The event hub can be in same or a different subscription as the Stream Analytics job.
ForSubscription, select the Azure subscription where you created the event hub. The event hub can be in same or a different subscription as the Stream Analytics job.
ForEvent Hubs namespace, select the Event Hubs namespace you created in the previous section. All the namespaces available in your current subscription are listed in the dropdown.
ForEvent Hubs namespace, select the Event Hubs namespace you created in the previous section. All the namespaces available in your current subscription are listed in the dropdown.
ForEvent hub name, select the event hub you created in the previous section. All the event hubs available in the selected namespace are listed in the dropdown.
ForEvent hub name, select the event hub you created in the previous section. All the event hubs available in the selected namespace are listed in the dropdown.
ForEvent hub consumer group, keep theCreate newoption selected so that a new consumer group is created on the event hub. We recommend that you use a distinct consumer group for each Stream Analytics job. If no consumer group is specified, the Stream Analytics job uses the$Defaultconsumer group. When a job contains a self-join or has multiple inputs, some inputs later might be read by more than one reader. This situation affects the number of readers in a single consumer group.
ForEvent hub consumer group, keep theCreate newoption selected so that a new consumer group is created on the event hub. We recommend that you use a distinct consumer group for each Stream Analytics job. If no consumer group is specified, the Stream Analytics job uses the$Defaultconsumer group. When a job contains a self-join or has multiple inputs, some inputs later might be read by more than one reader. This situation affects the number of readers in a single consumer group.
$Default
ForAuthentication mode, selectConnection string. It's easier to test the tutorial with this option.
ForAuthentication mode, selectConnection string. It's easier to test the tutorial with this option.
ForEvent hub policy name, selectUse existing, and then select the policy you created earlier.
ForEvent hub policy name, selectUse existing, and then select the policy you created earlier.
SelectSaveat the bottom of the page.
SelectSaveat the bottom of the page.

Configure job output
The last step is to define an output sink where the job can write the transformed data. In this tutorial, you output and visualize data with Power BI.
From the Azure portal, openAll resources, and select theASATutorialStream Analytics job.
From the Azure portal, openAll resources, and select theASATutorialStream Analytics job.
In theJob Topologysection of the Stream Analytics job, select theOutputsoption.
In theJob Topologysection of the Stream Analytics job, select theOutputsoption.
Select+ Add output>Power BI.
Select+ Add output>Power BI.

Fill the output form with the following details:SettingSuggested valueOutput aliasMyPBIoutputGroup workspaceMy workspaceDataset nameASAdatasetTable nameASATableAuthentication modeUser token
Fill the output form with the following details:
SelectAuthorizeand follow the prompts to authenticate Power BI.
SelectAuthorizeand follow the prompts to authenticate Power BI.

SelectSaveat the bottom of thePower BIpage.This tutorial uses theUser tokenauthentication mode. To use Managed Identity, seeUse Managed Identity to authenticate your Azure Stream Analytics job to Power BI.
SelectSaveat the bottom of thePower BIpage.
This tutorial uses theUser tokenauthentication mode. To use Managed Identity, seeUse Managed Identity to authenticate your Azure Stream Analytics job to Power BI.
Create queries to transform real-time data
At this point, you have a Stream Analytics job set up to read an incoming data stream. The next step is to create a query that analyzes the data in real time. The queries use a SQL-like language that has some extensions specific to Stream Analytics.
In this section of the tutorial, you create and test several queries to learn a few ways in which you can transform an input stream for analysis.
The queries you create here will just display the transformed data to the screen. In a later section, you'll write the transformed data to Power BI.
To learn more about the language, see theAzure Stream Analytics Query Language Reference.
Test using a pass-through query
If you want to archive every event, you can use a pass-through query to read all the fields in the payload of the event.
Navigate to your Stream Analytics job in the Azure portal and selectQueryunderJob topologyon the left menu.
Navigate to your Stream Analytics job in the Azure portal and selectQueryunderJob topologyon the left menu.
In the query window, enter this query:SELECT 
    *
FROM 
    CallStreamNoteAs with SQL, keywords are not case-sensitive, and whitespace is not significant.In this query,CallStreamis the alias that you specified when you created the input. If you used a different alias, use that name instead.
In the query window, enter this query:
SELECT 
    *
FROM 
    CallStream
SELECT 
    *
FROM 
    CallStream
Note
As with SQL, keywords are not case-sensitive, and whitespace is not significant.
In this query,CallStreamis the alias that you specified when you created the input. If you used a different alias, use that name instead.
CallStream
SelectTest query.The Stream Analytics job runs the query against the sample data from the input and displays the output at the bottom of the window. The results indicate that the Event Hubs and the Streaming Analytics job are configured correctly.The exact number of records you see depends on how many records were captured in the sample.
SelectTest query.
The Stream Analytics job runs the query against the sample data from the input and displays the output at the bottom of the window. The results indicate that the Event Hubs and the Streaming Analytics job are configured correctly.

The exact number of records you see depends on how many records were captured in the sample.
Reduce the number of fields using a column projection
In many cases, your analysis doesn't need all the columns from the input stream. You can use a query to project a smaller set of returned fields than in the pass-through query.
Run the following query and notice the output.
SELECT CallRecTime, SwitchNum, CallingIMSI, CallingNum, CalledNum 
INTO
    [MyPBIoutput]
FROM 
    CallStream
SELECT CallRecTime, SwitchNum, CallingIMSI, CallingNum, CalledNum 
INTO
    [MyPBIoutput]
FROM 
    CallStream
Count incoming calls by region: Tumbling window with aggregation
Suppose you want to count the number of incoming calls per region. In streaming data, when you want to perform aggregate functions like counting, you need to segment the stream into temporal units, since the data stream itself is effectively endless. You do this using a Streaming Analyticswindow function. You can then work with the data inside that window as a unit.
For this transformation, you want a sequence of temporal windows that don't overlapâeach window has a discrete set of data that you can group and aggregate. This type of window is referred to as aTumbling window. Within the Tumbling window, you can get a count of the incoming calls grouped bySwitchNum, which represents the country/region where the call originated.
SwitchNum
Paste the following query in the query editor:SELECT 
    System.Timestamp as WindowEnd, SwitchNum, COUNT(*) as CallCount 
FROM
    CallStream TIMESTAMP BY CallRecTime 
GROUP BY TUMBLINGWINDOW(s, 5), SwitchNumThis query uses theTimestamp Bykeyword in theFROMclause to specify which timestamp field in the input stream to use to define the Tumbling window. In this case, the window divides the data into segments by theCallRecTimefield in each record. (If no field is specified, the windowing operation uses the time that each event arrives at the event hub. See "Arrival Time vs Application Time" inStream Analytics Query Language Reference.The projection includesSystem.Timestamp, which returns a timestamp for the end of each window.To specify that you want to use a Tumbling window, you use theTUMBLINGWINDOWfunction in theGROUP BYclause. In the function, you specify a time unit (anywhere from a microsecond to a day) and a window size (how many units). In this example, the Tumbling window consists of 5-second intervals, so you get a count by country/region for every 5 seconds' worth of calls.
Paste the following query in the query editor:
SELECT 
    System.Timestamp as WindowEnd, SwitchNum, COUNT(*) as CallCount 
FROM
    CallStream TIMESTAMP BY CallRecTime 
GROUP BY TUMBLINGWINDOW(s, 5), SwitchNum
SELECT 
    System.Timestamp as WindowEnd, SwitchNum, COUNT(*) as CallCount 
FROM
    CallStream TIMESTAMP BY CallRecTime 
GROUP BY TUMBLINGWINDOW(s, 5), SwitchNum
This query uses theTimestamp Bykeyword in theFROMclause to specify which timestamp field in the input stream to use to define the Tumbling window. In this case, the window divides the data into segments by theCallRecTimefield in each record. (If no field is specified, the windowing operation uses the time that each event arrives at the event hub. See "Arrival Time vs Application Time" inStream Analytics Query Language Reference.
Timestamp By
FROM
CallRecTime
The projection includesSystem.Timestamp, which returns a timestamp for the end of each window.
System.Timestamp
To specify that you want to use a Tumbling window, you use theTUMBLINGWINDOWfunction in theGROUP BYclause. In the function, you specify a time unit (anywhere from a microsecond to a day) and a window size (how many units). In this example, the Tumbling window consists of 5-second intervals, so you get a count by country/region for every 5 seconds' worth of calls.
GROUP BY
SelectTest query. In the results, notice that the timestamps underWindowEndare in 5-second increments.
SelectTest query. In the results, notice that the timestamps underWindowEndare in 5-second increments.
Detect SIM fraud using a self-join
For this example, consider fraudulent usage to be calls that originate from the same user but in different locations within 5 seconds of one another. For example, the same user can't legitimately make a call from the US and Australia at the same time.
To check for these cases, you can use a self-join of the streaming data to join the stream to itself based on theCallRecTimevalue. You can then look for call records where theCallingIMSIvalue (the originating number) is the same, but theSwitchNumvalue (country/region of origin) isn't the same.
CallRecTime
CallingIMSI
SwitchNum
When you use a join with streaming data, the join must provide some limits on how far the matching rows can be separated in time. As noted earlier, the streaming data is effectively endless. The time bounds for the relationship are specified inside theONclause of the join, using theDATEDIFFfunction. In this case, the join is based on a 5-second interval of call data.
ON
DATEDIFF
Paste the following query in the query editor:SELECT System.Timestamp AS WindowEnd, COUNT(*) AS FraudulentCalls
    INTO "MyPBIoutput"
    FROM "CallStream" CS1 TIMESTAMP BY CallRecTime
    JOIN "CallStream" CS2 TIMESTAMP BY CallRecTime
    ON CS1.CallingIMSI = CS2.CallingIMSI
    AND DATEDIFF(ss, CS1, CS2) BETWEEN 1 AND 5
    WHERE CS1.SwitchNum != CS2.SwitchNum
    GROUP BY TumblingWindow(Duration(second, 1))This query is like any SQL join except for theDATEDIFFfunction in the join. This version ofDATEDIFFis specific to Streaming Analytics, and it must appear in theON...BETWEENclause. The parameters are a time unit (seconds in this example) and the aliases of the two sources for the join. This function is different from the standard SQLDATEDIFFfunction.TheWHEREclause includes the condition that flags the fraudulent call: the originating switches aren't the same.
Paste the following query in the query editor:
SELECT System.Timestamp AS WindowEnd, COUNT(*) AS FraudulentCalls
    INTO "MyPBIoutput"
    FROM "CallStream" CS1 TIMESTAMP BY CallRecTime
    JOIN "CallStream" CS2 TIMESTAMP BY CallRecTime
    ON CS1.CallingIMSI = CS2.CallingIMSI
    AND DATEDIFF(ss, CS1, CS2) BETWEEN 1 AND 5
    WHERE CS1.SwitchNum != CS2.SwitchNum
    GROUP BY TumblingWindow(Duration(second, 1))
SELECT System.Timestamp AS WindowEnd, COUNT(*) AS FraudulentCalls
    INTO "MyPBIoutput"
    FROM "CallStream" CS1 TIMESTAMP BY CallRecTime
    JOIN "CallStream" CS2 TIMESTAMP BY CallRecTime
    ON CS1.CallingIMSI = CS2.CallingIMSI
    AND DATEDIFF(ss, CS1, CS2) BETWEEN 1 AND 5
    WHERE CS1.SwitchNum != CS2.SwitchNum
    GROUP BY TumblingWindow(Duration(second, 1))
This query is like any SQL join except for theDATEDIFFfunction in the join. This version ofDATEDIFFis specific to Streaming Analytics, and it must appear in theON...BETWEENclause. The parameters are a time unit (seconds in this example) and the aliases of the two sources for the join. This function is different from the standard SQLDATEDIFFfunction.
DATEDIFF
DATEDIFF
ON...BETWEEN
DATEDIFF
TheWHEREclause includes the condition that flags the fraudulent call: the originating switches aren't the same.
WHERE
SelectTest query. Review the output, and then selectSave query.
SelectTest query. Review the output, and then selectSave query.
Start the job and visualize output
To start the job, navigate to the jobOverviewand selectStart.
To start the job, navigate to the jobOverviewand selectStart.
SelectNowfor job output start time and selectStart. You can view the job status in the notification bar.
SelectNowfor job output start time and selectStart. You can view the job status in the notification bar.
Once the job succeeds, navigate toPower BIand sign in with your work or school account. If the Stream Analytics job query is outputting results, theASAdatasetdataset you created exists under theDatasetstab.
Once the job succeeds, navigate toPower BIand sign in with your work or school account. If the Stream Analytics job query is outputting results, theASAdatasetdataset you created exists under theDatasetstab.
From your Power BI workspace, select+ Createto create a new dashboard namedFraudulent Calls.
From your Power BI workspace, select+ Createto create a new dashboard namedFraudulent Calls.
At the top of the window, selectEditandAdd tile.
At the top of the window, selectEditandAdd tile.
In theAdd tilewindow, selectCustom Streaming DataandNext.
In theAdd tilewindow, selectCustom Streaming DataandNext.
Choose theASAdatasetunderYour Datasets, and selectNext.
Choose theASAdatasetunderYour Datasets, and selectNext.
SelectCardfrom theVisualization typedropdown, addfraudulent callstoFields, and then selectNext.
SelectCardfrom theVisualization typedropdown, addfraudulent callstoFields, and then selectNext.

Enter a name for the tile (for example,Fraudulent calls), and then selectApplyto create the tile.
Enter a name for the tile (for example,Fraudulent calls), and then selectApplyto create the tile.

Follow the step 5 again with the following options:When you get to Visualization Type, select Line chart.Add an axis and selectwindowend.Add a value and selectfraudulent calls.ForTime window to display, select the last 10 minutes.
Follow the step 5 again with the following options:
When you get to Visualization Type, select Line chart.
Add an axis and selectwindowend.
Add a value and selectfraudulent calls.
ForTime window to display, select the last 10 minutes.

Your dashboard should look like the following example once both tiles are added. Notice that, if your event hub sender application and Streaming Analytics application are running, your Power BI dashboard periodically updates as new data arrives.
Your dashboard should look like the following example once both tiles are added. Notice that, if your event hub sender application and Streaming Analytics application are running, your Power BI dashboard periodically updates as new data arrives.

Embedding your Power BI Dashboard in a web application
For this part of the tutorial, you use a sampleASP.NETweb application created by the Power BI team to embed your dashboard. For more information about embedding dashboards, seeembedding with Power BIarticle.
To set up the application, go to thePower BI-Developer-SamplesGitHub repository and follow the instructions under theUser Owns Datasection (use the redirect and homepage URLs under theintegrate-web-appsubsection). Since we're using the Dashboard example, use theintegrate-web-appsample code located in theGitHub repository.
Once you have the application running in your browser, follow these steps to embed the dashboard you created earlier into the web page:
SelectSign in to Power BI, which grants the application access to the dashboards in your Power BI account.
SelectSign in to Power BI, which grants the application access to the dashboards in your Power BI account.
Select theGet Dashboardsbutton, which displays your account's Dashboards in a table. Find the name of the dashboard you created earlier,powerbi-embedded-dashboard, and copy the correspondingEmbedUrl.
Select theGet Dashboardsbutton, which displays your account's Dashboards in a table. Find the name of the dashboard you created earlier,powerbi-embedded-dashboard, and copy the correspondingEmbedUrl.
Finally, paste theEmbedUrlinto the corresponding text field and selectEmbed Dashboard. You can now view the same dashboard embedded within a web application.
Finally, paste theEmbedUrlinto the corresponding text field and selectEmbed Dashboard. You can now view the same dashboard embedded within a web application.
Next steps
In this tutorial, you created a simple Stream Analytics job, analyzed the incoming data, and presented results in a Power BI dashboard. To learn more about Stream Analytics jobs, continue to the next tutorial:
Run Azure Functions within Stream Analytics jobs
Feedback
Was this page helpful?
Additional resources