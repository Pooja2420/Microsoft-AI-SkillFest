Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Batch service workflow and resources
Article
2025-04-02
4 contributors
In this article
In this overview of the core components of the Azure Batch service, we discuss the high-level workflow that Batch developers can use to build large-scale parallel compute solutions, along with the primary service resources that are used.
Whether you're developing a distributed computational application or service that issues directREST APIcalls or you're using another one of theBatch SDKs, you'll use many of the resources and features discussed here.
Tip
For a higher-level introduction to the Batch service, seeWhat is Azure Batch?. Also see the latestBatch service updates.
Basic workflow
The following high-level workflow is typical of nearly all applications and services that use the Batch service for processing parallel workloads:
Upload thedata filesthat you want to process to anAzure Storageaccount. Batch includes built-in support for accessing Azure Blob storage, and your tasks can download these files tocompute nodeswhen the tasks are run.
Upload theapplication filesthat your tasks will run. These files can be binaries or scripts and their dependencies, and are executed by the tasks in your jobs. Your tasks can download these files from your Storage account, or you can use theapplication packagesfeature of Batch for application management and deployment.
Create apoolof compute nodes. When you create a pool, you specify the number of compute nodes for the pool, their size, and the operating system. When each task in your job runs, it's assigned to execute on one of the nodes in your pool.
Create ajob. A job manages a collection of tasks. You associate each job to a specific pool where that job's tasks will run.
Addtasksto the job. Each task runs the application or script that you uploaded to process the data files it downloads from your Storage account. As each task completes, it can upload its output to Azure Storage.
Monitor job progress and retrieve the task output from Azure Storage.
Note
You need aBatch accountto use the Batch service. Most Batch solutions also use an associatedAzure Storageaccount for file storage and retrieval.
Batch service resources
The following topics discuss the resources of Batch that enable your distributed computational scenarios.
Batch accounts and storage accounts
Nodes and pools
Jobs and tasks
Files and directories
Next steps
Learn about theBatch APIs and toolsavailable for building Batch solutions.
Learn the basics of developing a Batch-enabled application using theBatch .NET client libraryorPython. These quickstarts guide you through a sample application that uses the Batch service to execute a workload on multiple compute nodes, and includes using Azure Storage for workload file staging and retrieval.
Download and installBatch Explorerfor use while you develop your Batch solutions. Use Batch Explorer to help create, debug, and monitor Azure Batch applications.
See community resources includingStack Overflow, theBatch Community repo, and theAzure Batch forum.
Feedback
Was this page helpful?
Additional resources