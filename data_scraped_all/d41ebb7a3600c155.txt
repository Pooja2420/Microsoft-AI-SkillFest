Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Deploy a model to Azure Container Instances with CLI (v1)
Article
2025-03-31
5 contributors
In this article
Important
Some of the Azure CLI commands in this article use theazure-cli-ml, or v1, extension for Azure Machine Learning. Support for the v1 extension will end on September 30, 2025. You're able to install and use the v1 extension until that date.
azure-cli-ml
We recommend that you transition to theml, or v2, extension before September 30, 2025. For more information on the v2 extension, seeAzure Machine Learning CLI extension and Python SDK v2.
ml
Important
This article provides information on using the Azure Machine Learning SDK v1. The SDK v1 is deprecated as of March 31, 2025 and support for it will end on June 30, 2026. You're able to install and use the SDK v1 until that date.
We recommend that you transition to the SDK v2 before June 30, 2026. For more information on the SDK v2, seeWhat is the Azure Machine Learning Python SDK v2and theSDK v2 reference.
Important
This article shows how to use the CLI and SDK v1 to deploy a model.  For the recommended approach for v2, seeDeploy and score a machine learning model by using an online endpoint.
Learn how to use Azure Machine Learning to deploy a model as a web service on Azure Container Instances (ACI). Use Azure Container Instances if you:
prefer not to manage your own Kubernetes cluster
Are OK with having only a single replica of your service, which might affect uptime
For information on quota and region availability for ACI, seeQuotas and region availability for Azure Container Instancesarticle.
Important
It is highly advised to debug locally before deploying to the web service, for more information, seeDebug Locally
You can also refer to Azure Machine Learning -Deploy to Local Notebook
Prerequisites
An Azure Machine Learning workspace. For more information, seeCreate an Azure Machine Learning workspace.
An Azure Machine Learning workspace. For more information, seeCreate an Azure Machine Learning workspace.
A machine learning model registered in your workspace. If you don't have a registered model, seeHow and where to deploy models.
A machine learning model registered in your workspace. If you don't have a registered model, seeHow and where to deploy models.
TheAzure CLI extension (v1) for Machine Learning service,Azure Machine Learning Python SDK, or theAzure Machine Learning Visual Studio Code extension.
TheAzure CLI extension (v1) for Machine Learning service,Azure Machine Learning Python SDK, or theAzure Machine Learning Visual Studio Code extension.
ThePythoncode snippets in this article assume that the following variables are set:ws- Set to your workspace.model- Set to your registered model.inference_config- Set to the inference configuration for the model.For more information on setting these variables, seeHow and where to deploy models.
ThePythoncode snippets in this article assume that the following variables are set:
ws- Set to your workspace.
ws
model- Set to your registered model.
model
inference_config- Set to the inference configuration for the model.
inference_config
For more information on setting these variables, seeHow and where to deploy models.
TheCLIsnippets in this article assume that you've created aninferenceconfig.jsondocument. For more information on creating this document, seeHow and where to deploy models.
TheCLIsnippets in this article assume that you've created aninferenceconfig.jsondocument. For more information on creating this document, seeHow and where to deploy models.
inferenceconfig.json
Limitations
Note
Deploying Azure Container Instances in a virtual network is not supported. Instead, for network isolation, consider usingmanaged online endpoints.
To ensure effective support, it is essential to supply the necessary logs for your ACI containers. Without these logs, technical support cannot be guaranteed. It is recommended to use log analytics tools by specifyingenable_app_insights=Truein your deployment configuration to manage and analyze your ACI container logs efficiently.
enable_app_insights=True
Deploy to ACI
To deploy a model to Azure Container Instances, create adeployment configurationthat describes the compute resources needed. For example, number of cores and memory. You also need aninference configuration, which describes the environment needed to host the model and web service. For more information on creating the inference configuration, seeHow and where to deploy models.
Note
ACI is suitable only for small models that are under 1 GB in size.
We recommend using single-node AKS to dev-test larger models.
The number of models to be deployed is limited to 1,000 models per deployment (per container).
Using the SDK
APPLIES TO:Python SDK azuremlv1
from azureml.core.webservice import AciWebservice, Webservice
from azureml.core.model import Model

deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)
service = Model.deploy(ws, "aciservice", [model], inference_config, deployment_config)
service.wait_for_deployment(show_output = True)
print(service.state)
from azureml.core.webservice import AciWebservice, Webservice
from azureml.core.model import Model

deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)
service = Model.deploy(ws, "aciservice", [model], inference_config, deployment_config)
service.wait_for_deployment(show_output = True)
print(service.state)
For more information on the classes, methods, and parameters used in this example, see the following reference documents:
AciWebservice.deploy_configuration
Model.deploy
Webservice.wait_for_deployment
Using the Azure CLI
APPLIES TO:Azure CLI ml extensionv1
To deploy using the CLI, use the following command. Replacemymodel:1with the name and version of the registered model. Replacemyservicewith the name to give this service:
mymodel:1
myservice
az ml model deploy -n myservice -m mymodel:1 --ic inferenceconfig.json --dc deploymentconfig.json
az ml model deploy -n myservice -m mymodel:1 --ic inferenceconfig.json --dc deploymentconfig.json
The entries in thedeploymentconfig.jsondocument map to the parameters forAciWebservice.deploy_configuration. The following table describes the mapping between the entities in the JSON document and the parameters for the method:
deploymentconfig.json
computeType
ACI
containerResourceRequirements
cpu
cpu_cores
0.1
memoryInGB
memory_gb
0.5
location
location
authEnabled
auth_enabled
sslEnabled
ssl_enabled
appInsightsEnabled
enable_app_insights
sslCertificate
ssl_cert_pem_file
sslKey
ssl_key_pem_file
cname
ssl_cname
dnsNameLabel
dns_name_label
The following JSON is an example deployment configuration for use with the CLI:
{
    "computeType": "aci",
    "containerResourceRequirements":
    {
        "cpu": 0.5,
        "memoryInGB": 1.0
    },
    "authEnabled": true,
    "sslEnabled": false,
    "appInsightsEnabled": false
}
{
    "computeType": "aci",
    "containerResourceRequirements":
    {
        "cpu": 0.5,
        "memoryInGB": 1.0
    },
    "authEnabled": true,
    "sslEnabled": false,
    "appInsightsEnabled": false
}
For more information, see theaz ml model deployreference.
Using VS Code
Seehow to manage resources in VS Code.
Important
You don't need to create an ACI container to test in advance. ACI containers are created as needed.
Important
We append hashed workspace id to all underlying ACI resources which are created, all ACI names from same workspace will have same suffix. The Azure Machine Learning service name would still be the same customer provided "service_name" and all the user facing Azure Machine Learning SDK APIs do not need any change. We do not give any guarantees on the names of underlying resources being created.
Next steps
How to deploy a model using a custom Docker image
Deployment troubleshooting
Update the web service
Use TLS to secure a web service through Azure Machine Learning
Consume a ML Model deployed as a web service
Monitor your Azure Machine Learning models with Application Insights
Collect data for models in production
Feedback
Was this page helpful?
Additional resources