Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Transform data by running a Jar activity in Azure Databricks
Article
2025-01-16
12 contributors
In this article
APPLIES TO:Azure Data FactoryAzure Synapse Analytics
Tip
Try outData Factory in Microsoft Fabric, an all-in-one analytics solution for enterprises.Microsoft Fabriccovers everything from data movement to data science, real-time analytics, business intelligence, and reporting. Learn how tostart a new trialfor free!
The Azure Databricks Jar Activity in apipelineruns a Spark Jar in your Azure Databricks cluster. This article builds on thedata transformation activitiesarticle, which presents a general overview of data transformation and the supported transformation activities.Â Azure Databricks is a managed platform for running Apache Spark.
For an eleven-minute introduction and demonstration of this feature, watch the following video:
Add a Jar activity for Azure Databricks to a pipeline with UI
To use a Jar activity for Azure Databricks in a pipeline, complete the following steps:
Search forJarin the pipeline Activities pane, and drag a Jar activity to the pipeline canvas.
Search forJarin the pipeline Activities pane, and drag a Jar activity to the pipeline canvas.
Select the new Jar activity on the canvas if it is not already selected.
Select the new Jar activity on the canvas if it is not already selected.
Select theAzure Databrickstab to select or create a new Azure Databricks linked service that will execute the Jar activity.
Select theAzure Databrickstab to select or create a new Azure Databricks linked service that will execute the Jar activity.

Select theSettingstab and specify a class name to be executed on Azure Databricks, optional parameters to be passed to the Jar, and libraries to be installed on the cluster to execute the job.
Select theSettingstab and specify a class name to be executed on Azure Databricks, optional parameters to be passed to the Jar, and libraries to be installed on the cluster to execute the job.

Databricks Jar activity definition
Here's the sample JSON definition of a Databricks Jar Activity:
{
    "name": "SparkJarActivity",
    "type": "DatabricksSparkJar",
    "linkedServiceName": {
        "referenceName": "AzureDatabricks",
        "type": "LinkedServiceReference"
    },
    "typeProperties": {
        "mainClassName": "org.apache.spark.examples.SparkPi",
        "parameters": [ "10" ],
        "libraries": [
            {
                "jar": "dbfs:/docs/sparkpi.jar"
            }
        ]
    }
}
{
    "name": "SparkJarActivity",
    "type": "DatabricksSparkJar",
    "linkedServiceName": {
        "referenceName": "AzureDatabricks",
        "type": "LinkedServiceReference"
    },
    "typeProperties": {
        "mainClassName": "org.apache.spark.examples.SparkPi",
        "parameters": [ "10" ],
        "libraries": [
            {
                "jar": "dbfs:/docs/sparkpi.jar"
            }
        ]
    }
}
Databricks Jar activity properties
The following table describes the JSON properties used in the JSON
definition:
Note
Known Issue- When using the sameInteractive clusterfor running concurrent Databricks Jar activities (without cluster restart), there is a known issue in Databricks where in parameters of the 1st activity will be used by following activities as well. Hence resulting to incorrect parameters being passed to the subsequent jobs. To mitigate this use aJob clusterinstead.
Supported libraries for databricks activities
In the previous Databricks activity definition, you specified these library types:jar,egg,maven,pypi,cran.
jar
egg
maven
pypi
cran
{
    "libraries": [
        {
            "jar": "dbfs:/mnt/libraries/library.jar"
        },
        {
            "egg": "dbfs:/mnt/libraries/library.egg"
        },
        {
            "maven": {
                "coordinates": "org.jsoup:jsoup:1.7.2",
                "exclusions": [ "slf4j:slf4j" ]
            }
        },
        {
            "pypi": {
                "package": "simplejson",
                "repo": "http://my-pypi-mirror.com"
            }
        },
        {
            "cran": {
                "package": "ada",
                "repo": "https://cran.us.r-project.org"
            }
        }
    ]
}
{
    "libraries": [
        {
            "jar": "dbfs:/mnt/libraries/library.jar"
        },
        {
            "egg": "dbfs:/mnt/libraries/library.egg"
        },
        {
            "maven": {
                "coordinates": "org.jsoup:jsoup:1.7.2",
                "exclusions": [ "slf4j:slf4j" ]
            }
        },
        {
            "pypi": {
                "package": "simplejson",
                "repo": "http://my-pypi-mirror.com"
            }
        },
        {
            "cran": {
                "package": "ada",
                "repo": "https://cran.us.r-project.org"
            }
        }
    ]
}
For more information, see theDatabricks documentationfor library types.
How to upload a library in Databricks
You can use the Workspace UI:
Use the Databricks workspace UI
Use the Databricks workspace UI
To obtain the dbfs path of the library added using UI, you can useDatabricks CLI.Typically the Jar libraries are stored under dbfs:/FileStore/jars while using the UI. You can list all through the CLI:databricks fs ls dbfs:/FileStore/job-jars
To obtain the dbfs path of the library added using UI, you can useDatabricks CLI.
Typically the Jar libraries are stored under dbfs:/FileStore/jars while using the UI. You can list all through the CLI:databricks fs ls dbfs:/FileStore/job-jars
Or you can use the Databricks CLI:
FollowCopy the library using Databricks CLI
FollowCopy the library using Databricks CLI
Use Databricks CLI(installation steps)As an example, to copy a JAR to dbfs:dbfs cp SparkPi-assembly-0.1.jar dbfs:/docs/sparkpi.jar
Use Databricks CLI(installation steps)
As an example, to copy a JAR to dbfs:dbfs cp SparkPi-assembly-0.1.jar dbfs:/docs/sparkpi.jar
dbfs cp SparkPi-assembly-0.1.jar dbfs:/docs/sparkpi.jar
Related content
For an eleven-minute introduction and demonstration of this feature, watch thevideo.
Feedback
Was this page helpful?
Additional resources