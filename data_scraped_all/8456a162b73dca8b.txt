Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
SAP HANA Azure virtual machine Premium SSD storage configurations
Article
2024-10-29
5 contributors
In this article
This document is about HANA storage configurations for Azure premium storage or premium ssd as it was introduced years back as low latency storage for database management systems (DBMS) and other applications that need low latency storage. For general considerations around stripe sizes when using Logical Volume Manager (LVM), HANA data volume partitioning or other considerations that are independent of the particular storage type, check these two documents:
SAP HANA Azure virtual machine storage configurations
Azure Storage types for SAP workload
Important
The suggestions for the storage configurations in this document are meant as directions to start with. Running workload and analyzing storage utilization patterns, you might realize that you aren't utilizing all the storage bandwidth or IOPS (I/O operations per second) provided. You might consider downsizing on storage then. Or in contrary, your workload might need more storage throughput than suggested with these configurations. As a result, you might need to deploy more capacity, IOPS or throughput. In the field of tension between storage capacity required, storage latency needed, storage throughput and IOPS required and least expensive configuration, Azure offers enough different storage types with different capabilities and different price points to find and adjust to the right compromise for you and your HANA workload.
Solutions with premium storage and Azure Write Accelerator for Azure M-Series virtual machines
Azure Write Accelerator is a functionality that is available for Azure M-Series Virtual Machines (VM) exclusively in combination with Azure premium storage. As the name states, the purpose of the functionality is to improve I/O latency of writes against the Azure premium storage. For SAP HANA, Write Accelerator is supposed to be used against the/hana/logvolume only. Therefore,  the/hana/dataand/hana/logare separate volumes with Azure Write Accelerator supporting the/hana/logvolume only.
Important
When using Azure premium storage, the usage of AzureWrite Acceleratorfor the/hana/logvolume is mandatory. Write Accelerator is available for premium storage and M-Series and Mv2-Series VMs only. Write Accelerator is not working in combination with other Azure VM families, like Esv3 or Edsv4.
The caching recommendations for Azure premium disks below are assuming the I/O characteristics for SAP HANA that list like:
There hardly is any read workload against the HANA data files. Exceptions are large sized I/Os after restart of the HANA instance or when data is loaded into HANA. Another case of larger read I/Os against data files can be HANA database backups. As a result read caching mostly doesn't make sense since in most of the cases, all data file volumes need to be read completely.
Writing against the data files is experienced in bursts based by HANA savepoints and HANA crash recovery. Writing savepoints is asynchronous and aren't holding up any user transactions. Writing data during crash recovery is performance critical in order to get the system responding fast again. However, crash recovery should be rather exceptional situations
There are hardly any reads from the HANA redo files. Exceptions are large I/Os when performing transaction log backups, crash recovery, or in the restart phase of a HANA instance.
Main load against the SAP HANA redo log file is writes. Dependent on the nature of workload, you can have I/Os as small as 4 KB or in other cases I/O sizes of 1 MB or more. Write latency against the SAP HANA redo log is performance critical.
All writes need to be persisted on disk in a reliable fashion
Recommendation: As a result of these observed I/O patterns by SAP HANA, the caching for the different volumes using Azure premium storage should be set like:
/hana/data- None or read caching
/hana/log- None. Enable Write Accelerator for M- and Mv2-Series VMs, the option in the Azure portal is "None + Write Accelerator."
/hana/shared- read caching
OS disk- don't change default caching that is set by Azure at creation time of the VM
Note
With some of the new M(b)v3 VM types, the usage of read cached Premium SSD v1 storage could result in lower read and write IOPS rates and throughput than you would get if you don't use read cache.
Azure burst functionality for premium storage
For Azure premium storage disks smaller or equal to 512 GiB in capacity, burst functionality is offered. The exact way how disk bursting works is described in the articleDisk bursting. When you read the article, you understand the concept of accruing I/O Operations per second (IOPS) and throughput in the times when your I/O workload is below the nominal IOPS and throughput of the disks (for details on the nominal throughput seeManaged Disk pricing). You're going to accrue the delta of IOPS and throughput between your current usage and the nominal values of the disk. The bursts  are limited to a maximum of 30 minutes.
The ideal cases where this burst functionality can be planned in is likely going to be the volumes or disks that contain data files for the different DBMS. The I/O workload expected against those volumes, especially with small to mid-ranged systems is expected to look like:
Low to moderate read workload since data ideally is cached in memory, or like with SAP HANA should be completely in memory
Bursts of write triggered by database checkpoints or savepoints that are issued regularly
Backup workload that reads in a continuous stream in cases where backups aren't executed via storage snapshots
For SAP HANA, load of the data into memory after an instance restart
Especially on smaller DBMS systems where your workload is handling a few hundred transactions per seconds only, such a burst functionality can make sense as well for the disks or volumes that store the transaction or redo log. Expected workload against such a disk or volumes looks like:
Regular writes to the disk that are dependent on the workload and the nature of workload since every commit issued by the application is likely to trigger an I/O operation
Higher workload in throughput for cases of operational tasks, like creating or rebuilding indexes
Read bursts when performing transaction log or redo log backups
Production recommended storage solution based on Azure premium storage
Important
SAP HANA certification for Azure M-Series virtual machines is exclusively with Azure Write Accelerator for the/hana/logvolume. As a result, production scenario SAP HANA deployments on Azure M-Series virtual machines are expected to be configured with Azure Write Accelerator for the/hana/logvolume.
Note
In scenarios that involve Azure premium storage, we are implementing burst capabilities into the configuration. As you're using storage test tools of whatever shape or form, keep the wayAzure premium disk bursting worksin mind. Running the storage tests delivered through the SAP HWCCT or HCMT tool, we aren't expecting that all tests will pass the criteria since some of the tests will exceed the bursting credits you can accumulate. Especially when all the tests run sequentially without break.
Note
With M32ts and M32ls VMs it can happen that disk throughput could be lower than expected using HCMT/HWCCT disk tests. Even with disk bursting or with sufficiently provisioned I/O throughput of the underlying disks. Root cause of the observed behavior was that the HCMT/HWCCT storage test files were completely cached in the read cache of the Premium storage data disks. This cache is located on the compute host that hosts the virtual machine and can cache the test files of HCMT/HWCCT completely. In such a case the quotas listed in the columnMax cached and temp storage throughput: IOPS/MBps (cache size in GiB)in  the articleM-seriesare relevant. Specifically for M32ts and M32ls, the throughput quota against the read cache is only 400MB/sec. As a result of the tests files being completely cached, it is possible that despite disk bursting or higher provisioned I/O throughput, the tests can fall slightly short of 400MB/sec maximum throughput. As an alternative, you can test without read cache enabled on the Azure Premium storage data disks.
Note
For production scenarios, check whether a certain VM type is supported for SAP HANA by SAP in theSAP documentation for IAAS.
Recommendation: The recommended configurations with Azure premium storage for production scenarios look like:
Configuration for SAP/hana/datavolume:
1VM type not available by default. Contact your Microsoft account team
2Maximum throughput provided by the VM and throughput requirement by SAP HANA workload, especially savepoint activity,  can force you to deploy significant more premium storage v1 capacity.
For the/hana/logvolume. the configuration would look like:
1VM type not available by default. Contact your Microsoft account team
For the other volumes, the configuration would look like:
1VM type not available by default. Contact your Microsoft account team2Review carefully theconsiderations for sizing/hana/shared
Check whether the storage throughput for the different suggested volumes meets the workload that you want to run. If the workload requires higher volumes for/hana/dataand/hana/log, you need to increase the number of Azure premium storage VHDs. Sizing a volume with more VHDs than listed increases the IOPS and I/O throughput within the limits of the Azure virtual machine type.
Azure Write Accelerator only works withAzure managed disks. So at least the Azure premium storage disks forming the/hana/logvolume need to be deployed as managed disks. More detailed instructions and restrictions of Azure Write Accelerator can be found in the articleWrite Accelerator.
You may want to use Azure Ultra disk storage instead of Azure premium storage only for the/hana/logvolume to be compliant with the SAP HANA certification KPIs when using E-series VMs. Though, many customers are using premium storage SSD disks for the/hana/logvolume for non-production purposes or even for smaller production workloads since the write latency experienced with premium storage for the critical redo log writes are meeting the workload requirements. The configurations for the/hana/datavolume on Azure premium storage could look like:
For the other volumes, including/hana/logon Ultra disk, the configuration could look like:
1Review carefully theconsiderations for sizing/hana/shared
Cost conscious solution with Azure premium storage
So far, the Azure premium storage solution described in this document in sectionSolutions with premium storage and Azure Write Accelerator for Azure M-Series virtual machineswere meant for SAP HANA production supported scenarios. One of the characteristics of production supportable configurations is the separation of the volumes for SAP HANA data and redo log into two different volumes. Reason for such a separation is that the workload characteristics on the volumes are different. And that with the suggested production configurations, different type of caching or even different types of Azure block storage could be necessary. For non-production scenarios, some of the considerations taken for production systems may not apply to more low end non-production systems. As a result the HANA data and log volume could be combined. Though eventually with some culprits, like eventually not meeting certain throughput or latency KPIs that are required for production systems. Another aspect to reduce costs in such environments can be the usage ofAzure Standard SSD storage. Keep in mind that choosing Standard SSD or Standard HDD Azure storage has impact on your single VM SLAs as documented in the articleSLA for Virtual Machines.
A less costly alternative for such configurations could look like:
1Azure Write Acceleratorcan't be used with the Ev4 and Ev4 VM families. As a result of using Azure premium storage the I/O latency won't be less than 1ms
2The VM family supportsAzure Write Accelerator, but there's a potential that the IOPS limit of Write accelerator could limit the disk configurations IOPS capabilities
3Review carefully theconsiderations for sizing/hana/shared
When combining the data and log volume for SAP HANA, the disks building the striped volume shouldn't have read cache or read/write cache enabled.
There are VM types listed that aren't certified with SAP and as such not listed in the so calledSAP HANA hardware directory. Feedback of customers was that those non-listed VM types were used successfully for some non-production tasks.
Next steps
For more information, see:
SAP HANA High Availability guide for Azure virtual machines.
Feedback
Was this page helpful?
Additional resources