Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Deploy Azure Machine Learning extension on AKS or Arc Kubernetes cluster
Article
2025-03-07
15 contributors
In this article
To enable your AKS or Arc Kubernetes cluster to run training jobs or inference workloads, you must first deploy the Azure Machine Learning extension on an AKS or Arc Kubernetes cluster. The Azure Machine Learning extension is built on thecluster extension for AKSandcluster extension or Arc Kubernetes, and its lifecycle can be managed easily with Azure CLIk8s-extension.
In this article, you can learn:
Prerequisites
Limitations
Review Azure Machine Learning extension config settings
Azure Machine Learning extension deployment scenarios
Verify Azure Machine Learning extension deployment
Review Azure Machine Learning extension components
Manage Azure Machine Learning extension
Prerequisites
An AKS cluster running in Azure. If you haven't previously used cluster extensions, you need toregister the KubernetesConfiguration service provider.
Or an Arc Kubernetes cluster is up and running. Follow instructions inconnect existing Kubernetes cluster to Azure Arc.If the cluster is an Azure RedHat OpenShift (ARO) Service cluster or OpenShift Container Platform (OCP) cluster, you must satisfy other prerequisite steps as documented in theReference for configuring Kubernetes clusterarticle.
If the cluster is an Azure RedHat OpenShift (ARO) Service cluster or OpenShift Container Platform (OCP) cluster, you must satisfy other prerequisite steps as documented in theReference for configuring Kubernetes clusterarticle.
For production purposes, the Kubernetes cluster must have a minimum of4 vCPU cores and 14-GB memory. For more information on resource detail and cluster size recommendations, seeRecommended resource planning.
Cluster running behind anoutbound proxy serverorfirewallneeds extranetwork configurations.
Install or upgrade Azure CLI to version 2.24.0 or higher.
Install or upgrade Azure CLI extensionk8s-extensionto version 1.2.3 or higher.
k8s-extension
Limitations
Using a service principal with AKSisnot supportedby Azure Machine Learning. The AKS cluster must use amanaged identityinstead. Bothsystem-assigned managed identityanduser-assigned managed identityare supported. For more information, seeUse a managed identity in Azure Kubernetes Service.When your AKS cluster used service principal is converted to use Managed Identity, before installing the extension, all node pools need to be deleted and recreated, rather than updated directly.
When your AKS cluster used service principal is converted to use Managed Identity, before installing the extension, all node pools need to be deleted and recreated, rather than updated directly.
Disabling local accountsfor AKS isnot supportedby Azure Machine Learning. When the AKS Cluster is deployed, local accounts are enabled by default.
If your AKS cluster has anAuthorized IP range enabled to access the API server, enable the Azure Machine Learning control plane IP ranges for the AKS cluster. The Azure Machine Learning control plane is deployed across paired regions. Without access to the API server, the machine learning pods can't be deployed. Use theIP rangesfor both thepaired regionswhen enabling the IP ranges in an AKS cluster.
Azure Machine Learning doesn't support attaching an AKS cluster cross subscription. If you have an AKS cluster in a different subscription, you must firstconnect it to Azure-Arcand specify in the same subscription as your Azure Machine Learning workspace.
Azure Machine Learning doesn't guarantee support for all preview stage features in AKS. For example,Microsoft Entra pod identityisn't supported.
If you've followed the steps fromAzure Machine Learning AKS v1 documentto create or attach your AKS as inference cluster, use the following link toclean up the legacy azureml-fe related resourcesbefore you continue the next step.
Review Azure Machine Learning extension configuration settings
You can use Azure Machine Learning CLI commandk8s-extension createto deploy Azure Machine Learning extension. CLIk8s-extension createallows you to specify a set of configuration settings inkey=valueformat using--configor--config-protectedparameter. Following is the list of available configuration settings to be specified during Azure Machine Learning extension deployment.
k8s-extension create
k8s-extension create
key=value
--config
--config-protected
enableTraining
True
False
False
True
enableInference
True
False
False
True
allowInsecureConnections
True
False
False
True
inferenceRouterServiceType
loadBalancer
nodePort
clusterIP
enableInference=True
internalLoadBalancerProvider
azure
sslSecret
azureml
cert.pem
key.pem
allowInsecureConnections
False
sslSecret
sslCertPemFile
sslKeyPemFile
sslCname
allowInsecureConnections=False
inferenceRouterHA
True
False
True
False
nodeSelector
key1=value1
key2=value2
nodeSelector.key1=value1
nodeSelector.key2=value2
installNvidiaDevicePlugin
True
False
False
True
installPromOp
True
False
True
False
installVolcano
True
False
True
False
installDcgmExporter
True
False
False
installDcgmExporter
True
sslCertPemFile
sslKeyPemFile
allowInsecureConnections
As you can see from the configuration settings table, the combinations of different configuration settings allow you to deploy Azure Machine Learning extension for different ML workload scenarios:
For training job and batch inference workload, specifyenableTraining=True
enableTraining=True
For inference workload only, specifyenableInference=True
enableInference=True
For all kinds of ML workload, specify bothenableTraining=TrueandenableInference=True
enableTraining=True
enableInference=True
If you plan to deploy Azure Machine Learning extension for real-time inference workload and want to specifyenableInference=True, pay attention to following configuration settings related to real-time inference workload:
enableInference=True
azureml-ferouter service is required for real-time inference support and you need to specifyinferenceRouterServiceTypeconfig setting forazureml-fe.azureml-fecan be deployed with one of followinginferenceRouterServiceType:TypeLoadBalancer. Exposesazureml-feexternally using a cloud provider's load balancer. To specify this value, ensure that your cluster supports load balancer provisioning. Note most on-premises Kubernetes clusters might not support external load balancer.TypeNodePort. Exposesazureml-feon each Node's IP at a static port. You'll be able to contactazureml-fe, from outside of cluster, by requesting<NodeIP>:<NodePort>. UsingNodePortalso allows you to set up your own load balancing solution and TLS/SSL termination forazureml-fe. For more details on how to set up your own ingress, seeIntegrate other ingress controller with Azure Machine Learning extension over HTTP or HTTPS.TypeClusterIP. Exposesazureml-feon a cluster-internal IP, and it makesazureml-feonly reachable from within the cluster. Forazureml-feto serve inference requests coming outside of cluster, it requires you to set up your own load balancing solution and TLS/SSL termination forazureml-fe. For more details on how to set up your own ingress, seeIntegrate other ingress controller with Azure Machine Learning extension over HTTP or HTTPS.
azureml-fe
inferenceRouterServiceType
azureml-fe
azureml-fe
inferenceRouterServiceType
TypeLoadBalancer. Exposesazureml-feexternally using a cloud provider's load balancer. To specify this value, ensure that your cluster supports load balancer provisioning. Note most on-premises Kubernetes clusters might not support external load balancer.
LoadBalancer
azureml-fe
TypeNodePort. Exposesazureml-feon each Node's IP at a static port. You'll be able to contactazureml-fe, from outside of cluster, by requesting<NodeIP>:<NodePort>. UsingNodePortalso allows you to set up your own load balancing solution and TLS/SSL termination forazureml-fe. For more details on how to set up your own ingress, seeIntegrate other ingress controller with Azure Machine Learning extension over HTTP or HTTPS.
NodePort
azureml-fe
azureml-fe
<NodeIP>:<NodePort>
NodePort
azureml-fe
TypeClusterIP. Exposesazureml-feon a cluster-internal IP, and it makesazureml-feonly reachable from within the cluster. Forazureml-feto serve inference requests coming outside of cluster, it requires you to set up your own load balancing solution and TLS/SSL termination forazureml-fe. For more details on how to set up your own ingress, seeIntegrate other ingress controller with Azure Machine Learning extension over HTTP or HTTPS.
ClusterIP
azureml-fe
azureml-fe
azureml-fe
azureml-fe
To ensure high availability ofazureml-ferouting service, Azure Machine Learning extension deployment by default creates three replicas ofazureml-fefor clusters having three nodes or more. If your cluster hasless than 3 nodes, setinferenceRouterHA=False.
azureml-fe
azureml-fe
inferenceRouterHA=False
You also want to consider usingHTTPSto restrict access to model endpoints and secure the data that clients submit. For this purpose, you would need to specify eithersslSecretconfig setting or combination ofsslKeyPemFileandsslCertPemFileconfig-protected settings.
sslSecret
sslKeyPemFile
sslCertPemFile
By default, Azure Machine Learning extension deployment expects config settings forHTTPSsupport. For development or testing purposes,HTTPsupport is conveniently provided through config settingallowInsecureConnections=True.
allowInsecureConnections=True
Azure Machine Learning extension deployment - CLI examples and Azure portal
Azure CLI
Azure portal
To deploy Azure Machine Learning extension with CLI, useaz k8s-extension createcommand passing in values for the mandatory parameters.
az k8s-extension create
We list four typical extension deployment scenarios for reference. To deploy extension for your production usage, carefully read the complete list ofconfiguration settings.
Use AKS cluster in Azure for a quick proof of concept to run all kinds of ML workload, i.e., to run training jobs or to deploy models as online/batch endpointsFor Azure Machine Learning extension deployment on AKS cluster, make sure to specifymanagedClustersvalue for--cluster-typeparameter. Run the following Azure CLI command to deploy Azure Machine Learning extension:az k8s-extension create --name <extension-name> --extension-type Microsoft.AzureML.Kubernetes --config enableTraining=True enableInference=True inferenceRouterServiceType=LoadBalancer allowInsecureConnections=True InferenceRouterHA=False --cluster-type managedClusters --cluster-name <your-AKS-cluster-name> --resource-group <your-RG-name> --scope cluster
Use AKS cluster in Azure for a quick proof of concept to run all kinds of ML workload, i.e., to run training jobs or to deploy models as online/batch endpoints
For Azure Machine Learning extension deployment on AKS cluster, make sure to specifymanagedClustersvalue for--cluster-typeparameter. Run the following Azure CLI command to deploy Azure Machine Learning extension:
managedClusters
--cluster-type
az k8s-extension create --name <extension-name> --extension-type Microsoft.AzureML.Kubernetes --config enableTraining=True enableInference=True inferenceRouterServiceType=LoadBalancer allowInsecureConnections=True InferenceRouterHA=False --cluster-type managedClusters --cluster-name <your-AKS-cluster-name> --resource-group <your-RG-name> --scope cluster
az k8s-extension create --name <extension-name> --extension-type Microsoft.AzureML.Kubernetes --config enableTraining=True enableInference=True inferenceRouterServiceType=LoadBalancer allowInsecureConnections=True InferenceRouterHA=False --cluster-type managedClusters --cluster-name <your-AKS-cluster-name> --resource-group <your-RG-name> --scope cluster
Use Arc Kubernetes cluster outside of Azure for a quick proof of concept, to run training jobs onlyFor Azure Machine Learning extension deployment onArc Kubernetescluster, you would need to specifyconnectedClustersvalue for--cluster-typeparameter. Run the following Azure CLI command to deploy Azure Machine Learning extension:az k8s-extension create --name <extension-name> --extension-type Microsoft.AzureML.Kubernetes --config enableTraining=True --cluster-type connectedClusters --cluster-name <your-connected-cluster-name> --resource-group <your-RG-name> --scope cluster
Use Arc Kubernetes cluster outside of Azure for a quick proof of concept, to run training jobs only
For Azure Machine Learning extension deployment onArc Kubernetescluster, you would need to specifyconnectedClustersvalue for--cluster-typeparameter. Run the following Azure CLI command to deploy Azure Machine Learning extension:
connectedClusters
--cluster-type
az k8s-extension create --name <extension-name> --extension-type Microsoft.AzureML.Kubernetes --config enableTraining=True --cluster-type connectedClusters --cluster-name <your-connected-cluster-name> --resource-group <your-RG-name> --scope cluster
az k8s-extension create --name <extension-name> --extension-type Microsoft.AzureML.Kubernetes --config enableTraining=True --cluster-type connectedClusters --cluster-name <your-connected-cluster-name> --resource-group <your-RG-name> --scope cluster
Enable an AKS cluster in Azure for production training and inference workloadFor Azure Machine Learning extension deployment on AKS, make sure to specifymanagedClustersvalue for--cluster-typeparameter. Assuming your cluster has more than three nodes, and you use an Azure public load balancer and HTTPS for inference workload support. Run the following Azure CLI command to deploy Azure Machine Learning extension:az k8s-extension create --name <extension-name> --extension-type Microsoft.AzureML.Kubernetes --config enableTraining=True enableInference=True inferenceRouterServiceType=LoadBalancer sslCname=<ssl cname> --config-protected sslCertPemFile=<file-path-to-cert-PEM> sslKeyPemFile=<file-path-to-cert-KEY> --cluster-type managedClusters --cluster-name <your-AKS-cluster-name> --resource-group <your-RG-name> --scope cluster
Enable an AKS cluster in Azure for production training and inference workloadFor Azure Machine Learning extension deployment on AKS, make sure to specifymanagedClustersvalue for--cluster-typeparameter. Assuming your cluster has more than three nodes, and you use an Azure public load balancer and HTTPS for inference workload support. Run the following Azure CLI command to deploy Azure Machine Learning extension:
managedClusters
--cluster-type
az k8s-extension create --name <extension-name> --extension-type Microsoft.AzureML.Kubernetes --config enableTraining=True enableInference=True inferenceRouterServiceType=LoadBalancer sslCname=<ssl cname> --config-protected sslCertPemFile=<file-path-to-cert-PEM> sslKeyPemFile=<file-path-to-cert-KEY> --cluster-type managedClusters --cluster-name <your-AKS-cluster-name> --resource-group <your-RG-name> --scope cluster
az k8s-extension create --name <extension-name> --extension-type Microsoft.AzureML.Kubernetes --config enableTraining=True enableInference=True inferenceRouterServiceType=LoadBalancer sslCname=<ssl cname> --config-protected sslCertPemFile=<file-path-to-cert-PEM> sslKeyPemFile=<file-path-to-cert-KEY> --cluster-type managedClusters --cluster-name <your-AKS-cluster-name> --resource-group <your-RG-name> --scope cluster
Enable anArc Kubernetescluster anywhere for production training and inference workload using NVIDIA GPUsFor Azure Machine Learning extension deployment onArc Kubernetescluster, make sure to specifyconnectedClustersvalue for--cluster-typeparameter. Assuming your cluster has more than three nodes, you use a NodePort service type and HTTPS for inference workload support, run following Azure CLI command to deploy Azure Machine Learning extension:az k8s-extension create --name <extension-name> --extension-type Microsoft.AzureML.Kubernetes --config enableTraining=True enableInference=True inferenceRouterServiceType=NodePort sslCname=<ssl cname> installNvidiaDevicePlugin=True installDcgmExporter=True --config-protected sslCertPemFile=<file-path-to-cert-PEM> sslKeyPemFile=<file-path-to-cert-KEY> --cluster-type connectedClusters --cluster-name <your-connected-cluster-name> --resource-group <your-RG-name> --scope cluster
Enable anArc Kubernetescluster anywhere for production training and inference workload using NVIDIA GPUs
For Azure Machine Learning extension deployment onArc Kubernetescluster, make sure to specifyconnectedClustersvalue for--cluster-typeparameter. Assuming your cluster has more than three nodes, you use a NodePort service type and HTTPS for inference workload support, run following Azure CLI command to deploy Azure Machine Learning extension:
connectedClusters
--cluster-type
az k8s-extension create --name <extension-name> --extension-type Microsoft.AzureML.Kubernetes --config enableTraining=True enableInference=True inferenceRouterServiceType=NodePort sslCname=<ssl cname> installNvidiaDevicePlugin=True installDcgmExporter=True --config-protected sslCertPemFile=<file-path-to-cert-PEM> sslKeyPemFile=<file-path-to-cert-KEY> --cluster-type connectedClusters --cluster-name <your-connected-cluster-name> --resource-group <your-RG-name> --scope cluster
az k8s-extension create --name <extension-name> --extension-type Microsoft.AzureML.Kubernetes --config enableTraining=True enableInference=True inferenceRouterServiceType=NodePort sslCname=<ssl cname> installNvidiaDevicePlugin=True installDcgmExporter=True --config-protected sslCertPemFile=<file-path-to-cert-PEM> sslKeyPemFile=<file-path-to-cert-KEY> --cluster-type connectedClusters --cluster-name <your-connected-cluster-name> --resource-group <your-RG-name> --scope cluster
The UI experience to deploy extension is only available forArc Kubernetes. If you have an AKS cluster without Azure Arc connection, you need to use CLI to deploy Azure Machine Learning extension.
In theAzure portal, navigate toKubernetes - Azure Arcand select your cluster.
In theAzure portal, navigate toKubernetes - Azure Arcand select your cluster.
SelectExtensions(underSettings), and then select+ Add.
SelectExtensions(underSettings), and then select+ Add.

From the list of available extensions, selectAzure Machine Learning extensionto deploy the latest version of the extension.
From the list of available extensions, selectAzure Machine Learning extensionto deploy the latest version of the extension.

Follow the prompts to deploy the extension. You can customize the installation by configuring the installation in the tab ofBasics,ConfigurationsandAdvanced.  For a detailed list of Azure Machine Learning extension configuration settings, seeAzure Machine Learning extension configuration settings.
Follow the prompts to deploy the extension. You can customize the installation by configuring the installation in the tab ofBasics,ConfigurationsandAdvanced.  For a detailed list of Azure Machine Learning extension configuration settings, seeAzure Machine Learning extension configuration settings.

On theReview + createtab, selectCreate.
On theReview + createtab, selectCreate.

After the deployment completes, you're able to see the Azure Machine Learning extension inExtensionpage.  If the extension installation succeeds, you can seeInstalledfor theInstall status.
After the deployment completes, you're able to see the Azure Machine Learning extension inExtensionpage.  If the extension installation succeeds, you can seeInstalledfor theInstall status.

Verify Azure Machine Learning extension deployment
Run the following CLI command to check Azure Machine Learning extension details:az k8s-extension show --name <extension-name> --cluster-type connectedClusters --cluster-name <your-connected-cluster-name> --resource-group <resource-group>
Run the following CLI command to check Azure Machine Learning extension details:
az k8s-extension show --name <extension-name> --cluster-type connectedClusters --cluster-name <your-connected-cluster-name> --resource-group <resource-group>
az k8s-extension show --name <extension-name> --cluster-type connectedClusters --cluster-name <your-connected-cluster-name> --resource-group <resource-group>
In the response, look for "name" and "provisioningState": "Succeeded". Note it might show "provisioningState": "Pending" for the first few minutes.
In the response, look for "name" and "provisioningState": "Succeeded". Note it might show "provisioningState": "Pending" for the first few minutes.
If the provisioningState shows Succeeded, run the following command on your machine with the kubeconfig file pointed to your cluster to check that all pods under "azureml" namespace are in 'Running' state:kubectl get pods -n azureml
If the provisioningState shows Succeeded, run the following command on your machine with the kubeconfig file pointed to your cluster to check that all pods under "azureml" namespace are in 'Running' state:
kubectl get pods -n azureml
kubectl get pods -n azureml
Review Azure Machine Learning extension component
Upon Azure Machine Learning extension deployment completes, you can usekubectl get deployments -n azuremlto see list of resources created in the cluster. It usually consists a subset of following resources per configuration settings specified.
kubectl get deployments -n azureml
Important
Azure Relay resource  is under the same resource group as the Arc cluster resource. It is used to communicate with the Kubernetes cluster and modifying them will break attached compute targets.
By default, the kubernetes deployment resources are randomly deployed to 1 or more nodes of the cluster, and daemonset resources are deployed to ALL nodes. If you want to restrict the extension deployment to specific nodes, usenodeSelectorconfiguration setting described inconfiguration settings table.
nodeSelector
Note
{EXTENSION-NAME}:is the extension name specified withaz k8s-extension create --nameCLI command.
az k8s-extension create --name
Manage Azure Machine Learning extension
Update, list, show and delete an Azure Machine Learning extension.
For AKS cluster without Azure Arc connected, refer toDeploy and manage cluster extensions.
For Azure Arc-enabled Kubernetes, refer toDeploy and manage Azure Arc-enabled Kubernetes cluster extensions.
Next steps
Step 2: Attach Kubernetes cluster to workspace
Create and manage instance types
Azure Machine Learning inference router and connectivity requirements
Secure AKS inferencing environment
Feedback
Was this page helpful?
Additional resources