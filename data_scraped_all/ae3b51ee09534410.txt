Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Resources in YAML pipelines
Article
2025-02-26
48 contributors
In this article
Azure DevOps Services | Azure DevOps Server 2022 - Azure DevOps Server 2019
This article discusses resources for YAML pipelines. A resource is anything used by a pipeline that exists outside the pipeline. After you define a resource, you can consume it anywhere in your pipeline.
Resources provide full traceability for the services your pipeline uses, including the version, artifacts, associated commits, and work items. You can fully automate your DevOps workflows by subscribing to trigger events on your resources.
Resources schema
Resources in YAML represent sources of pipelines, builds, repositories, containers, packages, and webhooks. For complete schema information, see theresources definitionin theYAML schema reference for Azure Pipelines.
When a resource triggers a pipeline, the following variables get set:
resources.triggeringAlias
resources.triggeringCategory
resources.triggeringAlias
resources.triggeringCategory
The variableBuild.Reasonmust beResourceTriggerfor these values to get set. The values are empty if a resource didn't trigger the pipeline run.
Build.Reason
ResourceTrigger

Pipelines resource definition
If you have a pipeline that produces artifacts, you can consume the artifacts by defining apipelinesresource. Only Azure Pipelines can use thepipelinesresource. You can set triggers for your continuous deployment (CD) workflows on a pipeline resource.
pipelines
pipelines
In your resource definition,pipelineis a unique value that you can use to reference the pipeline resource later in your pipeline. Thesourceis the name of the pipeline that produced the pipeline artifact. For complete schema information, see theresources.pipelines.pipeline definition.
pipeline
source
You use the label defined bypipelineto reference the pipeline resource from other parts of your pipeline, such as when using pipeline resource variables or downloading artifacts. For an alternative way to download pipeline artifacts, seeDownload artifacts.
pipeline
Important
When you define a pipeline resource trigger:
If thepipelineresource is from the same repository as the current pipeline, orself, triggering follows the same branch and commit on which the event is raised.
pipeline
self
If the pipeline resource is from a different repository, the current pipeline triggers on the default branch of thepipelineresource repository.
pipeline
Example pipeline resource definitions
The following example consumes artifacts from a pipeline within the same project.
resources:
  pipelines:
  - pipeline: SmartHotel-resource # identifier to use in pipeline resource variables
    source: SmartHotel-CI # name of the pipeline that produces the artifacts
resources:
  pipelines:
  - pipeline: SmartHotel-resource # identifier to use in pipeline resource variables
    source: SmartHotel-CI # name of the pipeline that produces the artifacts
To consume a pipeline from another project, you include the project name and source name. The following example usesbranchto resolve the default version when the pipeline is triggered manually or scheduled. The branch input can't have wildcards.
branch
resources:
  pipelines:
  - pipeline: SmartHotel
    project: DevOpsProject
    source: SmartHotel-CI
    branch: releases/M142
resources:
  pipelines:
  - pipeline: SmartHotel
    project: DevOpsProject
    source: SmartHotel-CI
    branch: releases/M142
The following example shows a pipeline resource with a simple trigger.
resources:
  pipelines:
  - pipeline: SmartHotel
    project: DevOpsProject
    source: SmartHotel-CI
    trigger: true
resources:
  pipelines:
  - pipeline: SmartHotel
    project: DevOpsProject
    source: SmartHotel-CI
    trigger: true
The following example shows a pipeline resourcetriggerwith branch conditions.
trigger
resources:
  pipelines:
  - pipeline: SmartHotel
    project: DevOpsProject
    source: SmartHotel-CI
    trigger:
      branches:
      - releases/*
      - resources.triggeringAlias
resources:
  pipelines:
  - pipeline: SmartHotel
    project: DevOpsProject
    source: SmartHotel-CI
    trigger:
      branches:
      - releases/*
      - resources.triggeringAlias
The following example usesstagesfilters for evaluating trigger conditions for CD pipelines. Stages use theANDoperator. On successful completion of all the provided stages, the CD pipeline triggers.
stages
AND
resources:
  pipelines:
  - pipeline: MyCIAlias  
    project: Fabrikam  
    source: Farbrikam-CI  
    trigger:    
      stages:
      - PreProduction
      - Production
resources:
  pipelines:
  - pipeline: MyCIAlias  
    project: Fabrikam  
    source: Farbrikam-CI  
    trigger:    
      stages:
      - PreProduction
      - Production
The following example usestagsfilters for default version evaluation and for triggers. Tags use theANDoperator.
tags
AND
Thetagsare set on the continuous integration (CI) or CD pipeline. These tags differ from the tags set on branches in the Git repository.
tags
resources:
  pipelines:
  - pipeline: MyCIAlias
    project: Fabrikam
    source: Farbrikam-CI
    tags: 
    - Production 
    trigger:
      tags:
      - Production
      - Signed
resources:
  pipelines:
  - pipeline: MyCIAlias
    project: Fabrikam
    source: Farbrikam-CI
    tags: 
    - Production 
    trigger:
      tags:
      - Production
      - Signed

Pipelines artifact version evaluation
The resource pipeline's artifact version depends on how the pipeline triggers.
If the pipeline run is manually triggered or scheduled, the values of theversion,branch, andtagsproperties define the artifact version. Thebranchinput can't have wildcards. Thetagsproperties use theANDoperator.
version
branch
tags
branch
tags
AND
version
branch
tags
branch
tags
version
branch
The followingpipelineresource definition uses thebranchandtagsproperties to evaluate the default version when the pipeline is triggered manually or scheduled. When you manually trigger the pipeline to run, theMyCIAliaspipeline artifacts version is the latest build done on themainbranch that has theProductionandPrepProductiontags.
pipeline
branch
tags
MyCIAlias
main
Production
PrepProduction
resources:
  pipelines:
  - pipeline: MyCIAlias
    project: Fabrikam
    source: Farbrikam-CI
    branch: main
    tags:
    - Production
    - PreProduction
resources:
  pipelines:
  - pipeline: MyCIAlias
    project: Fabrikam
    source: Farbrikam-CI
    branch: main
    tags:
    - Production
    - PreProduction
When a pipeline triggers because one of its resource pipelines completes, the artifacts version is the version of the triggering pipeline. The values of theversion,branch, andtagsproperties are ignored.
version
branch
tags
branches
include
tags
stages
stages
branches
tags
stages
trigger: true
The following pipeline runs whenever theSmartHotel-CIresource pipeline:
SmartHotel-CI
Runs on one of thereleasesbranches or on themainbranch
releases
main
Is tagged with bothVerifiedandSigned
Verified
Signed
Completes both theProductionandPreProductionstages
Production
PreProduction
resources:
  pipelines:
  - pipeline: SmartHotel
    project: DevOpsProject
    source: SmartHotel-CI
    trigger:
      branches:
        include:
        - releases/*
        - main
        exclude:
        - topic/*
      tags: 
      - Verified
      - Signed
      stages:
      - Production
      - PreProduction
resources:
  pipelines:
  - pipeline: SmartHotel
    project: DevOpsProject
    source: SmartHotel-CI
    trigger:
      branches:
        include:
        - releases/*
        - main
        exclude:
        - topic/*
      tags: 
      - Verified
      - Signed
      stages:
      - Production
      - PreProduction
Pipeline artifact download
Thedownloadstep downloads artifacts associated with the current run or with another pipeline resource.
download
All artifacts from the current pipeline and all itspipelineresources are automatically downloaded and made available at the beginning of each deployment job. You can override this behavior by settingdownloadtonone, or by specifying another pipeline resource identifier.
pipeline
download
none
Regular job artifacts aren't automatically downloaded. Usedownloadexplicitly when needed.
download
Artifacts from thepipelineresource are downloaded to the$(PIPELINE.WORKSPACE)/<pipeline-identifier>/<artifact-identifier>folder. For more information, seePublish and download pipeline artifacts.
pipeline
The optionalartifactproperty specifies artifact names. If not specified, all available artifacts are downloaded. The optionalpatternsproperty defines patterns that represent files to include. For full schema information, see thesteps.download definition.
artifact
patterns
- job: deploy_windows_x86_agent
  steps:
  - download: SmartHotel
    artifact: WebTier1
    patterns: '**/*.zip'
- job: deploy_windows_x86_agent
  steps:
  - download: SmartHotel
    artifact: WebTier1
    patterns: '**/*.zip'
Pipeline resource variables
In each run, the metadata for a pipeline resource is available to all jobs aspredefined variables. These variables are available to your pipeline only at runtime, and therefore can't be used in template expressions, which are evaluated at pipeline compile time.
For more information, seePipeline resource metadata as predefined variables. To learn more about variable syntax, seeDefine variables.
The following example returns the predefined variable values for themyresourcevarspipeline resource.
myresourcevars
resources:
  pipelines:
  - pipeline: myresourcevars
    source: mypipeline
    trigger: true 

steps:
- script: |
    echo $(resources.pipeline.myresourcevars.pipelineID)
    echo $(resources.pipeline.myresourcevars.runName)
    echo $(resources.pipeline.myresourcevars.runID)
    echo $(resources.pipeline.myresourcevars.runURI)
    echo $(resources.pipeline.myresourcevars.sourceBranch)
    echo $(resources.pipeline.myresourcevars.sourceCommit)
    echo $(resources.pipeline.myresourcevars.sourceProvider)
    echo $(resources.pipeline.myresourcevars.requestedFor)
    echo $(resources.pipeline.myresourcevars.requestedForID)
resources:
  pipelines:
  - pipeline: myresourcevars
    source: mypipeline
    trigger: true 

steps:
- script: |
    echo $(resources.pipeline.myresourcevars.pipelineID)
    echo $(resources.pipeline.myresourcevars.runName)
    echo $(resources.pipeline.myresourcevars.runID)
    echo $(resources.pipeline.myresourcevars.runURI)
    echo $(resources.pipeline.myresourcevars.sourceBranch)
    echo $(resources.pipeline.myresourcevars.sourceCommit)
    echo $(resources.pipeline.myresourcevars.sourceProvider)
    echo $(resources.pipeline.myresourcevars.requestedFor)
    echo $(resources.pipeline.myresourcevars.requestedForID)

Builds resource definition
If you have an external CI build system that produces artifacts, you can consume artifacts withbuildsresources. Abuildresource can be from any external CI system like Jenkins, TeamCity, or CircleCI.
builds
build
Thebuildscategory is extensible. You can write an extension to consume artifacts from your build service, and introduce a new type of service as part ofbuilds.
builds
builds
In thebuilddefinition,versiondefaults to the latest successful build. Thetriggerisn't enabled by default and must be explicitly set. For complete schema information, see theresources.builds.build definition.
build
version
trigger
In the following example, Jenkins is the resourcetype.
type
resources:
  builds:
  - build: Spaceworkz
    type: Jenkins
    connection: MyJenkinsServer 
    source: SpaceworkzProj   # name of the Jenkins source project
    trigger: true
resources:
  builds:
  - build: Spaceworkz
    type: Jenkins
    connection: MyJenkinsServer 
    source: SpaceworkzProj   # name of the Jenkins source project
    trigger: true
Important
Triggers are supported for hosted Jenkins only where Azure DevOps has line of sight with the Jenkins server.
The downloadBuild task
Thebuildresource artifacts aren't automatically downloaded in yourjobs/deploy-jobs. To consume artifacts from thebuildresource as part of your jobs, you need to explicitly add thedownloadBuildtask. You can customize the download behavior for each deployment or job.
build
build
downloadBuild
This task automatically resolves to the corresponding download task for the type ofbuildresource the runtime defines. Artifacts from thebuildresource are downloaded to the$(PIPELINE.WORKSPACE)/<build-identifier>/folder.
build
build
In thedownloadBuilddefinition, you specify the resource to download artifacts from. The optionalartifactproperty specifies artifacts to download. If not specified, all artifacts associated with the resource are downloaded.
downloadBuild
artifact
The optionalpatternsproperty defines a minimatch path or list ofminimatch pathsto download. If blank, the entire artifact is downloaded. For example, the following snippet downloads only the*.zipfiles.
patterns
- job: deploy_windows_x86_agent
  steps:
  - downloadBuild: Spaceworkz
    patterns: '**/*.zip'
- job: deploy_windows_x86_agent
  steps:
  - downloadBuild: Spaceworkz
    patterns: '**/*.zip'
For complete schema information, see thesteps.downloadBuild definition.

Repository resource definition
Therepositorykeyword lets you specify an external repository. You can use this resource if your pipeline hastemplates in another repositoryor you want to usemulti-repo checkoutwith a repository that requires a service connection. You must let the system know about these repositories.
repository
For example:
resources:
  repositories:
  - repository: common
    type: github
    name: Contoso/CommonTools
    endpoint: MyContosoServiceConnection
resources:
  repositories:
  - repository: common
    type: github
    name: Contoso/CommonTools
    endpoint: MyContosoServiceConnection
For complete schema information, see theresources.repositories.repository definition.
Repository resource types
Azure Pipelines supports the following values for the repository type:git,github,githubenterprise, andbitbucket.
git
github
githubenterprise
bitbucket
Thegittype refers to Azure Repos Git repos.
git
GitHub Enterprise repos require aGitHub Enterprise service connectionfor authorization.
Bitbucket Cloud repos require aBitbucket Cloud service connectionfor authorization.
type: git
name: otherRepo
name: otherProject/otherRepo
type: github
name: Microsoft/vscode
type: githubenterprise
name: Microsoft/vscode
type: bitbucket
name: MyBitbucket/vscode
Repository resource variables
In each run, the following metadata for a repository resource is available to all jobs in the form of runtime variables. The<Alias>is the identifier that you give your repository resource.
<Alias>
resources.repositories.<Alias>.name
resources.repositories.<Alias>.ref
resources.repositories.<Alias>.type
resources.repositories.<Alias>.id
resources.repositories.<Alias>.url
resources.repositories.<Alias>.name
resources.repositories.<Alias>.ref
resources.repositories.<Alias>.type
resources.repositories.<Alias>.id
resources.repositories.<Alias>.url
The following example has a repository resource with an alias ofcommon, so the repository resource variables are accessed usingresources.repositories.common.*.
common
resources.repositories.common.*
resources:
  repositories:
    - repository: common
      type: git
      ref: main
      name: Repo

variables:
  ref: $[ resources.repositories.common.ref ]
  name: $[ resources.repositories.common.name ]
  id: $[ resources.repositories.common.id ]
  type: $[ resources.repositories.common.type ]
  url: $[ resources.repositories.common.url ]

steps:
- bash: |
    echo "name = $(name)"
    echo "ref = $(ref)"
    echo "id = $(id)"
    echo "type = $(type)"
    echo "url = $(url)"
resources:
  repositories:
    - repository: common
      type: git
      ref: main
      name: Repo

variables:
  ref: $[ resources.repositories.common.ref ]
  name: $[ resources.repositories.common.name ]
  id: $[ resources.repositories.common.id ]
  type: $[ resources.repositories.common.type ]
  url: $[ resources.repositories.common.url ]

steps:
- bash: |
    echo "name = $(name)"
    echo "ref = $(ref)"
    echo "id = $(id)"
    echo "type = $(type)"
    echo "url = $(url)"
In each run, the following metadata for a repository resource is available to all jobs in the form of runtime variables. The<Alias>is the identifier that you give your repository resource.
<Alias>
resources.repositories.<Alias>.name
resources.repositories.<Alias>.ref
resources.repositories.<Alias>.type
resources.repositories.<Alias>.id
resources.repositories.<Alias>.url
resources.repositories.<Alias>.version
resources.repositories.<Alias>.name
resources.repositories.<Alias>.ref
resources.repositories.<Alias>.type
resources.repositories.<Alias>.id
resources.repositories.<Alias>.url
resources.repositories.<Alias>.version
The following example has a repository resource with an alias ofcommon, so the repository resource variables are accessed usingresources.repositories.common.*.
common
resources.repositories.common.*
resources:
  repositories:
    - repository: common
      type: git
      ref: main
      name: Repo

variables:
  ref: $[ resources.repositories.common.ref ]
  name: $[ resources.repositories.common.name ]
  id: $[ resources.repositories.common.id ]
  type: $[ resources.repositories.common.type ]
  url: $[ resources.repositories.common.url ]
  version: $[ resources.repositories.common.version ]

steps:
- bash: |
    echo "name = $(name)"
    echo "ref = $(ref)"
    echo "id = $(id)"
    echo "type = $(type)"
    echo "url = $(url)"
    echo "version = $(version)"
resources:
  repositories:
    - repository: common
      type: git
      ref: main
      name: Repo

variables:
  ref: $[ resources.repositories.common.ref ]
  name: $[ resources.repositories.common.name ]
  id: $[ resources.repositories.common.id ]
  type: $[ resources.repositories.common.type ]
  url: $[ resources.repositories.common.url ]
  version: $[ resources.repositories.common.version ]

steps:
- bash: |
    echo "name = $(name)"
    echo "ref = $(ref)"
    echo "id = $(id)"
    echo "type = $(type)"
    echo "url = $(url)"
    echo "version = $(version)"
Checkout keyword for repositories
Repos from therepositoryresource aren't automatically synced in your jobs. Use thecheckoutkeyword to fetch a repository defined as part of therepositoryresource. For complete schema information, see thesteps.checkout definition.
repository
checkout
repository
For more information, seeCheck out multiple repositories in your pipeline.

Containers resource definition
If you need to consume container images as part of your CI/CD pipelines, you can usecontainersresources. Acontainerresource can be a public or private Docker registry or an Azure Container Registry instance.
containers
container
You can consume a generic container resource image as part of your job, or use the resource forcontainer jobs. If your pipeline requires the support of one or more services, you need to create and connect toservice containers. You can use volumes to share data between services.
If you need to consume images from a Docker registry as part of your pipeline, you can define a generic container resource. Notypekeyword is required. For example:
type
resources:         
  containers:
  - container: smartHotel 
    endpoint: myDockerRegistry
    image: smartHotelApp
resources:         
  containers:
  - container: smartHotel 
    endpoint: myDockerRegistry
    image: smartHotelApp
For complete schema information, see theresources.containers.container definition.
Note
Theenabled: 'true'syntax to enable container triggers for all image tags is different from the syntax for other resource triggers. Be sure to use the correct syntax for specific resources.
enabled: 'true'
Azure Container Registry resource type
To consume your Azure Container Registry images, you can use the first-class container resource typeacr. You can use this resource type as part of your jobs and to enable automatic pipeline triggers.
acr
You needContributororOwnerpermissions for Azure Container Registry to use automatic pipeline triggers. For more information, seeAzure Container Registry roles and permissions.
To use theacrresource type, you must specify theazureSubscription,resourceGroup, andrepositoryvalues for your Azure container registry. For example:
acr
azureSubscription
resourceGroup
repository
resources:         
  containers:
  - container: petStore      
    type: acr  
    azureSubscription: ContosoConnection
    resourceGroup: ContosoGroup
    registry: petStoreRegistry
    repository: myPets
    trigger: 
      tags:
        include: 
        - production*
resources:         
  containers:
  - container: petStore      
    type: acr  
    azureSubscription: ContosoConnection
    resourceGroup: ContosoGroup
    registry: petStoreRegistry
    repository: myPets
    trigger: 
      tags:
        include: 
        - production*
Note
Trigger evaluation only occurs on the default branch. Make sure to set the correct default branch or merge the YAML file into the current default branch. For more information on how to change the pipeline default branch, visitThe pipeline default branch.
Container resource variables
Once you define a container as a resource, container image metadata passes to the pipeline as variables. Information like image, registry, and connection details are accessible across all the jobs used in your container deployment tasks.
Container resource variables work with Docker and Azure Container Registry. You can't use container resource variables for local image containers. Thelocationvariable applies only to theacrtype of container resources.
location
acr
The following example has anAzure Resource Manager service connectionnamedarm-connection. For more information, seeAzure container registries, repositories, and images.
arm-connection
resources:
  containers:
  - container: mycontainer
    type: ACR
    azureSubscription: arm-connection
    resourceGroup: rg-storage-eastus
    registry: mycontainerregistry
    repository: hello-world
    trigger:
      tags:
      - latest

steps:
- script: echo |
    echo $(resources.container.mycontainer.type)
    echo $(resources.container.mycontainer.registry)
    echo $(resources.container.mycontainer.repository)
    echo $(resources.container.mycontainer.tag)
    echo $(resources.container.mycontainer.digest)
    echo $(resources.container.mycontainer.URI)
    echo $(resources.container.mycontainer.location)
resources:
  containers:
  - container: mycontainer
    type: ACR
    azureSubscription: arm-connection
    resourceGroup: rg-storage-eastus
    registry: mycontainerregistry
    repository: hello-world
    trigger:
      tags:
      - latest

steps:
- script: echo |
    echo $(resources.container.mycontainer.type)
    echo $(resources.container.mycontainer.registry)
    echo $(resources.container.mycontainer.repository)
    echo $(resources.container.mycontainer.tag)
    echo $(resources.container.mycontainer.digest)
    echo $(resources.container.mycontainer.URI)
    echo $(resources.container.mycontainer.location)

Packages resource definition
You can consume NuGet and npm GitHub packages as resources in YAML pipelines. To enable automated pipeline triggers when a new package version gets released, set thetriggerproperty totrue.
trigger
true
When you definepackageresources, specify the package <Repository>/<Name> in thenameproperty, and set the packagetypeasNuGetornpm. To use GitHub packages, use personal access token (PAT)-based authentication and create a GitHub service connection that uses the PAT.
package
name
type
NuGet
npm
For complete schema information, see theresources.packages.package definition.
By default, packages aren't automatically downloaded into jobs. To download, usegetPackage.
The following example has aGitHub service connectionnamedpat-contosoto a GitHub npm package namedcontoso. For more information, seeGitHub packages.
pat-contoso
contoso
resources:
  packages:
    - package: contoso
      type: npm
      connection: pat-contoso
      name: myname/contoso 
      version: 7.130.88 
      trigger: true

pool:
  vmImage: 'ubuntu-latest'

steps:
- getPackage: contoso
resources:
  packages:
    - package: contoso
      type: npm
      connection: pat-contoso
      name: myname/contoso 
      version: 7.130.88 
      trigger: true

pool:
  vmImage: 'ubuntu-latest'

steps:
- getPackage: contoso

Webhooks resource definition
Note
Webhooks were released in Azure DevOps Server 2020.1.
You can consume artifacts and enable automated triggers with pipeline, container, build, and package resources. However, you can't use these resources to automate your deployments based on external events or services.
Thewebhooksresource in YAML pipelines lets you integrate your pipelines with external services like GitHub, GitHub Enterprise, Nexus, and Artifactory to automate workflows. You can subscribe to any external events through webhooks and use the events to trigger your pipelines.
webhooks
Webhooks automate your workflow based on any external webhook event that isn't supported by first-class resources like pipelines, builds, containers, or packages. Also, for on-premises services where Azure DevOps doesn't have visibility into the process, you can configure webhooks on the service and trigger your pipelines automatically.
To subscribe to a webhook event, you define a webhook resource in your pipeline and point it to an incoming webhook service connection. You can also define more filters on the webhook resource, based on the JSON payload data, to customize the triggers for each pipeline.
Whenever the incoming webhook service connection receives a webhook event, a new run triggers for all the pipelines subscribed to the webhook event. You can consume the JSON payload data in your jobs as variables by using the format${{ parameters.<WebhookAlias>.<JSONPath>}}.
${{ parameters.<WebhookAlias>.<JSONPath>}}
For complete schema information, see theresources.webhooks.webhook definition.
The following example defines a webhook resource:
resources:
  webhooks:
    - webhook: WebHook
      connection: IncomingWH

steps:  
- script: echo ${{ parameters.WebHook.resource.message.title }}
resources:
  webhooks:
    - webhook: WebHook
      connection: IncomingWH

steps:  
- script: echo ${{ parameters.WebHook.resource.message.title }}
Webhook triggers
To configure webhook triggers, you first set up a webhook on your external service, providing the following information:
Request Url:https://dev.azure.com/<Azure DevOps organization>/_apis/public/distributedtask/webhooks/<webhook name>?api-version=6.0-preview
https://dev.azure.com/<Azure DevOps organization>/_apis/public/distributedtask/webhooks/<webhook name>?api-version=6.0-preview
Secret(Optional): If you need to secure your JSON payload, provide a secret value.
Next, you create a new incoming webhook service connection. For this service connection type, you define the following information:
WebHook Name: Same as the webhook created in your external service.
Secret(Optional): Used to verify the payload's HMAC-SHA1 hash for verification of the incoming request. If you used a secret when creating your webhook, you must provide the same secret.
Http Header: The HTTP header in the request that contains the payload's HMAC-SHA1 hash value for request verification. For example, the GitHub request header isX-Hub-Signature.
X-Hub-Signature

To trigger your pipeline using a webhook, you make aPOSTrequest tohttps://dev.azure.com/<org_name>/_apis/public/distributedtask/webhooks/<webhook_connection_name>?api-version=6.0-preview. This endpoint is publicly available, and needs no authorization. The request should have a body like the following example:
POST
https://dev.azure.com/<org_name>/_apis/public/distributedtask/webhooks/<webhook_connection_name>?api-version=6.0-preview
{
    "resource": {
        "message": {
            "title": "Hello, world!",
            "subtitle": "I'm using WebHooks!"
        }
    }
}
{
    "resource": {
        "message": {
            "title": "Hello, world!",
            "subtitle": "I'm using WebHooks!"
        }
    }
}
Note
Accessing data from the webhook's request body can lead to incorrect YAML. For example, the pipeline step- script: echo ${{ parameters.WebHook.resource.message }}pulls in the entire JSON message, which generates invalid YAML. Any pipeline triggered via this webhook doesn't run, because the generated YAML became invalid.
- script: echo ${{ parameters.WebHook.resource.message }}
The following snippet shows another example that uses webhook filters.
resources:
  webhooks:
    - webhook: MyWebhookTrigger          
      connection: MyWebhookConnection    
      filters:
        - path: repositoryName      
          value: maven-releases     
        - path: action
          value: CREATED
steps:
- task: PowerShell@2
  inputs:
    targetType: 'inline'
    script: |
      Write-Host ${{ parameters.MyWebhookTrigger.repositoryName}}
      Write-Host ${{ parameters.MyWebhookTrigger.component.group}}
resources:
  webhooks:
    - webhook: MyWebhookTrigger          
      connection: MyWebhookConnection    
      filters:
        - path: repositoryName      
          value: maven-releases     
        - path: action
          value: CREATED
steps:
- task: PowerShell@2
  inputs:
    targetType: 'inline'
    script: |
      Write-Host ${{ parameters.MyWebhookTrigger.repositoryName}}
      Write-Host ${{ parameters.MyWebhookTrigger.component.group}}
Manual version picker for resources
When you manually trigger a CD YAML pipeline, Azure Pipelines automatically evaluates the default versions for the resources defined in the pipeline, based on the inputs provided. However, Azure Pipelines considers only successfully completed CI runs when evaluating the default version for scheduled triggers, or if you don't manually choose a version.
You can use the resource version picker to manually choose a different version when you create a run. The resource version picker is supported for pipeline, build, repository, container, and package resources.
For pipeline resources, you can see all the available runs across all branches, search them based on the pipeline number or branch, and pick a run that's successful, failed, or in progress. This flexibility ensures that you can run your CD pipeline if you're sure a run produced all the artifacts you need. You don't need to wait for a CI run to complete, or rerun it because of an unrelated stage failure.
To use the resource version picker, in theRun pipelinepane, selectResources, then select a resource and pick a specific version from the list of available versions.

For resources where you can't fetch available versions, like GitHub packages, the version picker provides a text field so you can enter the version for the run to pick.

Resource authorization in YAML pipelines
Resources must be authorized before they can be used in pipelines. Resource owners control the users and pipelines that can access their resources. There are several ways to authorize a YAML pipeline to use resources.
Use the resource administration experience to authorizeall pipelinesto access the resource. For example, variable groups and secure files are managed in theLibrarypage underPipelines, and agent pools and service connections are managed inProject settings. This authorization is convenient if you don't need to restrict access to resources, such as for test resources.
Use the resource administration experience to authorizeall pipelinesto access the resource. For example, variable groups and secure files are managed in theLibrarypage underPipelines, and agent pools and service connections are managed inProject settings. This authorization is convenient if you don't need to restrict access to resources, such as for test resources.
When you create a pipeline, all the resources referenced in the YAML file are automatically authorized for use by the pipeline if you have theUserrole for those resources.
When you create a pipeline, all the resources referenced in the YAML file are automatically authorized for use by the pipeline if you have theUserrole for those resources.
If you add a resource to a YAML file and the build fails with an error likeCould not find a <resource> with name <resource-name>. The <resource> does not exist or has not been authorized for use., you see an option to authorize the resources on the failed build.If you're a member of theUserrole for the resource, you can select this option and authorize the resource on the failed build. Once the resource is authorized, you can start a new build.
If you add a resource to a YAML file and the build fails with an error likeCould not find a <resource> with name <resource-name>. The <resource> does not exist or has not been authorized for use., you see an option to authorize the resources on the failed build.
Could not find a <resource> with name <resource-name>. The <resource> does not exist or has not been authorized for use.
If you're a member of theUserrole for the resource, you can select this option and authorize the resource on the failed build. Once the resource is authorized, you can start a new build.
Verify that theagent pool security rolesfor your project are correct.
Verify that theagent pool security rolesfor your project are correct.
Approval checks for resources
You can use approval checks and templates to manually control when a resource runs. With therequired template approval check, you can require that any pipeline using a resource or environment extends from a specific YAML template.
Setting a required template approval ensures that your resource is used only under specific conditions, and enhances security. To learn more about how toenhance pipeline securitywith templates, seeUse templates for security.
Traceability
Azure Pipelines provides full traceability for any resource consumed at a pipeline or deployment job level.
Pipeline traceability
Azure Pipelines shows the following information for every pipeline run:
If a resource triggered the pipeline, the resource that triggered the pipeline.
The resource version and the artifacts consumed.
Commits associated with each resource.
Work items associated with each resource.
Environment traceability
Whenever a pipeline deploys to an environment, you can see a list of resources that are consumed. The view includes resources consumed as part of the deployment jobs and their associated commits and work items.

Associated CD pipelines information in CI pipelines
To provide end-to-end traceability, you can track which CD pipelines consume a specific CI pipeline through thepipelinesresource. If other pipelines consume your CI pipeline, you see anAssociated pipelinestab in theRunview. The view shows all the CD YAML pipeline runs that consumed your CI pipeline and the artifacts from it.
pipelines

Resource trigger issues
Resource triggers can fail to execute because:
The source of the provided service connection is invalid, there are syntax errors in the trigger, or the trigger isn't configured.
Trigger conditions aren't matched.
To see why pipeline triggers failed to execute, select theTrigger issuesmenu item on the pipeline definition page.Trigger issuesis available only for nonrepository resources.

On theTrigger issuespage, the error and warning messages describe why the trigger failed.

FAQ
When should I use pipelines resources, the download shortcut, or the Download Pipeline Artifacts task?
Using apipelinesresource is a way to consume artifacts from a CI pipeline and also configure automated triggers. A resource gives you full visibility into the process by displaying the version consumed, artifacts, commits, and work items. When you define a pipeline resource, the associated artifacts are automatically downloaded in deployment jobs.
pipelines
You can use thedownloadshortcut to download the artifacts in build jobs or to override the download behavior in deployment jobs. For more information, see thesteps.download definition.
download
TheDownload Pipeline Artifacts taskdoesn't provide traceability or triggers, but sometimes it makes sense to use this task directly. For example, you might have a script task stored in a different template that requires artifacts from a build to be downloaded. Or, you might not want to add a pipeline resource to a template. To avoid dependencies, you can use the Download Pipeline Artifacts task to pass all the build information to a task.
How can I trigger a pipeline run when my Docker Hub image gets updated?
The container resource trigger isn't available for Docker Hub for YAML pipelines, so you need to set up aclassic release pipeline.
Create a new Docker Hubservice connection.
Create a classic release pipeline and add a Docker Hub artifact. Set your service connection and select the namespace, repository, version, and source alias.
Select the trigger and toggle the continuous deployment trigger toEnable. Every Docker push that occurs to the selected repository creates a release.
Create a new stage and job. Add two tasks, Docker login and Bash.The Docker task has theloginaction and signs you in to Docker Hub.The Bash task runsdocker pull <hub-user>/<repo-name>[:<tag>].
The Docker task has theloginaction and signs you in to Docker Hub.
login
The Bash task runsdocker pull <hub-user>/<repo-name>[:<tag>].
docker pull <hub-user>/<repo-name>[:<tag>]
How can I validate and troubleshoot my webhook?
Create a service connection.
Create a service connection.
Reference your service connection and name your webhook in thewebhookssection.resources:
  webhooks:
    - webhook: MyWebhookTriggerAlias
      connection: MyServiceConnection
Reference your service connection and name your webhook in thewebhookssection.
webhooks
resources:
  webhooks:
    - webhook: MyWebhookTriggerAlias
      connection: MyServiceConnection
resources:
  webhooks:
    - webhook: MyWebhookTriggerAlias
      connection: MyServiceConnection
Run your pipeline. The webhook is created in Azure as a distributed task for your organization.
Run your pipeline. The webhook is created in Azure as a distributed task for your organization.
Perform aPOSTAPI call with valid JSON in the body tohttps://dev.azure.com/<organization>/_apis/public/distributedtask/webhooks/<webhook-name>?api-version=<apiversion>. If you receive a 200 status code response, your webhook is ready for consumption by your pipeline.
Perform aPOSTAPI call with valid JSON in the body tohttps://dev.azure.com/<organization>/_apis/public/distributedtask/webhooks/<webhook-name>?api-version=<apiversion>. If you receive a 200 status code response, your webhook is ready for consumption by your pipeline.
POST
https://dev.azure.com/<organization>/_apis/public/distributedtask/webhooks/<webhook-name>?api-version=<apiversion>
If you receive a 500 status code response with the errorCannot find webhook for the given webHookId ..., your code might be in a branch that's not your default branch. To address this issue:
Cannot find webhook for the given webHookId ...
SelectEditon your pipeline page.
From theMore actionsmenu, selectTriggers.
Select theYAMLtab and then selectGet sources.
UnderDefault branch for manual and scheduled builds, update your feature branch.
SelectSave & queue.
After this pipeline runs successfully, perform aPOSTAPI call with valid JSON in the body tohttps://dev.azure.com/<organization>/_apis/public/distributedtask/webhooks/<webhook-name>?api-version=<apiversion>. You should now receive a 200 status code response.
POST
https://dev.azure.com/<organization>/_apis/public/distributedtask/webhooks/<webhook-name>?api-version=<apiversion>
Related content
About resources for Azure Pipelines
Define variables
Add and use variable groups
Create and target an environment
Use YAML pipeline editor
YAML schema reference
Feedback
Was this page helpful?
Additional resources