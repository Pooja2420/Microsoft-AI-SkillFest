Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Create an Azure Machine Learning compute cluster
Article
2024-08-28
16 contributors
In this article
APPLIES TO:Azure CLI ml extension v2 (current)Python SDK azure-ai-ml v2 (current)
This article explains how to create and manage acompute clusterin your Azure Machine Learning workspace.
You can use Azure Machine Learning compute cluster to distribute a training or batch inference process across a cluster of CPU or GPU compute nodes in the cloud. For more information on the VM sizes that include GPUs, seeGPU-optimized virtual machine sizes.
Learn how to:
Create a compute cluster.
Lower your compute cluster cost with low priority VMs.
Set up amanaged identityfor the cluster.
Note
Instead of creating a compute cluster, useserverless computeto offload compute lifecycle management to Azure Machine Learning.
Prerequisites
An Azure Machine Learning workspace. For more information, seeManage Azure Machine Learning workspaces.
Select the appropriate tab for the rest of the prerequisites based on your preferred method of creating the compute cluster.
Python SDK
Azure CLI
Studio
If you're not running your code on a compute instance, install theAzure Machine Learning Python SDK. This SDK is already installed for you on a compute instance.
If you're not running your code on a compute instance, install theAzure Machine Learning Python SDK. This SDK is already installed for you on a compute instance.
Attach to the workspace in your Python script:Run this code to connect to your Azure Machine Learning workspace.Replace your Subscription ID, Resource Group name, and Workspace name in the following code. To find these values:Sign in toAzure Machine Learning studio.Open the workspace you wish to use.Select your workspace name in the upper right Azure Machine Learning studio toolbar.Copy the value for workspace, resource group, and subscription ID into the code.APPLIES TO:Python SDK azure-ai-mlv2 (current)# Enter details of your AML workspace
subscription_id = "<SUBSCRIPTION_ID>"
resource_group = "<RESOURCE_GROUP>"
workspace = "<AML_WORKSPACE_NAME>"# get a handle to the workspace
from azure.ai.ml import MLClient
from azure.identity import DefaultAzureCredential

ml_client = MLClient(
    DefaultAzureCredential(), subscription_id, resource_group, workspace
)ml_clientis a handler to the workspace that you use to manage other resources and jobs.
Attach to the workspace in your Python script:
Run this code to connect to your Azure Machine Learning workspace.
Replace your Subscription ID, Resource Group name, and Workspace name in the following code. To find these values:
Sign in toAzure Machine Learning studio.
Open the workspace you wish to use.
Select your workspace name in the upper right Azure Machine Learning studio toolbar.
Copy the value for workspace, resource group, and subscription ID into the code.
APPLIES TO:Python SDK azure-ai-mlv2 (current)
# Enter details of your AML workspace
subscription_id = "<SUBSCRIPTION_ID>"
resource_group = "<RESOURCE_GROUP>"
workspace = "<AML_WORKSPACE_NAME>"
# Enter details of your AML workspace
subscription_id = "<SUBSCRIPTION_ID>"
resource_group = "<RESOURCE_GROUP>"
workspace = "<AML_WORKSPACE_NAME>"
# get a handle to the workspace
from azure.ai.ml import MLClient
from azure.identity import DefaultAzureCredential

ml_client = MLClient(
    DefaultAzureCredential(), subscription_id, resource_group, workspace
)
# get a handle to the workspace
from azure.ai.ml import MLClient
from azure.identity import DefaultAzureCredential

ml_client = MLClient(
    DefaultAzureCredential(), subscription_id, resource_group, workspace
)
ml_clientis a handler to the workspace that you use to manage other resources and jobs.
ml_client
If you're not running these commands on a compute instance, install theAzure CLI extension for Machine Learning service (v2). This extension is already installed for you on a compute instance.
If you're not running these commands on a compute instance, install theAzure CLI extension for Machine Learning service (v2). This extension is already installed for you on a compute instance.
Authenticate and set the default workspace and resource group. Leave the terminal open to run the rest of the commands in this article.If you're on a compute instance:az login --identity
# next line needed only if you have multiple subscriptions:
az account set --subscription "<SUBSCRIPTION-NAME>" # replace with your subscription name
az configure --defaults group=$CI_RESOURCE_GROUP workspace=$CI_WORKSPACEIf you're running the commands locally, omit--identityand follow instructions for authentication. Also replace$CI_RESOURCE_GROUPand$CI_WORKSPACEwith your values.
Authenticate and set the default workspace and resource group. Leave the terminal open to run the rest of the commands in this article.
If you're on a compute instance:az login --identity
# next line needed only if you have multiple subscriptions:
az account set --subscription "<SUBSCRIPTION-NAME>" # replace with your subscription name
az configure --defaults group=$CI_RESOURCE_GROUP workspace=$CI_WORKSPACE
If you're on a compute instance:
az login --identity
# next line needed only if you have multiple subscriptions:
az account set --subscription "<SUBSCRIPTION-NAME>" # replace with your subscription name
az configure --defaults group=$CI_RESOURCE_GROUP workspace=$CI_WORKSPACE
az login --identity
# next line needed only if you have multiple subscriptions:
az account set --subscription "<SUBSCRIPTION-NAME>" # replace with your subscription name
az configure --defaults group=$CI_RESOURCE_GROUP workspace=$CI_WORKSPACE
If you're running the commands locally, omit--identityand follow instructions for authentication. Also replace$CI_RESOURCE_GROUPand$CI_WORKSPACEwith your values.
If you're running the commands locally, omit--identityand follow instructions for authentication. Also replace$CI_RESOURCE_GROUPand$CI_WORKSPACEwith your values.
--identity
$CI_RESOURCE_GROUP
$CI_WORKSPACE
Start atAzure Machine Learning studio.
Note
When configuring a Virtual Network (VNet) located in a different resource group from your Azure Machine Learning workspace, be aware that resources such as Network Security Groups (NSGs), Public IPs, and Load Balancers will be created in the same resource group as the VNet. This behavior ensures proper network management and isolation.
What is a compute cluster?
Azure Machine Learning compute cluster is a managed-compute infrastructure that allows you to easily create a single or multi-node compute. The compute cluster is a resource that can be shared with other users in your workspace. The compute scales up automatically when a job is submitted, and can be put in an Azure Virtual Network. Compute cluster supportsno public IPdeployment as well in virtual network. The compute executes in a containerized environment and packages your model dependencies in aDocker container.
Compute clusters can run jobs securely in either amanaged virtual networkor anAzure virtual network, without requiring enterprises to open up SSH ports. The job executes in a containerized environment and packages your model dependencies in a Docker container.
Limitations
Compute clusters can be created in a different region than your workspace. This functionality is only available forcompute clusters, not compute instances.WarningWhen using a compute cluster in a different region than your workspace or datastores, you might see increased network latency and data transfer costs. The latency and costs can occur when creating the cluster, and when running jobs on it.
Compute clusters can be created in a different region than your workspace. This functionality is only available forcompute clusters, not compute instances.
Warning
When using a compute cluster in a different region than your workspace or datastores, you might see increased network latency and data transfer costs. The latency and costs can occur when creating the cluster, and when running jobs on it.
Azure Machine Learning Compute has default limits, such as the number of cores that can be allocated. For more information, seeManage and request quotas for Azure resources.
Azure Machine Learning Compute has default limits, such as the number of cores that can be allocated. For more information, seeManage and request quotas for Azure resources.
Azure allows you to placelockson resources, so that they can't be deleted or are read only.Do not apply resource locks to the resource group that contains your workspace. Applying a lock to the resource group that contains your workspace prevents scaling operations for Azure Machine Learning compute clusters. For more information on locking resources, seeLock resources to prevent unexpected changes.
Azure allows you to placelockson resources, so that they can't be deleted or are read only.Do not apply resource locks to the resource group that contains your workspace. Applying a lock to the resource group that contains your workspace prevents scaling operations for Azure Machine Learning compute clusters. For more information on locking resources, seeLock resources to prevent unexpected changes.
Caution
Applying resource locks, such as "Delete" or "Read-only", to the resource group that contains your Machine Learning workspace or to a separate resource group where you've configured a virtual network can prevent operations like creation, scaling, or deletion of these clusters. Ensure that resource locks are configured appropriately to avoid unintended disruptions.
Create
Time estimate: Approximately five minutes.
Note
If you use serverless compute, you don't need to create a compute cluster.
Azure Machine Learning Compute can be reused across runs. The compute can be shared with other users in the workspace and is retained between runs, automatically scaling nodes up or down based on the number of runs submitted, and themax_nodesset on your cluster. Themin_nodessetting controls the minimum nodes available.
max_nodes
min_nodes
The dedicated cores per region per VM family quota and total regional quota, which applies to compute cluster creation, is unified and shared with Azure Machine Learning training compute instance quota.
Important
To avoid charges when no jobs are running,set the minimum nodes to 0. This setting allows Azure Machine Learning to de-allocate the nodes when they aren't in use. Any value larger than 0 will keep that number of nodes running, even if they are not in use.
The compute autoscales down to zero nodes when it isn't used. Dedicated VMs are created to run your jobs as needed.
Use the following examples to create a compute cluster:
Python SDK
Azure CLI
Studio
To create a persistent Azure Machine Learning Compute resource in Python, specify thesizeandmax_instancesproperties. Azure Machine Learning then uses smart defaults for the other properties.
size
max_instances
size: The VM family of the nodes created by Azure Machine Learning Compute.
max_instances: The maximum number of nodes to autoscale up to when you run a job on Azure Machine Learning Compute.
APPLIES TO:Python SDK azure-ai-mlv2 (current)
from azure.ai.ml.entities import AmlCompute

cluster_basic = AmlCompute(
    name="basic-example",
    type="amlcompute",
    size="STANDARD_DS3_v2",
    location="westus",
    min_instances=0,
    max_instances=2,
    idle_time_before_scale_down=120,
)
ml_client.begin_create_or_update(cluster_basic).result()
from azure.ai.ml.entities import AmlCompute

cluster_basic = AmlCompute(
    name="basic-example",
    type="amlcompute",
    size="STANDARD_DS3_v2",
    location="westus",
    min_instances=0,
    max_instances=2,
    idle_time_before_scale_down=120,
)
ml_client.begin_create_or_update(cluster_basic).result()
You can also configure several advanced properties when you create Azure Machine Learning Compute. The properties allow you to create a persistent cluster of fixed size, or within an existing Azure Virtual Network in your subscription. See theAmlCompute classfor details.
Warning
When setting thelocationparameter, if it's a different region than your workspace or datastores, you might see increased network latency and data transfer costs. The latency and costs can occur when creating the cluster, and when running jobs on it.
location
APPLIES TO:Azure CLI ml extensionv2 (current)
az ml compute create -f create-cluster.yml
az ml compute create -f create-cluster.yml
Where the filecreate-cluster.ymlis:
$schema: https://azuremlschemas.azureedge.net/latest/amlCompute.schema.json 
name: location-example
type: amlcompute
size: STANDARD_DS3_v2
min_instances: 0
max_instances: 2
idle_time_before_scale_down: 120
location: westus
$schema: https://azuremlschemas.azureedge.net/latest/amlCompute.schema.json 
name: location-example
type: amlcompute
size: STANDARD_DS3_v2
min_instances: 0
max_instances: 2
idle_time_before_scale_down: 120
location: westus
Warning
When you use a compute cluster in a different region than your workspace or datastores, you might see increased network latency and data transfer costs. The latency and costs can occur when creating the cluster, and when running jobs on it.
Create a single- or multi- node compute cluster for your training, batch inference or reinforcement learning workloads.
Navigate toAzure Machine Learning studio.
Navigate toAzure Machine Learning studio.
UnderManage, selectCompute.
UnderManage, selectCompute.
If you have no compute resources, selectNewin the middle of the page.
If you have no compute resources, selectNewin the middle of the page.

If you see a list of compute resources, select+Newabove the list.
If you see a list of compute resources, select+Newabove the list.

In the tabs at the top, selectCompute cluster.
In the tabs at the top, selectCompute cluster.
Fill out the form as follows:FieldDescriptionLocationThe Azure region where the compute cluster is created. By default, this is the same location as the workspace. If you don't have sufficient quota in the default region, switch to a different region for more options.When using a different region than your workspace or datastores, you might see increased network latency and data transfer costs. The latency and costs can occur when creating the cluster, and when running jobs on it.Virtual machine typeChoose CPU or GPU. This type can't be changed after creation.Virtual machine priorityChooseDedicatedorLow priority. Low priority virtual machines are cheaper but don't guarantee the compute nodes. Your job might be preempted.Virtual machine sizeSupported virtual machine sizes might be restricted in your region. Check theavailability list
Fill out the form as follows:
SelectNextto proceed toAdvanced Settingsand fill out the form as follows:FieldDescriptionCompute name* Name is required and must be between 3 to 24 characters long.* Valid characters are upper and lower case letters, digits, and the-character.* Name must start with a letter.* Name needs to be unique across all existing computes within an Azure region. You see an alert if the name you choose isn't unique.* If-character is used, then it needs to be followed by at least one letter later in the name.Minimum number of nodesMinimum number of nodes that you want to provision. If you want a dedicated number of nodes, set that count here. Save money by setting the minimum to 0, so you don't pay for any nodes when the cluster is idle.Maximum number of nodesMaximum number of nodes that you want to provision. The compute automatically scales to a maximum of this node count when a job is submitted.Idle seconds before scale downIdle time before scaling the cluster down to the minimum node count.Enable SSH accessUse the same instructions asEnable SSH accessfor a compute instance.Advanced settingsOptional. Configure network settings.* If anAzure Virtual Network, Specify theResource group,Virtual network, andSubnetto create the compute instance inside the network. For more information, seenetwork requirements.* If anAzure Machine Learning managed network, the compute cluster is automatically in the managed network. For more information, seemanaged computes with a managed network.* No public IP configures whether the compute cluster has a public IP address when in a network.* Assign amanaged identityto grant access to resources.
SelectNextto proceed toAdvanced Settingsand fill out the form as follows:
SelectCreate.
SelectCreate.
Enable SSH access
SSH access is disabled by default. SSH access can't be changed after creation. Make sure to enable access if you plan to debug interactively withVS Code Remote.
After you have selectedNext: Advanced Settings:
Turn onEnable SSH access.
In theSSH public key source, select one of the options from the dropdown:If youGenerate new key pair:Enter a name for the key inKey pair name.SelectCreate.SelectDownload private key and create compute.  The key is usually downloaded into theDownloadsfolder.If you selectUse existing public key stored in Azure, search for and select the key inStored key.If you selectUse existing public key, provide an RSA public key in the single-line format (starting with "ssh-rsa") or the multi-line PEM format. You can generate SSH keys using ssh-keygen on Linux and OS X, or PuTTYGen on Windows.
If youGenerate new key pair:Enter a name for the key inKey pair name.SelectCreate.SelectDownload private key and create compute.  The key is usually downloaded into theDownloadsfolder.
Enter a name for the key inKey pair name.
SelectCreate.
SelectDownload private key and create compute.  The key is usually downloaded into theDownloadsfolder.
If you selectUse existing public key stored in Azure, search for and select the key inStored key.
If you selectUse existing public key, provide an RSA public key in the single-line format (starting with "ssh-rsa") or the multi-line PEM format. You can generate SSH keys using ssh-keygen on Linux and OS X, or PuTTYGen on Windows.
Connect with SSH access
After you create a compute with SSH access enabled, use these steps for access.
Find the compute in your workspace resources:On the left, selectCompute.Use the tabs at the top to selectCompute instanceorCompute clusterto find your machine.
Find the compute in your workspace resources:
On the left, selectCompute.
Use the tabs at the top to selectCompute instanceorCompute clusterto find your machine.
Select the compute name in the list of resources.
Select the compute name in the list of resources.
Find the connection string:For acompute instance, selectConnectat the top of theDetailssection.For acompute cluster, selectNodesat the top, then select theConnection stringin the table for your node.
Find the connection string:
For acompute instance, selectConnectat the top of theDetailssection.
For acompute instance, selectConnectat the top of theDetailssection.

For acompute cluster, selectNodesat the top, then select theConnection stringin the table for your node.
For acompute cluster, selectNodesat the top, then select theConnection stringin the table for your node.
Copy the connection string.
Copy the connection string.
For Windows, open PowerShell or a command prompt:Go into the directory or folder where your key is storedAdd the -i flag to the connection string to locate the private key and point to where it is stored:ssh -i <keyname.pem> azureuser@... (rest of connection string)
For Windows, open PowerShell or a command prompt:
Go into the directory or folder where your key is stored
Go into the directory or folder where your key is stored
Add the -i flag to the connection string to locate the private key and point to where it is stored:ssh -i <keyname.pem> azureuser@... (rest of connection string)
Add the -i flag to the connection string to locate the private key and point to where it is stored:
ssh -i <keyname.pem> azureuser@... (rest of connection string)
ssh -i <keyname.pem> azureuser@... (rest of connection string)
For Linux users, follow the steps fromCreate and use an SSH key pair for Linux VMs in Azure
For Linux users, follow the steps fromCreate and use an SSH key pair for Linux VMs in Azure
For SCP use:scp -i key.pem -P {port} {fileToCopyFromLocal }  azureuser@yourComputeInstancePublicIP:~/{destination}
For SCP use:
scp -i key.pem -P {port} {fileToCopyFromLocal }  azureuser@yourComputeInstancePublicIP:~/{destination}
scp -i key.pem -P {port} {fileToCopyFromLocal }  azureuser@yourComputeInstancePublicIP:~/{destination}
Lower your compute cluster cost with low priority VMs
You can also choose to uselow-priority VMsto run some or all of your workloads. These VMs don't have guaranteed availability and might be preempted while in use. You have to restart a preempted job.
Using Azure Low Priority Virtual Machines allows you to take advantage of Azure's unused capacity at a significant cost savings. At any point in time when Azure needs the capacity back, the Azure infrastructure evicts Azure Low Priority Virtual Machines. Therefore, Azure Low Priority Virtual Machine is great for workloads that can handle interruptions. The amount of available capacity can vary based on size, region, time of day, and more. When deploying Azure Low Priority Virtual Machines, Azure allocates the VMs if there's capacity available, but there's no SLA for these VMs. An Azure Low Priority Virtual Machine offers no high availability guarantees. At any point in time when Azure needs the capacity back, the Azure infrastructure evicts Azure Low Priority Virtual Machines.
Use any of these ways to specify a low-priority VM:
Python SDK
Azure CLI
Studio
APPLIES TO:Python SDK azure-ai-mlv2 (current)
from azure.ai.ml.entities import AmlCompute

cluster_low_pri = AmlCompute(
    name="low-pri-example",
    size="STANDARD_DS3_v2",
    min_instances=0,
    max_instances=2,
    idle_time_before_scale_down=120,
    tier="low_priority",
)
ml_client.begin_create_or_update(cluster_low_pri).result()
from azure.ai.ml.entities import AmlCompute

cluster_low_pri = AmlCompute(
    name="low-pri-example",
    size="STANDARD_DS3_v2",
    min_instances=0,
    max_instances=2,
    idle_time_before_scale_down=120,
    tier="low_priority",
)
ml_client.begin_create_or_update(cluster_low_pri).result()
APPLIES TO:Azure CLI ml extensionv2 (current)
Set thevm-priority:
vm-priority
az ml compute create -f create-cluster.yml
az ml compute create -f create-cluster.yml
Where the filecreate-cluster.ymlis:
$schema: https://azuremlschemas.azureedge.net/latest/amlCompute.schema.json 
name: low-pri-example
type: amlcompute
size: STANDARD_DS3_v2
min_instances: 0
max_instances: 2
idle_time_before_scale_down: 120
tier: low_priority
$schema: https://azuremlschemas.azureedge.net/latest/amlCompute.schema.json 
name: low-pri-example
type: amlcompute
size: STANDARD_DS3_v2
min_instances: 0
max_instances: 2
idle_time_before_scale_down: 120
tier: low_priority
Note
If you useserverless compute, you don't need to create a compute cluster. To specify a low-priority serverless compute, set thejob_tiertoSpotin thequeue settings.
job_tier
Spot
In the studio, chooseLow Prioritywhen you create a VM.
Delete
While your compute cluster scales down to zero nodes when not in use, unprovisioned nodes contribute to your quota usage. Deleting the compute cluster removes the compute target from your workspace, and releases the quota.
Python SDK
Azure CLI
Studio
APPLIES TO:Python SDK azure-ai-mlv2 (current)
This deletes the basic compute cluster, created from thecreate_basicobject earlier in this article.
create_basic
from azure.ai.ml.entities import AmlCompute

ml_client.compute.begin_delete(cluster_basic.name).wait()
from azure.ai.ml.entities import AmlCompute

ml_client.compute.begin_delete(cluster_basic.name).wait()
APPLIES TO:Azure CLI ml extensionv2 (current)
This deletes a compute cluster namedbasic-example.
basic-example
az ml compute delete --name basic-example
az ml compute delete --name basic-example
Navigate toAzure Machine Learning studio.
In the left menu, underManage, selectCompute.
At the top of the Compute page, selectCompute cluster.
Select the cluster you want to delete.
At the top of the page, selectDelete.
Set up managed identity
For information on how to configure a managed identity with your compute cluster, seeSet up authentication between Azure Machine Learning and other services.
Troubleshooting
There's a chance that some users who created their Azure Machine Learning workspace from the Azure portal before the GA release might not be able to create AmlCompute in that workspace. You can either raise a support request against the service or create a new workspace through the portal or the SDK to unblock yourself immediately.
Important
If your compute instance or compute clusters are based on any of these series, recreate with another VM size.
These series retired on August 31, 2023:
Azure NC-series
Azure NCv2-series
Azure ND-series
Azure NV- and NV_Promo series
These series retired on August 31, 2024:
Azure Av1-series
Azure HB-series
Stuck at resizing
If your Azure Machine Learning compute cluster appears stuck at resizing (0 -> 0) for the node state, Azure resource locks might be the cause.
Azure allows you to placelockson resources, so that they cannot be deleted or are read only.Locking a resource can lead to unexpected results.Some operations that don't seem to modify the resource actually require actions that are blocked by the lock.
With Azure Machine Learning, applying a delete lock to the resource group for your workspace will prevent scaling operations for Azure ML compute clusters. To work around this problem we recommendremovingthe lock from resource group and instead applying it to individual items in the group.
Important
Do notapply the lock to the following resources:
<GUID>-azurebatch-cloudservicenetworksecurityggroup
<GUID>-azurebatch-cloudservicepublicip
<GUID>-azurebatch-cloudserviceloadbalancer
These resources are used to communicate with, and perform operations such as scaling on, the compute cluster. Removing the resource lock from these resources should allow autoscaling for your compute clusters.
For more information on resource locking, seeLock resources to prevent unexpected changes.
Next step
Use your compute cluster to:
Submit a training run
Run batch inference
Feedback
Was this page helpful?
Additional resources