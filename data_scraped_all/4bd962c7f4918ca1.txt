Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
SQL language reference
Article
2025-03-14
8 contributors
In this article
This is a SQL command reference for Databricks SQL and Databricks Runtime.
For information about using SQL with DLT, seeDLT SQL language reference.
Note
Databricks SQL Serverless is not available in Azure China. Databricks SQL is not available in Azure Government regions.
General reference
This general reference describes data types, functions, identifiers, literals, and semantics:
âApplies toâ label
How to read a syntax diagram
How to add comments to SQL statements
Configuration parameters
Data types and literals
Functions
SQL data type rules
Datetime patterns
H3 geospatial functions
Lambda functions
Window functions
Identifiers
Names
IDENTIFIER clause
NULL semantics
Expressions
Parameter markers
Variables
Name resolution
JSON path expressions
Collation
Partitions
ANSI compliance in Databricks Runtime
Apache Hive compatibility
Principals
Privileges and securable objects in Unity Catalog
Privileges and securable objects in the Hive metastore
Refresh Unity Catalog metadata
External locations
External tables
Credentials
Volumes
SQL Scripting
Delta Sharing
Federated queries (Lakehouse Federation)
Information schema
Reserved words
DDL statements
You use data definition statements to create or modify the structure of database objects in a database:
ALTER CATALOG
ALTER CONNECTION
ALTER CREDENTIAL
ALTER DATABASE
ALTER LOCATION
ALTER MATERIALIZED VIEW
ALTER PROVIDER
ALTER RECIPIENT
ALTER STREAMING TABLE
ALTER TABLE
ALTER SCHEMA
ALTER SHARE
ALTER VIEW
ALTER VOLUME
COMMENT ON
CREATE BLOOMFILTER INDEX
CREATE CATALOG
CREATE CONNECTION
CREATE DATABASE
CREATE FUNCTION (SQL)
CREATE FUNCTION (External)
CREATE LOCATION
CREATE MATERIALIZED VIEW
CREATE RECIPIENT
CREATE SCHEMA
CREATE SERVER
CREATE SHARE
CREATE STREAMING TABLE
CREATE TABLE
CREATE VIEW
CREATE VOLUME
DECLARE VARIABLE
DROP BLOOMFILTER INDEX
DROP CATALOG
DROP CONNECTION
DROP DATABASE
DROP CREDENTIAL
DROP FUNCTION
DROP LOCATION
DROP PROVIDER
DROP RECIPIENT
DROP SCHEMA
DROP SHARE
DROP TABLE
DROP VARIABLE
DROP VIEW
DROP VOLUME
MSCK REPAIR TABLE
REFRESH FOREIGN (CATALOG, SCHEMA, or TABLE)
REFRESH (MATERIALIZED VIEW or STREAMING TABLE)
SYNC
TRUNCATE TABLE
UNDROP TABLE
DML statements
You use data manipulation statements to add, change, or delete data from a Delta Lake table:
COPY INTO
DELETE FROM
INSERT INTO
INSERT OVERWRITE DIRECTORY
INSERT OVERWRITE DIRECTORY with Hive format
LOAD DATA
MERGE INTO
UPDATE
Data retrieval statements
You use a query to retrieve rows from one or more tables according to the specified clauses. The full syntax
and brief description of supported clauses are explained in theQueryarticle.
The related SQL statementsSELECTandVALUESare also included in this section.
SELECT
VALUES
In addition to standard SQL queries in the style ofSELECT FROM WHERE, Azure Databricks also supportsSQL Pipeline Syntaxwhich composes SQL as a series of chained operations such asFROM |> WHERE |> SELECT.
SELECT FROM WHERE
FROM |> WHERE |> SELECT
Query
SELECT
VALUES
SQL Pipeline Syntax
Databricks SQL also provides the ability to inspect the generated logical and physical plan for a query using theEXPLAINstatement.
EXPLAIN
EXPLAIN
Delta Lake statements
You use Delta Lake SQL statements to manage tables stored in Delta Lake format:
CACHE SELECT
CONVERT TO DELTA
DESCRIBE HISTORY
FSCK REPAIR TABLE
GENERATE
OPTIMIZE
REORG TABLE
RESTORE
VACUUM
For details on using Delta Lake statements, seeWhat is Delta Lake?.
SQL scripting statements
You use SQL scripting to execute procedural logic in SQL.
CASE statement
BEGIN END compound statement
FOR statement
GET DIAGNOSTICS statement
IF THEN ELSE statement
ITERATE statement
LEAVE statement
LOOP statement
REPEAT statement
RESIGNAL statement
SIGNAL statement
WHILE statement
Auxiliary statements
You use auxiliary statements to collect statistics, manage caching,
explore metadata, set configurations, and manage resources:
Analyze statement
Apache Spark Cache statements
Describe statements
Show statements
Configuration, variable management, and misc statements
Resource management
Analyze statement
ANALYZE TABLE
Apache Spark Cache statements
Applies to:Databricks Runtime
CACHE TABLE
CLEAR CACHE
REFRESH FUNCTION
REFRESH TABLE
REFRESH CACHE
UNCACHE TABLE
Describe statements
DESCRIBE CATALOG
DESCRIBE CONNECTION
DESCRIBE CREDENTIAL
DESCRIBE DATABASE
DESCRIBE FUNCTION
DESCRIBE LOCATION
DESCRIBE PROVIDER
DESCRIBE QUERY
DESCRIBE RECIPIENT
DESCRIBE SCHEMA
DESCRIBE SHARE
DESCRIBE TABLE
DESCRIBE VOLUME
Show statements
LIST
SHOW ALL IN SHARE
SHOW CATALOGS
SHOW COLUMNS
SHOW CONNECTIONS
SHOW CREATE TABLE
SHOW CREDENTIALS
SHOW DATABASES
SHOW FUNCTIONS
SHOW GROUPS
SHOW LOCATIONS
SHOW PARTITIONS
SHOW PROVIDERS
SHOW RECIPIENTS
SHOW SCHEMAS
SHOW SHARES
SHOW SHARES IN PROVIDER
SHOW TABLE
SHOW TABLES
SHOW TABLES DROPPED
SHOW TBLPROPERTIES
SHOW USERS
SHOW VIEWS
SHOW VOLUMES
Configuration, variable management, and misc statements
EXECUTE IMMEDIATE
RESET
SET
SET RECIPIENT
SET TIMEZONE
SET VARIABLE
USE CATALOG
USE DATABASE
USE SCHEMA
Resource management
Applies to:Databricks Runtime
ADD ARCHIVE
ADD FILE
ADD JAR
LIST ARCHIVE
LIST FILE
LIST JAR
Applies to:Databricks SQL Connector
GET
PUT INTO
REMOVE
Security statements
You use security SQL statements to manage access to data:
ALTER GROUP
CREATE GROUP
DENY
DROP GROUP
GRANT
GRANT SHARE
REPAIR PRIVILEGES
REVOKE
REVOKE SHARE
SHOW GRANTS
SHOW GRANTS ON SHARE
SHOW GRANTS TO RECIPIENT
For details about using these statements, seeHive metastore privileges and securable objects (legacy).
Feedback
Was this page helpful?
Additional resources