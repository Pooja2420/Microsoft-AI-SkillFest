Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Copy in bulk from a database to Azure Data Explorer by using the Azure Data Factory template
Article
2023-11-19
7 contributors
In this article
Azure Data Explorer is a fast, fully managed, data-analytics service. It offers real-time analysis on large volumes of data that stream from many sources, such as applications, websites, and IoT devices.
To copy data from a database in Oracle Server, Netezza, Teradata, or SQL Server to Azure Data Explorer, you have to load huge amounts of data from multiple tables. Usually, the data has to be partitioned in each table so that you can load rows with multiple threads in parallel from a single table. This article describes a template to use in these scenarios.
Azure Data Factory templatesare predefined Data Factory pipelines. These templates can help you get started quickly with Data Factory and reduce development time on data integration projects.
You create theBulk Copy from Database to Azure Data Explorertemplate by usingLookupandForEachactivities. For faster data copying, you can use the template to create many pipelines per database or per table.
Important
Be sure to use the tool that's appropriate for the quantity of data you want to copy.
Use theBulk Copy from Database to Azure Data Explorertemplate to copy large amounts of data from databases such as SQL server and Google BigQuery to Azure Data Explorer.
Use theData Factory Copy Data toolto copy a few tables with small or moderate amounts of data into Azure Data Explorer.
Prerequisites
An Azure subscription. Create afree Azure account.
An Azure Data Explorer cluster and database.Create a cluster and database.
A data factory.Create a data factory.
A source of data.
Create ControlTableDataset
ControlTableDatasetindicates what data will be copied from the source to the destination in the pipeline. The number of rows indicates the total number of pipelines that are needed to copy the data. You should define ControlTableDataset as part of the source database.
An example of the SQL Server source table format is shown in the following code:
CREATE TABLE control_table (
PartitionId int,
SourceQuery varchar(255),
ADXTableName varchar(255)
);
CREATE TABLE control_table (
PartitionId int,
SourceQuery varchar(255),
ADXTableName varchar(255)
);
The code elements are described in the following table:
select * from table where lastmodifiedtime  LastModifytime >= ''2015-01-01 00:00:00''>
If your ControlTableDataset is in a different format, create a comparable ControlTableDataset for your format.
Use the Bulk Copy from Database to Azure Data Explorer template
In theLet's get startedpane, selectCreate pipeline from templateto open theTemplate gallerypane.
In theLet's get startedpane, selectCreate pipeline from templateto open theTemplate gallerypane.

Select theBulk Copy from Database to Azure Data Explorertemplate.
Select theBulk Copy from Database to Azure Data Explorertemplate.

In theBulk Copy from Database to Azure Data Explorerpane, underUser Inputs, specify your datasets by doing the following:a. In theControlTableDatasetdrop-down list, select the linked service to the control table that indicates what data is copied from the source to the destination and where it will be placed in the destination.b. In theSourceDatasetdrop-down list, select the linked service to the source database.c. In theAzureDataExplorerTabledrop-down list, select the Azure Data Explorer table. If the dataset doesn't exist,create the Azure Data Explorer linked serviceto add the dataset.d. SelectUse this template.
In theBulk Copy from Database to Azure Data Explorerpane, underUser Inputs, specify your datasets by doing the following:
a. In theControlTableDatasetdrop-down list, select the linked service to the control table that indicates what data is copied from the source to the destination and where it will be placed in the destination.
b. In theSourceDatasetdrop-down list, select the linked service to the source database.
c. In theAzureDataExplorerTabledrop-down list, select the Azure Data Explorer table. If the dataset doesn't exist,create the Azure Data Explorer linked serviceto add the dataset.
d. SelectUse this template.

Select an area in the canvas, outside the activities, to access the template pipeline. Select theParameterstab to enter the parameters for the table, includingName(control table name) andDefault value(column names).
Select an area in the canvas, outside the activities, to access the template pipeline. Select theParameterstab to enter the parameters for the table, includingName(control table name) andDefault value(column names).

UnderLookup, selectGetPartitionListto view the default settings. The query is automatically created.
UnderLookup, selectGetPartitionListto view the default settings. The query is automatically created.
Select the Command activity,ForEachPartition, select theSettingstab, and then do the following:a. In theBatch countbox, enter a number from 1 to 50. This selection determines the number of pipelines that run in parallel until the number ofControlTableDatasetrows is reached.b. To ensure that the pipeline batches run in parallel,do notselect theSequentialcheck box.TipThe best practice is to run many pipelines in parallel so that your data can be copied more quickly. To increase efficiency, partition the data in the source table and allocate one partition per pipeline, according to date and table.
Select the Command activity,ForEachPartition, select theSettingstab, and then do the following:
a. In theBatch countbox, enter a number from 1 to 50. This selection determines the number of pipelines that run in parallel until the number ofControlTableDatasetrows is reached.
b. To ensure that the pipeline batches run in parallel,do notselect theSequentialcheck box.

Tip
The best practice is to run many pipelines in parallel so that your data can be copied more quickly. To increase efficiency, partition the data in the source table and allocate one partition per pipeline, according to date and table.
SelectValidate Allto validate the Azure Data Factory pipeline, and then view the result in thePipeline Validation Outputpane.
SelectValidate Allto validate the Azure Data Factory pipeline, and then view the result in thePipeline Validation Outputpane.

If necessary, selectDebug, and then selectAdd triggerto run the pipeline.
If necessary, selectDebug, and then selectAdd triggerto run the pipeline.

You can now use the template to efficiently copy large amounts of data from your databases and tables.
Related content
Learn about theAzure Data Explorer connectorfor Azure Data Factory.
Edit linked services, datasets, and pipelines in theData Factory UI.
Query data in the Azure Data Explorer web UI.
Feedback
Was this page helpful?
Additional resources