Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Role-based access control for Speech resources
Article
2025-04-15
7 contributors
In this article
You can manage access and permissions to your Speech resources with Azure role-based access control (Azure RBAC). Assigned roles can vary across Speech resources. For example, you can assign a role to an AI Services resource for Speech that should only be used to train a custom speech model. You can assign another role to an AI Services resource for Speech that is used to transcribe audio files. Depending on who can access each Speech resource, you can effectively set a different level of access per application or user. For more information on Azure RBAC, see theAzure RBAC documentation.
Note
An AI Services resource for Speech can inherit or be assigned multiple roles. The final level of access to the resource is a combination of all role permissions.
Roles for Speech resources
A role definition is a collection of permissions. When you create an AI Services resource for Speech, the built-in roles in the following table are available for assignment.
Warning
Speech service architecture differs from other Azure AI services in the way it usesAzure control plane and data plane. Speech service is extensively using data plane comparing to other Azure AI services, and this requires different set up for the roles. Because of this some general Cognitive Services roles have actual access right set that doesn't exactly match their name when used in Speech services scenario. For instanceCognitive Services Userprovides in effect the Contributor rights, whileCognitive Services Contributorprovides no access at all. The same is true for genericOwnerandContributorroles which have no data plane rights and consequently provide no access to Speech resource. To keep consistency we recommend to use roles containingSpeechin their names. These roles areCognitive Services Speech UserandCognitive Services Speech Contributor. Their access right sets were designed specifically for the Speech service. In case you would like to use general Cognitive Services roles and Azure generic roles, we ask you to very carefully study the following access right table.
Important
Whether a role can list resource keys is important forSpeech Studio authentication. To list resource keys, a role must have permission to run theMicrosoft.CognitiveServices/accounts/listKeys/actionoperation. Please note that if key authentication is disabled in the Azure portal, then none of the roles can list keys.
Microsoft.CognitiveServices/accounts/listKeys/action
Keep the built-in roles if your Speech resource can have full read and write access to the projects.
For finer-grained resource access control, you canadd or remove rolesusing the Azure portal. For example, you could create a custom role with permission to upload custom speech datasets, but without permission to deploy a custom speech model to an endpoint.
Authentication with keys and tokens
Therolesdefine what permissions you have. Authentication is required to use the Speech resource.
To authenticate with Speech resource keys, all you need is the key and region. To authenticate with a Microsoft Entra token, the Speech resource must have acustom subdomain.
Here's how to create a new Azure AI Services resource with a custom subdomain. You can also use an existing resource, but it must have a custom subdomain. For more information about creating a custom subdomain, seeCreate a custom domain name.
resourceGroupName=my-speech-rg
location=eastus
AIServicesResourceName=my-aiservices-$location

# create an AIServices resource for Speech and other AI services
az cognitiveservices account create --name $AIServicesResourceName --resource-group $resourceGroupName --kind AIServices --sku S0 --location $location --custom-domain $AIServicesResourceName

# get the resource id
speechResourceId=$(az cognitiveservices account show --name $AIServicesResourceName --resource-group $resourceGroupName --query id -o tsv)
# assign Cognitive Services User role to the app id
appId=$(az ad signed-in-user show --query id -o tsv)
az role assignment create --role "Cognitive Services User" --assignee $appId --scope $speechResourceId
# assign Cognitive Services Speech User role to the app id
az role assignment create --role "Cognitive Services Speech User" --assignee $appId --scope $speechResourceId

# get an access token
accessToken=$(az account get-access-token --scope "https://cognitiveservices.azure.com/.default" --query accessToken -o tsv)
echo $accessToken
resourceGroupName=my-speech-rg
location=eastus
AIServicesResourceName=my-aiservices-$location

# create an AIServices resource for Speech and other AI services
az cognitiveservices account create --name $AIServicesResourceName --resource-group $resourceGroupName --kind AIServices --sku S0 --location $location --custom-domain $AIServicesResourceName

# get the resource id
speechResourceId=$(az cognitiveservices account show --name $AIServicesResourceName --resource-group $resourceGroupName --query id -o tsv)
# assign Cognitive Services User role to the app id
appId=$(az ad signed-in-user show --query id -o tsv)
az role assignment create --role "Cognitive Services User" --assignee $appId --scope $speechResourceId
# assign Cognitive Services Speech User role to the app id
az role assignment create --role "Cognitive Services Speech User" --assignee $appId --scope $speechResourceId

# get an access token
accessToken=$(az account get-access-token --scope "https://cognitiveservices.azure.com/.default" --query accessToken -o tsv)
echo $accessToken
The returnedaccessTokenis a Microsoft Entra token that you can use to authenticate without API keys. The token has alimited lifetime.
accessToken
Now you can use theaccessTokento authenticate with the AI Services resource. For example, you can use the token via theFast transcription REST API:
accessToken
uri="https://$AIServicesResourceName.cognitiveservices.azure.com/speechtotext/transcriptions:transcribe?api-version=2024-11-15"

curl -v "$uri" \
    --header 'Content-Type: multipart/form-data' \
    --form 'definition={"locales": ["en-US"]}' \
    --form 'audio=@Call1_separated_16k_health_insurance.wav' \
    --header "Authorization: Bearer $accessToken"
uri="https://$AIServicesResourceName.cognitiveservices.azure.com/speechtotext/transcriptions:transcribe?api-version=2024-11-15"

curl -v "$uri" \
    --header 'Content-Type: multipart/form-data' \
    --form 'definition={"locales": ["en-US"]}' \
    --form 'audio=@Call1_separated_16k_health_insurance.wav' \
    --header "Authorization: Bearer $accessToken"
Speech SDK authentication
For the SDK, you configure whether to authenticate with an API key or Microsoft Entra token. For details, seeMicrosoft Entra authentication with the Speech SDK.
Speech Studio authentication
Once you're signed intoSpeech Studio, you select a subscription and Speech resource. You don't choose whether to authenticate with an API key or Microsoft Entra token. Speech Studio gets the key or token automatically from the Speech resource. If one of the assignedroleshas permission to list resource keys and the key authentication is not disabled, Speech Studio authenticates with the key. Otherwise, Speech Studio authenticates with the Microsoft Entra token.
If Speech Studio utilizes your Microsoft Entra token and your Speech resource lacks a properly configured custom subdomain, Role-based access control (RBAC) will not be activated, and you will be unable to access any features in Speech Studio. RBAC determines your access to features based on the role assigned to you and the permissions associated with that role. If your role does not grant access to a specific feature, a warning message will be displayed on the page. Ensure you have the appropriate role to access the desired feature.
Next steps
Microsoft Entra authentication with the Speech SDK.
Speech service encryption of data at rest.
Feedback
Was this page helpful?
Additional resources