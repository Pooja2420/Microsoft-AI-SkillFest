Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Logs Ingestion API in Azure Monitor
Article
2024-11-04
12 contributors
In this article
The Logs Ingestion API in Azure Monitor lets you send data to a Log Analytics workspace using either aREST API callorclient libraries. The API allows you to send data tosupported Azure tablesor tocustom tables that you create. You can alsoextend the schema of Azure tables with custom columnsto accept additional data.
Basic operation
Data can be sent to the Logs Ingestion API from any application that can make a REST API call. This may be a custom application that you create, or it may be an application or agent that understands how to send data to the API. It specifies adata collection rule (DCR)that includes the target table and workspace and the credentials of an app registration with access to the specified DCR. It sends the data to an endpoint specified by the DCR, or to adata collection endpoint (DCE)if you're using private link.
The data sent by your application to the API must be formatted in JSON and match the structure expected by the DCR. It doesn't necessarily need to match the structure of the target table because the DCR can include atransformationto convert the data to match the table's structure. You can modify the target table and workspace by modifying the DCR without any change to the API call or source data.

Configuration
The following table describes each component in Azure that you must configure before you can use the Logs Ingestion API.
Note
For a PowerShell script that automates the configuration of these components, seeSample code to send data to Azure Monitor using Logs ingestion API.
Endpoint
The REST API endpoint for the Logs Ingestion API can either be adata collection endpoint (DCE)or the DCR logs ingestion endpoint.
The DCR logs ingestion endpoint is generated when you create a DCR for direct ingestion. To retrieve this endpoint, open the DCR in the JSON view in the Azure portal. You may need to change theAPI versionto the latest version for the endpoints to be displayed.

A DCE is only required when you're connecting to a Log Analytics workspace usingprivate linkor if your DCR doesn't include the logs ingestion endpoint. This may be the case if you're using an older DCR or if you created the DCR without the"kind": "Direct"parameter. SeeData collection rule (DCR)below for more details.
"kind": "Direct"
Note
ThelogsIngestionproperty was added on March 31, 2024. Prior to this date, a DCE was required for the Logs ingestion API. Endpoints can't be added to an existing DCR, but you can keep using any existing DCRs with existing DCEs. If you want to move to a DCR endpoint, then you must create a new DCR to replace the existing one. A DCR with endpoints can also use a DCE. In this case, you can choose whether to use the DCE or the DCR endpoints for each of the clients that use the DCR.
logsIngestion
Data collection rule (DCR)
When youcreate a custom tablein a Log Analytics workspace using the Azure portal, a DCR that can be used with the Logs ingestion API is created for you. If you're sending data to a table that already exists, then you must create the DCR manually. Start with the sample DCR below, replacing values for the following parameters in the template. Use any of the methods described inCreate and edit data collection rules (DCRs) in Azure Monitorto create the DCR.
region
dataCollectionEndpointId
streamDeclarations
streams
dataFlows
workspaceResourceId
destinations
dataFlows
transformKql
source
outputStream
{
    "location": "eastus",
    "dataCollectionEndpointId": "/subscriptions/aaaa0a0a-bb1b-cc2c-dd3d-eeeeee4e4e4e/resourceGroups/my-resource-group/providers/Microsoft.Insights/dataCollectionEndpoints/dce-eastus",
    "kind": "Direct",
    "properties": {
        "streamDeclarations": {
            "Custom-MyTable": {
                "columns": [
                    {
                        "name": "Time",
                        "type": "datetime"
                    },
                    {
                        "name": "Computer",
                        "type": "string"
                    },
                    {
                        "name": "AdditionalContext",
                        "type": "string"
                    }
                ]
            }
        },
        "destinations": {
            "logAnalytics": [
                {
                    "workspaceResourceId": "/subscriptions/aaaa0a0a-bb1b-cc2c-dd3d-eeeeee4e4e4e/resourceGroups/cefingestion/providers/microsoft.operationalinsights/workspaces/my-workspace",
                    "name": "LogAnalyticsDest"
                }
            ]
        },
        "dataFlows": [
            {
                "streams": [
                    "Custom-MyTable"
                ],
                "destinations": [
                    "LogAnalyticsDest"
                ],
                "transformKql": "source",
                "outputStream": "Custom-MyTable_CL"
            }
        ]
    }
}
{
    "location": "eastus",
    "dataCollectionEndpointId": "/subscriptions/aaaa0a0a-bb1b-cc2c-dd3d-eeeeee4e4e4e/resourceGroups/my-resource-group/providers/Microsoft.Insights/dataCollectionEndpoints/dce-eastus",
    "kind": "Direct",
    "properties": {
        "streamDeclarations": {
            "Custom-MyTable": {
                "columns": [
                    {
                        "name": "Time",
                        "type": "datetime"
                    },
                    {
                        "name": "Computer",
                        "type": "string"
                    },
                    {
                        "name": "AdditionalContext",
                        "type": "string"
                    }
                ]
            }
        },
        "destinations": {
            "logAnalytics": [
                {
                    "workspaceResourceId": "/subscriptions/aaaa0a0a-bb1b-cc2c-dd3d-eeeeee4e4e4e/resourceGroups/cefingestion/providers/microsoft.operationalinsights/workspaces/my-workspace",
                    "name": "LogAnalyticsDest"
                }
            ]
        },
        "dataFlows": [
            {
                "streams": [
                    "Custom-MyTable"
                ],
                "destinations": [
                    "LogAnalyticsDest"
                ],
                "transformKql": "source",
                "outputStream": "Custom-MyTable_CL"
            }
        ]
    }
}
Client libraries
In addition to making a REST API call, you can use the following client libraries to send data to the Logs ingestion API. The libraries require the same components described inConfiguration. For examples using each of these libraries, seeSample code to send data to Azure Monitor using Logs ingestion API.
.NET
Go
Java
JavaScript
Python
REST API call
To send data to Azure Monitor with a REST API call, make a POST call over HTTP. Details required for this call are described in this section.
URI
The URI includes the region, theDCE or DCR ingestion endpoint, DCR ID, and the stream name. It also specifies the API version.
The URI uses the following format.
{Endpoint}/dataCollectionRules/{DCR Immutable ID}/streams/{Stream Name}?api-version=2023-01-01
{Endpoint}/dataCollectionRules/{DCR Immutable ID}/streams/{Stream Name}?api-version=2023-01-01
For example:
https://my-dce-5kyl.eastus-1.ingest.monitor.azure.com/dataCollectionRules/dcr-000a00a000a00000a000000aa000a0aa/streams/Custom-MyTable?api-version=2023-01-01
https://my-dce-5kyl.eastus-1.ingest.monitor.azure.com/dataCollectionRules/dcr-000a00a000a00000a000000aa000a0aa/streams/Custom-MyTable?api-version=2023-01-01
TheDCR Immutable IDis generated for the DCR when it's created. You can retrieve it from theOverview page for the DCR in the Azure portal.
DCR Immutable ID

Stream Namerefers to thestreamin the DCR that should handle the custom data.
Stream Name
Headers
The following table describes that headers for your API call.
https://monitor.azure.com
https://monitor.azure.cn
https://monitor.azure.us
application/json
gzip
Body
The body of the call includes the custom data to be sent to Azure Monitor. The shape of the data must be a JSON array with item structure that matches the format expected by the stream in the DCR. If it's needed to send a single item within API call, the data should be sent as a single-item array.
For example:
[
{
    "TimeGenerated": "2023-11-14 15:10:02",
    "Column01": "Value01",
    "Column02": "Value02"
}
]
[
{
    "TimeGenerated": "2023-11-14 15:10:02",
    "Column01": "Value01",
    "Column02": "Value02"
}
]
Ensure that the request body is properly encoded in UTF-8 to prevent any issues with data transmission.
Example
SeeSample code to send data to Azure Monitor using Logs ingestion APIfor an example of the API call using PowerShell.
Supported tables
Data sent to the ingestion API can be sent to the following tables:
_CL
ADAssessmentRecommendation
ADSecurityAssessmentRecommendation
Anomalies
ASimAuditEventLogs
ASimAuthenticationEventLogs
ASimDhcpEventLogs
ASimDnsActivityLogs
ASimDnsAuditLogs
ASimFileEventLogs
ASimNetworkSessionLogs
ASimProcessEventLogs
ASimRegistryEventLogs
ASimUserManagementActivityLogs
ASimWebSessionLogs
AWSCloudTrail
AWSCloudWatch
AWSGuardDuty
AWSVPCFlow
AzureAssessmentRecommendation
CommonSecurityLog
DeviceTvmSecureConfigurationAssessmentKB
DeviceTvmSoftwareVulnerabilitiesKB
ExchangeAssessmentRecommendation
ExchangeOnlineAssessmentRecommendation
GCPAuditLogs
GoogleCloudSCC
SCCMAssessmentRecommendation
SCOMAssessmentRecommendation
SecurityEvent
SfBAssessmentRecommendation
SfBOnlineAssessmentRecommendation
SharePointOnlineAssessmentRecommendation
SPAssessmentRecommendation
SQLAssessmentRecommendation
StorageInsightsAccountPropertiesDaily
StorageInsightsDailyMetrics
StorageInsightsHourlyMetrics
StorageInsightsMonthlyMetrics
StorageInsightsWeeklyMetrics
Syslog
UCClient
UCClientReadinessStatus
UCClientUpdateStatus
UCDeviceAlert
UCDOAggregatedStatus
UCDOStatus
UCServiceUpdateStatus
UCUpdateAlert
WindowsClientAssessmentRecommendation
WindowsEvent
WindowsServerAssessmentRecommendation|
Note
Column names must start with a letter and can consist of up to 45 alphanumeric characters and underscores (_)._ResourceId,id,_ResourceId,_SubscriptionId,TenantId,Type,UniqueId, andTitleare reserved column names. Custom columns you add to an Azure table must have the suffix_CF.
_
_ResourceId
id
_ResourceId
_SubscriptionId
TenantId
Type
UniqueId
Title
_CF
Limits and restrictions
For limits related to the Logs Ingestion API, seeAzure Monitor service limits.
Next steps
Walk through a tutorial sending data to Azure Monitor Logs with Logs ingestion API on the Azure portal
Walk through a tutorial sending custom logs using Resource Manager templates and REST API
Get guidance on using the client libraries for the Logs ingestion API for.NET,Java,JavaScript, orPython.
Feedback
Was this page helpful?
Additional resources