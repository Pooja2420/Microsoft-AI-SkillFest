Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Update policy overview
Article
2024-12-18
12 contributors
In this article
Applies to: 창혵Microsoft Fabric창혵Azure Data Explorer
Update policies are automation mechanisms triggered when new data is written to a table. They eliminate the need for special orchestration by running a query to transform the ingested data and save the result to a destination table. Multiple update policies can be defined on a single table, allowing for different transformations and saving data to multiple tables simultaneously. The target tables can have a different schema, retention policy, and other policies from the source table.
For example, a high-rate trace source table can contain data formatted as a free-text column. The target table can include specific trace lines, with a well-structured schema generated from a transformation of the source table's free-text data using theparse operator. For more information,common scenarios.
The following diagram depicts a high-level view of an update policy. It shows two update policies that are triggered when data is added to the second source table. Once they're triggered, transformed data is added to the two target tables.

An update policy is subject to the same restrictions and best practices as regular ingestion. The policy scales-out according to the cluster size, and is more efficient when handling bulk ingestion.
An update policy is subject to the same restrictions and best practices as regular ingestion. The policy scales-out according to the Eventhouse size, and is more efficient when handling bulk ingestion.
Note
The source and target table must be in the same database.
The update policy function schema and the target table schema must match in their column types, and order.
The update policy function can reference tables in other databases. To do this, the update policy must be defined with aManagedIdentityproperty, and the managed identity must haveviewerroleon the referenced databases.
Ingesting formatted data improves performance, and CSV is preferred because of it's a well-defined format. Sometimes, however, you have no control over the format of the data, or you want to enrich ingested data, for example, by joining records with a static dimension table in your database.
ManagedIdentity
viewer
Update policy query
If the update policy is defined on the target table, multiple queries can run on data ingested into a source table. If there are multiple update policies, the order of execution isn't necessarily known.
Query limitations
The policy-related query can invoke stored functions, but:It can't perform cross-cluster queries.It can't access external data or external tables.It can't make callouts (by using a plugin).
It can't perform cross-cluster queries.
It can't access external data or external tables.
It can't make callouts (by using a plugin).
The query doesn't have read access to tables that have theRestrictedViewAccess policyenabled.
For update policy limitations in streaming ingestion, seestreaming ingestion limitations.
The policy-related query can invoke stored functions, but:It can't perform cross-eventhouse queries.It can't access external data or external tables.It can't make callouts (by using a plugin).
It can't perform cross-eventhouse queries.
It can't access external data or external tables.
It can't make callouts (by using a plugin).
The query doesn't have read access to tables that have theRestrictedViewAccess policyenabled.
By default, theStreaming ingestion policyis enabled for all tables in the Eventhouse. To use functions with thejoinoperator in an update policy, the streaming ingestion policy must be disabled. Use the.altertableTableNamepolicystreamingingestionPolicyObjectcommand to disable it.
join
.alter
table
policy
streamingingestion
Warning
An incorrect query can prevent data ingestion into the source table. It is important to note that limitations, as well as the compatibility between the query results and the schema of the source and destination tables, can cause an incorrect query to prevent data ingestion into the source table.
These limitations are validated during the creation and execution of the policy, but not when arbitrary stored functions that the query might reference are updated. Therefore, it is crucial to make any changes with caution to ensure the update policy remains intact.
When referencing theSourcetable in theQuerypart of the policy, or in functions referenced by theQuerypart:
Source
Query
Query
Don't use the qualified name of the table. Instead, useTableName.
TableName
Don't usedatabase("<DatabaseName>").TableNameorcluster("<ClusterName>").database("<DatabaseName>").TableName.
database("<DatabaseName>").TableName
cluster("<ClusterName>").database("<DatabaseName>").TableName
Don't use the qualified name of the table. Instead, useTableName.
TableName
Don't usedatabase("<DatabaseName>").TableNameorcluster("<EventhouseName>").database("<DatabaseName>").TableName.
database("<DatabaseName>").TableName
cluster("<EventhouseName>").database("<DatabaseName>").TableName
The update policy object
A table can have zero or more update policy objects associated with it.
Each such object is represented as a JSON property bag, with the following properties defined.
bool
string
string
bool
bool
string
system
Note
In production systems, setIsTransactional:trueto ensure that the target table doesn't lose data in transient failures.
IsTransactional
Note
Cascading updates are allowed, for example from table A, to table B, to table C.
However, if update policies are defined in a circular manner, this is detected at runtime, and the chain of updates is cut. Data is ingested only once to each table in the chain.
Management commands
Update policy management commands include:
.show table *TableName* policy updateshows the current update policy of a table.
.show table *TableName* policy update
.alter table *TableName* policy updatedefines the current update policy of a table.
.alter table *TableName* policy update
.alter-merge table *TableName* policy updateappends definitions to the current update policy of a table.
.alter-merge table *TableName* policy update
.delete table *TableName* policy updatedeletes the current update policy of a table.
.delete table *TableName* policy update
Update policy is initiated following ingestion
Update policies take effect when data is ingested or moved to a source table, or extents are created in a source table. These actions can be done using any of the following commands:
.ingest (pull)
.ingest (inline)
.set | .append | .set-or-append | .set-or-replace
.move extents
.replace extentsThePropagateIngestionPropertiescommand only takes effect in ingestion operations. When the update policy is triggered as part of a.move extentsor.replace extentscommand, this option has no effect.
ThePropagateIngestionPropertiescommand only takes effect in ingestion operations. When the update policy is triggered as part of a.move extentsor.replace extentscommand, this option has no effect.
PropagateIngestionProperties
.move extents
.replace extents
Warning
When the update policy is invoked as part of a.set-or-replacecommand, by default data in derived tables is replaced in the same way as in the source table.
Data may be lost in all tables with an update policy relationship if thereplacecommand is invoked.
Consider using.set-or-appendinstead.
.set-or-replace
replace
.set-or-append
Remove data from source table
After ingesting data to the target table, you can optionally remove it from the source table. Set a soft-delete period of0sec(or00:00:00) in the source table'sretention policy, and the update policy as transactional. The following conditions apply:
0sec
00:00:00
The source data isn't queryable from the source table
The source data doesn't persist in durable storage as part of the ingestion operation
Operational performance improves. Post-ingestion resources are reduced for background grooming operations onextentsin the source table.
Note
When the source table has a soft delete period of0sec(or00:00:00), any update policy referencing this table must be transactional.
0sec
00:00:00
Performance impact
Update policies can affect performance, and ingestion for data extents is multiplied by the number of target tables. It's important to optimize the policy-related query. You can test an update policy's performance impact by invoking the policy on already-existing extents, before creating or altering the policy, or on the function used with the query.
Evaluate resource usage
Use.show queries, to evaluate resource usage (CPU, memory, and so on) with the following parameters:
.show queries
Set theSourceproperty, the source table name, asMySourceTable
Source
MySourceTable
Set theQueryproperty to call a function namedMyFunction()
Query
MyFunction()
// '_extentId' is the ID of a recently created extent, that likely hasn't been merged yet.
let _extentId = toscalar(
    MySourceTable
    | project ExtentId = extent_id(), IngestionTime = ingestion_time()
    | where IngestionTime > ago(10m)
    | top 1 by IngestionTime desc
    | project ExtentId
);
// This scopes the source table to the single recent extent.
let MySourceTable =
    MySourceTable
    | where ingestion_time() > ago(10m) and extent_id() == _extentId;
// This invokes the function in the update policy (that internally references `MySourceTable`).
MyFunction
// '_extentId' is the ID of a recently created extent, that likely hasn't been merged yet.
let _extentId = toscalar(
    MySourceTable
    | project ExtentId = extent_id(), IngestionTime = ingestion_time()
    | where IngestionTime > ago(10m)
    | top 1 by IngestionTime desc
    | project ExtentId
);
// This scopes the source table to the single recent extent.
let MySourceTable =
    MySourceTable
    | where ingestion_time() > ago(10m) and extent_id() == _extentId;
// This invokes the function in the update policy (that internally references `MySourceTable`).
MyFunction
Transactional settings
The update policyIsTransactionalsetting defines whether the update policy is transactional and can affect the behavior of the policy update, as follows:
IsTransactional
IsTransactional:false: If the value is set to the default value,false, the update policy doesn't guarantee consistency between data in the source and target table. If an update policy fails, data is ingested only to the source table and not to the target table. In this scenario, ingestion operation is successful.
IsTransactional:false
IsTransactional:true: If the value is set totrue, the setting does guarantee consistency between data in the source and target tables. If an update policy fails, data isn't ingested to the source or target table. In this scenario, the ingestion operation is unsuccessful.
IsTransactional:true
Handling failures
When policy updates fail, they're handled differently based on whether theIsTransactionalsetting istrueorfalse. Common reasons for update policy failures are:
IsTransactional
true
false
A mismatch between the query output schema and the target table.
Any query error.
You can view policy update failures using the.show ingestion failurescommandwith the following command:
In any other case, you can manually retry ingestion.
.show ingestion failures
.show ingestion failures
| where FailedOn > ago(1hr) and OriginatesFromUpdatePolicy == true
.show ingestion failures
| where FailedOn > ago(1hr) and OriginatesFromUpdatePolicy == true
Example of extract, transform, load
You can use update policy settings to perform extract, transform, load (ETL).
In this example, use an update policy with a simple function to perform ETL. First, we create two tables:
The source table - Contains a single string-typed column into which data is ingested.
The target table - Contains the desired schema. The update policy is defined on this table.
Let's create the source table:.create table MySourceTable (OriginalRecord:string)
Let's create the source table:
.create table MySourceTable (OriginalRecord:string)
.create table MySourceTable (OriginalRecord:string)
Next, create the target table:.create table MyTargetTable (Timestamp:datetime, ThreadId:int, ProcessId:int, TimeSinceStartup:timespan, Message:string)
Next, create the target table:
.create table MyTargetTable (Timestamp:datetime, ThreadId:int, ProcessId:int, TimeSinceStartup:timespan, Message:string)
.create table MyTargetTable (Timestamp:datetime, ThreadId:int, ProcessId:int, TimeSinceStartup:timespan, Message:string)
Then create a function to extract data:.create function
 with (docstring = 'Parses raw records into strongly-typed columns', folder = 'UpdatePolicyFunctions')
     ExtractMyLogs()
    {
    MySourceTable
    | parse OriginalRecord with "[" Timestamp:datetime "] [ThreadId:" ThreadId:int "] [ProcessId:" ProcessId:int "] TimeSinceStartup: " TimeSinceStartup:timespan " Message: " Message:string
    | project-away OriginalRecord
}
Then create a function to extract data:
.create function
 with (docstring = 'Parses raw records into strongly-typed columns', folder = 'UpdatePolicyFunctions')
     ExtractMyLogs()
    {
    MySourceTable
    | parse OriginalRecord with "[" Timestamp:datetime "] [ThreadId:" ThreadId:int "] [ProcessId:" ProcessId:int "] TimeSinceStartup: " TimeSinceStartup:timespan " Message: " Message:string
    | project-away OriginalRecord
}
.create function
 with (docstring = 'Parses raw records into strongly-typed columns', folder = 'UpdatePolicyFunctions')
     ExtractMyLogs()
    {
    MySourceTable
    | parse OriginalRecord with "[" Timestamp:datetime "] [ThreadId:" ThreadId:int "] [ProcessId:" ProcessId:int "] TimeSinceStartup: " TimeSinceStartup:timespan " Message: " Message:string
    | project-away OriginalRecord
}
Now, set the update policy to invoke the function that we created:.alter table MyTargetTable policy update
@'[{ "IsEnabled": true, "Source": "MySourceTable", "Query": "ExtractMyLogs()", "IsTransactional": true, "PropagateIngestionProperties": false}]'
Now, set the update policy to invoke the function that we created:
.alter table MyTargetTable policy update
@'[{ "IsEnabled": true, "Source": "MySourceTable", "Query": "ExtractMyLogs()", "IsTransactional": true, "PropagateIngestionProperties": false}]'
.alter table MyTargetTable policy update
@'[{ "IsEnabled": true, "Source": "MySourceTable", "Query": "ExtractMyLogs()", "IsTransactional": true, "PropagateIngestionProperties": false}]'
To empty the source table after data is ingested into the target table, define the retention policy on the source table to have 0s as itsSoftDeletePeriod..alter-merge table MySourceTable policy retention softdelete = 0s
To empty the source table after data is ingested into the target table, define the retention policy on the source table to have 0s as itsSoftDeletePeriod.
SoftDeletePeriod
.alter-merge table MySourceTable policy retention softdelete = 0s
.alter-merge table MySourceTable policy retention softdelete = 0s
Related content
Common scenarios for using table update policies
Tutorial: Route data using table update policies
Feedback
Was this page helpful?
Additional resources