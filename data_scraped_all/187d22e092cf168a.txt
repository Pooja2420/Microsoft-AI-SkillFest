Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Get object detection insights
Article
2025-04-02
2 contributors
In this article
Object detection
Azure AI Video Indexer detects objects in videos such as cars, handbags, backpacks, and laptops.
Supported objects
airplane
apple
backpack
banana
baseball glove
bed
bench
bicycle
boat
book
bottle
bowl
broccoli
bus
cake
car
carrot
cell phone
chair
clock
computer mouse
couch
cup
dining table
donut
fire hydrant
fork
frisbee
hair dryer
handbag
hot dog
keyboard
kite
knife
laptop
microwave
motorcycle
computer mouse
necktie
orange
oven
parking meter
pizza
potted plant
sandwich
scissors
sink
skateboard
skis
snowboard
spoon
sports ball
stop sign
suitcase
surfboard
teddy bear
tennis racket
toaster
toilet
toothbrush
traffic light
train
umbrella
vase
wine glass
View the insight JSON with the web portal
After you upload and index a video, insights are available in JSON format for download using the web portal.
Select theLibrarytab.
Select media you want to work with.
SelectDownloadand theInsights (JSON). The JSON file opens in a new browser tab.
Look for the key pair described in the example response.
Use the API
Use aGet Video Indexrequest. We recommend passing&includeSummarizedInsights=false.
&includeSummarizedInsights=false
Look for the key pairs described in the example response.
Example response
Detected and tracked objects appear under "detected Objects" in the downloadedinsights.jsonfile. Every time a unique object is detected, the object is given an ID. That object is also tracked, meaning that the model watches for the detected object to return to the frame. If it does, another instance is added to the instances for the object with different start and end times.
In this example, the first car was detected and given an ID of 1 since it was also the first object detected. Then, a different car was detected and that car was given the ID of 23 since it was the 23rd object detected. Later, the first car appeared again and another instance was added to the JSON. Here's the resulting JSON:
detectedObjects: [
    {
    id: 1,
    type: "Car",
    thumbnailId: "1c0b9fbb-6e05-42e3-96c1-abe2cd48t33",
    displayName: "car",
    wikiDataId: "Q1420",
    instances: [
        {
        confidence: 0.468,
        adjustedStart: "0:00:00",
        adjustedEnd: "0:00:02.44",
        start: "0:00:00",
        end: "0:00:02.44"
        },
        {
        confidence: 0.53,
        adjustedStart: "0:03:00",
        adjustedEnd: "0:00:03.55",
        start: "0:03:00",
        end: "0:00:03.55"
        }    
    ]
    },
    {
    id: 23,
    type: "Car",
    thumbnailId: "1c0b9fbb-6e05-42e3-96c1-abe2cd48t34",
    displayName: "car",
    wikiDataId: "Q1420",
    instances: [
        {
        confidence: 0.427,
        adjustedStart: "0:00:00",
        adjustedEnd: "0:00:14.24",
        start: "0:00:00",
        end: "0:00:14.24"
        }    
    ]
    }
]
detectedObjects: [
    {
    id: 1,
    type: "Car",
    thumbnailId: "1c0b9fbb-6e05-42e3-96c1-abe2cd48t33",
    displayName: "car",
    wikiDataId: "Q1420",
    instances: [
        {
        confidence: 0.468,
        adjustedStart: "0:00:00",
        adjustedEnd: "0:00:02.44",
        start: "0:00:00",
        end: "0:00:02.44"
        },
        {
        confidence: 0.53,
        adjustedStart: "0:03:00",
        adjustedEnd: "0:00:03.55",
        start: "0:03:00",
        end: "0:00:03.55"
        }    
    ]
    },
    {
    id: 23,
    type: "Car",
    thumbnailId: "1c0b9fbb-6e05-42e3-96c1-abe2cd48t34",
    displayName: "car",
    wikiDataId: "Q1420",
    instances: [
        {
        confidence: 0.427,
        adjustedStart: "0:00:00",
        adjustedEnd: "0:00:14.24",
        start: "0:00:00",
        end: "0:00:14.24"
        }    
    ]
    }
]
Components
No components are defined for object detection.
Transparency notes
Important
It's important to read thetransparency note overviewfor all VI features. Each insight also has transparency notes of its own:
There are up to 20 detections per frame for standard and advanced processing and 35 tracks per class.
Object size shouldn't be greater than 90 percent of the frame. Large objects that consistently span over a large portion of the frame might not be recognized.
Small or blurry objects can be hard to detect. They can either be missed or misclassified (wine glass, cup).
Objects that are transient and appear in few frames might not be recognized.
Other factors that might affect the accuracy of the object detection include low light conditions, camera motion, and occlusions.
Azure AI Video Indexer supports only real world objects. There's no support for animation or CGI. Computer generated graphics (such as news-stickers) might produce strange results.
Binders, brochures, and other written materials tend to be detected as "book."
Sample code
See all samples for VI
Feedback
Was this page helpful?
Additional resources