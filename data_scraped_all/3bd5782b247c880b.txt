Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Architecture best practices for Azure Load Balancer
Article
2025-02-04
3 contributors
In this article
The load balancing process distributes network traffic to a group of two or more back-end servers. Azure Load Balancer is an Azure-native service that does Layer-4 load balancing for User Datagram Protocol (UDP) and Transmission Control Protocol (TCP). Load Balancer helps provide low latency and high availability for regional and global deployments.
This article assumes that as an architect, you've reviewed theload-balancing optionsin Azure and chose Load Balancer for your workload. The guidance in this article provides architectural recommendations that are mapped to the principles of theWell-Architected Framework pillars.
Important
How to use this guide
Each section has adesign checklistthat presents architectural areas of concern along with design strategies localized to the technology scope.
Also included are recommendations for the technology capabilities that can help materialize those strategies. The recommendations don't represent an exhaustive list of all configurations that are available for Load Balancer and its dependencies. Instead, they list the key recommendations mapped to the design perspectives. Use the recommendations to build your proof-of-concept or to optimize your existing environments.
Foundational architecture that demonstrates the key recommendations:Azure Virtual Machines baseline architecture.
Technology scope
This review focuses on the interrelated decisions for the following Azure resources:
Load Balancer
This guidance focuses the Standard Load Balancer SKU. Basic Load Balancer and Gateway Load Balancer SKUs are out of scope for this article.

Note
For HTTP applications, consider Azure Application Gateway or Azure Front Door instead of Load Balancer. These alternatives manage load balancing and also provide features like Web Application Firewall (WAF) and Transport Layer Security (TLS) termination.
For more information, see:
Well-Architected Framework perspective on Azure Front Door
Well-Architected Framework perspective on Azure Application Gateway
Reliability
The purpose of the Reliability pillar is to provide continued functionality bybuilding enough resilience and the ability to recover fast from failures.
Reliability design principlesprovide a high-level design strategy applied for individual components, system flows, and the system as a whole.
Design checklist
Start your design strategy based on thedesign review checklist for Reliability. Determine its relevance to your business requirements while keeping in mind the tiers and features of virtual machines (VMs). Extend the strategy to include more approaches as needed.
Understand the impact of Microsoft-backed guarantees.In addition to other components in your architecture, factor service-level agreements (SLA) into the reliability target of your workload. Keep in mind the following important points:If the load-balanced endpoint can't connect to all healthy back-end servers for an entire minute, that minute is considered unavailable. However, if at least one request succeeds within the same minute, even if others fail, that minute isn't considered downtime.Downtime doesn't include minutes caused by Source Network Address Translation (SNAT) port exhaustion. Ensure that you configure your workload to handle the expected number of connections and open ports accordingly.
Understand the impact of Microsoft-backed guarantees.In addition to other components in your architecture, factor service-level agreements (SLA) into the reliability target of your workload. Keep in mind the following important points:
If the load-balanced endpoint can't connect to all healthy back-end servers for an entire minute, that minute is considered unavailable. However, if at least one request succeeds within the same minute, even if others fail, that minute isn't considered downtime.
If the load-balanced endpoint can't connect to all healthy back-end servers for an entire minute, that minute is considered unavailable. However, if at least one request succeeds within the same minute, even if others fail, that minute isn't considered downtime.
Downtime doesn't include minutes caused by Source Network Address Translation (SNAT) port exhaustion. Ensure that you configure your workload to handle the expected number of connections and open ports accordingly.
Downtime doesn't include minutes caused by Source Network Address Translation (SNAT) port exhaustion. Ensure that you configure your workload to handle the expected number of connections and open ports accordingly.
Support zone redundancy in your workload architecture.We recommend the Standard Load Balancer SKU. It has reliability features, such as availability zone support, traffic distribution across multiple regions, and the ability to handle more instances in the back-end pool. These feature help withstand failures at zonal, regional, and individual VM instance levels. Be aware of limitations, such as the maximum back-end pool size.NoteIn Load Balancer, you manage the number of load-balanced VMs but not the number of Load Balancer instances. You can configure a Load Balancer instance to be zone redundant, or pin it to a zone if the workload needs to collocate VMs in a single zone. The front-end IP address's zonal or multizone configuration dictates the load-balancing redundancy.
Support zone redundancy in your workload architecture.We recommend the Standard Load Balancer SKU. It has reliability features, such as availability zone support, traffic distribution across multiple regions, and the ability to handle more instances in the back-end pool. These feature help withstand failures at zonal, regional, and individual VM instance levels. Be aware of limitations, such as the maximum back-end pool size.
Note
In Load Balancer, you manage the number of load-balanced VMs but not the number of Load Balancer instances. You can configure a Load Balancer instance to be zone redundant, or pin it to a zone if the workload needs to collocate VMs in a single zone. The front-end IP address's zonal or multizone configuration dictates the load-balancing redundancy.
Support regional redundancy in your workload architecture.You can configure Load Balancer to be a global load balancer. In this setup, Load Balancer has a static anycast public IP address that broadcasts to multiple regions. When clients request this IP address, their requests go to the closest server instance. Load Balancer connects to regional load balancers to distribute traffic efficiently.
Support regional redundancy in your workload architecture.You can configure Load Balancer to be a global load balancer. In this setup, Load Balancer has a static anycast public IP address that broadcasts to multiple regions. When clients request this IP address, their requests go to the closest server instance. Load Balancer connects to regional load balancers to distribute traffic efficiently.
Evaluate changes in your networking stack to support reliable scaling.Consider scaling out the back-end pool by using autoscale rules. Be aware of potential SNAT port exhaustion for outbound traffic. To address this problem, use Azure NAT Gateway for easier configuration, but understand that it lacks availability zone redundancy. Alternatively, use Load Balancer for added zone redundancy. For more information, seeOutbound connections.
Evaluate changes in your networking stack to support reliable scaling.Consider scaling out the back-end pool by using autoscale rules. Be aware of potential SNAT port exhaustion for outbound traffic. To address this problem, use Azure NAT Gateway for easier configuration, but understand that it lacks availability zone redundancy. Alternatively, use Load Balancer for added zone redundancy. For more information, seeOutbound connections.
Mitigate potential failures.Do failure mode analysis and identify mitigations. The following table shows types of failures and how to mitigate them.FailureMitigationTraffic is routed to unhealthy application instances.Monitor workload instance health. Implement HTTP health probes that include checks for workload dependencies.Traffic is routed to a region that has an outage.Deploy extra instances in another region. Add a global load balancer to redirect traffic to the new region.The workload's user base was expanded to support users in a new region, and they have high latency. The application now experiences a high number of timeouts and failures.Deploy extra instances in a new region, and add them in the service configuration. As a global load balancer, Azure Load Balancer routes traffic closer to the users.
Mitigate potential failures.Do failure mode analysis and identify mitigations. The following table shows types of failures and how to mitigate them.
Route traffic to healthy instances.You can use HTTP or TCP for health probes. To provide richer status responses, consider creating an HTTP endpoint for health checks, even for non-HTTP apps. This approach is especially useful for checking dependencies and databases. Without HTTP probes, the load balancer relies on TCP connections, which might not accurately reflect VM health.You can configure the health probe on Load Balancer. For more information, seeDesign guidance on health probes.
Route traffic to healthy instances.You can use HTTP or TCP for health probes. To provide richer status responses, consider creating an HTTP endpoint for health checks, even for non-HTTP apps. This approach is especially useful for checking dependencies and databases. Without HTTP probes, the load balancer relies on TCP connections, which might not accurately reflect VM health.
You can configure the health probe on Load Balancer. For more information, seeDesign guidance on health probes.
Security
The purpose of the Security pillar is to provideconfidentiality, integrity, and availabilityguarantees to the workload.
TheSecurity design principlesprovide a high-level design strategy for achieving those goals by applying approaches to the technical design of Load Balancer.
Design checklist
Start your design strategy based on thedesign review checklist for Securityand identify vulnerabilities and controls to improve the security posture. Extend the strategy to include more approaches as needed.
Review security baselines.To enhance the security posture of your application that's load balanced by Azure Load Balancer, review thesecurity baseline for Load Balancer.
Review security baselines.To enhance the security posture of your application that's load balanced by Azure Load Balancer, review thesecurity baseline for Load Balancer.
Protect the back-end servers.Deploy resources in a virtual network that doesn't have direct internet exposure. Front the virtual network with a load balancer. Ideally, the load balancer should have firewall capabilities. For HTTP applications, consider Application Gateway or Azure Front Door. For non-HTTP applications, consider Load Balancer with a private IP address (internal load balancer), and route traffic through Azure Firewall for added security. For more information, seeInternal load balancer.You can also use Load Balancer as a reverse proxy. In that case, the load balancer has a public IP address with SNAT, which exposes resources while masking their IP addresses.NoteTo filter traffic to back-end servers, use network security groups (NSGs) on the subnets that contain the front end and back end. Don't apply NSGs directly to the Load Balancer service. When NSGs enforce rules, they consider the source ports, destination ports, and address ranges of the originating and destination computers, not the load balancer.
Protect the back-end servers.Deploy resources in a virtual network that doesn't have direct internet exposure. Front the virtual network with a load balancer. Ideally, the load balancer should have firewall capabilities. For HTTP applications, consider Application Gateway or Azure Front Door. For non-HTTP applications, consider Load Balancer with a private IP address (internal load balancer), and route traffic through Azure Firewall for added security. For more information, seeInternal load balancer.
You can also use Load Balancer as a reverse proxy. In that case, the load balancer has a public IP address with SNAT, which exposes resources while masking their IP addresses.
Note
To filter traffic to back-end servers, use network security groups (NSGs) on the subnets that contain the front end and back end. Don't apply NSGs directly to the Load Balancer service. When NSGs enforce rules, they consider the source ports, destination ports, and address ranges of the originating and destination computers, not the load balancer.
Design for private connectivity.Load Balancer works with Azure Private Link. If you spread application resources across virtual networks, you can connect resources in different virtual networks. Use virtual network peering or place Private Link in front of the internal load balancer. The Private Link option provides more secure access without needing a public IP address. It also restricts access from nonpeered networks.You can authorize private links viarole-based access controlto restrict access to only the identities that need it.
Design for private connectivity.Load Balancer works with Azure Private Link. If you spread application resources across virtual networks, you can connect resources in different virtual networks. Use virtual network peering or place Private Link in front of the internal load balancer. The Private Link option provides more secure access without needing a public IP address. It also restricts access from nonpeered networks.
You can authorize private links viarole-based access controlto restrict access to only the identities that need it.
Protect your application from threats at the network edge.For designs that use Load Balancer as the point of entry, implement traffic inspection at the endpoint level. This design doesn't have built-in security features like a WAF, so you must add extra measures to help secure HTTP applications. For more information, seePublic load balancer. Also ensure that you protect the load balancer endpoints from distributed denial-of-service (DDoS) attacks.
Protect your application from threats at the network edge.For designs that use Load Balancer as the point of entry, implement traffic inspection at the endpoint level. This design doesn't have built-in security features like a WAF, so you must add extra measures to help secure HTTP applications. For more information, seePublic load balancer. Also ensure that you protect the load balancer endpoints from distributed denial-of-service (DDoS) attacks.
Encrypt network traffic.Load Balancer works at Layer 4 and fully supports load balancing TCP and UDP traffic. Load Balancer doesn't support Secure Sockets Layer (SSL) and TLS termination. For HTTPS load balancing at the application layer, use Application Gateway.
Encrypt network traffic.Load Balancer works at Layer 4 and fully supports load balancing TCP and UDP traffic. Load Balancer doesn't support Secure Sockets Layer (SSL) and TLS termination. For HTTPS load balancing at the application layer, use Application Gateway.
Cost Optimization
Cost Optimization focuses ondetecting spend patterns, prioritizing investments in critical areas, and optimizing in othersto meet the organization's budget while meeting business requirements.
TheCost Optimization design principlesprovide a high-level design strategy for achieving those goals and making tradeoffs as necessary in the technical design related to Load Balancer and its environment.
Start your design strategy based on thedesign review checklist for Cost Optimizationfor investments. Fine-tune the design so that the workload is aligned with the budget that's allocated for the workload. Your design should use the right Azure capabilities, monitor investments, and find opportunities to optimize over time.
Factor load balancing expenses into your cost model.Consider primary factors, such as the amount of data that Load Balancer processes and the number of inbound and outbound load balancing rules. For a precise cost estimation, use traffic logs to gauge your inbound and outbound traffic needs.
Factor load balancing expenses into your cost model.Consider primary factors, such as the amount of data that Load Balancer processes and the number of inbound and outbound load balancing rules. For a precise cost estimation, use traffic logs to gauge your inbound and outbound traffic needs.
Set controls on spending.Log and analyze Load Balancer costs. To manage costs effectively, useMicrosoft Cost Managementtocreate budgetsand configure alerts. Costs can accumulate based on the amount of logged data and the storage duration, which affects bandwidth and storage expenses.
Set controls on spending.Log and analyze Load Balancer costs. To manage costs effectively, useMicrosoft Cost Managementtocreate budgetsand configure alerts. Costs can accumulate based on the amount of logged data and the storage duration, which affects bandwidth and storage expenses.
Remove unused resources.Identify and remove unused load balancer instances. Analyze logs to evaluate usage. Delete load balancer instances that aren't associated with back-end VMs. Examine traffic logs to find underused resources.
Remove unused resources.Identify and remove unused load balancer instances. Analyze logs to evaluate usage. Delete load balancer instances that aren't associated with back-end VMs. Examine traffic logs to find underused resources.
Optimize flow costs.Use efficient protocols and data compression to reduce the load on the traffic flow and minimize costs.To optimize costs, you can reduce the number of rules. Instead of having rules that use individual IP addresses and ports for each endpoint, define a rule for a range of ports in the front end that connects to a back-end pool.Implement optimization in the back-end flows. For example, multiple database queries that a load balancer intercepts can increase costs per query. To prevent this extra cost, consider implementing a stored procedure to consolidate the sequence of queries.
Optimize flow costs.Use efficient protocols and data compression to reduce the load on the traffic flow and minimize costs.
To optimize costs, you can reduce the number of rules. Instead of having rules that use individual IP addresses and ports for each endpoint, define a rule for a range of ports in the front end that connects to a back-end pool.
Implement optimization in the back-end flows. For example, multiple database queries that a load balancer intercepts can increase costs per query. To prevent this extra cost, consider implementing a stored procedure to consolidate the sequence of queries.
Evaluate the cost of operations.Consider resource expenses and operational costs, like maintenance, scaling, and compliance. Load balancer rules can significantly affect costs. Reduce the number of rules to optimize financial and management costs.
Evaluate the cost of operations.Consider resource expenses and operational costs, like maintenance, scaling, and compliance. Load balancer rules can significantly affect costs. Reduce the number of rules to optimize financial and management costs.
Operational Excellence
Operational Excellence primarily focuses on procedures fordevelopment practices, observability, and release management.
TheOperational Excellence design principlesprovide a high-level design strategy for achieving those goals for the operational requirements of the workload.
Start your design strategy based on thedesign review checklist for Operational Excellencefor defining processes for observability, testing, and deployment related to Load Balancer.
Use infrastructure as code.Deploy and configure Load Balancer along with other networking components, like virtual networks, network peerings, private endpoints, and NSGs. Familiarize yourself with theMicrosoft.Network loadBalancers resource type.
Use infrastructure as code.Deploy and configure Load Balancer along with other networking components, like virtual networks, network peerings, private endpoints, and NSGs. Familiarize yourself with theMicrosoft.Network loadBalancers resource type.
Use layered deployment for hub-and-spoke architectures.Deploy the hub first because it changes less frequently than the workload that's deployed in the spoke network. Deploy the load balancer with the workload. If you reuse a single load balancer across multiple workloads, consider placing it in the hub.
Use layered deployment for hub-and-spoke architectures.Deploy the hub first because it changes less frequently than the workload that's deployed in the spoke network. Deploy the load balancer with the workload. If you reuse a single load balancer across multiple workloads, consider placing it in the hub.
Implement a comprehensive networking monitoring system.Impelement diagnostic capabilities, like multidimensional metrics for real-time insights and alerts, resource logs based on the health event schema, and the Azure Monitor Insights dashboard for comprehensive load balancer monitoring.
Implement a comprehensive networking monitoring system.Impelement diagnostic capabilities, like multidimensional metrics for real-time insights and alerts, resource logs based on the health event schema, and the Azure Monitor Insights dashboard for comprehensive load balancer monitoring.
Average
Down
Performance Efficiency
Performance Efficiency is aboutmaintaining user experience even when there's an increase in loadby managing capacity. The strategy includes scaling resources, identifying and optimizing potential bottlenecks, and optimizing for peak performance.
ThePerformance Efficiency design principlesprovide a high-level design strategy for achieving those capacity goals against the expected usage.
Start your design strategy based on thedesign review checklist for Performance Efficiencyfor defining a baseline that's based on key performance indicators for Load Balancer.
Determine the network performance targets.The load balancer has no limit on the traffic that it can support. But when you define performance targets and plan for capacity, you should test network performance.Use stress testing to understand the workload's bandwidth requirements. Include the load balancer in those tests. If a single virtual machine scale set with multiple VMs isn't sufficient, you might add another scale set by using the same load balancer. If the VMs don't receive requests quickly enough, you might need to adjust the networking components, such as adding more load balancers. But instead of changing the load balancer, consider making design changes and optimizing your workload to handle the load better.
Determine the network performance targets.The load balancer has no limit on the traffic that it can support. But when you define performance targets and plan for capacity, you should test network performance.
Use stress testing to understand the workload's bandwidth requirements. Include the load balancer in those tests. If a single virtual machine scale set with multiple VMs isn't sufficient, you might add another scale set by using the same load balancer. If the VMs don't receive requests quickly enough, you might need to adjust the networking components, such as adding more load balancers. But instead of changing the load balancer, consider making design changes and optimizing your workload to handle the load better.
Understand the limits when you design your scaling strategy.To meet performance requirements and scale your workload, add or remove VMs from the back-end pool. A single back-end pool in Standard Load Balancer can handle up to 5,000 VMs.Load Balancer doesn't apply throughput limits. But throughput limits for VMs and virtual networks still apply. For more information, seeVM network bandwidth.
Understand the limits when you design your scaling strategy.To meet performance requirements and scale your workload, add or remove VMs from the back-end pool. A single back-end pool in Standard Load Balancer can handle up to 5,000 VMs.
Load Balancer doesn't apply throughput limits. But throughput limits for VMs and virtual networks still apply. For more information, seeVM network bandwidth.
Serve requests quickly.Standard Load Balancer has a tier that routes traffic to back-end endpoints based on their geographic proximity to the user.Load Balancer also supports load distribution based on session persistence. When you enable this feature, requests from the same client are consistently directed to the same back-end server that handled their previous sessions.
Serve requests quickly.Standard Load Balancer has a tier that routes traffic to back-end endpoints based on their geographic proximity to the user.
Load Balancer also supports load distribution based on session persistence. When you enable this feature, requests from the same client are consistently directed to the same back-end server that handled their previous sessions.
Collect data to analyze performance.Load Balancermultidimensional metricscan analyze the service's performance. Configure alerts to detect performance changes. Use tools like theAzure Monitor Insights dashboardto visualize the status of Load Balancer. Ensure that the resource health feature monitors the health status, and stay informed about performance problems and outages.
Collect data to analyze performance.Load Balancermultidimensional metricscan analyze the service's performance. Configure alerts to detect performance changes. Use tools like theAzure Monitor Insights dashboardto visualize the status of Load Balancer. Ensure that the resource health feature monitors the health status, and stay informed about performance problems and outages.
Optimize network traffic.Don't process the same data multiple times in separate steps. Instead, perform all necessary calculations in a batch, and then persist the data. This approach reduces latency and minimizes network traffic, which improves overall performance.
Optimize network traffic.Don't process the same data multiple times in separate steps. Instead, perform all necessary calculations in a batch, and then persist the data. This approach reduces latency and minimizes network traffic, which improves overall performance.
Azure policies
Azure provides an extensive set of built-in policies related to Load Balancer and its dependencies. Some of the preceding recommendations can be audited through Azure Policy. For example, you can check whether:
Load balancers, excluding Basic SKU load balancers, have resiliency features enabled for public IP addresses in their front end.
Resource logs are enabled to track activities and events that occur on your resources and provide visibility and insights into changes.
For comprehensive governance, review theAzure Policy built-in definitions for Load Balancerand other policies that might impact the security of traffic distribution.
Azure Advisor recommendations
Azure Advisor is a personalized cloud consultant that helps you follow best practices to optimize your Azure deployments. Advisor recommendations are aligned with Well-Architected Framework pillars.
For more information, see the recommendations inAzure Advisor.
Related resources
Virtual Machines baseline architecture
Load Balancer documentation
Feedback
Was this page helpful?
Additional resources