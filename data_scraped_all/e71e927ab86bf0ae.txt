Azure OpenAI
Reference

Connects to Azure OpenAI to perform operations on large language models.
This article describes the operations for the Azure OpenAIbuilt-inconnector, which is availableonlyfor Standard workflows in single-tenant Azure Logic Apps.
Built-in connector settings
In a Standard logic app resource, the application and host settings control various thresholds for performance, throughput, timeout, and so on. For more information, seeEdit host and app settings for Standard logic app workflows.
Connector how-to guide
For more information about integrating Azure OpenAI with your workflow in Azure Logic Apps, seeIntegrate Azure AI services with Standard workflows in Azure Logic Apps.
Authentication
URL and key-based authentication
Authentication type
Parameters
Active Directory OAuth
Active Directory OAuth
Parameters
Managed identity
Managed identity
Parameters
Actions
Executes a GetEmbeddings request for the specified single text input.
Gets chat completions for the specified text input.
Gets chat completions for the specified Prompt Template.
Gets completion for the specified text prompt.
Get multiple chat completion options for the specified text input.
Executes a GetEmbeddings request for the specified array of text inputs.
Get an embedding
Executes a GetEmbeddings request for the specified single text input.
The deployment or model name.
The single text to convert to an embedding.
An array of floats that represent the input's computed embeddings.
The token usage details.
Get chat completions
Gets chat completions for the specified text input.
The deployment or model name.
A value used to control the apparent creativity of generated completions. SeeAzure.AI.Inference.ChatCompletionsOptions.Temperature Property.
The deployment or model name.
A value used to control the apparent creativity of generated completions and an alternative value to Temperature. SeeChatCompletionsOptions.NucleusSamplingFactor Property.
The maximum number of tokens to generate. SeeChatCompletionsOptions.MaxTokens Property.
A value that influences the probability of generated tokens appearing based on their existing presence in generated text. SeeChatCompletionsOptions.PresencePenalty Property.
A value that influences the probability of generated tokens appearing based on their cumulative frequence. SeeChatCompletionsOptions.FrequencyPenalty Property.
The chat completion output role.
The chat completion response.
The chat user.
The token usage details.
Get chat completions using Prompt Template (Preview)
Gets chat completions for the specified Prompt Template.
The deployment or model name.
A value used to control the apparent creativity of generated completions. SeeAzure.AI.Inference.ChatCompletionsOptions.Temperature Property.
The prompt template in Prompty liquid format. Seehttps://aka.ms/logic-apps/liquid-prompt-templatesfor more details.
The prompt template variables.
A value used to control the apparent creativity of generated completions and an alternative value to Temperature. SeeChatCompletionsOptions.NucleusSamplingFactor Property.
The maximum number of tokens to generate. SeeChatCompletionsOptions.MaxTokens Property.
A value that influences the probability of generated tokens appearing based on their existing presence in generated text. SeeChatCompletionsOptions.PresencePenalty Property.
A value that influences the probability of generated tokens appearing based on their cumulative frequence. SeeChatCompletionsOptions.FrequencyPenalty Property.
The prompt template request.
The chat completion input role.
The token usage details.
Get completion (Preview)
Gets completion for the specified text prompt.
The deployment or model name.
A value used to control the apparent creativity of generated completions. SeeAzure.AI.Inference.ChatCompletionsOptions.Temperature Property.
The deployment or model name.
The deployment or model name.
The maximum number of tokens to generate. SeeChatCompletionsOptions.MaxTokens Property.
A value that influences the probability of generated tokens appearing based on their existing presence in generated text. SeeChatCompletionsOptions.PresencePenalty Property.
A value that influences the probability of generated tokens appearing based on their cumulative frequence. SeeChatCompletionsOptions.FrequencyPenalty Property.
The completion response.
The token usage details.
Get multiple chat completions (Preview)
Get multiple chat completion options for the specified text input.
The deployment or model name.
A value used to control the apparent creativity of generated completions. SeeAzure.AI.Inference.ChatCompletionsOptions.Temperature Property.
The deployment or model name.
A value used to control the apparent creativity of generated completions and an alternative value to Temperature. SeeChatCompletionsOptions.NucleusSamplingFactor Property.
The maximum number of tokens to generate. SeeChatCompletionsOptions.MaxTokens Property.
The number of chat responses to generate. SeeChatCompletionsOptions.ChoiceCount Property.
A value that influences the probability of generated tokens appearing based on their existing presence in generated text. SeeChatCompletionsOptions.PresencePenalty Property.
A value that influences the probability of generated tokens appearing based on their cumulative frequence. SeeChatCompletionsOptions.FrequencyPenalty Property.
The array of chat message choices.
The token usage details.
Get multiple embeddings
Executes a GetEmbeddings request for the specified array of text inputs.
The deployment or model name.
The array input to convert to embeddings.
An array with arrays of floats representing the input's computed embeddings.
The token usage details.