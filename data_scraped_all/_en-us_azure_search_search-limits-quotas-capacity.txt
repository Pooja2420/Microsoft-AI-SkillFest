Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Service limits in Azure AI Search
Article
2025-04-14
27 contributors
In this article
Maximum limits on storage, workloads, and quantities of indexes and other objects depend on whether youcreate Azure AI SearchatFree,Basic,Standard, orStorage Optimizedpricing tiers.
Freeis a multitenant shared service that comes with your Azure subscription.
Freeis a multitenant shared service that comes with your Azure subscription.
Basicprovides dedicated computing resources for production workloads at a smaller scale.
Basicprovides dedicated computing resources for production workloads at a smaller scale.
Standardruns on dedicated machines with more storage and processing capacity at every level. Standard comes in four levels: S1, S2, S3, and S3 HD. S3 High Density (S3 HD) is engineered formulti-tenancyand large quantities of small indexes (3,000 indexes per service). S3 HD doesn't provide theindexer featureand data ingestion must use APIs that push data from source to index.
Standardruns on dedicated machines with more storage and processing capacity at every level. Standard comes in four levels: S1, S2, S3, and S3 HD. S3 High Density (S3 HD) is engineered formulti-tenancyand large quantities of small indexes (3,000 indexes per service). S3 HD doesn't provide theindexer featureand data ingestion must use APIs that push data from source to index.
Storage Optimizedruns on dedicated machines with more total storage, storage bandwidth, and memory thanStandard. This tier targets large, slow-changing indexes. Storage Optimized comes in two levels: L1 and L2.
Storage Optimizedruns on dedicated machines with more total storage, storage bandwidth, and memory thanStandard. This tier targets large, slow-changing indexes. Storage Optimized comes in two levels: L1 and L2.
Subscription limits
You can create multiplebillablesearch services (Basic and higher), up to the maximum number of services allowed at each tier, per region. For example, you could create up to 16 services at the Basic tier and another 16 services at the S1 tier within the same subscription and region. You could then create an additional 16 Basic services in another region for a combined total of 32 Basic services under the same subscription. For more information about tiers, seeChoose a tier (or SKU) for Azure AI Search.
Maximum service limits can be raised upon request. If you need more services within the same subscription,file a support request.
1You can have one free search service per Azure subscription. The free tier is based on infrastructure shared with other customers. Because the hardware isn't dedicated, scale-up isn't supported, and storage is limited to 50 MB. A free search service might be deleted after extended periods of inactivity to make room for more services.
2Search units (SU) are billing units, allocated as either areplicaor apartition. You need both. To learn more about SU combinations, seeEstimate and manage capacity of a search service.
Service limits
The following table covers SLA, partition counts, and replica counts at the service level.
1Basic tier supports three partitions and three replicas, for a total of nine search units (SU) onnew search servicescreated after April 3, 2024. Older basic services are limited to one partition and three replicas.
A search service is subject to a maximum storage limit (partition size multiplied by the number of partitions) or by a hard limit on themaximum number of indexesorindexers, whichever comes first.
Service-level agreements (SLAs) apply to billable services that have two or more replicas for query workloads, or three or more replicas for query and indexing workloads. The number of partitions isn't an SLA consideration. For more information, seeReliability in Azure AI Search.
Free services don't have fixed partitions or replicas and share resources with other subscribers.
Partition storage (GB)
Per-service storage limits vary by two things:service creation dateandregion. There are higher limits fornewer servicesin most supported regions.
This table shows the progression of storage quota increases in GB over time. Starting in April 2024, higher capacity partitions were brought online in the regions listed in the footnotes. If you have an older service in a supported region, check if you canupgrade your serviceto the higher storage limits.
1Higher capacity storage for Basic, S1, S2, S3 in these regions.Americas: Brazil Southâ, Canada Centralâ, Canada Eastââ, East USâ, East US 2, âCentral USâ, North Central USâ, South Central USâ, West USâ, West US 2â, West US 3â, West Central US.Europe: France Centralâ. Italy Northââ, North Europeââ, Norway East, Poland Centralââ, Switzerland Northâ, Sweden Centralâ, UK Southâ, UK Westâ.Middle East:  UAE North.Africa: South Africa North.Asia Pacific: Australia Eastâ, Australia Southeastââ, Central India, Jio India Westâ, East Asia, Southeast Asiaâ, Japan East, Japan Westâ, Korea Central, Korea Southâ.
2Higher capacity storage for L1 and L2. More regions provide higher capacity at every billable tier.Europe: Germany Northâ, Germany West Central, Switzerland Westâ.Azure Government: Texas, Arizona, Virginia.Africa: South Africa Northâ.Asia Pacific: China North 3, China East 3.
3Higher capacity storage is available in West Europe.
Important
Currently, higher storage limits aren't available in the following regions, which are subject to the pre-April 3 limits.
Israel Central
Qatar Central
â Spain Central
South India
Index limits
1Basic services created before December 2017 have lower limits (5 instead of 15) on indexes. Basic tier is the only tier with a lower limit of 100 fields per index.
2The upper limit on fields includes both first-level fields and nested subfields in a complex collection. For example, if an index contains 15 fields and has two complex collections with five subfields each, the field count of your index is 25. Indexes with a very large fields collection can be slow.Limit fields and attributesto just those you need, and run indexing and query test to ensure performance is acceptable.
3An upper limit exists for elements because having a large number of them significantly increases the storage required for your index. An element of a complex collection is defined as a member of that collection. For example, assume aHotel document with a Rooms complex collection, each room in the Rooms collection is considered an element. During indexing, the indexing engine can safely process a maximum of 3,000 elements across the document as a whole.This limitwas introduced inapi-version=2019-05-06and applies to complex collections only, and not to string collections or to complex fields.
api-version=2019-05-06
4For most tiers, the maximum index size is the total available storage on your search service. For S2, S3, and S3 HD services with multiple partitions, and therefore more storage, the maximum size of a single index is provided in the table. Applies to search services created after April 3, 2024.
You might find some variation in maximum limits if your service happens to be provisioned on a more powerful cluster. The limits here represent the common denominator. Indexes built to the above specifications are portable across equivalent service tiers in any region.
Document limits
Maximum number of documents per index are:
24 billion on Basic, S1, S2, S3
2 billion on S3 HD
288 billion on L1
576 billion on L2
Maximum size of each document is approximately 16 megabytes. Document size is actually a limit on the size of the indexing API request payload, which is 16 megabytes. That payload can be a single document, or a batch of documents. For a batch with a single document, the maximum document size is 16 MB of JSON.
Document size applies topush modeindexing that uploads documents to a search service. If you're using an indexer forpull modeindexing, your source files can be any file size, subject toindexer limits. For the blob indexer, file size limits are larger for higher tiers. For example, the S1 limit is 128 megabytes, S2 limit is 256 megabytes, and so forth.
When estimating document size, remember to index only those fields that add value to your search scenarios, and exclude any source fields that have no purpose in the queries you intend to run.
Vector index size limits
When you index documents with vector fields, Azure AI Search constructs internal vector indexes using the algorithm parameters you provide. The size of these vector indexes is restricted by the memory reserved for vector search for your service's tier (orSKU). For guidance on managing and maximizing vector storage, seeVector index size and staying under limits.
SKU
Vector limits vary by:
Service creation date
Region
Higher vector limits from April 2024 onwards exist onnew search servicesin regions providing the extra capacity, which is most of them. If you have an older service in a supported region, check if you canupgrade your serviceto the higher vector limits.
This table shows the progression of vector quota increases in GB over time. The quota is per partition, so if you scale a new Standard (S1) service to 6 partitions, the total vector quota is 35 multiplied by 6.
1Initial vector limits during early preview.
2Vector limits during the later preview period. Three regions didn't have the higher limits: Germany West Central, West India, Qatar Central.
3Higher vector quota based on the larger partitions for supported tiers and regions.
4Higher vector quota for more tiers and regions based on partition size updates.
The service enforces a vector index size quotafor every partitionin your search service. Each extra partition increases the available vector index size quota. This quota is a hard limit to ensure your service remains healthy, which means that further indexing attempts once the limit is exceeded results in failure. You can resume indexing once you free up available quota by either deleting some vector documents or by scaling up in partitions.
Important
Higher vector limits are tied tolarger partition sizes. Currently, higher vector limits aren't available in the following regions, which are subject to the JulyâApril limits.
Israel Central
Qatar Central
â Spain Central
South India
Indexer limits
Maximum running times exist to provide balance and stability to the service as a whole, but larger data sets might need more indexing time than the maximum allows. If an indexing job can't complete within the maximum time allowed, try running it on a schedule. The scheduler keeps track of indexing status. If a scheduled indexing job is interrupted for any reason, the indexer can pick up where it last left off at the next scheduled run.
1Free services have indexer maximum execution time of 3 minutes for blob sources and 1 minute for all other data sources. Indexer invocation is once every 180 seconds. For AI indexing that calls into Azure AI services, free services are limited to 20 free transactions per indexer per day, where a transaction is defined as a document that successfully passes through the enrichment pipeline (tip: you can reset an indexer to reset its count).
2Basic services created before December 2017 have lower limits (5 instead of 15) on indexers, data sources, and skillsets.
3S3 HD services don't include indexer support.
4Maximum of 30 skills per skillset.
5Regarding the 2 or 24 hour maximum duration for indexers: a 2-hour maximum is the most common and it's what you should plan for. It refers to indexers that run in thepublic environment, used to offload computationally intensive processing and leave more resources for queries. The 24-hour limit applies if you configure the indexer to run in a private environment using only the infrastructure that's allocated to your search service. Note that some older indexers are incapable of running in the public environment, and those indexers always have a 24-hour processing range. If you have unscheduled indexers that run continuously for 24 hours, you can assume those indexers couldn't be migrated to the newer infrastructure. As a general rule, for indexing jobs that can't finish within two hours, put the indexer on a5 minute scheduleso that the indexer can quickly pick up where it left off. On the Free tier, the 3-10 minute maximum running time is for indexers with skillsets.
6The maximum number of characters is based on Unicode code units, specifically UTF-16.
Note
As stated in theIndex limits, indexers will also enforce the upper limit of 3000 elements across all complex collections per document starting with the latest GA API version that supports complex types (2019-05-06) onwards. This means that if you've created your indexer with a prior API version, you will not be subject to this limit. To preserve maximum compatibility, an indexer that was created with a prior API version and then updated with an API version2019-05-06or later, will still beexcludedfrom the limits. Customers should be aware of the adverse impact of having very large complex collections (as stated previously) and we highly recommend creating any new indexers with the latest GA API version.
2019-05-06
2019-05-06
Shared private link resource limits
Indexers can access other Azure resourcesover private endpointsmanaged via theshared private link resource API. This section describes the limits associated with this capability.
1AI enrichment and image analysis are computationally intensive and consume disproportionate amounts of available processing power. For this reason, private connections are disabled on lower tiers to ensure the performance and stability of the search service itself. On Basic services, private connections to an Azure AI services multi-service resource are unsupported to preserve service stability. For the S1 tier, make sure the service was created withhigher limitsafter April 3, 2024.
2Private connections to an embedding model are supported on Basic and S1 high-capacity search services created after April 3, 2024, with thehigher limitsfor storage and computational processing.
3The number of distinct resource types are computed as the number of uniquegroupIdvalues used across all shared private link resources for a given search service, irrespective of the status of the resource.
groupId
Synonym limits
Maximum number of synonym maps varies by tier. Each rule can have up to 20 expansions, where an expansion is an equivalent term. For example, given "cat", association with "kitty", "feline", and "felis" (the genus for cats) would count as 3 expansions.
Index alias limits
Maximum number ofindex aliasesvaries by tier andservice creation date. In all tiers, if the service was created after October 2022 the maximum number of aliases is double the maximum number of indexes allowed. If the service was created before October 2022, the limit is the number of indexes allowed.
1Basic services created before December 2017 have lower limits (5 instead of 15) on indexes
Data limits (AI enrichment)
AnAI enrichment pipelinethat makes calls to an Azure AI Language resource forentity recognition,entity linking,key phrase extraction,sentiment analysis,language detection, andpersonal-information detectionis subject to data limits. The maximum size of a record should be 50,000 characters as measured byString.Length. If you need to break up your data before sending it to the sentiment analyzer, use theText Split skill.
String.Length
Throttling limits
API requests are throttled as the system approaches peak capacity. Throttling behaves differently for different APIs. Query APIs (Search/Suggest/Autocomplete) and indexing APIs throttle dynamically based on the load on the service. Index APIs and service operations API have static request rate limits.
Static rate request limits for operations related to an index:
List Indexes (GET /indexes): 3 per second per search unit
Get Index (GET /indexes/myindex): 10 per second per search unit
Create Index (POST /indexes): 12 per minute per search unit
Create or Update Index (PUT /indexes/myindex): 6 per second per search unit
Delete Index (DELETE /indexes/myindex): 12 per minute per search unit
Static rate request limits for operations related to a service:
Service Statistics (GET /servicestats): 4 per second per search unit
Semantic ranker throttling limits
Semantic rankeruses a queuing system to manage concurrent requests. This system allows search services get the highest number of queries per second possible. When the limit of concurrent requests is reached, additional requests are placed in a queue. If the queue is full, further requests are rejected and must be retried.
Total semantic ranker queries per second varies based on the following factors:
The tier of the search service. Both queue capacity and concurrent request limits vary by tier.
The number of search units in the search service. The simplest way to increase the maximum number of concurrent semantic ranker queries is toadd more search units to your search service.
The total available semantic ranker capacity in the region.
The amount of time it takes to serve a query using semantic ranker. This varies based on how busy the search service is.
The following table describes the semantic ranker throttling limits by tier, subject to available capacity in the region. You can contact Microsoft support to request a limit increase.
API request limits
Limits on queries exist because unbounded queries can destabilize your search service. Typically, such queries are created programmatically. If your application generates search queries programmatically, we recommend designing it in such a way that it doesn't generate queries of unbounded size.
Limits on payloads exist for similar reasons, ensuring the stability of your search service. The limit applies to the entire request, inclusive of all its components. For example, if the request batches several documents or commands, the entire request must fit within the supported limit.
If you must exceed a supported limit, you shouldtest your workloadso that you know what to expect.
Except where noted, the following API requests apply to all programmable interfaces, including the Azure SDKs.
General:
Supported maximum payload limit is 16 MB for indexing and query request via REST API and SDKs.
Maximum 8-KB URL length (applies to REST APIs only).
Indexing APIs:
Supported maximum 1,000 documents per batch of index uploads, merges, or deletes.
Query APIs:
Maximum 32 fields in $orderby clause.
Maximum 100,000 characters in a search clause.
Maximum number of clauses inâ¯search is 3,000.
Maximum limits onwildcardandregular expressionqueries, as enforced byLucene. It caps the number of patterns, variations, or matches to 1,000 instances. This limit is in place to avoid engine overload.
Search terms:
Supported maximum search term size is 32,766 bytes (32 KB minus 2 bytes) of UTF-8 encoded text. Applies to keyword search and the text property of vector search.
Supported maximum search term size is 1,000 characters forprefix searchandregex search.
API response limits
Maximum 1,000 documents returned per page of search results
Maximum 100 suggestions returned per Suggest API request
The search engine returns 50 results by default, but you canoverride this parameterup to the maximum limit.
API key limits
API keys are used for service authentication. There are two types. Admin keys are specified in the request header and grant full read-write access to the service. Query keys are read-only, specified on the URL, and typically distributed to client applications.
Maximum of 2 admin keys per service
Maximum of 50 query keys per service
Feedback
Was this page helpful?
Additional resources