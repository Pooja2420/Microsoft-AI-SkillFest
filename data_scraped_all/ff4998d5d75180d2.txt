Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Image captions (version 4.0)
Article
2024-09-25
4 contributors
In this article
Image captions in Image Analysis 4.0 are available through theCaptionandDense Captionsfeatures.
The Caption feature generates a one-sentence description of all the image contents. Dense Captions provides more detail by generating one-sentence descriptions of up to 10 different regions of the image in addition to describing the whole image. Dense Captions also returns bounding box coordinates of the described image regions. Both of these features use the latest Florence-based AI models.
Image captioning is available in English only.
Important
Image captioning in Image Analysis 4.0 is only available in certain Azure data center regions: seeRegion availability. You must use an Azure AI Vision resource located in one of these regions to get results from Caption and Dense Captions features.
If you need to use a Vision resource outside these regions to generate image captions, please useImage Analysis 3.2which is available in all Azure AI Vision regions.
Try out the image captioning features quickly and easily in your browser using Vision Studio.
Try Vision Studio
Gender-neutral captions
By default, captions contain gender terms ("man", "woman", "boy" and "girl"). You have the option to replace these terms with "person" in your results and receive gender-neutral captions. You can do so by setting the optional API request parametergender-neutral-captiontotruein the request URL.
gender-neutral-caption
true
Caption and Dense Captions examples
Caption
Dense Captions
The following JSON response illustrates what the Image Analysis 4.0 API returns when describing the example image based on its visual features.

"captions": [
    {
        "text": "a man pointing at a screen",
        "confidence": 0.4891590476036072
    }
]
"captions": [
    {
        "text": "a man pointing at a screen",
        "confidence": 0.4891590476036072
    }
]
The following JSON response illustrates what the Image Analysis 4.0 API returns when generating dense captions for the example image.

{
  "denseCaptionsResult": {
    "values": [
      {
        "text": "a man driving a tractor in a farm",
        "confidence": 0.535620927810669,
        "boundingBox": {
          "x": 0,
          "y": 0,
          "w": 850,
          "h": 567
        }
      },
      {
        "text": "a man driving a tractor in a field",
        "confidence": 0.5428450107574463,
        "boundingBox": {
          "x": 132,
          "y": 266,
          "w": 209,
          "h": 219
        }
      },
      {
        "text": "a blurry image of a tree",
        "confidence": 0.5139822363853455,
        "boundingBox": {
          "x": 147,
          "y": 126,
          "w": 76,
          "h": 131
        }
      },
      {
        "text": "a man riding a tractor",
        "confidence": 0.4799223840236664,
        "boundingBox": {
          "x": 206,
          "y": 264,
          "w": 64,
          "h": 97
        }
      },
      {
        "text": "a blue sky above a hill",
        "confidence": 0.35495415329933167,
        "boundingBox": {
          "x": 0,
          "y": 0,
          "w": 837,
          "h": 166
        }
      },
      {
        "text": "a tractor in a field",
        "confidence": 0.47338250279426575,
        "boundingBox": {
          "x": 0,
          "y": 243,
          "w": 838,
          "h": 311
        }
      }
    ]
  },
  "modelVersion": "2024-02-01",
  "metadata": {
    "width": 850,
    "height": 567
  }
}
{
  "denseCaptionsResult": {
    "values": [
      {
        "text": "a man driving a tractor in a farm",
        "confidence": 0.535620927810669,
        "boundingBox": {
          "x": 0,
          "y": 0,
          "w": 850,
          "h": 567
        }
      },
      {
        "text": "a man driving a tractor in a field",
        "confidence": 0.5428450107574463,
        "boundingBox": {
          "x": 132,
          "y": 266,
          "w": 209,
          "h": 219
        }
      },
      {
        "text": "a blurry image of a tree",
        "confidence": 0.5139822363853455,
        "boundingBox": {
          "x": 147,
          "y": 126,
          "w": 76,
          "h": 131
        }
      },
      {
        "text": "a man riding a tractor",
        "confidence": 0.4799223840236664,
        "boundingBox": {
          "x": 206,
          "y": 264,
          "w": 64,
          "h": 97
        }
      },
      {
        "text": "a blue sky above a hill",
        "confidence": 0.35495415329933167,
        "boundingBox": {
          "x": 0,
          "y": 0,
          "w": 837,
          "h": 166
        }
      },
      {
        "text": "a tractor in a field",
        "confidence": 0.47338250279426575,
        "boundingBox": {
          "x": 0,
          "y": 243,
          "w": 838,
          "h": 311
        }
      }
    ]
  },
  "modelVersion": "2024-02-01",
  "metadata": {
    "width": 850,
    "height": 567
  }
}
Use the API
Image captions
Dense captions
The image captioning feature is part of theAnalyze ImageAPI. IncludeCaptionin thefeaturesquery parameter. Then, when you get the full JSON response, parse the string for the contents of the"captionResult"section.
Caption
"captionResult"
The dense captioning feature is part of theAnalyze ImageAPI. IncludedenseCaptionsin thefeaturesquery parameter. Then, when you get the full JSON response, parse the string for the contents of the"denseCaptionsResult"section.
denseCaptions
"denseCaptionsResult"
Next steps
Learn the related concept ofobject detection.
Quickstart: Image Analysis REST API or client libraries
Call the Analyze Image API
Feedback
Was this page helpful?
Additional resources