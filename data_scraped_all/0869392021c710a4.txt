Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Data format options
Article
2024-10-12
2 contributors
In this article
Azure Databricks has built-in keyword bindings for all of the data formats natively supported by Apache Spark. Azure Databricks uses Delta Lake as the default protocol for reading and writing data and tables, whereas Apache Spark uses Parquet.
These articles provide an overview of many of the options and configurations available when you query data on Azure Databricks.
The following data formats have built-in keyword configurations in Apache Spark DataFrames and SQL:
Delta Lake
Delta Sharing
Parquet
ORC
JSON
CSV
Avro
Text
Binary
XML
Azure Databricks also provides a custom keyword for loadingMLflow experiments.
Data formats with special considerations
Some data formats require additional configuration or special considerations for use:
Databricks recommends loadingimagesasbinarydata.
binary
Azure Databricks can directly read compressed files in many file formats. You can alsounzip compressed fileson Azure Databricks if necessary.
For more information about Apache Spark data sources, seeGeneric Load/Save FunctionsandGeneric File Source Options.
Feedback
Was this page helpful?
Additional resources