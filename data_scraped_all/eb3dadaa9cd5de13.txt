Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Ingest from query (.set, .append, .set-or-append, .set-or-replace)
Article
2024-11-27
20 contributors
In this article
Applies to: 창혵Microsoft Fabric창혵Azure Data Explorer
These commands execute a query or a management command and ingest the results of the query into a table. The difference between these commands is how they treat existing or nonexistent tables and data.
.set
.append
.set-or-append
.set-or-replace
To cancel an ingest from query command, seecancel operation.
cancel operation
Note
Ingest from query is adirect ingestion. As such, it does not include automatic retries. Automatic retries are available when ingesting through the data management service. Use theingestion overviewdocument to decide which is the most suitable ingestion option for your scenario.
Note
Ingest from query is adirect ingestion. As such, it does not include automatic retries. Automatic retries are available when ingesting through the data management service.
Permissions
To perform different actions on a table, you need specific permissions:
To add rows to an existing table using the.appendcommand, you need a minimum of Table Ingestor permissions.
.append
To create a new table using the various.setcommands, you need a minimum of Database User permissions.
.set
To replace rows in an existing table using the.set-or-replacecommand, you need a minimum of Table Admin permissions.
.set-or-replace
For more information on permissions, seeKusto role-based access control.
Syntax
(.set|.append|.set-or-append|.set-or-replace) [async]tableName[with(propertyName=propertyValue[,...])]<|queryOrCommand
.set
.append
.set-or-append
.set-or-replace
async
with
(
=
,
)
<|
Learn more aboutsyntax conventions.
Parameters
string
OperationId
.show operations
string
string
string
.show
Performance tips
Set thedistributedproperty totrueif the amount of data produced by the query is large, exceeds one gigabyte (GB), and doesn't require serialization. Then, multiple nodes can produce output in parallel. Don't use this flag when query results are small, since it might needlessly generate many small data shards.
distributed
true
Data ingestion is a resource-intensive operation that might affect concurrent activities on the database, including running queries. Avoid running too many ingestion commands at the same time.
Limit the data for ingestion to less than one GB per ingestion operation. If necessary, use multiple ingestion commands.
Supported ingestion properties
distributed
bool
true
false
creationTime
string
datetime
string
now()
Lookback
extend_schema
bool
true
false
.append
.set-or-append
set-or-replace
recreate_schema
bool
true
false
.set-or-replace
extend_schema
folder
string
ingestIfNotExists
string
ingest-by:
policy_ingestiontime
bool
true
true
tags
string
string
docstring
string
persistDetails
false
with (persistDetails=true)
Schema considerations
.set-or-replacepreserves the schema unless one ofextend_schemaorrecreate_schemaingestion properties is set totrue.
.set-or-replace
extend_schema
recreate_schema
true
.set-or-appendand.appendcommands preserve the schema unless theextend_schemaingestion property is set totrue.
.set-or-append
.append
extend_schema
true
Matching the result set schema to that of the target table is based on the column types. There's no matching of column names. Make sure that the query result schema columns are in the same order as the table, otherwise data is ingested into the wrong columns.
Caution
If the schema is modified, it happens in a separate transaction before the actual data ingestion. This means the schema might be modified even when there is a failure to ingest the data.
Character limitation
The command fails if the query generates an entity name with the$character. Theentity namesmust comply with the naming rules, so the$character must be removed for the ingest command to succeed.
$
$
For example, in the following query, thesearchoperator generates a column$table. To store the query results, useproject-renameto rename the column.
search
$table
.set Texas <| search State has 'Texas' | project-rename tableName=$table
.set Texas <| search State has 'Texas' | project-rename tableName=$table
Returns
Returns information on the extents created because of the.setor.appendcommand.
.set
.append
Examples
Create and update table from query source
The following query creates theRecentErrorstable with the same schema asLogsTable. It updatesRecentErrorswith all error logs fromLogsTableover the last hour.
.set RecentErrors <|
   LogsTable
   | where Level == "Error" and Timestamp > now() - time(1h)
.set RecentErrors <|
   LogsTable
   | where Level == "Error" and Timestamp > now() - time(1h)
Create and update table from query source using thedistributedflag
The following example creates a new table calledOldExtentsin the database, asynchronously. The dataset is expected to be bigger than one GB (more than ~one million rows) so thedistributedflag is used. It updatesOldExtentswithExtentIdentries from theMyExtentstable that were created more than 30 days ago.
OldExtents
OldExtents
ExtentId
MyExtents
.set async OldExtents with(distributed=true) <|
   MyExtents 
   | where CreatedOn < now() - time(30d)
   | project ExtentId
.set async OldExtents with(distributed=true) <|
   MyExtents 
   | where CreatedOn < now() - time(30d)
   | project ExtentId
Append data to table
The following example filtersExtentIdentries in theMyExtentstable that were created more than 30 days ago and appends the entries to theOldExtentstable with associated tags.
ExtentId
MyExtents
OldExtents
.append OldExtents with(tags='["TagA","TagB"]') <| 
   MyExtents 
   | where CreatedOn < now() - time(30d) 
   | project ExtentId
.append OldExtents with(tags='["TagA","TagB"]') <| 
   MyExtents 
   | where CreatedOn < now() - time(30d) 
   | project ExtentId
Create or append a table with possibly existing tagged data
The following example either appends to or creates theOldExtentstable asynchronously. It filtersExtentIdentries in theMyExtentstable that were created more than 30 days ago and specifies the tags to append to the new extents withingest-by:myTag. TheingestIfNotExistsparameter ensures that the ingestion only occurs if the data doesn't already exist in the table with the specified tag.
OldExtents
ExtentId
MyExtents
ingest-by:myTag
ingestIfNotExists
.set-or-append async OldExtents with(tags='["ingest-by:myTag"]', ingestIfNotExists='["myTag"]') <|
   MyExtents
   | where CreatedOn < now() - time(30d)
   | project ExtentId
.set-or-append async OldExtents with(tags='["ingest-by:myTag"]', ingestIfNotExists='["myTag"]') <|
   MyExtents
   | where CreatedOn < now() - time(30d)
   | project ExtentId
Create table or replace data with associated data
The following query replaces the data in theOldExtentstable, or creates the table if it doesn't already exist, withExtentIdentries in theMyExtentstable that were created more than 30 days ago. Tag the new extent withingest-by:myTagif the data doesn't already exist in the table with the specified tag.
OldExtents
ExtentId
MyExtents
ingest-by:myTag
.set-or-replace async OldExtents with(tags='["ingest-by:myTag"]', ingestIfNotExists='["myTag"]') <| 
   MyExtents 
   | where CreatedOn < now() - time(30d) 
   | project ExtentId
.set-or-replace async OldExtents with(tags='["ingest-by:myTag"]', ingestIfNotExists='["myTag"]') <| 
   MyExtents 
   | where CreatedOn < now() - time(30d) 
   | project ExtentId
Append data with associated data
The following example appends data to theOldExtentstable asynchronously, usingExtentIdentries from theMyExtentstable that were created more than 30 days ago. It sets a specific creation time for the new extents.
OldExtents
ExtentId
MyExtents
.append async OldExtents with(creationTime='2017-02-13T11:09:36.7992775Z') <| 
   MyExtents 
   | where CreatedOn < now() - time(30d) 
   | project ExtentId
.append async OldExtents with(creationTime='2017-02-13T11:09:36.7992775Z') <| 
   MyExtents 
   | where CreatedOn < now() - time(30d) 
   | project ExtentId
Sample output
The following is a sample of the type of output you may see from your queries.
Related content
Data formats supported for ingestion
Inline ingestion
Ingest from storage
Feedback
Was this page helpful?
Additional resources