Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Quickstart: Use the Copy Data tool in Azure Data Factory Studio to copy data
Article
2025-04-10
3 contributors
In this article
APPLIES TO:Azure Data FactoryAzure Synapse Analytics
Tip
Try outData Factory in Microsoft Fabric, an all-in-one analytics solution for enterprises.Microsoft Fabriccovers everything from data movement to data science, real-time analytics, business intelligence, and reporting. Learn how tostart a new trialfor free!
In this quickstart, you use the Copy Data tool in Azure Data Factory Studio to create a pipeline that copies data from a source folder in Azure Blob Storage to a target folder.
Prerequisites
Azure subscription
If you don't have an Azure subscription, create afree accountbefore you begin.
Prepare source data in Azure Blob Storage
To prepare source data by using a template:
Select the following button.
Select the following button.

You're directed to the configuration page to deploy the template. On this page:ForResource group, selectCreate newto create a resource group. You can leave all the other values with their defaults.SelectReview + create, and then selectCreateto deploy the resources.
You're directed to the configuration page to deploy the template. On this page:
ForResource group, selectCreate newto create a resource group. You can leave all the other values with their defaults.
ForResource group, selectCreate newto create a resource group. You can leave all the other values with their defaults.
SelectReview + create, and then selectCreateto deploy the resources.
SelectReview + create, and then selectCreateto deploy the resources.

Note
The user who deploys the template needs to assign a role to a managed identity. This step requires permissions that can be granted through the Owner, User Access Administrator, or Managed Identity Operator role.
A new Blob Storage account is created in the new resource group. The moviesDB2.csv file is stored in a folder calledinputin Blob Storage.
Create a data factory
You can use your existing data factory, or you can create a new one as described inQuickstart: Create a data factory.
Use the Copy Data tool to copy data
The Copy Data tool has five pages that walk you through the task of copying data. To start the tool:
InAzure Data Factory Studio, go to your data factory.
InAzure Data Factory Studio, go to your data factory.
Select theIngesttile.
Select theIngesttile.

Step 1: Select the task type
On thePropertiespage of the Copy Data tool, chooseBuilt-in copy taskunderTask type.
On thePropertiespage of the Copy Data tool, chooseBuilt-in copy taskunderTask type.
SelectNext.
SelectNext.

Step 2: Complete source configuration
On theSourcepage of the Copy Data tool, select+ Create new connectionto add a connection.
On theSourcepage of the Copy Data tool, select+ Create new connectionto add a connection.
Select the linked service type that you want to create for the source connection. (The example in this quickstart usesAzure Blob Storage.) Then selectContinue.
Select the linked service type that you want to create for the source connection. (The example in this quickstart usesAzure Blob Storage.) Then selectContinue.

In theNew connection (Azure Blob Storage)dialog:ForName, specify a name for your connection.UnderAccount selection method, selectFrom Azure subscription.In theAzure subscriptionlist, select your Azure subscription.In theStorage account namelist, select your storage account.SelectTest connectionand confirm that the connection is successful.SelectCreate.
In theNew connection (Azure Blob Storage)dialog:
ForName, specify a name for your connection.
UnderAccount selection method, selectFrom Azure subscription.
In theAzure subscriptionlist, select your Azure subscription.
In theStorage account namelist, select your storage account.
SelectTest connectionand confirm that the connection is successful.
SelectCreate.

UnderSource data store:ForConnection, select the newly created connection.In theFile or foldersection, selectBrowseto go to theadftutorial/inputfolder. Select themoviesDB2.csvfile, and then selectOK.Select theBinary copycheckbox to copy the file as is.SelectNext.
UnderSource data store:
ForConnection, select the newly created connection.
In theFile or foldersection, selectBrowseto go to theadftutorial/inputfolder. Select themoviesDB2.csvfile, and then selectOK.
Select theBinary copycheckbox to copy the file as is.
SelectNext.

Step 3: Complete destination configuration
On theTargetpage of the Copy Data tool, forConnection, select theAzureBlobStorageconnection that you created.
On theTargetpage of the Copy Data tool, forConnection, select theAzureBlobStorageconnection that you created.
In theFolder pathsection, enteradftutorial/output.
In theFolder pathsection, enteradftutorial/output.

Leave other settings as default. SelectNext.
Leave other settings as default. SelectNext.
Step 4: Enter a name and description for the pipeline
On theSettingspage of the Copy Data tool, specify a name for the pipeline and its description.
On theSettingspage of the Copy Data tool, specify a name for the pipeline and its description.
SelectNextto use other default configurations.
SelectNextto use other default configurations.

Step 5: Review settings and deploy
On theReview and finishpage, review all settings.
On theReview and finishpage, review all settings.
SelectNext.
SelectNext.
TheDeployment completepage shows whether the deployment is successful.
Monitor the running results
After you finish copying the data, you can monitor the pipeline that you created:
On theDeployment completepage, selectMonitor.
On theDeployment completepage, selectMonitor.

The application switches to theMonitortab, which shows the status of the pipeline. SelectRefreshto refresh the list of pipelines. Select the link underPipeline nameto view activity run details or to rerun the pipeline.
The application switches to theMonitortab, which shows the status of the pipeline. SelectRefreshto refresh the list of pipelines. Select the link underPipeline nameto view activity run details or to rerun the pipeline.

On the page that shows the details of the activity run, select theDetailslink (eyeglasses icon) in theActivity namecolumn for more details about the copy operation. For information about the properties, see theoverview article about the copy activity.
On the page that shows the details of the activity run, select theDetailslink (eyeglasses icon) in theActivity namecolumn for more details about the copy operation. For information about the properties, see theoverview article about the copy activity.
Related content
The pipeline in this sample copies data from one location to another location in Azure Blob Storage. To learn about using Data Factory in more scenarios, see the following tutorial:
Copy data from Azure Blob storage to a database in Azure SQL Database by using Azure Data Factory
Feedback
Was this page helpful?
Additional resources