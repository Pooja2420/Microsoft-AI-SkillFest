Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Migrate your PostgreSQL database by using dump and restore
Article
2025-01-24
4 contributors
In this article
APPLIES TO:Azure Database for PostgreSQL flexible server
You can usepg_dumpto extract a PostgreSQL database into a dump file. The method to restore the database depends on the format of the dump you choose. If your dump is taken with the plain format (which is the default-Fp, so no specific option needs to be specified), then the only option to restore it is by usingpsql, as it outputs a plain text file. For the other three dump methods: custom, directory, and tar,pg_restoreshould be used.
-Fp
Important
The instructions and commands provided in this article are designed to be executed in bash terminals. This includes environments such as Windows Subsystem for Linux (WSL), Azure Cloud Shell, and other bash-compatible interfaces. Please ensure you are using a bash terminal to follow the steps and execute the commands detailed in this guide. Using a different type of terminal or shell environment might result in differences in command behavior and might not produce the intended outcomes.
In this article, we focus on the plain (default) and directory formats. The directory format is useful as it allows you to use multiple cores for processing, which can significantly enhance efficiency, especially for large databases.
The Azure portal streamlines this process via the Connect blade by offering preconfigured commands that are tailored to your server, with values substituted with your user data. It's important to note that the Connect blade is only available for Azure Database for PostgreSQL flexible server and not for Single Server. Here's how you can use this feature:
Access Azure portal: First, go to the Azure portal and choose the Connect blade.
Access Azure portal: First, go to the Azure portal and choose the Connect blade.

Select your database: In the Connect blade, you find a dropdown list of your databases. Select the database you wish to perform a dump from.
Select your database: In the Connect blade, you find a dropdown list of your databases. Select the database you wish to perform a dump from.

Choose the appropriate method: Depending on your database size, you can choose between two methods:pg_dump&psql- using singular text file**: Ideal for smaller databases, this option utilizes a single text file for the dump and restore process.pg_dump&pg_restore- using multiple cores**: For larger databases, this method is more efficient as it uses multiple cores to handle the dump and restore process.
Choose the appropriate method: Depending on your database size, you can choose between two methods:
pg_dump&psql- using singular text file**: Ideal for smaller databases, this option utilizes a single text file for the dump and restore process.
pg_dump
psql
pg_dump&pg_restore- using multiple cores**: For larger databases, this method is more efficient as it uses multiple cores to handle the dump and restore process.
pg_dump
pg_restore

Copy and paste commands: The portal provides you with ready to usepg_dumpandpsqlorpg_restorecommands. These commands come with values already substituted according to the server and database you've chosen. Copy and paste these commands.
Copy and paste commands: The portal provides you with ready to usepg_dumpandpsqlorpg_restorecommands. These commands come with values already substituted according to the server and database you've chosen. Copy and paste these commands.
pg_dump
psql
pg_restore
Prerequisites
If you're using a Single Server, or don't have access to the Flexible Server portal, read through this documentation page. It contains information that is similar to what is presented in the Connect blade for Flexible Server on the portal.
Note
Becausepg_dump,psql,pg_restoreandpg_dumpallutilities all rely on libpq, you can use any of the supportedenvironment variablesit offers, or you can use thepassword fileto avoid being prompted for the password every time you run any of these commands.
pg_dump
psql
pg_restore
pg_dumpall
To step through this how-to guide, you need:
AnAzure Database for PostgreSQL server, including firewall rules to allow access.
pg_dump,psql,pg_restoreandpg_dumpallin case you want to migrate with roles and permissions, command-line utilities installed.
Decide on the location for the dump: Choose the place you want to perform the dump from. It can be done from various locations, such as a separate VM,cloud shell(where the command-line utilities are already installed, but might not be in the appropriate version, so always check the version using, for instance,psql --version), or your own laptop. Always keep in mind the distance and latency between the PostgreSQL server and the location from which you're running the dump or restore.
psql --version
Important
It is essential to use thepg_dump,psql,pg_restoreandpg_dumpallutilities that are either of the same major version or a higher major version than the database server you are exporting data from or importing data to. Failing to do so might result in unsuccessful data migration. If your target server has a higher major version than the source server, use utilities that are either the same major version or higher than the target server.
pg_dump
psql
pg_restore
pg_dumpall
Note
It's important to be aware thatpg_dumpcan export only one database at a time. This limitation applies regardless of the method you have chosen, whether it's using a singular file or multiple cores.
pg_dump
Dumping users and roles withpg_dumpall -r
pg_dumpall -r
pg_dumpis used to extract a PostgreSQL database into a dump file. However, it's crucial to understand thatpg_dumpdoes not dump roles or users definitions, as these are considered global objects within the PostgreSQL environment. For a comprehensive migration, including users and roles, you need to usepg_dumpall -r.This command allows you to capture all role and user information from your PostgreSQL environment. If you're migrating within databases on the same server, please feel free to skip this step and move to theCreate a new databasesection.
pg_dump
pg_dump
pg_dumpall -r
pg_dumpall -r -h <server name> -U <user name> > roles.sql
pg_dumpall -r -h <server name> -U <user name> > roles.sql
For example, if you have a server namedmydemoserverand a user namedmyuserrun the following command:
mydemoserver
myuser
pg_dumpall -r -h mydemoserver.postgres.database.azure.com -U myuser > roles.sql
pg_dumpall -r -h mydemoserver.postgres.database.azure.com -U myuser > roles.sql
If you're using a Single Server, your username includes the server name component. Therefore, instead ofmyuser, usemyuser@mydemoserver.
myuser
myuser@mydemoserver
Dumping Roles from a Flexible Server
In a Flexible Server environment, enhanced security measures mean users don't have access to the pg_authid table, which is where role passwords are stored. This restriction affects how you perform a roles dump, as the standardpg_dumpall -rcommand attempts to access this table for passwords and fail due to lack of permission.
pg_dumpall -r
When dumping roles from a Flexible Server, it's crucial to include the--no-role-passwordsoption in yourpg_dumpallcommand. This option preventspg_dumpallfrom attempting to access thepg_authidtable, which it cannot read due to security restrictions.
--no-role-passwords
pg_dumpall
pg_dumpall
pg_authid
To successfully dump roles from a Flexible Server, use the following command:
pg_dumpall -r --no-role-passwords -h <server name> -U <user name> > roles.sql
pg_dumpall -r --no-role-passwords -h <server name> -U <user name> > roles.sql
For example, if you have a server namedmydemoserver, a user namedmyuser, run the following command:
mydemoserver
myuser
pg_dumpall -r --no-role-passwords -h mydemoserver.postgres.database.azure.com -U myuser > roles.sql
pg_dumpall -r --no-role-passwords -h mydemoserver.postgres.database.azure.com -U myuser > roles.sql
Cleaning up the roles dump
When migrating the output fileroles.sqlmight include certain roles and attributes that aren't applicable or permissible in the new environment. Here's what you need to consider:
roles.sql
Removing attributes that can be set only by superusers: If migrating to an environment where you don't have superuser privileges, remove attributes likeNOSUPERUSERandNOBYPASSRLSfrom the roles dump.
Removing attributes that can be set only by superusers: If migrating to an environment where you don't have superuser privileges, remove attributes likeNOSUPERUSERandNOBYPASSRLSfrom the roles dump.
NOSUPERUSER
NOBYPASSRLS
Excluding service-specific users: Exclude Single Server service users, such asazure_superuserorazure_pg_admin. These are specific to the service and will be created automatically in the new environment.
Excluding service-specific users: Exclude Single Server service users, such asazure_superuserorazure_pg_admin. These are specific to the service and will be created automatically in the new environment.
azure_superuser
azure_pg_admin
Use the followingsedcommand to clean up your roles dump:
sed
sed -i '/azure_superuser/d; /azure_pg_admin/d; /azuresu/d; /^CREATE ROLE replication/d; /^ALTER ROLE replication/d; /^ALTER ROLE/ {s/NOSUPERUSER//; s/NOBYPASSRLS//;}' roles.sql
sed -i '/azure_superuser/d; /azure_pg_admin/d; /azuresu/d; /^CREATE ROLE replication/d; /^ALTER ROLE replication/d; /^ALTER ROLE/ {s/NOSUPERUSER//; s/NOBYPASSRLS//;}' roles.sql
This command deletes lines containingazure_superuser,azure_pg_admin,azuresu, lines starting withCREATE ROLE replicationandALTER ROLE replication, and removes theNOSUPERUSERandNOBYPASSRLSattributes fromALTER ROLEstatements.
azure_superuser
azure_pg_admin
azuresu
CREATE ROLE replication
ALTER ROLE replication
NOSUPERUSER
NOBYPASSRLS
ALTER ROLE
Create a dump file that contains the data to be loaded
To export your existing PostgreSQL database on-premises or in a VM to an sql script file, run the following command in your existing environment:
pg_dump & psql - using singular text file
pg_dump & pg_restore - using multiple cores
pg_dump <database name> -h <server name> -U <user name> > <database name>_dump.sql
pg_dump <database name> -h <server name> -U <user name> > <database name>_dump.sql
For example, if you have a server namedmydemoserver, a user namedmyuserand a database calledtestdb, run the following command:
mydemoserver
myuser
testdb
pg_dump testdb -h mydemoserver.postgres.database.azure.com -U myuser > testdb_dump.sql
pg_dump testdb -h mydemoserver.postgres.database.azure.com -U myuser > testdb_dump.sql
pg_dump -Fd -j <number of cores> <database name> -h <server name> -U <user name> -f <database name>.dump
pg_dump -Fd -j <number of cores> <database name> -h <server name> -U <user name> -f <database name>.dump
In these commands, the-joption stands for the number of cores you wish to use for the dump process. You can adjust this number based on how many cores are available on your PostgreSQL server and how many you would like to allocate for the dump process. Feel free to change this setting depending on your server's capacity and your performance requirements.
-j
For example, if you have a server namedmydemoserver, a user namedmyuserand a database calledtestdb, and you want to use two cores for the dump, run the following command:
mydemoserver
myuser
testdb
pg_dump -Fd -j 2 testdb -h mydemoserver.postgres.database.azure.com -U myuser -f testdb.dump
pg_dump -Fd -j 2 testdb -h mydemoserver.postgres.database.azure.com -U myuser -f testdb.dump
If you're using a Single Server, your username includes the server name component. Therefore, instead ofmyuser, usemyuser@mydemoserver.
myuser
myuser@mydemoserver
Restore the data into the target database
Restore roles and users
Before restoring your database objects, make sure you have properly dumped and cleaned up the roles. If you're migrating within databases on the same server, both dumping the roles and restoring them might not be necessary. However, for migrations across different servers or environments, this step is crucial.
To restore the roles and users into the target database, use the following command:
psql -f roles.sql -h <server_name> -U <user_name>
psql -f roles.sql -h <server_name> -U <user_name>
Replace<server_name>with the name of your target server and<user_name>with your username. This command uses thepsqlutility to execute the SQL commands contained in theroles.sqlfile, effectively restoring the roles and users to your target database.
<server_name>
<user_name>
psql
roles.sql
For example, if you have a server namedmydemoserver, a user namedmyuser, run the following command:
mydemoserver
myuser
psql -f roles.sql -h mydemoserver.postgres.database.azure.com -U myuser
psql -f roles.sql -h mydemoserver.postgres.database.azure.com -U myuser
If you're using a Single Server, your username includes the server name component. Therefore, instead ofmyuser, usemyuser@mydemoserver.
myuser
myuser@mydemoserver
Note
If you already have users with the same names on your Single Server or on-premises server from which you are migrating, and your target server, be aware that this restoration process might change the passwords for these roles. Consequently, any subsequent commands you need to execute might require the updated passwords. This does not apply if your source server is a Flexible Server, as Flexible Server does not allow dumping passwords for users due to enhanced security measures.
Create a new database
Before restoring your database, you might need to create a new, empty database. To do this, user that you are using must have theCREATEDBpermission. Here are two commonly used methods:
CREATEDB
UsingcreatedbutilityThecreatedbprogram allows for database creation directly from the bash command line, without the need to log into PostgreSQL or leave the operating system environment. For instance:createdb <new database name> -h <server name> -U <user name>For example, if you have a server namedmydemoserver, a user namedmyuserand the new database you want to create istestdb_copy, run the following command:createdb testdb_copy -h mydemoserver.postgres.database.azure.com -U myuserIf you're using a Single Server, your username includes the server name component. Therefore, instead ofmyuser, usemyuser@mydemoserver.
UsingcreatedbutilityThecreatedbprogram allows for database creation directly from the bash command line, without the need to log into PostgreSQL or leave the operating system environment. For instance:
createdb
createdb
createdb <new database name> -h <server name> -U <user name>
createdb <new database name> -h <server name> -U <user name>
For example, if you have a server namedmydemoserver, a user namedmyuserand the new database you want to create istestdb_copy, run the following command:
mydemoserver
myuser
testdb_copy
createdb testdb_copy -h mydemoserver.postgres.database.azure.com -U myuser
createdb testdb_copy -h mydemoserver.postgres.database.azure.com -U myuser
If you're using a Single Server, your username includes the server name component. Therefore, instead ofmyuser, usemyuser@mydemoserver.
myuser
myuser@mydemoserver
Using SQL commandTo create a database using a SQL command, you'll need to connect to your PostgreSQL server via a command line interface or a database management tool. Once connected, you can use the following SQL command to create a new database:
Using SQL commandTo create a database using a SQL command, you'll need to connect to your PostgreSQL server via a command line interface or a database management tool. Once connected, you can use the following SQL command to create a new database:
CREATE DATABASE <new database name>;
CREATE DATABASE <new database name>;
Replace<new database name>with the name you wish to give your new database. For example, to create a database namedtestdb_copy, the command would be:
<new database name>
testdb_copy
CREATE DATABASE testdb_copy;
CREATE DATABASE testdb_copy;
Restoring the dump
After you've created the target database, you can restore the data into this database from the dump file. During the restoration, log any errors to anerrors.logfile and check its content for any errors after the restore is done.
errors.log
pg_dump & psql - using singular text file
pg_dump & pg_restore - using multiple cores
psql -f <database name>_dump.sql <new database name> -h <server name> -U <user name> 2> errors.log
psql -f <database name>_dump.sql <new database name> -h <server name> -U <user name> 2> errors.log
For example, if you have a server namedmydemoserver, a user namedmyuserand a new database calledtestdb_copy, run the following command:
mydemoserver
myuser
testdb_copy
psql -f testdb_dump.sql testdb_copy -h mydemoserver.postgres.database.azure.com -U myuser 2> errors.log
psql -f testdb_dump.sql testdb_copy -h mydemoserver.postgres.database.azure.com -U myuser 2> errors.log
pg_restore -Fd -j <number of cores> -d <new database name> <database name>.dump -h <server name> -U <user name> 2> errors.log
pg_restore -Fd -j <number of cores> -d <new database name> <database name>.dump -h <server name> -U <user name> 2> errors.log
In these commands, the-joption stands for the number of cores you wish to use for the restore process. You can adjust this number based on how many cores are available on your PostgreSQL server and how many you would like to allocate for the restore process. Feel free to change this setting depending on your server's capacity and your performance requirements.
-j
For example, if you have a server namedmydemoserver, a user namedmyuserand a new database calledtestdb_copy, and you want to use two cores for the dump, run the following command:
mydemoserver
myuser
testdb_copy
pg_restore -Fd -j 2 -d testdb_copy testdb.dump -h mydemoserver.postgres.database.azure.com -U myuser 2> errors.log
pg_restore -Fd -j 2 -d testdb_copy testdb.dump -h mydemoserver.postgres.database.azure.com -U myuser 2> errors.log
Post-restoration check
After the restoration process is complete, it's important to review theerrors.logfile for any errors that might have occurred. This step is crucial for ensuring the integrity and completeness of the restored data. Address any issues found in the log file to maintain the reliability of your database.
errors.log
Optimize the migration process
When working with large databases, the dump and restore process can be lengthy and might require optimization to ensure efficiency and reliability. It's important to be aware of the various factors that can impact the performance of these operations and to take steps to optimize them.
For detailed guidance on optimizing the dump and restore process, refer to theBest practices for pg_dump and pg_restorearticle. This resource provides comprehensive information and strategies that can be beneficial for handling large databases.
Related content
Best practices for pg_dump and pg_restore
Database Migration Guide
Feedback
Was this page helpful?
Additional resources