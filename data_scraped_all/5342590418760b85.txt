Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Data drift (preview) will be retired, and replaced by Model Monitor
Article
2025-02-04
9 contributors
In this article
APPLIES TO:Python SDK azuremlv1
Important
This article provides information on using the Azure Machine Learning SDK v1. The SDK v1 is deprecated as of March 31, 2025 and support for it will end on June 30, 2026. You're able to install and use the SDK v1 until that date.
We recommend that you transition to the SDK v2 before June 30, 2026. For more information on the SDK v2, seeWhat is the Azure Machine Learning Python SDK v2and theSDK v2 reference.
Data drift(preview) will be retired at 09/01/2025, and you can start to useModel Monitorfor your data drift tasks.
Please check the content below to understand the replacement, feature gaps and manual change steps.
Learn how to monitor data drift and set alerts when drift is high.
Note
Azure Machine Learning model monitoring (v2) provides improved capabilities for data drift along with additional functionalities for monitoring signals and metrics. To learn more about the capabilities of model monitoring in Azure Machine Learning (v2), seeModel monitoring with Azure Machine Learning.
With Azure Machine Learning dataset monitors (preview), you can:
Analyze drift in your datato understand how it changes over time.
Monitor model datafor differences between training and serving datasets. Start bycollecting model data from deployed models.
Monitor new datafor differences between any baseline and target dataset.
Profile features in datato track how statistical properties change over time.
Set up alerts on data driftfor early warnings to potential issues.
Create a new dataset versionwhen you determine the data has drifted too much.
AnAzure Machine Learning datasetis used to create the monitor. The dataset must include a timestamp column.
You can view data drift metrics with the Python SDK or in Azure Machine Learning studio. Other metrics and insights are available through theAzure Application Insightsresource associated with the Azure Machine Learning workspace.
Important
Data drift detection for datasets is currently in public preview.
The preview version is provided without a service level agreement, and it's not recommended for production workloads. Certain features might not be supported or might have constrained capabilities.
For more information, seeSupplemental Terms of Use for Microsoft Azure Previews.
Prerequisites
To create and work with dataset monitors, you need:
An Azure subscription. If you don't have an Azure subscription, create a free account before you begin. Try thefree or paid version of Azure Machine Learningtoday.
AnAzure Machine Learning workspace.
TheAzure Machine Learning SDK for Python installed, which includes the azureml-datasets package.
Structured (tabular) data with a timestamp specified in the file path, file name, or column in the data.
Prerequisites (Migrate to Model Monitor)
When you migrate to Model Monitor, please check the prerequisites as mentioned in this articlePrerequisites of Azure Machine Learning model monitoring.
What is data drift?
Model accuracy degrades over time, largely because of data drift. For machine learning models, data drift is the change in model input data that leads to model performance degradation. Monitoring data drift helps detect these model performance issues.
Causes of data drift include:
Upstream process changes, such as a sensor being replaced that changes the units of measurement from inches to centimeters.
Data quality issues, such as a broken sensor always reading 0.
Natural drift in the data, such as mean temperature changing with the seasons.
Change in relation between features, or covariate shift.
Azure Machine Learning simplifies drift detection by computing a single metric abstracting the complexity of datasets being compared. These datasets may have hundreds of features and tens of thousands of rows. Once drift is detected, you drill down into which features are causing the drift. You then inspect feature level metrics to debug and isolate the root cause for the drift.
This top down approach makes it easy to monitor data instead of traditional rules-based techniques. Rules-based techniques such as allowed data range or allowed unique values can be time consuming and error prone.
In Azure Machine Learning, you use dataset monitors to detect and alert for data drift.
Dataset monitors
With a dataset monitor you can:
Detect and alert to data drift on new data in a dataset.
Analyze historical data for drift.
Profile new data over time.
The data drift algorithm provides an overall measure of change in data and indication of which features are responsible for further investigation. Dataset monitors produce many other metrics by profiling new data in thetimeseriesdataset.
timeseries
Custom alerting can be set up on all metrics generated by the monitor throughAzure Application Insights. Dataset monitors can be used to quickly catch data issues and reduce the time to debug the issue by identifying likely causes.
Conceptually, there are three primary scenarios for setting up dataset monitors in Azure Machine Learning.
Dataset monitors depend on the following Azure services.
Baseline and target datasets
You monitorAzure Machine Learning datasetsfor data drift. When you create a dataset monitor, you reference your:
Baseline dataset - usually the training dataset for a model.
Target dataset - usually model input data - is compared over time to your baseline dataset. This comparison means that your target dataset must have a timestamp column specified.
The monitor compares the baseline and target datasets.
Migrate to Model Monitor
In Model Monitor, you can find corresponding concepts as following, and you can find more details in this articleSet up model monitoring by bringing in your production data to Azure Machine Learning:
Reference dataset: similar to your baseline dataset for data drift detection, it is set as the recent past production inference dataset.
Production inference data: similar to your target dataset in data drift detection, the production inference data can be collected automatically from models deployed in production. It can also be inference data you store.
Create target dataset
The target dataset needs thetimeseriestrait set on it by specifying the timestamp column either from a column in the data or a virtual column derived from the path pattern of the files. Create the dataset with a timestamp through thePython SDKorAzure Machine Learning studio. A column representing a "timestamp" must be specified to addtimeseriestrait to the dataset. If your data is partitioned into folder structure with time info, such as '{yyyy/MM/dd}', create a virtual column through the path pattern setting and set it as the "partition timestamp" to enable time series API functionality.
timeseries
timeseries
Python SDK
Studio
Azure CLI

APPLIES TO:Python SDK azuremlv1
TheDatasetclasswith_timestamp_columns()method defines the time stamp column for the dataset.
Dataset
with_timestamp_columns()
from azureml.core import Workspace, Dataset, Datastore

# get workspace object
ws = Workspace.from_config()

# get datastore object
dstore = Datastore.get(ws, 'your datastore name')

# specify datastore paths
dstore_paths = [(dstore, 'weather/*/*/*/*/data.parquet')]

# specify partition format
partition_format = 'weather/{state}/{date:yyyy/MM/dd}/data.parquet'

# create the Tabular dataset with 'state' and 'date' as virtual columns
dset = Dataset.Tabular.from_parquet_files(path=dstore_paths, partition_format=partition_format)

# assign the timestamp attribute to a real or virtual column in the dataset
dset = dset.with_timestamp_columns('date')

# register the dataset as the target dataset
dset = dset.register(ws, 'target')
from azureml.core import Workspace, Dataset, Datastore

# get workspace object
ws = Workspace.from_config()

# get datastore object
dstore = Datastore.get(ws, 'your datastore name')

# specify datastore paths
dstore_paths = [(dstore, 'weather/*/*/*/*/data.parquet')]

# specify partition format
partition_format = 'weather/{state}/{date:yyyy/MM/dd}/data.parquet'

# create the Tabular dataset with 'state' and 'date' as virtual columns
dset = Dataset.Tabular.from_parquet_files(path=dstore_paths, partition_format=partition_format)

# assign the timestamp attribute to a real or virtual column in the dataset
dset = dset.with_timestamp_columns('date')

# register the dataset as the target dataset
dset = dset.register(ws, 'target')
Tip
For a full example of using thetimeseriestrait of datasets, see theexample notebookor thedatasets SDK documentation.
timeseries

If you create your dataset using Azure Machine Learning studio, ensure the path to your data contains timestamp information, include all subfolders with data, and set the partition format.
In the following example, all data under the subfolderNoaaIsdFlorida/2019is taken, and the partition format specifies the timestamp's year, month, and day.

In theSchemasettings, specify thetimestampcolumn from a virtual or real column in the specified dataset. This type indicates that your data has a time component.

If your data is already partitioned by date or time, as is the case here, you can also specify thePartition timestamp. This allows more efficient processing of dates and enables time series APIs that you can apply during training.


Not supported.
Create dataset monitor
Create a dataset monitor to detect and alert to data drift on a new dataset. Use either thePython SDKorAzure Machine Learning studio.
As described later, a dataset monitor runs at a set frequency (daily, weekly, monthly) intervals. It analyzes new data available in the target dataset since its last run. In some cases, such analysis of the most recent data may not suffice:
The new data from the upstream source was delayed due to a broken data pipeline, and this new data wasn't available when the dataset monitor ran.
A time series dataset had only historical data, and you want to analyze drift patterns in the dataset over time. For example: compare traffic flowing to a website, in both winter and summer seasons, to identify seasonal patterns.
You're new to Dataset Monitors. You want to evaluate how the feature works with your existing data before you set it up to monitor future days. In such scenarios, you can submit an on-demand run, with a specific target dataset set date range, to compare with the baseline dataset.
Thebackfillfunction runs a backfill job, for a specified start and end date range. A backfill job fills in expected missing data points in a data set, as a way to ensure data accuracy and completeness.
Note
Azure Machine Learning model monitoring doesn't support manualbackfillfunction, if you want to redo the model monitor for a specif time range, you can create another model monitor for that specific time range.
Python SDK
Studio
Azure CLI

APPLIES TO:Python SDK azuremlv1
See thePython SDK reference documentation on data driftfor full details.
The following example shows how to create a dataset monitor using the Python SDK:
from azureml.core import Workspace, Dataset
from azureml.datadrift import DataDriftDetector
from datetime import datetime

# get the workspace object
ws = Workspace.from_config()

# get the target dataset
target = Dataset.get_by_name(ws, 'target')

# set the baseline dataset
baseline = target.time_before(datetime(2019, 2, 1))

# set up feature list
features = ['latitude', 'longitude', 'elevation', 'windAngle', 'windSpeed', 'temperature', 'snowDepth', 'stationName', 'countryOrRegion']

# set up data drift detector
monitor = DataDriftDetector.create_from_datasets(ws, 'drift-monitor', baseline, target,
                                                      compute_target='cpu-cluster',
                                                      frequency='Week',
                                                      feature_list=None,
                                                      drift_threshold=.6,
                                                      latency=24)

# get data drift detector by name
monitor = DataDriftDetector.get_by_name(ws, 'drift-monitor')

# update data drift detector
monitor = monitor.update(feature_list=features)

# run a backfill for January through May
backfill1 = monitor.backfill(datetime(2019, 1, 1), datetime(2019, 5, 1))

# run a backfill for May through today
backfill1 = monitor.backfill(datetime(2019, 5, 1), datetime.today())

# disable the pipeline schedule for the data drift detector
monitor = monitor.disable_schedule()

# enable the pipeline schedule for the data drift detector
monitor = monitor.enable_schedule()
from azureml.core import Workspace, Dataset
from azureml.datadrift import DataDriftDetector
from datetime import datetime

# get the workspace object
ws = Workspace.from_config()

# get the target dataset
target = Dataset.get_by_name(ws, 'target')

# set the baseline dataset
baseline = target.time_before(datetime(2019, 2, 1))

# set up feature list
features = ['latitude', 'longitude', 'elevation', 'windAngle', 'windSpeed', 'temperature', 'snowDepth', 'stationName', 'countryOrRegion']

# set up data drift detector
monitor = DataDriftDetector.create_from_datasets(ws, 'drift-monitor', baseline, target,
                                                      compute_target='cpu-cluster',
                                                      frequency='Week',
                                                      feature_list=None,
                                                      drift_threshold=.6,
                                                      latency=24)

# get data drift detector by name
monitor = DataDriftDetector.get_by_name(ws, 'drift-monitor')

# update data drift detector
monitor = monitor.update(feature_list=features)

# run a backfill for January through May
backfill1 = monitor.backfill(datetime(2019, 1, 1), datetime(2019, 5, 1))

# run a backfill for May through today
backfill1 = monitor.backfill(datetime(2019, 5, 1), datetime.today())

# disable the pipeline schedule for the data drift detector
monitor = monitor.disable_schedule()

# enable the pipeline schedule for the data drift detector
monitor = monitor.enable_schedule()
Tip
For a full example of setting up atimeseriesdataset and data drift detector, see ourexample notebook.
timeseries

Navigate to thestudio's homepage.
Navigate to thestudio's homepage.
Select theDatatab.
Select theDatatab.
SelectDataset monitors.
SelectDataset monitors.
Select the+Create monitorbutton, and selectNextto continue through the wizard.
Select the+Create monitorbutton, and selectNextto continue through the wizard.

Select target dataset. The target dataset is a tabular dataset with a timestamp column specified which to analyze for data drift. The target dataset must have features in common with the baseline dataset, and should be atimeseriesdataset, which new data is appended to. Historical data in the target dataset can be analyzed, or new data can be monitored.
Select target dataset. The target dataset is a tabular dataset with a timestamp column specified which to analyze for data drift. The target dataset must have features in common with the baseline dataset, and should be atimeseriesdataset, which new data is appended to. Historical data in the target dataset can be analyzed, or new data can be monitored.
timeseries
Select baseline dataset.Select the tabular dataset to be used as the baseline for comparison of the target dataset over time. The baseline dataset must have features in common with the target dataset. Select a time range to use a slice of the target dataset, or specify a separate dataset to use as the baseline.
Select baseline dataset.Select the tabular dataset to be used as the baseline for comparison of the target dataset over time. The baseline dataset must have features in common with the target dataset. Select a time range to use a slice of the target dataset, or specify a separate dataset to use as the baseline.
Monitor settings. These settings are for the scheduled dataset monitor pipeline to create.SettingDescriptionTipsMutableNameName of the dataset monitor.NoFeaturesList of features that to analyze for data drift over time.Set to a model's output feature(s) to measure concept drift. Don't include features that naturally drift over time (month, year, index, etc.). You can backfill and existing data drift monitor after adjusting the list of features.YesCompute targetAzure Machine Learning compute target to run the dataset monitor jobs.YesEnableEnable or disable the schedule on the dataset monitor pipelineDisable the schedule to analyze historical data with the backfill setting. It can be enabled after the dataset monitor is created.YesFrequencyThe frequency that to use, to schedule the pipeline job and analyze historical data if running a backfill. Options include daily, weekly, or monthly.Each job compares data in the target dataset according to the frequency:Daily: Compare most recent complete day in target dataset with baselineWeekly: Compare most recent complete week (Monday - Sunday) in target dataset with baselineMonthly: Compare most recent complete month in target dataset with baselineNoLatencyTime, in hours, it takes for data to arrive in the dataset. For instance, if it takes three days for data to arrive in the SQL DB the dataset encapsulates, set the latency to 72.Can't be changed after the creation of the dataset monitorNoEmail addressesEmail addresses for alerting based on breach of the data drift percentage threshold.Emails are sent through Azure Monitor.YesThresholdData drift percentage threshold for email alerting.Further alerts and events can be set on many other metrics in the workspace's associated Application Insights resource.Yes
Monitor settings. These settings are for the scheduled dataset monitor pipeline to create.
Daily: Compare most recent complete day in target dataset with baseline
Weekly: Compare most recent complete week (Monday - Sunday) in target dataset with baseline
Monthly: Compare most recent complete month in target dataset with baseline
After completion of the wizard, the resulting dataset monitor will appear in the list. Select it to go to that monitor's details page.

Not supported
Create Model Monitor (Migrate to Model Monitor)
When you migrate to Model Monitor, if you have deployed your model to production in an Azure Machine Learning online endpoint and enableddata collectionat deployment time, Azure Machine Learning collects production inference data, and automatically stores it in Microsoft Azure Blob Storage. You can then use Azure Machine Learning model monitoring to continuously monitor this production inference data, and you can directly choose the model to create target dataset (production inference data in Model Monitor).
When you migrate to Model Monitor, if you didn't deploy your model to production in an Azure Machine Learning online endpoint, or you don't want to usedata collection, you can alsoset up model monitoring with custom signals and metrics.
Following sections contain more details on how to migrate to Model Monitor.
Create Model Monitor via automatically collected production data (Migrate to Model Monitor)
If you have deployed your model to production in an Azure Machine Learning online endpoint and enableddata collectionat deployment time.
Python SDK
Studio
Azure CLI

You can use the following code to set up the out-of-box model monitoring:
from azure.identity import DefaultAzureCredential
from azure.ai.ml import MLClient
from azure.ai.ml.entities import (
    AlertNotification,
    MonitoringTarget,
    MonitorDefinition,
    MonitorSchedule,
    RecurrencePattern,
    RecurrenceTrigger,
    ServerlessSparkCompute
)

# get a handle to the workspace
ml_client = MLClient(
    DefaultAzureCredential(),
    subscription_id="subscription_id",
    resource_group_name="resource_group_name",
    workspace_name="workspace_name",
)

# create the compute
spark_compute = ServerlessSparkCompute(
    instance_type="standard_e4s_v3",
    runtime_version="3.3"
)

# specify your online endpoint deployment
monitoring_target = MonitoringTarget(
    ml_task="classification",
    endpoint_deployment_id="azureml:credit-default:main"
)


# create alert notification object
alert_notification = AlertNotification(
    emails=['abc@example.com', 'def@example.com']
)

# create the monitor definition
monitor_definition = MonitorDefinition(
    compute=spark_compute,
    monitoring_target=monitoring_target,
    alert_notification=alert_notification
)

# specify the schedule frequency
recurrence_trigger = RecurrenceTrigger(
    frequency="day",
    interval=1,
    schedule=RecurrencePattern(hours=3, minutes=15)
)

# create the monitor
model_monitor = MonitorSchedule(
    name="credit_default_monitor_basic",
    trigger=recurrence_trigger,
    create_monitor=monitor_definition
)

poller = ml_client.schedules.begin_create_or_update(model_monitor)
created_monitor = poller.result()
from azure.identity import DefaultAzureCredential
from azure.ai.ml import MLClient
from azure.ai.ml.entities import (
    AlertNotification,
    MonitoringTarget,
    MonitorDefinition,
    MonitorSchedule,
    RecurrencePattern,
    RecurrenceTrigger,
    ServerlessSparkCompute
)

# get a handle to the workspace
ml_client = MLClient(
    DefaultAzureCredential(),
    subscription_id="subscription_id",
    resource_group_name="resource_group_name",
    workspace_name="workspace_name",
)

# create the compute
spark_compute = ServerlessSparkCompute(
    instance_type="standard_e4s_v3",
    runtime_version="3.3"
)

# specify your online endpoint deployment
monitoring_target = MonitoringTarget(
    ml_task="classification",
    endpoint_deployment_id="azureml:credit-default:main"
)


# create alert notification object
alert_notification = AlertNotification(
    emails=['abc@example.com', 'def@example.com']
)

# create the monitor definition
monitor_definition = MonitorDefinition(
    compute=spark_compute,
    monitoring_target=monitoring_target,
    alert_notification=alert_notification
)

# specify the schedule frequency
recurrence_trigger = RecurrenceTrigger(
    frequency="day",
    interval=1,
    schedule=RecurrencePattern(hours=3, minutes=15)
)

# create the monitor
model_monitor = MonitorSchedule(
    name="credit_default_monitor_basic",
    trigger=recurrence_trigger,
    create_monitor=monitor_definition
)

poller = ml_client.schedules.begin_create_or_update(model_monitor)
created_monitor = poller.result()

Navigate toAzure Machine Learning studio.
Navigate toAzure Machine Learning studio.
Go to your workspace.
Go to your workspace.
SelectMonitoringfrom theManagesection
SelectMonitoringfrom theManagesection
SelectAdd.
SelectAdd.

On theBasic settingspage, use(Optional) Select modelto choose the model to monitor.
On theBasic settingspage, use(Optional) Select modelto choose the model to monitor.
The(Optional) Select deployment with data collection enableddropdown list should be automatically populated if the model is deployed to an Azure Machine Learning online endpoint. Select the deployment from the dropdown list.
The(Optional) Select deployment with data collection enableddropdown list should be automatically populated if the model is deployed to an Azure Machine Learning online endpoint. Select the deployment from the dropdown list.
Select the training data to use as the comparison reference in the(Optional) Select training databox.
Select the training data to use as the comparison reference in the(Optional) Select training databox.
Enter a name for the monitoring inMonitor nameor keep the default name.
Enter a name for the monitoring inMonitor nameor keep the default name.
Notice that the virtual machine size is already selected for you.
Notice that the virtual machine size is already selected for you.
Select yourTime zone.
Select yourTime zone.
SelectRecurrenceorCron expressionscheduling.
SelectRecurrenceorCron expressionscheduling.
ForRecurrencescheduling, specify the repeat frequency, day, and time. ForCron expressionscheduling, enter a cron expression for monitoring run.
ForRecurrencescheduling, specify the repeat frequency, day, and time. ForCron expressionscheduling, enter a cron expression for monitoring run.

SelectNextto go to theAdvanced settingssection.
SelectNextto go to theAdvanced settingssection.
SelectNexton theConfigure data assetpage to keep the default datasets.
SelectNexton theConfigure data assetpage to keep the default datasets.
SelectNextto go to theSelect monitoring signalspage.
SelectNextto go to theSelect monitoring signalspage.
SelectNextto go to theNotificationspage. Add your email to receive email notifications.
SelectNextto go to theNotificationspage. Add your email to receive email notifications.
Review your monitoring details and selectCreateto create the monitor.
Review your monitoring details and selectCreateto create the monitor.

Azure Machine Learning model monitoring usesaz ml scheduleto schedule a monitoring job. You can create the out-of-box model monitor with the following CLI command and YAML definition:
az ml schedule
az ml schedule create -f ./out-of-box-monitoring.yaml
az ml schedule create -f ./out-of-box-monitoring.yaml
The following YAML contains the definition for the out-of-box model monitoring.
# out-of-box-monitoring.yaml
$schema:  http://azureml/sdk-2-0/Schedule.json
name: credit_default_model_monitoring
display_name: Credit default model monitoring
description: Credit default model monitoring setup with minimal configurations

trigger:
  # perform model monitoring activity daily at 3:15am
  type: recurrence
  frequency: day #can be minute, hour, day, week, month
  interval: 1 # #every day
  schedule: 
    hours: 3 # at 3am
    minutes: 15 # at 15 mins after 3am

create_monitor:

  compute: # specify a spark compute for monitoring job
    instance_type: standard_e4s_v3
    runtime_version: "3.3"

  monitoring_target: 
    ml_task: classification # model task type: [classification, regression, question_answering]
    endpoint_deployment_id: azureml:credit-default:main # azureml endpoint deployment id

  alert_notification: # emails to get alerts
    emails:
      - abc@example.com
      - def@example.com
# out-of-box-monitoring.yaml
$schema:  http://azureml/sdk-2-0/Schedule.json
name: credit_default_model_monitoring
display_name: Credit default model monitoring
description: Credit default model monitoring setup with minimal configurations

trigger:
  # perform model monitoring activity daily at 3:15am
  type: recurrence
  frequency: day #can be minute, hour, day, week, month
  interval: 1 # #every day
  schedule: 
    hours: 3 # at 3am
    minutes: 15 # at 15 mins after 3am

create_monitor:

  compute: # specify a spark compute for monitoring job
    instance_type: standard_e4s_v3
    runtime_version: "3.3"

  monitoring_target: 
    ml_task: classification # model task type: [classification, regression, question_answering]
    endpoint_deployment_id: azureml:credit-default:main # azureml endpoint deployment id

  alert_notification: # emails to get alerts
    emails:
      - abc@example.com
      - def@example.com
Create Model Monitor via custom data preprocessing component (Migrate to Model Monitor)
When you migrate to Model Monitor, if you didn't deploy your model to production in an Azure Machine Learning online endpoint, or you don't want to usedata collection, you can alsoset up model monitoring with custom signals and metrics.
If you don't have a deployment, but you have production data, you can use the data to perform continuous model monitoring. To monitor these models, you must be able to:
Collect production inference data from models deployed in production.
Register the production inference data as an Azure Machine Learning data asset, and ensure continuous updates of the data.
Provide a custom data preprocessing component and register it as an Azure Machine Learning component.
You must provide a custom data preprocessing component if your data isn't collected with thedata collector. Without this custom data preprocessing component, the Azure Machine Learning model monitoring system won't know how to process your data into tabular form with support for time windowing.
Your custom preprocessing component must have these input and output signatures:
data_window_start
data_window_end
input_data
preprocessed_data
For an example of a custom data preprocessing component, seecustom_preprocessing in the azuremml-examples GitHub repo.
Understand data drift results
This section shows you the results of monitoring a dataset, found in theDatasets/Dataset monitorspage in Azure studio. You can update the settings, and analyze existing data for a specific time period on this page.
Start with the top-level insights into the magnitude of data drift and a highlight of features to be further investigated.

Drift magnitude trend
See how the dataset differs from the target dataset in the specified time period. The closer to 100%, the more the two datasets differ.

Drift magnitude by features
This section contains feature-level insights into the change in the selected feature's distribution, and other statistics, over time.
The target dataset is also profiled over time. The statistical distance between the baseline distribution of each feature is compared with the target dataset's over time. Conceptually, this resembles the data drift magnitude. However this statistical distance is for an individual feature rather than all features. Min, max, and mean are also available.
In the Azure Machine Learning studio, select a bar in the graph to see the feature-level details for that date. By default, you see the baseline dataset's distribution and the most recent job's distribution of the same feature.

These metrics can also be retrieved in the Python SDK through theget_metrics()method on aDataDriftDetectorobject.
get_metrics()
DataDriftDetector
Feature details
Finally, scroll down to view details for each individual feature. Use the dropdowns above the chart to select the feature, and additionally select the metric you want to view.

Metrics in the chart depend on the type of feature.
Numeric featuresMetricDescriptionWasserstein distanceMinimum amount of work to transform baseline distribution into the target distribution.Mean valueAverage value of the feature.Min valueMinimum value of the feature.Max valueMaximum value of the feature.
Numeric features
Categorical featuresMetricDescriptionEuclidian distanceComputed for categorical columns. Euclidean distance is computed on two vectors, generated from empirical distribution of the same categorical column from two datasets. 0 indicates no difference in the empirical distributions.  The more it deviates from 0, the more this column has drifted. Trends can be observed from a time series plot of this metric and can be helpful in uncovering a drifting feature.Unique valuesNumber of unique values (cardinality) of the feature.
Categorical features
On this chart, select a single date to compare the feature distribution between the target and this date for the displayed feature. For numeric features, this shows two probability distributions. If the feature is numeric, a bar chart is shown.

Metrics, alerts, and events
Metrics can be queried in theAzure Application Insightsresource associated with your machine learning workspace. You have access to all features of Application Insights including set up for custom alert rules and action groups to trigger an action such as an Email/SMS/Push/Voice or Azure Function. Refer to the complete Application Insights documentation for details.
To get started, navigate to theAzure portaland select your workspace'sOverviewpage. The associated Application Insights resource is on the far right:

Select Logs (Analytics) under Monitoring on the left pane:

The dataset monitor metrics are stored ascustomMetrics. You can write and run a query after setting up a dataset monitor to view them:
customMetrics

After identifying metrics to set up alert rules, create a new alert rule:

You can use an existing action group, or create a new one to define the action to be taken when the set conditions are met:

Troubleshooting
Limitations and known issues for data drift monitors:
The time range when analyzing historical data is limited to 31 intervals of the monitor's frequency setting.
The time range when analyzing historical data is limited to 31 intervals of the monitor's frequency setting.
Limitation of 200 features, unless a feature list is not specified (all features used).
Limitation of 200 features, unless a feature list is not specified (all features used).
Compute size must be large enough to handle the data.
Compute size must be large enough to handle the data.
Ensure your dataset has data within the start and end date for a given monitor job.
Ensure your dataset has data within the start and end date for a given monitor job.
Dataset monitors only work on datasets that contain 50 rows or more.
Dataset monitors only work on datasets that contain 50 rows or more.
Columns, or features, in the dataset are classified as categorical or numeric based on the conditions in the following table. If the feature doesn't meet these conditions - for instance, a column of type string with >100 unique values - the feature is dropped from our data drift algorithm, but is still profiled.Feature typeData typeConditionLimitationsCategoricalstringThe number of unique values in the feature is less than 100 and less than 5% of the number of rows.Null is treated as its own category.Numericalint, floatThe values in the feature are of a numerical data type, and don't meet the condition for a categorical feature.Feature dropped if >15% of values are null.
Columns, or features, in the dataset are classified as categorical or numeric based on the conditions in the following table. If the feature doesn't meet these conditions - for instance, a column of type string with >100 unique values - the feature is dropped from our data drift algorithm, but is still profiled.
When you have created a data drift monitor but can't see data on theDataset monitorspage in Azure Machine Learning studio, try the following.Check if you have selected the right date range at the top of the page.On theDataset Monitorstab, select the experiment link to check job status. This link is on the far right of the table.If the job completed successfully, check the driver logs to see how many metrics have been generated or if there's any warning messages. Find driver logs in theOutput + logstab after you select an experiment.
When you have created a data drift monitor but can't see data on theDataset monitorspage in Azure Machine Learning studio, try the following.
Check if you have selected the right date range at the top of the page.
On theDataset Monitorstab, select the experiment link to check job status. This link is on the far right of the table.
If the job completed successfully, check the driver logs to see how many metrics have been generated or if there's any warning messages. Find driver logs in theOutput + logstab after you select an experiment.
If the SDKbackfill()function doesn't generate the expected output, it may be due to an authentication issue. When you create the compute to pass into this function, don't useRun.get_context().experiment.workspace.compute_targets. Instead, useServicePrincipalAuthenticationsuch as the following to create the compute that you pass into thatbackfill()function:
If the SDKbackfill()function doesn't generate the expected output, it may be due to an authentication issue. When you create the compute to pass into this function, don't useRun.get_context().experiment.workspace.compute_targets. Instead, useServicePrincipalAuthenticationsuch as the following to create the compute that you pass into thatbackfill()function:
backfill()
Run.get_context().experiment.workspace.compute_targets
backfill()
Note
Do not hard code the service principal password in your code. Instead, retrieve it from the Python environment, key store, or other secure method of accessing secrets.
auth = ServicePrincipalAuthentication(
        tenant_id=tenant_id,
        service_principal_id=app_id,
        service_principal_password=client_secret
        )
 ws = Workspace.get("xxx", auth=auth, subscription_id="xxx", resource_group="xxx")
 compute = ws.compute_targets.get("xxx")
auth = ServicePrincipalAuthentication(
        tenant_id=tenant_id,
        service_principal_id=app_id,
        service_principal_password=client_secret
        )
 ws = Workspace.get("xxx", auth=auth, subscription_id="xxx", resource_group="xxx")
 compute = ws.compute_targets.get("xxx")
From the Model Data Collector, it can take up to 10 minutes for data to arrive in your blob storage account. However, it usually takes less time. In a script or Notebook, wait 10 minutes to ensure that the cells below successfully run.import time
time.sleep(600)
From the Model Data Collector, it can take up to 10 minutes for data to arrive in your blob storage account. However, it usually takes less time. In a script or Notebook, wait 10 minutes to ensure that the cells below successfully run.
import time
time.sleep(600)
import time
time.sleep(600)
Next steps
Head to theAzure Machine Learning studioor thePython notebookto set up a dataset monitor.
See how to set up data drift onmodels deployed to Azure Kubernetes Service.
Set up dataset drift monitors withAzure Event Grid.
Feedback
Was this page helpful?
Additional resources