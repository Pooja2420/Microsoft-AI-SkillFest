Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Emit metrics for consumption of Azure OpenAI tokens
Article
2025-04-18
3 contributors
In this article
APPLIES TO: All API Management tiers
Theazure-openai-emit-token-metricpolicy sends custom metrics to Application Insights about consumption of large language model tokens through Azure OpenAI Service APIs. Token count metrics include: Total Tokens, Prompt Tokens, and Completion Tokens.
azure-openai-emit-token-metric
Note
Set the policy's elements and child elements in the order provided in the policy statement. Learn more abouthow to set or edit API Management policies.
Supported Azure OpenAI Service models
The policy is used with APIsadded to API Management from the Azure OpenAI Serviceof the following types:
1Thegpt-4omodel is multimodal (accepts text or image inputs and generates text).
gpt-4o
Note
Traditional completion APIs are only available with legacy model versions and support is limited.
For more information, seeAzure OpenAI Service models.
Limits for custom metrics
Azure Monitor imposesusage limitsfor custom metrics that may affect your ability to emit metrics from API Management. For example, Azure Monitor currently sets a limit of 10 dimension keys per metric, and a limit of 50,000 total active time series per region in a subscription (within a 12 hour period).
These limits have the following implications for configuring custom metrics in an API Management policy such asemit-metricorazure-openai-emit-token-metric:
emit-metric
azure-openai-emit-token-metric
You can configure a maximum of 10 custom dimensions per policy.
You can configure a maximum of 10 custom dimensions per policy.
The number of active time series generated by the policy within a 12 hour period is the product of the number of unique values of each configured dimension during the period. For example, if three custom dimensions were configured in the policy, and each dimension had 10 possible values within the period, the policy would contribute 1,000 (10 x 10 x 10) active time series.
The number of active time series generated by the policy within a 12 hour period is the product of the number of unique values of each configured dimension during the period. For example, if three custom dimensions were configured in the policy, and each dimension had 10 possible values within the period, the policy would contribute 1,000 (10 x 10 x 10) active time series.
If you configure the policy in multiple API Management instances that are in the same region in a subscription, all instances can contribute to the regional active time series limit.
If you configure the policy in multiple API Management instances that are in the same region in a subscription, all instances can contribute to the regional active time series limit.
Learn more aboutdesign limitations and considerationsfor custom metrics in Azure Monitor.
Prerequisites
One or more Azure OpenAI Service APIs must be added to your API Management instance. For more information, seeAdd an Azure OpenAI Service API to Azure API Management.
Your API Management instance must be integrated with Application insights. For more information, seeHow to integrate Azure API Management with Azure Application Insights.
Enable Application Insights logging for your Azure OpenAI APIs.
Enable custom metrics with dimensions in Application Insights. For more information, seeEmit custom metrics.
Policy statement
<azure-openai-emit-token-metric
        namespace="metric namespace" >      
        <dimension name="dimension name" value="dimension value" />
        ...additional dimensions...
</azure-openai-emit-token-metric>
<azure-openai-emit-token-metric
        namespace="metric namespace" >      
        <dimension name="dimension name" value="dimension value" />
        ...additional dimensions...
</azure-openai-emit-token-metric>
Attributes
Elements
dimension attributes
name
Default dimension names that may be used without value
API ID
Operation ID
Product ID
User ID
Subscription ID
Location
Gateway ID
Backend ID
Usage
Policy sections:inbound
Policy scopes:global, workspace, product, API, operation
Gateways:classic, v2, consumption, self-hosted, workspace
Usage notes
This policy can be used multiple times per policy definition.
You can configure at most 10 custom dimensions for this policy.
This policy can optionally be configured when adding an API from the Azure OpenAI Service using the portal.
Where available, values in the usage section of the response from the Azure OpenAI Service API are used to determine token metrics.
Certain Azure OpenAI endpoints support streaming of responses. Whenstreamis set totruein the API request to enable streaming, token metrics are estimated.
stream
true
Example
The following example sends Azure OpenAI token count metrics to Application Insights along with API ID as a default dimension.
<policies>
  <inbound>
      <azure-openai-emit-token-metric
            namespace="AzureOpenAI">   
            <dimension name="API ID" />
        </azure-openai-emit-token-metric> 
  </inbound>
  <outbound>
  </outbound>
</policies>
<policies>
  <inbound>
      <azure-openai-emit-token-metric
            namespace="AzureOpenAI">   
            <dimension name="API ID" />
        </azure-openai-emit-token-metric> 
  </inbound>
  <outbound>
  </outbound>
</policies>
Related policies
Logging
emit-metricpolicy
azure-openai-token-limitpolicy
Related content
For more information about working with policies, see:
Tutorial: Transform and protect your API
Policy referencefor a full list of policy statements and their settings
Policy expressions
Set or edit policies
Reuse policy configurations
Policy snippets repo
Azure API Management policy toolkit
Get Copilot assistance to create, explain, and troubleshoot policies
Feedback
Was this page helpful?
Additional resources