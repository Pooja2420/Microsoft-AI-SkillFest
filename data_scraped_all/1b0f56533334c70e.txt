Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Configure log collection in Container insights
Article
2024-09-11
2 contributors
In this article
This article provides details on how to configure data collection inContainer insightsfor your Kubernetes cluster once it's been onboarded. For guidance on enabling Container insights on your cluster, seeEnable monitoring for Kubernetes clusters.
Configuration methods
There are two methods use to configure and filter data being collected in Container insights. Depending on the setting, you may be able to choose between the two methods or you may be required to use one or the other. The two methods are described in the table below with detailed information in the following sections.
Configure data collection using DCR
The DCR created by Container insights is namedMSCI-<cluster-region>-<cluster-name>. You canview this DCRalong with others in your subscription, and you can edit it using methods described inCreate and edit data collection rules (DCRs) in Azure Monitor. While you can directly modify the DCR for particular customizations, you can perform most required configuration using the methods described below. SeeData transformations in Container insightsfor details on editing the DCR directly for more advanced configurations.
Important
AKS clusters must use either a system-assigned or user-assigned managed identity. If cluster is using a service principal, you must update the cluster to use asystem-assigned managed identityor auser-assigned managed identity.
Azure portal
CLI
ARM
Configure DCR with Azure portal
Using the Azure portal, you can select from multiple preset configurations for data collection in Container insights. These configurations include different sets of tables and collection frequencies depending on your particular priorities. You can also customize the settings to collect only the data you require. You can use the Azure portal to customize configuration on your existing cluster after Container insights has been enabled, or you can perform this configuration when you enable Container insights on your cluster.
Select the cluster in the Azure portal.
Select the cluster in the Azure portal.
Select theInsightsoption in theMonitoringsection of the menu.
Select theInsightsoption in theMonitoringsection of the menu.
If Container insights has already been enabled on the cluster, select theMonitoring Settingsbutton. If not, selectConfigure Azure Monitorand seeEnable monitoring on your Kubernetes cluster with Azure Monitorfor details on enabling monitoring.
If Container insights has already been enabled on the cluster, select theMonitoring Settingsbutton. If not, selectConfigure Azure Monitorand seeEnable monitoring on your Kubernetes cluster with Azure Monitorfor details on enabling monitoring.

For AKS and Arc-enabled Kubernetes, selectUse managed identityif you haven't yet migrated the cluster tomanaged identity authentication.
For AKS and Arc-enabled Kubernetes, selectUse managed identityif you haven't yet migrated the cluster tomanaged identity authentication.
Select one of the cost presets.Cost presetCollection frequencyNamespace filtersSyslog collectionCollected dataStandard1 mNoneNot enabledAll standard container insights tablesCost-optimized5 mExcludes kube-system, gatekeeper-system, azure-arcNot enabledAll standard container insights tablesSyslog1 mNoneEnabled by defaultAll standard container insights tablesLogs and Events1 mNoneNot enabledContainerLog/ContainerLogV2KubeEventsKubePodInventory
Select one of the cost presets.

If you want to customize the settings, clickEdit collection settings.NameDescriptionCollection frequencyDetermines how often the agent collects data.  Valid values are 1m - 30m in 1m intervals The default value is 1m. This option can't be configured through the ConfigMap.Namespace filteringOff: Collects data on all namespaces.Include: Collects only data from the values in thenamespacesfield.Exclude: Collects data from all namespaces except for the values in thenamespacesfield.Array of comma separated Kubernetes namespaces to collect inventory and perf data based on thenamespaceFilteringMode. For example,namespaces = ["kube-system", "default"]with anIncludesetting collects only these two namespaces. With anExcludesetting, the agent collects data from all other namespaces except forkube-systemanddefault.Collected DataDefines which Container insights tables to collect. See below for a description of each grouping.Enable ContainerLogV2Boolean flag to enableContainerLogV2 schema. If set to true, the stdout/stderr Logs are ingested toContainerLogV2table. If not, the container logs are ingested toContainerLogtable, unless otherwise specified in the ConfigMap. When specifying the individual streams, you must include the corresponding table for ContainerLog or ContainerLogV2.Enable Syslog collectionEnables Syslog collection from the cluster.TheCollected dataoption allows you to select the tables that are populated for the cluster. The tables are grouped by the most common scenarios. To specify individual tables, you must modify the DCR using another method.GroupingTablesNotesAll (Default)All standard container insights tablesRequired for enabling the default Container insights visualizationsPerformancePerf, InsightsMetricsLogs and eventsContainerLog or ContainerLogV2, KubeEvents, KubePodInventoryRecommended if you have enabled managed Prometheus metricsWorkloads, Deployments, and HPAsInsightsMetrics, KubePodInventory, KubeEvents, ContainerInventory, ContainerNodeInventory, KubeNodeInventory, KubeServicesPersistent VolumesInsightsMetrics, KubePVInventory
If you want to customize the settings, clickEdit collection settings.

TheCollected dataoption allows you to select the tables that are populated for the cluster. The tables are grouped by the most common scenarios. To specify individual tables, you must modify the DCR using another method.

ClickConfigureto save the settings.
ClickConfigureto save the settings.
Configure DCR with Azure portal
Azure CLI minimum version 2.51.0.
For AKS clusters,aks-previewversion 0.5.147 or higher
For Arc enabled Kubernetes and AKS hybrid,k8s-extensionversion 1.4.3 or higher
When you use CLI to configure monitoring for your AKS cluster, you provide the configuration as a JSON file using the following format. See the section below for how to use CLI to apply these settings to different cluster configurations.
{
  "interval": "1m",
  "namespaceFilteringMode": "Include",
  "namespaces": ["kube-system"],
  "enableContainerLogV2": true, 
  "streams": ["Microsoft-Perf", "Microsoft-ContainerLogV2"]
}
{
  "interval": "1m",
  "namespaceFilteringMode": "Include",
  "namespaces": ["kube-system"],
  "enableContainerLogV2": true, 
  "streams": ["Microsoft-Perf", "Microsoft-ContainerLogV2"]
}
Each of the settings in the configuration is described in the following table.
interval
namespaceFilteringMode
namespaces
enableContainerLogV2
streams
AKS cluster
Important
In the commands in this section, when deploying on a Windows machine, the dataCollectionSettings field must be escaped. For example, dataCollectionSettings={"interval":"1m","namespaceFilteringMode": "Include", "namespaces": [ "kube-system"]} instead of dataCollectionSettings='{"interval":"1m","namespaceFilteringMode": "Include", "namespaces": [ "kube-system"]}'
Use the following command to create a new AKS cluster with monitoring enabled. This assumes a configuration file nameddataCollectionSettings.json.
az aks create -g <clusterResourceGroup> -n <clusterName> --enable-managed-identity --node-count 1 --enable-addons monitoring --data-collection-settings dataCollectionSettings.json --generate-ssh-keys
az aks create -g <clusterResourceGroup> -n <clusterName> --enable-managed-identity --node-count 1 --enable-addons monitoring --data-collection-settings dataCollectionSettings.json --generate-ssh-keys
Cluster without the monitoring addonUse the following command to add monitoring to an existing cluster without Container insights enabled. This assumes a configuration file nameddataCollectionSettings.json.
az aks enable-addons -a monitoring -g <clusterResourceGroup> -n <clusterName> --data-collection-settings dataCollectionSettings.json
az aks enable-addons -a monitoring -g <clusterResourceGroup> -n <clusterName> --data-collection-settings dataCollectionSettings.json
Cluster with an existing monitoring addonUse the following command to add a new configuration to an existing cluster with Container insights enabled. This assumes a configuration file nameddataCollectionSettings.json.
# get the configured log analytics workspace resource id
az aks show -g <clusterResourceGroup> -n <clusterName> | grep -i "logAnalyticsWorkspaceResourceID"

# disable monitoring 
az aks disable-addons -a monitoring -g <clusterResourceGroup> -n <clusterName>

# enable monitoring with data collection settings
az aks enable-addons -a monitoring -g <clusterResourceGroup> -n <clusterName> --workspace-resource-id <logAnalyticsWorkspaceResourceId> --data-collection-settings dataCollectionSettings.json
# get the configured log analytics workspace resource id
az aks show -g <clusterResourceGroup> -n <clusterName> | grep -i "logAnalyticsWorkspaceResourceID"

# disable monitoring 
az aks disable-addons -a monitoring -g <clusterResourceGroup> -n <clusterName>

# enable monitoring with data collection settings
az aks enable-addons -a monitoring -g <clusterResourceGroup> -n <clusterName> --workspace-resource-id <logAnalyticsWorkspaceResourceId> --data-collection-settings dataCollectionSettings.json
Arc-enabled Kubernetes cluster
Use the following command to add monitoring to an existing Arc-enabled Kubernetes cluster.
az k8s-extension create --name azuremonitor-containers --cluster-name <cluster-name> --resource-group <resource-group> --cluster-type connectedClusters --extension-type Microsoft.AzureMonitor.Containers --configuration-settings amalogs.useAADAuth=true dataCollectionSettings='{"interval":"1m","namespaceFilteringMode": "Include", "namespaces": [ "kube-system"],"enableContainerLogV2": true,"streams": ["<streams to be collected>"]}'
az k8s-extension create --name azuremonitor-containers --cluster-name <cluster-name> --resource-group <resource-group> --cluster-type connectedClusters --extension-type Microsoft.AzureMonitor.Containers --configuration-settings amalogs.useAADAuth=true dataCollectionSettings='{"interval":"1m","namespaceFilteringMode": "Include", "namespaces": [ "kube-system"],"enableContainerLogV2": true,"streams": ["<streams to be collected>"]}'
AKS hybrid cluster
Use the following command to add monitoring to an existing AKS hybrid cluster.
az k8s-extension create --name azuremonitor-containers --cluster-name <cluster-name> --resource-group <resource-group> --cluster-type provisionedclusters --cluster-resource-provider "microsoft.hybridcontainerservice" --extension-type Microsoft.AzureMonitor.Containers --configuration-settings amalogs.useAADAuth=true dataCollectionSettings='{"interval":"1m","namespaceFilteringMode":"Include", "namespaces": ["kube-system"],"enableContainerLogV2": true,"streams": ["<streams to be collected>"]}'
az k8s-extension create --name azuremonitor-containers --cluster-name <cluster-name> --resource-group <resource-group> --cluster-type provisionedclusters --cluster-resource-provider "microsoft.hybridcontainerservice" --extension-type Microsoft.AzureMonitor.Containers --configuration-settings amalogs.useAADAuth=true dataCollectionSettings='{"interval":"1m","namespaceFilteringMode":"Include", "namespaces": ["kube-system"],"enableContainerLogV2": true,"streams": ["<streams to be collected>"]}'
Configure DCR with ARM templates
The following template and parameter files are available for different cluster configurations.
AKS cluster
Template:https://aka.ms/aks-enable-monitoring-costopt-onboarding-template-file
Parameter:https://aka.ms/aks-enable-monitoring-costopt-onboarding-template-parameter-file
Arc-enabled Kubernetes
Template:https://aka.ms/arc-k8s-enable-monitoring-costopt-onboarding-template-file
Parameter:https://aka.ms/arc-k8s-enable-monitoring-costopt-onboarding-template-parameter-file
AKS hybrid cluster
Template:https://aka.ms/existingClusterOnboarding.json
Parameter:https://aka.ms/existingClusterParam.json
The following table describes the parameters you need to provide values for in each of the parameter files.
aksResourceId
aksResourceLocation
workspaceRegion
enableContainerLogV2
enableSyslog
syslogLevels
dataCollectionInterval
namespaceFilteringModeForDataCollection
namespacesForDataCollection
streams
Microsoft-ContainerLogV2-HighScale
useAzureMonitorPrivateLinkScope
azureMonitorPrivateLinkScopeResourceId
Applicable tables and metrics for DCR
The settings forcollection frequencyandnamespace filteringin the DCR don't apply to all Container insights data. The following tables list the tables in the Log Analytics workspace used by Container insights and the metrics it collects along with the settings that apply to each.
Note
Namespace filtering does not apply to ama-logs agent records. As a result, even if the kube-system namespace is listed among excluded namespaces, records associated to ama-logs agent container will still be ingested.
Stream values in DCR
When you specify the tables to collect using CLI or ARM, you specify a stream name that corresponds to a particular table in the Log Analytics workspace. The following table lists the stream name for each table.
Note
If you're familiar with thestructure of a data collection rule, the stream names in this table are specified in theData flowssection of the DCR.
1You shouldn't use both Microsoft-ContainerLogV2 and Microsoft-ContainerLogV2-HighScale in the same DCR. This will result in duplicate data.
Share DCR with multiple clusters
When you enable Container insights on a Kubernetes cluster, a new DCR is created for that cluster, and the DCR for each cluster can be modified independently. If you have multiple clusters with custom monitoring configurations, you may want to share a single DCR with multiple clusters. You can then make changes to a single DCR that are automatically implemented for any clusters associated with it.
A DCR is associated with a cluster with adata collection rule associates (DCRA). Use thepreview DCR experienceto view and remove existing DCR associations for each cluster. You can then use this feature to add an association to a single DCR for multiple clusters.
Configure data collection using ConfigMap
ConfigMapsare a Kubernetes mechanism that allow you to store non-confidential data such as a configuration file or environment variables. Container insights looks for a ConfigMap on each cluster with particular settings that define data that it should collect.
Important
ConfigMap is a global list and there can be only one ConfigMap applied to the agent for Container insights. Applying another ConfigMap will overrule the previous ConfigMap collection settings.
Prerequisites
The minimum agent version supported to collect stdout, stderr, and environmental variables from container workloads isciprod06142019or later.
Configure and deploy ConfigMap
Use the following procedure to configure and deploy your ConfigMap configuration file to your cluster:
If you don't already have a ConfigMap for Container insights, download thetemplate ConfigMap YAML fileand open it in an editor.
If you don't already have a ConfigMap for Container insights, download thetemplate ConfigMap YAML fileand open it in an editor.
Edit the ConfigMap YAML file with your customizations. The template includes all valid settings with descriptions. To enable a setting, remove the comment character (#) and set its value.
Edit the ConfigMap YAML file with your customizations. The template includes all valid settings with descriptions. To enable a setting, remove the comment character (#) and set its value.
Create a ConfigMap by running the following kubectl command:kubectl config set-context <cluster-name>
kubectl apply -f <configmap_yaml_file.yaml>

# Example: 
kubectl config set-context my-cluster
kubectl apply -f container-azm-ms-agentconfig.yamlThe configuration change can take a few minutes to finish before taking effect. Then all Azure Monitor Agent pods in the cluster will restart. The restart is a rolling restart for all Azure Monitor Agent pods, so not all of them restart at the same time. When the restarts are finished, you'll receive a message similar to the following result:configmap "container-azm-ms-agentconfig" created`.
Create a ConfigMap by running the following kubectl command:
kubectl config set-context <cluster-name>
kubectl apply -f <configmap_yaml_file.yaml>

# Example: 
kubectl config set-context my-cluster
kubectl apply -f container-azm-ms-agentconfig.yaml
kubectl config set-context <cluster-name>
kubectl apply -f <configmap_yaml_file.yaml>

# Example: 
kubectl config set-context my-cluster
kubectl apply -f container-azm-ms-agentconfig.yaml
The configuration change can take a few minutes to finish before taking effect. Then all Azure Monitor Agent pods in the cluster will restart. The restart is a rolling restart for all Azure Monitor Agent pods, so not all of them restart at the same time. When the restarts are finished, you'll receive a message similar to the following result:
configmap "container-azm-ms-agentconfig" created`.
configmap "container-azm-ms-agentconfig" created`.
Verify configuration
To verify the configuration was successfully applied to a cluster, use the following command to review the logs from an agent pod.
kubectl logs ama-logs-fdf58 -n kube-system -c ama-logs
kubectl logs ama-logs-fdf58 -n kube-system -c ama-logs
If there are configuration errors from the Azure Monitor Agent pods, the output will show errors similar to the following:
***************Start Config Processing******************** 
config::unsupported/missing config schema version - 'v21' , using defaults
***************Start Config Processing******************** 
config::unsupported/missing config schema version - 'v21' , using defaults
Use the following options to perform more troubleshooting of configuration changes:
Use the samekubectl logscommand from an agent pod.
Use the samekubectl logscommand from an agent pod.
kubectl logs
Review live logs for errors similar to the following:config::error::Exception while parsing config map for log collection/env variable settings: \nparse error on value \"$\" ($end), using defaults, please check config map for errors
Review live logs for errors similar to the following:
config::error::Exception while parsing config map for log collection/env variable settings: \nparse error on value \"$\" ($end), using defaults, please check config map for errors
config::error::Exception while parsing config map for log collection/env variable settings: \nparse error on value \"$\" ($end), using defaults, please check config map for errors
Data is sent to theKubeMonAgentEventstable in your Log Analytics workspace every hour with error severity for configuration errors. If there are no errors, the entry in the table will have data with severity info, which reports no errors. TheTagscolumn contains more information about the pod and container ID on which the error occurred and also the first occurrence, last occurrence, and count in the last hour.
Data is sent to theKubeMonAgentEventstable in your Log Analytics workspace every hour with error severity for configuration errors. If there are no errors, the entry in the table will have data with severity info, which reports no errors. TheTagscolumn contains more information about the pod and container ID on which the error occurred and also the first occurrence, last occurrence, and count in the last hour.
KubeMonAgentEvents
Tags
Verify schema version
Supported config schema versions are available as pod annotation (schema-versions) on the Azure Monitor Agent pod. You can see them with the following kubectl command.
kubectl describe pod ama-logs-fdf58 -n=kube-system.
kubectl describe pod ama-logs-fdf58 -n=kube-system.
ConfigMap settings
The following table describes the settings you can configure to control data collection with ConfigMap.
schema-version
config-version
[stdout]
enabled
true
true
[stdout]
exclude_namespaces
enabled
true
["kube-system","gatekeeper-system"]
[stderr]
enabled
true
true
[stderr]
exclude_namespaces
enabled
true
["kube-system","gatekeeper-system"]
[env_var]
enabled
true
[enrich_container_logs]
enabled
Name
Image
false
[collect_all_kube_events]
enabled
true
false
[schema]
containerlog_schema_version
v2
v1
v2
[enable_multiline_logs]
enabled
false
schema
v2
[metadata_collection]
enabled
KubernetesMetadata
ContainerLogV2
[metadata_collection]
include_fields
["podLabels","podAnnotations","podUid","image","imageID","imageRepo","imageTag"]
[log_collection_settings.multi_tenancy]
enabled
false
[collect_kube_system_pv_metrics]
enabled
true
false
[proxy_config]
ignore_proxy_settings
true
false
enable_internal_metrics
false
Next steps
SeeFilter log collection in Container insightsfor details on saving costs by configuring Container insights to filter data that you don't require.
Feedback
Was this page helpful?
Additional resources