Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Create Azure Cosmos DB containers and databases with autoscale throughput
Article
2024-12-12
9 contributors
In this article
APPLIES TO:NoSQLMongoDBCassandraGremlinTable
In Azure Cosmos DB, you can configure either standard (manual) or autoscale provisioned throughput on your databases and containers. Autoscale provisioned throughput in Azure Cosmos DB allows you toscale the throughput (RU/s) of your database or container automatically and instantly.
Autoscale provisioned throughput is well suited for mission-critical workloads that have variable or unpredictable traffic patterns, and require SLAs on high performance and scale. Autoscale by default scales workloads based on the most active region and partition. For nonuniform workloads that have different workload patterns across regions and partitions, this scaling can cause unnecessary scale-ups.Dynamic scaling or dynamic autoscaleis an enhancement to autoscale provisioned throughout that helps scaling of such nonuniform workloads independently based on usage, at per region and per partition level. Dynamic scaling allows you to save cost if you often experience hot partitions and/or have multiple regions.
Benefits of autoscale
Azure Cosmos DB databases and containers that are configured with autoscale provisioned throughput have the following benefits:
Simple:Autoscale removes the complexity of managing RU/s with custom scripting or manually scaling capacity.
Simple:Autoscale removes the complexity of managing RU/s with custom scripting or manually scaling capacity.
Scalable:Databases and containers automatically scale the provisioned throughput as needed. There's no disruption to client connections, applications, or to Azure Cosmos DB SLAs.
Scalable:Databases and containers automatically scale the provisioned throughput as needed. There's no disruption to client connections, applications, or to Azure Cosmos DB SLAs.
Cost-effective:Autoscale helps optimize your RU/s usage and cost usage by scaling down when not in use. You only pay for the resources that your workloads need on a per-hour basis. Of all hours in a month, if you set autoscale max RU/s(Tmax) and use the full amount Tmax for 66% of the hours or less, you can save with autoscale. In addition with dynamic scaling, adding a secondary region for high availability is more cost-efficient as each region and partition scales independently based on actual usage. To learn more, see thehow to choose between standard (manual) and autoscale provisioned throughputarticle.
Cost-effective:Autoscale helps optimize your RU/s usage and cost usage by scaling down when not in use. You only pay for the resources that your workloads need on a per-hour basis. Of all hours in a month, if you set autoscale max RU/s(Tmax) and use the full amount Tmax for 66% of the hours or less, you can save with autoscale. In addition with dynamic scaling, adding a secondary region for high availability is more cost-efficient as each region and partition scales independently based on actual usage. To learn more, see thehow to choose between standard (manual) and autoscale provisioned throughputarticle.
Highly available:Databases and containers using autoscale use the same globally distributed, fault-tolerant, highly available Azure Cosmos DB backend to ensure data durability and high availability.
Highly available:Databases and containers using autoscale use the same globally distributed, fault-tolerant, highly available Azure Cosmos DB backend to ensure data durability and high availability.
Use cases of autoscale
The use cases of autoscale include:
Variable or unpredictable workloads:When your workloads have variable or unpredictable spikes in usage, autoscale helps by automatically scaling up and down based on usage. Examples include retail websites that have different traffic patterns depending on seasonality; IOT workloads that have spikes at various times during the day; line of business applications that see peak usage a few times a month or year, and more. With autoscale, you no longer need to manually provision for peak or average capacity.
Variable or unpredictable workloads:When your workloads have variable or unpredictable spikes in usage, autoscale helps by automatically scaling up and down based on usage. Examples include retail websites that have different traffic patterns depending on seasonality; IOT workloads that have spikes at various times during the day; line of business applications that see peak usage a few times a month or year, and more. With autoscale, you no longer need to manually provision for peak or average capacity.
New applications:If you're developing a new application and not sure about the throughput (RU/s) you need, autoscale makes it easy to get started. You can start with the autoscale entry point of 100 - 1000 RU/s, monitor your usage, and determine the right RU/s over time.
New applications:If you're developing a new application and not sure about the throughput (RU/s) you need, autoscale makes it easy to get started. You can start with the autoscale entry point of 100 - 1000 RU/s, monitor your usage, and determine the right RU/s over time.
Infrequently used applications:If you have an application, which is only used for a few hours several times a day, week, or monthâsuch as a low-volume application/web/blog site. Autoscale adjusts the capacity to handle peak usage and scales down when it's over.
Infrequently used applications:If you have an application, which is only used for a few hours several times a day, week, or monthâsuch as a low-volume application/web/blog site. Autoscale adjusts the capacity to handle peak usage and scales down when it's over.
Development and test workloads:If you or your team use Azure Cosmos DB databases and containers during work hours, but don't need them on nights or weekends, autoscale helps save cost by scaling down to a minimum when not in use.
Development and test workloads:If you or your team use Azure Cosmos DB databases and containers during work hours, but don't need them on nights or weekends, autoscale helps save cost by scaling down to a minimum when not in use.
Scheduled production workloads/queries:If you have a series of scheduled requests, operations, or queries that you want to run during idle periods, you can do that easily with autoscale. When you need to run the workload, the throughput automatically scales to needed value and scales down afterward.
Scheduled production workloads/queries:If you have a series of scheduled requests, operations, or queries that you want to run during idle periods, you can do that easily with autoscale. When you need to run the workload, the throughput automatically scales to needed value and scales down afterward.
Building a custom solution to these problems not only requires an enormous amount of time, but also introduces complexity in your application's configuration or code. Autoscale enables the above scenarios out of the box and removes the need for custom or manual scaling of capacity.
Use cases of dynamic scaling
The use cases of dynamic scaling include:
Database workloads that have a highly trafficked primary region and a secondary passive region for disaster recovery.With dynamic scaling, achieving high availability with multiple regions is more cost effective. The secondary region independently and automatically scales down while idle. The secondary region also automatically scales up as it becomes active and while handling write replication traffic from the primary region.
With dynamic scaling, achieving high availability with multiple regions is more cost effective. The secondary region independently and automatically scales down while idle. The secondary region also automatically scales up as it becomes active and while handling write replication traffic from the primary region.
Multi-region database workloads.These workloads often observe uneven distribution of requests across regions due to natural traffic growth and dips throughout the day. For example, a database might be active during business hours across globally distributed time zones.
These workloads often observe uneven distribution of requests across regions due to natural traffic growth and dips throughout the day. For example, a database might be active during business hours across globally distributed time zones.
How autoscale provisioned throughput works
When configuring containers and databases with autoscale, you specify the maximum throughputTmaxrequired. Azure Cosmos DB scales the throughputTsuch0.1*Tmax <= T <= Tmax. For example, if you set the maximum throughput to 20,000 RU/s, the throughput scales between 2000 to 20,000 RU/s. Because scaling is automatic and instantaneous, at any point in time, you can consume up to the provisionedTmaxwith no delay.
Tmax
T
0.1*Tmax <= T <= Tmax
Tmax
Each hour, you're billed for the highest throughputTthe system scaled to within the hour. When dynamic scaling is enabled, scaling is based on the RU/s usage at each physical partition and region. As each partition and region scale independently, this can lead to cost savings for nonuniform workloads, as unnecessary scale-ups are avoided.
T
The entry point for autoscale maximum throughputTmaxstarts at 1000 RU/s, which scales between 100 - 1000 RU/s. You can setTmaxin increments of 1000 RU/s and change the value at any time.
Tmax
Tmax
For example, if we have a collection with1000RU/s and2partitions, each partition can go up to500RU/s. For one hour of activity, the utilization would look like this:
Without dynamic scaling, all partitions are scaled uniformly based on the hottest partition. In this example, because the hottest partition had 100% utilization, all partitions in both the write and read regions are scaled to 1000 RU/s, making the total RU/s scaled to2000 RU/s.
With dynamic scaling, because each partition and region's throughput is scaled independently, the total RU/s scaled to would be900 RU/s, which better reflects the actual traffic pattern and lowers costs.
Enabling autoscale on existing resources
Use theAzure portal,CLIorPowerShellto enable autoscale on an existing database or container. You can switch between autoscale and standard (manual) provisioned throughput at any time. For more information, refer thisdocumentationfor more information.
Throughput and storage limits for autoscale
For any value ofTmax, the database or container can store a total of0.1 * Tmax GB. After this amount of storage is reached, the maximum RU/s will be automatically increased based on the new storage value, without impacting your application.
Tmax
0.1 * Tmax GB
For example, if you start with a maximum RU/s of 50,000 RU/s (scales between 5000 - 50,000 RU/s), you can store up to 5000 GB of data. If you exceed 5000 GB - for example, storage is now 6000 GB, the new maximum RU/s becomes 60,000 RU/s (scales between 6000 - 60,000 RU/s).
When you use database level throughput with autoscale, you can have the first 25 containers share an autoscale maximum RU/s of 1000 (scales between 100 - 1000 RU/s), as long as you don't exceed 100 GB of storage. For more information, refer thisdocumentation.
Enabling dynamic scaling
Dynamic scaling is enabled by default for all Azure Cosmos DB accounts created afterSeptember 25, 2024. Customers who wish to enable this feature for their older accounts can do soprogrammaticallythrough Azure PowerShell/CLI/Rest API or from the features pane of Azure portal as shown:
Navigate to your Azure Cosmos DB account in theAzure portal.
Navigate to your Azure Cosmos DB account in theAzure portal.
Navigate to theFeaturespage.
Navigate to theFeaturespage.
Locate and enable theDynamic Scaling (Per Region and Per Partition Autoscale)feature.ImportantThe feature is enabled at the account level, so all autoscale containers and autoscale shared throughput databases within the account will automatically have this capability applied. Enabling this feature does not affect resources in the account that are using manual throughput. Manual resources will need to be changed to autoscale to take advantage of dynamic scaling. Enabling this feature has zero downtime or performance impact. This feature is not applicable for serverless accounts. This feature is supported on all clouds.
Locate and enable theDynamic Scaling (Per Region and Per Partition Autoscale)feature.

Important
The feature is enabled at the account level, so all autoscale containers and autoscale shared throughput databases within the account will automatically have this capability applied. Enabling this feature does not affect resources in the account that are using manual throughput. Manual resources will need to be changed to autoscale to take advantage of dynamic scaling. Enabling this feature has zero downtime or performance impact. This feature is not applicable for serverless accounts. This feature is supported on all clouds.
Monitoring Metrics
You can use the following metrics to monitor autoscale and dynamic scaling:
Provisioned Throughput
Normalized RU Consumption
Autoscaled RU
Important
It is recommended to use Azure Cosmos DB's native dynamic scaling capability to manage your capacity. However, if needed, theNormalized RU Consumption metricin Azure Monitor can be used to make programmatic scaling decisions. Other approaches, like using the ReadThroughputAsync() call in the Azure Cosmos DB SDKs to get the ProvisionedThroughput, or using ProvisionedThroughput in Azure Monitor are not recommended and will lead to inaccurate results. These metrics represent billed throughput with a delay and shouldn't be used for scaling decisions.
Comparison â containers configured with manual vs autoscale throughput
For more detail, see thisdocumentationon how to choose between standard (manual) and autoscale throughput.
Migrate standard provisioned throughput to autoscale
Users that want to migrate a large number of resources from standard provisioned throughput to autoscale can use an Azure CLI script to migrate every throughput resource in an Azure subscription to autoscale.
Next steps
Review theautoscale FAQ.
Learn how tochoose between manual and autoscale throughput.
Learn how toprovision autoscale throughput on an Azure Cosmos DB database or container.
Learn more aboutpartitioningin Azure Cosmos DB.
Trying to do capacity planning for a migration to Azure Cosmos DB? You can use information about your existing database cluster for capacity planning.If all you know is the number of vCores and servers in your existing database cluster, read aboutestimating request units using vCores or vCPUsIf you know typical request rates for your current database workload, read aboutestimating request units using Azure Cosmos DB capacity planner
If all you know is the number of vCores and servers in your existing database cluster, read aboutestimating request units using vCores or vCPUs
If you know typical request rates for your current database workload, read aboutestimating request units using Azure Cosmos DB capacity planner
Feedback
Was this page helpful?
Additional resources