Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Configure diagnostic log delivery
Article
2025-03-19
2 contributors
In this article
Note
Databricks recommends using the audit log system table (system.access.audit) to access your account's audit logs. SeeAudit log system table reference.
system.access.audit
This article describes how to enable diagnostic log delivery for your Azure Databricks workspaces.
Note
Diagnostic logs require thePremium plan.
Log in to the Azure portal as an Owner, Contributor, or as a user with a custom role with theMicrosoft.Databricks/workspaces/assignWorkspaceAdmin/actionpermission for the Azure Databricks workspace. Then click your Azure Databricks service resource.
Log in to the Azure portal as an Owner, Contributor, or as a user with a custom role with theMicrosoft.Databricks/workspaces/assignWorkspaceAdmin/actionpermission for the Azure Databricks workspace. Then click your Azure Databricks service resource.
Microsoft.Databricks/workspaces/assignWorkspaceAdmin/action
In the Monitoring section of the sidebar, click theDiagnostic settingstab.
In the Monitoring section of the sidebar, click theDiagnostic settingstab.
ClickTurn on diagnostics.
ClickTurn on diagnostics.

On the Diagnostic settings page, provide the following configuration:NameEnter a name for the logs to create.Archive to a storage accountTo use this option, you need an existing storage account to connect to. To create a new storage account in the portal, seeCreate a storage accountand follow the instructions to create an Azure Resource Manager, general-purpose account. Then return to this page in the portal to select your storage account. It might take a few minutes for newly created storage accounts to appear in the drop-down menu. For information about additional costs incurred by writing to a storage account, seeAzure Storage pricing.Stream to an event hubTo use this option, you need an existing Azure Event Hubs namespace and event hub to connect to. To create an Event Hubs namespace, seeCreate an Event Hubs namespace and an event hub by using the Azure portal. Then return to this page in the portal to select the Event Hubs namespace and policy name. For information about additional costs incurred by writing to an event hub, seeAzure Event Hubs pricing.Send to Log AnalyticsTo use this option, either use an existing Log Analytics workspace or create a new one by following the steps toCreate a new workspacein the portal. For information about additional costs incurred by sending logs to Log Analytics, seeAzure Monitor pricing.
On the Diagnostic settings page, provide the following configuration:
Name
Enter a name for the logs to create.
Archive to a storage account
To use this option, you need an existing storage account to connect to. To create a new storage account in the portal, seeCreate a storage accountand follow the instructions to create an Azure Resource Manager, general-purpose account. Then return to this page in the portal to select your storage account. It might take a few minutes for newly created storage accounts to appear in the drop-down menu. For information about additional costs incurred by writing to a storage account, seeAzure Storage pricing.
Stream to an event hub
To use this option, you need an existing Azure Event Hubs namespace and event hub to connect to. To create an Event Hubs namespace, seeCreate an Event Hubs namespace and an event hub by using the Azure portal. Then return to this page in the portal to select the Event Hubs namespace and policy name. For information about additional costs incurred by writing to an event hub, seeAzure Event Hubs pricing.
Send to Log Analytics
To use this option, either use an existing Log Analytics workspace or create a new one by following the steps toCreate a new workspacein the portal. For information about additional costs incurred by sending logs to Log Analytics, seeAzure Monitor pricing.

Choose the services you want diagnostic logs for.
Choose the services you want diagnostic logs for.
SelectSave.
SelectSave.
If you receive an error that says âFailed to update diagnostics for<workspace name>. The subscription<subscription id>is not registered to use microsoft.insights,â follow theTroubleshoot Azure Diagnosticsinstructions to register the account and then retry this procedure.
If you receive an error that says âFailed to update diagnostics for<workspace name>. The subscription<subscription id>is not registered to use microsoft.insights,â follow theTroubleshoot Azure Diagnosticsinstructions to register the account and then retry this procedure.
<workspace name>
<subscription id>
If you want to change how your diagnostic logs are saved at any point in the future, return to this page to modify the diagnostic log settings for your account.
If you want to change how your diagnostic logs are saved at any point in the future, return to this page to modify the diagnostic log settings for your account.
Note
If you want to set storage retention policies, configure anAzure lifecycle management policy.
Enable logging using PowerShell
Start an Azure PowerShell session and sign in to your Azure account with the following command:Connect-AzAccountTo sign in to your Azure account as a user, seePowerShell login with an Azure Databricks user account. To sign in to your Azure account as a service principal, seePowerShell login with a Microsoft Entra ID service principal.If you do not have Azure Powershell installed already, use the following commands to install Azure PowerShell.Install-Module -Name Az -AllowClobber
Start an Azure PowerShell session and sign in to your Azure account with the following command:
Connect-AzAccount
Connect-AzAccount
To sign in to your Azure account as a user, seePowerShell login with an Azure Databricks user account. To sign in to your Azure account as a service principal, seePowerShell login with a Microsoft Entra ID service principal.
If you do not have Azure Powershell installed already, use the following commands to install Azure PowerShell.
Install-Module -Name Az -AllowClobber
Install-Module -Name Az -AllowClobber
In the pop-up browser window, enter your Azure account user name and password. Azure PowerShell gets all of the subscriptions that are associated with this account, and by default, uses the first one.If you have more than one subscription, you might have to specify the specific subscription that was used to create your Azure Key Vault. To see the subscriptions for your account, type the following command:Get-AzSubscriptionTo specify the subscription thatâs associated with the Azure Databricks account that youâre logging, type the following command:Set-AzContext -SubscriptionId <subscription ID>
In the pop-up browser window, enter your Azure account user name and password. Azure PowerShell gets all of the subscriptions that are associated with this account, and by default, uses the first one.
If you have more than one subscription, you might have to specify the specific subscription that was used to create your Azure Key Vault. To see the subscriptions for your account, type the following command:
Get-AzSubscription
Get-AzSubscription
To specify the subscription thatâs associated with the Azure Databricks account that youâre logging, type the following command:
Set-AzContext -SubscriptionId <subscription ID>
Set-AzContext -SubscriptionId <subscription ID>
Set your Log Analytics resource name to a variable namedlogAnalytics, whereResourceNameis the name of the Log Analytics workspace.$logAnalytics = Get-AzResource -ResourceGroupName <resource group name> -ResourceName <resource name> -ResourceType "Microsoft.OperationalInsights/workspaces"
Set your Log Analytics resource name to a variable namedlogAnalytics, whereResourceNameis the name of the Log Analytics workspace.
logAnalytics
ResourceName
$logAnalytics = Get-AzResource -ResourceGroupName <resource group name> -ResourceName <resource name> -ResourceType "Microsoft.OperationalInsights/workspaces"
$logAnalytics = Get-AzResource -ResourceGroupName <resource group name> -ResourceName <resource name> -ResourceType "Microsoft.OperationalInsights/workspaces"
Set the Azure Databricks service resource name to a variable nameddatabricks, whereResourceNameis the name of the Azure Databricks service.$databricks = Get-AzResource -ResourceGroupName <your resource group name> -ResourceName <your Azure Databricks service name> -ResourceType "Microsoft.Databricks/workspaces"
Set the Azure Databricks service resource name to a variable nameddatabricks, whereResourceNameis the name of the Azure Databricks service.
databricks
ResourceName
$databricks = Get-AzResource -ResourceGroupName <your resource group name> -ResourceName <your Azure Databricks service name> -ResourceType "Microsoft.Databricks/workspaces"
$databricks = Get-AzResource -ResourceGroupName <your resource group name> -ResourceName <your Azure Databricks service name> -ResourceType "Microsoft.Databricks/workspaces"
To enable logging for Azure Databricks, use theNew-AzDiagnosticSettingcmdlet with variables for the new storage account, Azure Databricks service, and the category to enable for logging. Run the following command and set the-Enabledflag to$true:New-AzDiagnosticSetting -ResourceId $databricks.ResourceId -WorkspaceId $logAnalytics.ResourceId -Enabled $true -name "<diagnostic setting name>" -Category <comma separated list>
To enable logging for Azure Databricks, use theNew-AzDiagnosticSettingcmdlet with variables for the new storage account, Azure Databricks service, and the category to enable for logging. Run the following command and set the-Enabledflag to$true:
-Enabled
$true
New-AzDiagnosticSetting -ResourceId $databricks.ResourceId -WorkspaceId $logAnalytics.ResourceId -Enabled $true -name "<diagnostic setting name>" -Category <comma separated list>
New-AzDiagnosticSetting -ResourceId $databricks.ResourceId -WorkspaceId $logAnalytics.ResourceId -Enabled $true -name "<diagnostic setting name>" -Category <comma separated list>
Enable logging by using Azure CLI
Open PowerShell.
Open PowerShell.
Use the following command to connect to your Azure account:az loginTo connect by using a Microsoft Entra ID service principal, seeAzure CLI login with a Microsoft Entra ID service principal.To connect by using an Azure Databricks user account, seeAzure CLI login with an Azure Databricks user account.
Use the following command to connect to your Azure account:
az login
az login
To connect by using a Microsoft Entra ID service principal, seeAzure CLI login with a Microsoft Entra ID service principal.
To connect by using an Azure Databricks user account, seeAzure CLI login with an Azure Databricks user account.
Run the following diagnostic setting command:az monitor diagnostic-settings create --name <diagnostic name>
--resource-group <log analytics workspace resource group>
--workspace <log analytics name or object ID>
--resource <target resource object ID>
--logs '[
{
 \"category\": <category name>,
  \"enabled\": true
}
]'
Run the following diagnostic setting command:
az monitor diagnostic-settings create --name <diagnostic name>
--resource-group <log analytics workspace resource group>
--workspace <log analytics name or object ID>
--resource <target resource object ID>
--logs '[
{
 \"category\": <category name>,
  \"enabled\": true
}
]'
az monitor diagnostic-settings create --name <diagnostic name>
--resource-group <log analytics workspace resource group>
--workspace <log analytics name or object ID>
--resource <target resource object ID>
--logs '[
{
 \"category\": <category name>,
  \"enabled\": true
}
]'
REST API
Use theLogSettingsAPI.
Request
PUT https://management.azure.com/{resourceUri}/providers/microsoft.insights/diagnosticSettings/{name}?api-version=2017-05-01-preview
PUT https://management.azure.com/{resourceUri}/providers/microsoft.insights/diagnosticSettings/{name}?api-version=2017-05-01-preview
Request body
{
  "properties": {
    "workspaceId": "<log analytics resourceId>",
    "logs": [
      {
        "category": "<category name>",
        "enabled": true,
        "retentionPolicy": {
          "enabled": false,
          "days": 0
        }
      }
    ]
  }
}
{
  "properties": {
    "workspaceId": "<log analytics resourceId>",
    "logs": [
      {
        "category": "<category name>",
        "enabled": true,
        "retentionPolicy": {
          "enabled": false,
          "days": 0
        }
      }
    ]
  }
}
Diagnostic log latency
After logging is enabled for your account, Azure Databricks automatically sends diagnostic logs to your delivery location. Logs are typically available within 15 minutes of activation. Azure Databricks auditable events typically appear in diagnostic logs within 15 minutes in Azure Commercial regions.
SSH login logs are delivered with high latency.
Note
While most logs are expected to be delivered within 15 minutes, Azure Databricks does not guarantee a time frame for log delivery.
Feedback
Was this page helpful?
Additional resources