Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Architecture best practices for Log Analytics
Article
2024-03-01
8 contributors
In this article
Well-Architected Framework workload functionality and performance must be monitored in diverse ways and for diverse reasons. Azure Monitor Log Analytics workspaces are the primary log and metric sink for a large portion of the monitoring data. Workspaces support multiple features in Azure Monitor including ad-hoc queries, visualizations, and alerts. For general monitoring principles, seeMonitoring and diagnostics guidance. The guidance presents general monitoring principles. It identifies the different types of data. It identifies the required analysis that Azure Monitor supports and it also identifies the data stored in the workspace that enables the analysis.
This article assumes that you understand system design principles. You also need a working knowledge of Log Analytics workspaces and features in Azure Monitor that populate operational workload data. For more information, seeLog Analytics workspace overview.
Important
How to use this guide
Each section has adesign checklistthat presents architectural areas of concern along with design strategies localized to the technology scope.
Also included arerecommendationson the technology capabilities or deployment topologies that can help materialize those strategies. The recommendations don't represent an exhaustive list of all configurations available for Log Analytics workspaces and its related Azure Monitor resources. Instead, they list the key recommendations mapped to the design perspectives. Use the recommendations to build your proof-of-concept, design your workload monitoring environment, or optimize your existing workload monitoring solution.
Technology scope
This guide focuses on the interrelated decisions for the following Azure resources.
Log Analytics workspaces
Workload operational log data
Diagnostic settings on Azure resources in your workload
Reliability
The purpose of the Reliability pillar is to provide continued functionality bybuilding enough resilience and the ability to recover fast from failures.
TheReliability design principlesprovide a high-level design strategy applied for individual components, system flows, and the system as a whole.
The reliability situations to consider for Log Analytics workspaces are:
Availability of the workspace.
Protection of collected data in the rare case of an Azure datacenter or region failure.
There's currently no standard feature for failover between workspaces in different regions, but there are strategies to use if you have particular requirements for availability or compliance.
Design checklist for Reliability
Start your design strategy based on thedesign review checklist for Reliabilityand determine its relevance to your business requirements while keeping in mind the SKUs and features of virtual machines (VMs) and their dependencies. Extend the strategy to include more approaches as needed.
Reviewservice limits for Log Analytics workspaces. The service limits section helps you understand restrictions on data collection and retention, and other aspects of the service. These limits help you determine how to properly design your workload observability strategy. Be sure to reviewAzure Monitor service limitssince many of the functions discussed therein, like queries, work hand-in-hand with Log Analytics workspaces.
Plan for workspace resilience and recovery.Log Analytics workspaces are regional, with no built-in support for cross-regional redundancy or replication. Also, availability zone redundancy options are limited. As such, you should determine the reliability requirements of your workspaces and strategize to meet those targets. Your requirements might stipulate that your workspace must be resilient to datacenter failures or regional failures, or they might stipulate that you must be able to recover your data to a new workspace in a failover region. Each of these scenarios require additional resources and processes to be put in place to be successful, so balancing your reliability targets with cost and complexity should be carefully considered.
Choose the right deployment regions to meet your reliability requirements.Deploy your Log Analytics workspace and data collection endpoints (DCEs) co-located with the workload components emitting operational data. Your choice of the appropriate region in which to deploy your workspace and your DCEs should be informed by where youdeploy your workload. You might need to weigh the regional availability of certain Log Analytics functionality, like dedicated clusters, against other factors more central to your workload's reliability, cost, and performance requirements.
Ensure that your observability systems are healthy.Like any other component of your workload, ensure that your monitoring and logging systems are functioning properly. To accomplish this, enable features that send health data signals to your operations teams. Set up health data signals specific to your Log Analytics workspaces and associated resources.
Configuration recommendations for Reliability
Azure Policy
Azure offers no policies related to reliability of Log Analytics workspaces. You can createcustom policiesto build compliance guardrails around your workspace deployments, such as ensuring workspaces are associated to a dedicated cluster.
While not directly related to the reliability of Log Analytics workspaces, there are Azure policies for nearly every service available. The policies ensure that diagnostics settings are enabled for that service and validate that the service's log data is flowing into a Log Analytics workspace. All services in workload architecture should be sending their log data to a Log Analytics workspace for their own reliability needs, and the policies can help enforce it. Likewise, policies exist to ensure agent-based platforms, such as VMs and Kubernetes, have the agent installed.
Azure Advisor
Azure offers no Azure Advisor recommendations related to the reliability of Log Analytics workspaces.
Security
The purpose of the Security pillar is to provideconfidentiality, integrity, and availabilityguarantees to the workload.
TheSecurity design principlesprovide a high-level design strategy for achieving these goals by applying approaches to the technical design around your monitoring and logging solution.
Design checklist for Security
Start your design strategy based on thedesign review checklist for Securityand identify vulnerabilities and controls to improve the security posture. Extend the strategy to include more approaches as needed.
Review the Azure Monitorsecurity baselineandManage access to Log Analytics workspacestopics. These topics provide guidance on security best practices.
Deploy your workspaces with segmentation as a cornerstone principle.Implement segmentation at the networking, data, and access levels. Segmentation helps ensure that your workspaces are isolated to the appropriate degree and are better protected from unauthorized access to the highest degree possible, while still meeting your business requirements for reliability, cost optimization, operational excellence, and performance efficiency.
Ensure that you can audit workspace reads and writes activities and associated identities.Attackers can benefit from viewing operational logs. A compromised identity can lead to log injection attacks. Enable auditing of operations run from the Azure Portal or through API interactions and the associated users. If you're not set up to audit your workspace, you might be putting your organization at risk of being in breach of compliance requirements.
Implement robust network controls.Helps secure your network access to your workspace and your logs through network isolation and firewall functions. Insufficiently configured network controls might put you at risk of being accessed by unauthorized or malicious actors.
Determine what types of data need immutability or long-term retention.Your log data should be treated with the same rigor as workload data inside production systems. Include log data in your data classification practices to ensure that you're successfully storing sensitive log data according to its compliance requirements.
Protect log data at rest through encryption.Segmentation alone won't completely protect confidentiality of your log data. If unauthorized raw access happens, having the log data encrypted at rest helps prevent bad actors from using that data outside of your workspace.
Protect sensitive log data through obfuscation.Just like workload data residing in production systems, you must take extra measures to ensure confidentiality is retained for sensitive information that might be intentionally or unintentionally present in operational logs. When you use obfuscation methods, it helps you hide sensitive log data from unauthorized eyes.
Configuration recommendations for Security
Azure Policy
Azure offers policies related to the security of Log Analytics workspaces to help enforce your desired security posture. Examples of such policies are:
Azure Monitor Logs clusters should be encrypted with customer-managed key
Saved-queries in Azure Monitor should be saved in customer storage account for logs encryption
Log Analytics Workspaces should block non-Microsoft Entra ID based ingestion
Azure also offers numerous policies to help enforce private link configuration, such asLog Analytics workspaces should block log ingestion and querying from public networksor even configuring the solution through DINE policies such asConfigure Azure Monitor Private Link Scope to use private DNS zones.
Azure Advisor
Azure offers no Azure Advisor recommendations related to the security of Log Analytics workspaces.
Cost Optimization
Cost Optimization focuses ondetecting spend patterns, prioritizing investments in critical areas, and optimizing in othersto meet the organization's budget while meeting business requirements.
TheCost Optimization design principlesprovide a high-level design strategy for achieving those business goals. They also help you make tradeoffs as necessary in the technical design related to your monitoring and logging solution.
For more information on how data charges are calculated for your Log Analytics workspaces, seeAzure Monitor Logs cost calculations and options.
Design checklist for Cost Optimization
Start your design strategy based on thedesign review checklist for Cost Optimizationfor investments and fine tune the design so that the workload is aligned with the budget allocated for the workload. Your design should use the right Azure capabilities, monitor investments, and find opportunities to optimize over time.
Perform cost modeling exercises. These exercizes help you understand your current workspace costs and forecast your costs relative to workspace growth. Analyze your growth trends in your workload and ensure that you understand plans for workload expansion to properly forecast your future operational logging costs.
Choose the right billing model.Use your cost model to determine the bestbilling modelfor your scenario. How you use your workspaces currently, and how you plan to you use them as your workload evolves determines whether a pay-as-you-go or a commitment tier model is the best fit for your scenario.Remember that you can choose different billing models for each workspace, and you can combine workspace costs in certain cases, so you can be granular in your analysis and decision-making.
Collect just the right amount of log data.Perform regularly scheduled analysis of your diagnostic settings on your resources, data collection rule configuration, and custom application code logging to ensure that you aren't collecting unnecessary log data.
Treat nonproduction environments differently than production.Review your nonproduction environments to ensure that you have configured your diagnostic settings and retention policies appropriately. These can often be significantly less robust than production, especially for dev/test or sandbox environments.
Configuration recommendations for Cost Optimization
Azure Policy
Azure offers no policies related to cost optimization of Log Analytics workspaces. You can createcustom policiesto build compliance guardrails around your workspace deployments, such as ensuring that your workspaces contain the right retention settings.
Azure Advisor
Azure Advisor makes recommendations to move specific tables in a workspace to the low-cost Basic Log data plan for tables that receive relatively high ingestion volume. Understand the limitations by using basic logs before switching. For more information, seeWhen should I use Basic Logs?. Azure Advisor might also recommendchanging pricing commitment tierfor the whole workspace based on overall usage volume.
Operational Excellence
Operational Excellence primarily focuses on procedures fordevelopment practices, observability, and release management.
TheOperational Excellence design principlesprovide a high-level design strategy for achieving those goals towards the operational requirements of the workload.
Design checklist for Operational Excellence
Start your design strategy based on thedesign review checklist for Operational Excellencefor defining processes for observability, testing, and deployment related to Log Analytics workspaces.
Use infrastructure as code (IaC) for all functions related to your workload's Log Analytics workspaces.Minimize the risk of human error that can occur with manually administering and operating your log collection, ingestion, storage and querying functions, including saved queries and query packs, by automating as many of those functions as possible through code. Also, include alerts that report health status changes and the configuration of diagnostic settings for resources that send logs to your workspaces in your IaC code. Include the code with your other workload-related code to ensure that your safe deployment practices are maintained for the management of your workspaces.
Ensure that your workspaces are healthy, and you're notified when issues arise.Like any other component of your workload, your workspaces can encounter issues. The issues can cost valuable time and resources to troubleshoot and resolve, and potentially leave your team unaware of the production workload status. Being able to proactively monitor workspaces and mitigate potential issues helps your operations teams minimize the time they spend troubleshooting and fixing issues.
Separate your production from nonproduction workloads.Avoid unnecessary complexity that can cause extra work for an operations team by using different workspaces for your production environment than those used by nonproduction environments. Comingled data can also lead to confusion as testing activities might appear to be events in production.
Prefer built-in tools and functions over non-Microsoft solutionsUse built-in tools to extend the functionality of your monitoring and logging systems. You might need to put additional configurations in place to support requirements like recoverability or data sovereignty that aren't available out-of-the-box with Log Analytics workspaces. In these cases, whenever practical, use native Azure or Microsoft tools to keep the number of tools that your organization must support to a minimum.
Treat your workspaces as static rather than ephemeral componentsLike other types of data stores, workspaces shouldn't be considered among the ephemeral components of your workload. The Well-Architected Framework generally favors immutable infrastructure and the ability to quickly and easily replace resources within your workload as part of your deployments. But the loss of workspace data can be catastrophic and irreversible. For this reason, leave workspaces out of deployment packages that replace infrastructure during updates, and only perform in-place upgrades on the workspaces.
Ensure that operations staff is trained on Kusto Query LanguageTrain staff to create or modify queries when needed. If operators are unable to write or modify queries, it can slow critical troubleshooting or other functions as operators must rely on other teams to do that work for them.
Configuration recommendations for Operational Excellence
Azure Policy and Azure Advisor
Azure offers no policies nor Azure Advisor recommendations related to the operational excellence of Log Analytics workspaces.
Performance efficiency
Performance Efficiency is aboutmaintaining user experience even when there's an increase in loadby managing capacity. The strategy includes scaling resources, identifying and optimizing potential bottlenecks, and optimizing for peak performance.
ThePerformance Efficiency design principlesprovide a high-level design strategy for achieving those capacity goals against the expected usage.
Design checklist for Performance Efficiency
Start your design strategy based on thedesign review checklist for Performance Efficiencyfor defining a baseline for your Log Analytics workspaces and associated functions.
Be familiar with fundamentals oflog data ingestion latency in Azure Monitor.There are several factors that contribute to latency when ingesting logs into your workspaces. Many of these factors are inherent to the Azure Monitor platform. Understanding the factors and the normal latency behavior can help you set appropriate expectations within your workload operations teams.
Separate your nonproduction and production workloads.Production-specific workspaces mitigate any overhead that nonproduction systems might introduce. It reduces the overall footprint of your workspaces, requiring fewer resources to handle log data processing.
Choose the right deployment regions to meet your performance requirements.Deploy your Log Analytics workspace and data collection endpoints (DCEs) close to your workload. Your choice of the appropriate region in which to deploy your workspace and your DCEs should be informed by where you deploy the workload. You might need to weigh the performance benefits of deploying your workspaces and DCEs in the same region as your workload against your reliability requirements if you have already deployed your workload into a region that cannot support those requirements for your log data.
Configuration recommendations for Performance Efficiency
Azure Policy and Azure Advisor
Azure offers no policies nor Azure Advisor recommendations related to the performance of Log Analytics workspaces.
Next step
Get best practices for a complete deployment of Azure Monitor.
Feedback
Was this page helpful?
Additional resources