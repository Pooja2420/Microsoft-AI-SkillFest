Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Optimize the performance of AzCopy with Azure Storage
Article
2024-02-01
6 contributors
In this article
AzCopy is a command-line utility that you can use to copy blobs or files to or from a storage account. This article helps you to optimize performance.
Note
If you're looking for content to help you get started with AzCopy, seeGet started with AzCopy
You can benchmark performance, and then use commands and environment variables to find an optimal tradeoff between performance and resource consumption.
Run benchmark tests
You can run a performance benchmark test on specific blob containers or file shares to view general performance statistics and to identify performance bottlenecks. You can run the test by uploading or downloading generated test data.
Use the following command to run a performance benchmark test.
Syntax
azcopy benchmark 'https://<storage-account-name>.blob.core.windows.net/<container-name>'
azcopy benchmark 'https://<storage-account-name>.blob.core.windows.net/<container-name>'
Example
azcopy benchmark 'https://mystorageaccount.blob.core.windows.net/mycontainer/myBlobDirectory?sv=2018-03-28&ss=bjqt&srs=sco&sp=rjklhjup&se=2019-05-10T04:37:48Z&st=2019-05-09T20:37:48Z&spr=https&sig=/SOVEFfsKDqRry4bk3qz1vAQFwY5DDzp2%2B/3Eykf/JLs%3D'
azcopy benchmark 'https://mystorageaccount.blob.core.windows.net/mycontainer/myBlobDirectory?sv=2018-03-28&ss=bjqt&srs=sco&sp=rjklhjup&se=2019-05-10T04:37:48Z&st=2019-05-09T20:37:48Z&spr=https&sig=/SOVEFfsKDqRry4bk3qz1vAQFwY5DDzp2%2B/3Eykf/JLs%3D'
Tip
This example encloses path arguments with single quotes (''). Use single quotes in all command shells except for the Windows Command Shell (cmd.exe). If you're using a Windows Command Shell (cmd.exe), enclose path arguments with double quotes ("") instead of single quotes ('').
This command runs a performance benchmark by uploading test data to a specified destination. The test data is generated in memory, uploaded to the destination, then deleted from the destination after the test is complete. You can specify how many files to generate and what size you'd like them to be by using optional command parameters.
If you prefer to run this test by downloading data, set themodeparameter todownload. For detailed reference docs, seeazcopy benchmark.
mode
download
Optimize for large numbers of files
Throughput can decrease when transferring large numbers of files. Each copy operation translates to one or more transactions that must be executed in the storage service. When you are transferring a large number of files, consider the number of transactions that need to be executed and any potential impact those transactions can have if other activities are occurring in the storage account at the same time.
To maximize performance, you can reduce the size of each job by limiting the number of files that are copied in a single job. For download and upload operations, increase concurrency as needed, decrease log activity, and turn off features that incur high performance costs.
To achieve optimal performance, ensure that each jobs transfers fewer than 10 million files. Jobs that transfer more than 50 million files can perform poorly because the AzCopy job tracking mechanism incurs a significant amount of overhead. To reduce overhead, consider dividing large jobs into smaller ones.
One way to reduce the size of a job is to limit the number of files affected by a job. You can use command parameters to do that. For example, a job can copy only a subset of directories by using theinclude pathparameter as part of theazcopy copycommand.
include path
Use theinclude-patternparameter to copy files that have a specific extension (for example:*.pdf). In a separate job, use theexclude-patternparameter to copy all files that don't have*.pdfextension. SeeUpload specific filesandDownload specific blobsfor examples.
include-pattern
*.pdf
exclude-pattern
*.pdf
After you've decided how to divide large jobs into smaller ones, consider running jobs on more than one Virtual Machine (VM).
If you're uploading or downloading files, use theAZCOPY_CONCURRENCY_VALUEenvironment variable to increase the number of concurrent requests that can occur on your machine. Set this variable as high as possible without compromising the performance of your machine. To learn more about this variable, see theIncrease the number of concurrent requestssection of this article.
AZCOPY_CONCURRENCY_VALUE
If you're copying blobs between storage accounts, consider setting the value of theAZCOPY_CONCURRENCY_VALUEenvironment variable to a value greater than1000. You can set this variable high because AzCopy uses server-to-server APIs, so data is copied directly between storage servers and does not use your machine's processing power.
AZCOPY_CONCURRENCY_VALUE
1000
You can improve performance by reducing the number of log entries that AzCopy creates as it completes an operation. By default, AzCopy logs all activity related to an operation. To achieve optimal performance, consider setting the--log-levelparameter of your copy, sync, or remove command toERROR. That way, AzCopy logs only errors. By default, the value log level is set toINFO.
--log-level
ERROR
INFO
If you're uploading or downloading files, consider setting the--check-lengthof your copy and sync commands tofalse. This prevents AzCopy from verifying the length of a file after a transfer. By default, AzCopy checks the length to ensure that source and destination files match after a transfer completes. AzCopy performs this check after each file transfer. This check can degrade performance when jobs transfer large numbers of small files.
--check-length
false
File scans on some Linux systems don't execute fast enough to saturate all of the parallel network connections. In these cases, you can set theAZCOPY_CONCURRENT_SCANto a higher number.
AZCOPY_CONCURRENT_SCAN
Increase the number of concurrent requests
You can increase throughput by setting theAZCOPY_CONCURRENCY_VALUEenvironment variable. This variable specifies the number of concurrent requests that can occur.
AZCOPY_CONCURRENCY_VALUE
If your computer has fewer than 5 CPUs, then the value of this variable is set to32. Otherwise, the default value is equal to 16 multiplied by the number of CPUs. The maximum default value of this variable is3000, but you can manually set this value higher or lower.
32
3000
set AZCOPY_CONCURRENCY_VALUE=<value>
export AZCOPY_CONCURRENCY_VALUE=<value>
export AZCOPY_CONCURRENCY_VALUE=<value>
Use theazcopy envto check the current value of this variable. If the value is blank, then you can read which value is being used by looking at the beginning of any AzCopy log file. The selected value, and the reason it was selected, are reported there.
azcopy env
Before you set this variable, we recommend that you run a benchmark test. The benchmark test process will report the recommended concurrency value. Alternatively, if your network conditions and payloads vary, set this variable to the wordAUTOinstead of to a particular number. That will cause AzCopy to always run the same automatic tuning process that it uses in benchmark tests.
AUTO
Limit the throughput data rate
You can use thecap-mbpsflag in your commands to place a ceiling on the throughput data rate. For example, the following command resumes a job and caps throughput to10megabits (Mb) per second. Please note, this is only supported for uploading or downloading files, not copying between accounts.
cap-mbps
10
azcopy jobs resume <job-id> --cap-mbps 10
azcopy jobs resume <job-id> --cap-mbps 10
Optimize memory use
Set theAZCOPY_BUFFER_GBenvironment variable to specify the maximum amount of your system memory you want AzCopy to use for buffering when downloading and uploading files. Express this value in gigabytes (GB).
AZCOPY_BUFFER_GB
set AZCOPY_BUFFER_GB=<value>
export AZCOPY_BUFFER_GB=<value>
export AZCOPY_BUFFER_GB=<value>
Note
Job tracking always incurs additional overhead in memory usage. The amount varies based on the number of transfers in a job. Buffers are the largest component of memory usage. You can help control overhead by usingAZCOPY_BUFFER_GBto approximately meet your requirements, but there is no flag available to strictly cap the overall memory usage.
AZCOPY_BUFFER_GB
Optimize file synchronization
Thesynccommand identifies all files at the destination, and then compares file names and last modified timestamps before the starting the sync operation. If you have a large number of files, then you can improve performance by eliminating this up-front processing.
To accomplish this, use theazcopy copycommand instead, and set the--overwriteflag toifSourceNewer. AzCopy will compare files as they are copied without performing any up-front scans and comparisons. This provides a performance edge in cases where there are a large number of files to compare.
--overwrite
ifSourceNewer
Theazcopy copycommand doesn't delete files from the destination, so if you want to delete files at the destination when they no longer exist at the source, then use theazcopy synccommand with the--delete-destinationflag set to a value oftrueorprompt.
--delete-destination
true
prompt
Use multiple clients to run jobs in parallel
AzCopy performs best when only one instance runs on the client. If you want to transfer files in parallel, then use multiple clients and run only one instance of AzCopy on each one.
See also
Get started with AzCopy
Feedback
Was this page helpful?
Additional resources