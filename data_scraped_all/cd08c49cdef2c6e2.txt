Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Copy jobs in Azure Cosmos DB (preview)
Article
2024-10-25
2 contributors
In this article
You can perform data copy in Azure Cosmos DB by using container copy jobs.
You might need to copy data from your Azure Cosmos DB account if you want to achieve any of these scenarios:
Copy all items from one container to another.
Change thegranularity at which throughput is provisioned, from database to containerand vice versa.
Change thepartition keyof a container.
Update theunique keysfor a container.
Rename a container or database.
Change capacity mode of an account from serverless to provisioned or vice-versa.
Adopt new features that are supported only for new containers, e.g.Hierarchical partition keys.
Copy jobs can becreated and managed by using Azure CLI commands.
Get started
Online copy
Offline copy
To get started with online container copy for Azure Cosmos DB for NoSQL API accounts, register for theOnline container copy (NoSQL)preview feature flag inPreview Featuresin the Azure portal. Once the registration is complete, the preview is effective for all NoSQL API accounts in the subscription.
Enablecontinuous backupon source Azure Cosmos DB account.
Register forAll version and delete change feed modepreview feature on the source accountâs subscription.
Important
All write operations to the source container will be charged 10% additional RUs in order to preserve both the previous and current versions of changes to items in the container. This RU charge increase is subject to change in the future.
Copy a container's data
Create the target Azure Cosmos DB container by using the settings that you want to use (partition key, throughput granularity, request units, unique key, and so on).
Create the container copy job.
Monitor the progress of the copy job.
Once all documents have been copied, stop the updates on source container and then call the completion API to mark job as completed.
Resume the operations by appropriately pointing the application or client to the source or target container as intended.
How does container copy work?
The platform allocates server-side compute instances for the destination Azure Cosmos DB account to run the container copy jobs.
A single job is executed across all instances at any time.
The online copy jobs utilizeall version and delete change feed modeto copy the data and replicate incremental changes from the source container to the destination container.
Once the job is completed, the platform de-allocates these instances after 15 minutes of inactivity.
Start using offline copy by followinghow to create, monitor, and manage copy jobs.
Copy a container's data
Create the target Azure Cosmos DB container by using the settings that you want to use (partition key, throughput granularity, request units, unique key, and so on).
Stop the operations on the source container by pausing the application instances or any clients that connect to it.
Create the container copy job.
Monitor the progress of the container copy joband wait until it's completed.
Resume the operations by appropriately pointing the application or client to the source or target container as intended.
Note
We strongly recommend that you stop performing any operations on the source container before you begin the offline container copy job. Item deletions and updates that are done on the source container after you start the copy job might not be captured. If you continue to perform operations on the source container while the container job is in progress, you might have duplicate or missing data on the target container.
How does container copy work?
The platform allocates server-side compute instances for the destination Azure Cosmos DB account.
These instances are allocated when one or more container copy jobs are created within the account.
The container copy jobs run on these instances.
A single job is executed across all instances at any time.
The instances are shared by all the container copy jobs that are running within the same account.
The offline copy jobs utilizeLatest version change feed modeto copy the data and replicate incremental changes from the source container to the destination container.
The platform might de-allocate the instances if they're idle for longer than 15 minutes.
You can perform offline collection copy jobs to copy data within the same Azure Cosmos DB for Mongo DB account.
Copy a collection's data
Create the target Azure Cosmos DB collection by using the settings that you want to use (partition key, throughput granularity, request units, unique key, and so on).
Stop the operations on the source collection by pausing the application instances or any clients that connect to it.
Create the copy job.
Monitor the progress of the copy joband wait until it's completed.
Resume the operations by appropriately pointing the application or client to the source or target collection as intended.
Note
We strongly recommend that you stop performing any operations on the source collection before you begin the offline collection copy job. Item deletions and updates that are done on the source collection after you start the copy job might not be captured. If you continue to perform operations on the source collection while the copy job is in progress, you might have duplicate or missing data on the target collection.
How does collection copy work?
The platform allocates server-side compute instances for the destination Azure Cosmos DB account.
These instances are allocated when one or more collection copy jobs are created within the account.
The copy jobs run on these instances.
A single job is executed across all instances at any time.
The instances are shared by all the copy jobs that are running within the same account.
The offline copy jobs utilizeChange streamsto copy the data and replicate incremental changes from the source collection to the destination collection.
The platform might de-allocate the instances if they're idle for longer than 15 minutes.
You can perform offline table copy to copy data of one table to another table within the same Azure Cosmos DB for Apache Cassandra account.
Copy a table's data
Create the target Azure Cosmos DB table by using the settings that you want to use (partition key, throughput granularity, request units and so on).
Stop the operations on the source table by pausing the application instances or any clients that connect to it.
Create the copy job.
Monitor the progress of the copy joband wait until it's completed.
Resume the operations by appropriately pointing the application or client to the source or target table as intended.
Note
We strongly recommend that you stop performing any operations on the source table before you begin the offline table copy job. Item deletions and updates that are done on the source table after you start the copy job might not be captured. If you continue to perform operations on the source table while the copy job is in progress, you might have duplicate or missing data on the target table.
How does table copy work?
The platform allocates server-side compute instances for the destination Azure Cosmos DB account.
These instances are allocated when one or more copy jobs are created within the account.
The copy jobs run on these instances.
A single job is executed across all instances at any time.
The instances are shared by all the copy jobs that are running within the same account.
The offline copy jobs utilizeChange feedto copy the data and replicate incremental changes from the source table to the destination table.
The platform might de-allocate the instances if they're idle for longer than 15 minutes.
Factors that affect the rate of a copy job
The rate of container copy job progress is determined by these factors:
The source container or database throughput setting.
The source container or database throughput setting.
The target container or database throughput setting.TipSet the target container throughput to at least two times the source container's throughput.
The target container or database throughput setting.
Tip
Set the target container throughput to at least two times the source container's throughput.
Server-side compute instances that are allocated to the Azure Cosmos DB account for performing the data transfer.ImportantThe default SKU offers two 4-vCPU 16-GB server-side instances per account.
Server-side compute instances that are allocated to the Azure Cosmos DB account for performing the data transfer.
Important
The default SKU offers two 4-vCPU 16-GB server-side instances per account.
Limitations
Preview eligibility criteria
Container copy jobs don't work with accounts that have the following capabilities enabled. Disable these features before you run container copy jobs:
Merge partition
Disable local auth
Account configurations
The Time to Live (TTL) setting isn't adjusted in the destination container. As a result, if a document hasn't expired in the source container, it starts its countdown anew in the destination container.
FAQs
Is there a service-level agreement for container copy jobs?
Container copy jobs are currently supported on a best-effort basis. We don't provide any service-level agreement (SLA) guarantees for the time it takes for the jobs to finish.
Can I create multiple container copy jobs within an account?
Yes, you can create multiple jobs within the same account. The jobs run consecutively. You canlist all the jobsthat are created within an account, and monitor their progress.
Can I copy an entire database within the Azure Cosmos DB account?
You must create a job for each container in the database.
I have an Azure Cosmos DB account with multiple regions. In which region will the container copy job run?
The container copy job runs in the write region. In an account that's configured with multi-region writes, the job runs in one of the regions in the list of write regions.
What happens to the container copy jobs when the account's write region changes?
The account's write region might change in the rare scenario of a region outage or due to manual failover. In this scenario, incomplete container copy jobs that were created within the account fail. You would need to re-create these failed jobs. Re-created jobs then run in the new (current) write region.
Supported regions
Currently, container copy is supported in the following regions:
Known and common issues
Error - Owner resource doesn't exist.If the job creation fails and displays the errorOwner resource doesn't exist(error code 404), either the target container hasn't been created yet or the container name that's used to create the job doesn't match an actual container name.Make sure that the target container is created before you run the job and ensure that the container name in the job matches an actual container name."code": "404",
"message": "Response status code does not indicate success: NotFound (404); Substatus: 1003; ActivityId: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx; Reason: (Message: {\"Errors\":[\"Owner resource does not exist\"]
Error - Owner resource doesn't exist.
If the job creation fails and displays the errorOwner resource doesn't exist(error code 404), either the target container hasn't been created yet or the container name that's used to create the job doesn't match an actual container name.
Make sure that the target container is created before you run the job and ensure that the container name in the job matches an actual container name.
"code": "404",
"message": "Response status code does not indicate success: NotFound (404); Substatus: 1003; ActivityId: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx; Reason: (Message: {\"Errors\":[\"Owner resource does not exist\"]
"code": "404",
"message": "Response status code does not indicate success: NotFound (404); Substatus: 1003; ActivityId: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx; Reason: (Message: {\"Errors\":[\"Owner resource does not exist\"]
Error - Request is unauthorized.If the request fails and displays the errorUnauthorized(error code 401), local authorization might be disabled.Container copy jobs use primary keys to authenticate. If local authorization is disabled, the job creation fails. Local authorization must be enabled for container copy jobs to work."code": "401",
"message": " Response status code does not indicate success: Unauthorized (401); Substatus: 5202; ActivityId: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx; Reason: Local Authorization is disabled. Use an AAD token to authorize all requests."
Error - Request is unauthorized.
If the request fails and displays the errorUnauthorized(error code 401), local authorization might be disabled.
Container copy jobs use primary keys to authenticate. If local authorization is disabled, the job creation fails. Local authorization must be enabled for container copy jobs to work.
"code": "401",
"message": " Response status code does not indicate success: Unauthorized (401); Substatus: 5202; ActivityId: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx; Reason: Local Authorization is disabled. Use an AAD token to authorize all requests."
"code": "401",
"message": " Response status code does not indicate success: Unauthorized (401); Substatus: 5202; ActivityId: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx; Reason: Local Authorization is disabled. Use an AAD token to authorize all requests."
Error - Error while getting resources for job.This error might occur due to internal server issues. To resolve this issue, contact Microsoft Support by opening aNew Support Requestin the Azure portal. ForProblem Type, selectData Migration. ForProblem subtype, selectIntra-account container copy."code": "500"
"message": "Error while getting resources for job, StatusCode: 500, SubStatusCode: 0, OperationId:  xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx, ActivityId: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
Error - Error while getting resources for job.
This error might occur due to internal server issues. To resolve this issue, contact Microsoft Support by opening aNew Support Requestin the Azure portal. ForProblem Type, selectData Migration. ForProblem subtype, selectIntra-account container copy.
"code": "500"
"message": "Error while getting resources for job, StatusCode: 500, SubStatusCode: 0, OperationId:  xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx, ActivityId: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
"code": "500"
"message": "Error while getting resources for job, StatusCode: 500, SubStatusCode: 0, OperationId:  xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx, ActivityId: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
Next steps
Learnhow to create, monitor, and manage container copy jobsin Azure Cosmos DB account by using CLI commands.
Feedback
Was this page helpful?
Additional resources