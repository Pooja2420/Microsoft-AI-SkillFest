Note
Access to this page requires authorization. You can trysigning inorchanging directories.
Access to this page requires authorization. You can trychanging directories.
Azure Data Factory and Azure Synapse Analytics connector overview
Article
2024-11-06
10 contributors
In this article
APPLIES TO:Azure Data FactoryAzure Synapse Analytics
Tip
Try outData Factory in Microsoft Fabric, an all-in-one analytics solution for enterprises.Microsoft Fabriccovers everything from data movement to data science, real-time analytics, business intelligence, and reporting. Learn how tostart a new trialfor free!
Azure Data Factory and Azure Synapse Analytics pipelines support the following data stores and formats via Copy, Data Flow, Look up, Get Metadata, and Delete activities. Click each data store to learn the supported capabilities and the corresponding configurations in details.
Supported data stores
Note
Connectors markedPrevieware available to try, but are not recommended for production workloads. Certain features might not be supported or might have constrained capabilities.
Integrate with more data stores
Azure Data Factory and Synapse pipelines can reach broader set of data stores than the list mentioned above. If you need to move data to/from a data store that is not in the service built-in connector list, here are some extensible options:
For database and data warehouse, usually you can find a corresponding ODBC driver, with which you can usegeneric ODBC connector.
For SaaS applications:If it provides RESTful APIs, you can usegeneric REST connector.If it has OData feed, you can usegeneric OData connector.If it provides SOAP APIs, you can usegeneric HTTP connector.If it has ODBC driver, you can usegeneric ODBC connector.
If it provides RESTful APIs, you can usegeneric REST connector.
If it has OData feed, you can usegeneric OData connector.
If it provides SOAP APIs, you can usegeneric HTTP connector.
If it has ODBC driver, you can usegeneric ODBC connector.
For others, check if you can load data to or expose data as any supported data stores, e.g. Azure Blob/File/FTP/SFTP/etc, then let the service pick up from there. You can invoke custom data loading mechanism viaAzure Function,Custom activity,Databricks/HDInsight,Web activity, etc.
Supported file formats
The following file formats are supported. Refer to each article for format-based settings.
Avro format
Binary format
Common Data Model format
Delimited text format
Delta format
Excel format
Iceberg format
JSON format
ORC format
Parquet format
XML format
Related content
Copy activity
Mapping Data Flow
Lookup Activity
Get Metadata Activity
Delete Activity
Feedback
Was this page helpful?
Additional resources